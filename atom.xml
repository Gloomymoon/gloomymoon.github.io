<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Gloomymoon</title>
  <icon>https://www.gravatar.com/avatar/c7a1f93ddd2dfb93fb0200fd5218663d</icon>
  <subtitle>Try not. Do or do not. There is no try.</subtitle>
  <link href="http://gloomymoon.github.io/atom.xml" rel="self"/>
  
  <link href="http://gloomymoon.github.io/"/>
  <updated>2025-09-22T13:53:37.000Z</updated>
  <id>http://gloomymoon.github.io/</id>
  
  <author>
    <name>Gloomymoon</name>
    <email>Gloomymoon@gmail.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Changchun Air Show 2025</title>
    <link href="http://gloomymoon.github.io/2025/09/21/Changchun-Air-Show-2025/"/>
    <id>http://gloomymoon.github.io/2025/09/21/Changchun-Air-Show-2025/</id>
    <published>2025-09-21T11:15:22.000Z</published>
    <updated>2025-09-22T13:53:37.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Changchun-Air-Show-2025-9-20"><a href="#Changchun-Air-Show-2025-9-20" class="headerlink" title="Changchun Air Show 2025/9/20"></a>Changchun Air Show 2025/9/20</h1><p>@吉林省长春市大房身机场</p><h2 id="0-导览"><a href="#0-导览" class="headerlink" title="0 导览"></a>0 导览</h2><h2 id="1-飞行表演"><a href="#1-飞行表演" class="headerlink" title="1 飞行表演"></a>1 飞行表演</h2><p>党旗、国旗、军旗、空军旗<br><img src="/img/ChangchunAirShow2025/101.JPG" alt=""></p><p>听党指挥、能打胜仗、作风优良<br><img src="/img/ChangchunAirShow2025/102.JPG" alt=""></p><p>运油20+歼16<br><img src="/img/ChangchunAirShow2025/111.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/112.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/117.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/118.JPG" alt=""></p><p>轰6<br><img src="/img/ChangchunAirShow2025/113.JPG" alt=""></p><p>空警500+歼20<br><img src="/img/ChangchunAirShow2025/114.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/115.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/116.JPG" alt=""></p><p>八一飞行表演队的歼10<br><img src="/img/ChangchunAirShow2025/121.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/122.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/123.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/124.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/125.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/126.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/127.JPG" alt=""></p><p>红鹰飞行表演队的教8<br><img src="/img/ChangchunAirShow2025/131.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/132.JPG" alt=""></p><h2 id="10-静态展示B区"><a href="#10-静态展示B区" class="headerlink" title="10 静态展示B区"></a>10 静态展示B区</h2><p>无人机<br><img src="/img/ChangchunAirShow2025/201.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/202.JPG" alt=""></p><p>教练机<br><img src="/img/ChangchunAirShow2025/203.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/204.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/205.JPG" alt=""></p><p>歼击机&amp;强击机<br><img src="/img/ChangchunAirShow2025/211.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/212.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/213.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/214.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/215.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/216.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/217.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/218.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/219.JPG" alt=""></p><p>轰炸机&amp;运输机<br><img src="/img/ChangchunAirShow2025/221.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/222.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/223.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/224.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/225.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/226.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/227.JPG" alt=""></p><p>该区还有枭龙</p><h2 id="11-静态展示A区"><a href="#11-静态展示A区" class="headerlink" title="11 静态展示A区"></a>11 静态展示A区</h2><p>族谱单开一页的歼10C，和霹雳15E<br><img src="/img/ChangchunAirShow2025/301.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/302.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/303.JPG" alt=""></p><p>多款无人机<br><img src="/img/ChangchunAirShow2025/304.JPG" alt=""></p><p>天之翼飞行表演队的初教6<br><img src="/img/ChangchunAirShow2025/305.JPG" alt=""></p><p>红鹰飞行表演队的教8<br><img src="/img/ChangchunAirShow2025/306.JPG" alt=""></p><p>歼教7A<br><img src="/img/ChangchunAirShow2025/307.JPG" alt=""></p><p>歼11B<br><img src="/img/ChangchunAirShow2025/308.JPG" alt=""></p><p>直9WA<br><img src="/img/ChangchunAirShow2025/309.JPG" alt=""></p><p>直8KA<br><img src="/img/ChangchunAirShow2025/310.JPG" alt=""></p><p>歼20<br><img src="/img/ChangchunAirShow2025/311.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/312.JPG" alt=""></p><p>空警500<br><img src="/img/ChangchunAirShow2025/321.JPG" alt=""></p><p>运20<br><img src="/img/ChangchunAirShow2025/322.JPG" alt=""><br><img src="/img/ChangchunAirShow2025/323.JPG" alt=""></p><h2 id="100-室内展览"><a href="#100-室内展览" class="headerlink" title="100 室内展览"></a>100 室内展览</h2><h2 id="101-地面装备"><a href="#101-地面装备" class="headerlink" title="101 地面装备"></a>101 地面装备</h2><h2 id="110-小结"><a href="#110-小结" class="headerlink" title="110 小结"></a>110 小结</h2><p><strong>一天根本看不完！</strong><br><strong>一天根本看不完！</strong><br><strong>一天根本看不完！</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Changchun-Air-Show-2025-9-20&quot;&gt;&lt;a href=&quot;#Changchun-Air-Show-2025-9-20&quot; class=&quot;headerlink&quot; title=&quot;Changchun Air Show 2025/9/20&quot;&gt;&lt;/a&gt;Ch</summary>
      
    
    
    
    
    <category term="FLAAF" scheme="http://gloomymoon.github.io/tags/FLAAF/"/>
    
    <category term="Air Show" scheme="http://gloomymoon.github.io/tags/Air-Show/"/>
    
  </entry>
  
  <entry>
    <title>A Thought on Industrial Revolution and AI</title>
    <link href="http://gloomymoon.github.io/2025/03/12/A-Thought-on-Industrial-Revolution-and-AI/"/>
    <id>http://gloomymoon.github.io/2025/03/12/A-Thought-on-Industrial-Revolution-and-AI/</id>
    <published>2025-03-12T01:57:39.000Z</published>
    <updated>2025-07-10T02:00:07.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="A-Thought-on-Industrial-Revolution-and-AI"><a href="#A-Thought-on-Industrial-Revolution-and-AI" class="headerlink" title="A Thought on Industrial Revolution and AI"></a>A Thought on Industrial Revolution and AI</h2><p>生产力（Productivity）指单位时间内，通过有效整合生产要素（如劳动力、资本、技术等）创造出的产品或服务价值的能力。其核心是资源转化效率，即如何以最小投入获取最大产出。生产力代表人类改造自然、创造物质与精神财富的能力，反映社会与自然之间的互动关系。其提升标志着文明对资源利用、知识应用和组织协作的优化水平。</p><p>工业化是生产力发展的核心驱动力之一，两者之间存在双向强化关系：工业化通过技术、组织与资源整合推动生产力跃升，而生产力提升又为工业化深化提供物质基础和持续动力。300多年以来，工业化不仅是技术工具升级的过程，更是社会生产组织形态重构与资源利用效率的升级。其核心价值在于将分散的要素（劳动力、资本、技术）整合为系统化生产力量，并通过持续创新突破效率边界，让人类文明出现指数级的提升，重构的生产关系甚至影响了人类文明的形态。</p><blockquote><p>卡尔达舍夫等级（Kardashev Scale）是一种用来衡量一个文明的技术的先进等级的方法。 苏联天文学家尼古拉·卡尔达舍夫（Николай Кардашёв）在1964年提出了这个概念，他用能量级将文明分为3个等级：I型、Ⅱ型和Ⅲ型，这些文明分别可以利用一颗行星，一颗恒星和一个星系的能量<sup><span id="a1"><a href="#fn1">[1]</a></span></sup>。</p><ul><li>I型文明是行星级文明。这种文明可以充分利用宿主恒星（对人类而言，是太阳）传递到其母星（地球）上的能量，也能充分利用这颗行星自身包含的能量（化石能源、核能等），对应的能耗为10¹⁶W。</li><li>Ⅱ型文明是恒星级文明。恒星主要通过发光的方式向外传递能量，太阳向外辐射能量的总功率为4×10²⁶W，Ⅱ型文明对应的能耗指标就为10²⁶W。</li><li>Ⅲ型文明是星系级文明。银河系的总亮度为4×10³⁷W，考虑到整个星系实在太过庞大，只要整个文明的能耗达到银河系总亮度的2.5%，也就是10³⁶W。</li></ul><p><img src="/img/AThoughtOnIndustrialRevolutionAndAI_01.webp" alt=""></p><p>卡尔达舍夫等级并不是离散、分立的，它其实可以通过一个对数公式表示。如果一个文明的全部能源消耗为P，那么这个文明对应的卡尔达舍夫等级K可以表示为:</p><p><img src="/img/AThoughtOnIndustrialRevolutionAndAI_02.webp" alt=""></p><p>根据国际能源署的数据，2018年全球能源消费为14 281 889千吨油当量（能量单位，kTOE，kilo ton oil equivalent），大约为1.90×10¹³W。再由上述公式计算可得，地球上的人类文明目前属于0.728级文明。</p><p>人类能源消费大约是按照指数增长的——每年增长的能源消费制造了更多机器，能让我们在下一年消耗更多能源。如果仅仅按照以往的增长率简单粗暴地进行拟合，就能发现我们大约能在2347年左右成为I型文明，在几千年后成为Ⅱ型文明，在几十万年后成为Ⅲ型文明。</p></blockquote><h3 id="第一次工业革命（约1760年-1840年）"><a href="#第一次工业革命（约1760年-1840年）" class="headerlink" title="第一次工业革命（约1760年-1840年）"></a>第一次工业革命（约1760年-1840年）</h3><p>第一次工业革命不仅重塑了生产方式，更彻底改变了人类社会的组织形态，标志着农业文明向工业文明的跨越，其影响至今仍在延续。</p><h4 id="时间范围"><a href="#时间范围" class="headerlink" title="时间范围"></a>时间范围</h4><p>18世纪60年代至19世纪40年代，起源于英国，后逐步扩散至欧洲及北美。</p><h4 id="发展历程"><a href="#发展历程" class="headerlink" title="发展历程"></a>发展历程</h4><p><strong>纺织业机械化</strong>（1760s-1780s）</p><ul><li>1764年哈格里夫斯发明珍妮纺纱机（可同时纺8根纱），开启机械化生产。</li><li>1771年阿克赖特建立水力纺纱厂，首次实现工厂化生产。</li><li>1785年卡特莱特发明动力织布机，纺织效率提升40倍。</li></ul><p><strong>蒸汽动力革命</strong>（1770s-1800s）</p><ul><li>1776年瓦特改良高效蒸汽机（热效率从0.5%提升至3%），取代水力与畜力。</li><li>1804年特里维西克制造首台实用蒸汽机车，推动矿山与运输业变革。</li></ul><p><strong>交通与能源网络形成</strong>（1800s-1840s）</p><ul><li>1825年斯托克顿-达灵顿铁路通车，开启铁路运输时代。</li><li>运河与公路系统完善，煤炭产量从1770年的620万吨增至1830年的3000万吨。</li></ul><h4 id="主要变革点"><a href="#主要变革点" class="headerlink" title="主要变革点"></a>主要变革点</h4><p><strong>技术突破</strong></p><ul><li>动力革命：蒸汽机取代人力和水力，成为核心动力来源。</li><li>机械化生产：纺织、冶金等行业实现机器替代手工劳动。</li><li>材料革新：焦炭炼铁技术普及，推动钢铁产量和质量飞跃。</li></ul><p><strong>生产模式转型</strong></p><ul><li>工厂制度取代家庭作坊，工人集中化生产，分工细化。</li><li>标准化零件（如机床制造）初现，为大规模生产奠基。</li></ul><p><strong>能源与交通</strong></p><ul><li>煤炭成为主导能源，英国煤炭消费占比达全球80%。</li><li>铁路与蒸汽船大幅降低运输成本，加速商品流通。</li></ul><h4 id="后续影响"><a href="#后续影响" class="headerlink" title="后续影响"></a>后续影响</h4><p><strong>经济与社会结构剧变</strong></p><ul><li>城市化：英国城市人口占比从1750年的17%增至1851年的54%（如曼彻斯特人口增长8倍）。</li><li>阶级分化：工业资产阶级与无产阶级对立加剧，工人运动萌芽。</li></ul><p><strong>全球格局重塑</strong></p><ul><li>英国成为“世界工厂”，19世纪中叶工业产值占全球40%。</li><li>殖民扩张加速，原材料掠夺与商品倾销推动全球化雏形。</li></ul><p><strong>环境与资源压力</strong></p><ul><li>煤炭大规模使用导致空气污染，伦敦“雾都”现象初现。</li><li>自然资源过度开发，生态破坏问题开始显现。</li></ul><p><strong>技术扩散与后续革命铺垫</strong></p><ul><li>蒸汽技术为第二次工业革命（电气化）奠定能源基础。</li><li>工厂制度与资本积累模式成为现代工业社会的原型。</li></ul><h4 id="关键数据"><a href="#关键数据" class="headerlink" title="关键数据"></a>关键数据</h4><ul><li>英国棉纺织品出口额从1780年的£35万激增至1850年的<strong>£2800万</strong>。</li><li>蒸汽机功率从1800年的约10万马力增至1840年的160万马力。</li><li>铁路里程在1830-1850年间从不足100公里增至2.4万公里。</li></ul><h3 id="第二次工业革命（约1870年-1914年）"><a href="#第二次工业革命（约1870年-1914年）" class="headerlink" title="第二次工业革命（约1870年-1914年）"></a>第二次工业革命（约1870年-1914年）</h3><h4 id="时间范围-1"><a href="#时间范围-1" class="headerlink" title="时间范围"></a>时间范围</h4><p>19世纪70年代至20世纪初（第一次世界大战前），以欧美为中心，德、美两国成为技术创新的引领者。</p><h4 id="发展历程-1"><a href="#发展历程-1" class="headerlink" title="发展历程"></a>发展历程</h4><p><strong>电气化革命</strong>（1870s-1890s）</p><ul><li>1866年西门子发明自励式发电机，实现稳定电力供应。</li><li>1882年爱迪生在纽约建成珍珠街发电站，开启商业供电时代。</li><li>1888年特斯拉发明交流输电系统，解决电力远程传输难题。</li></ul><p><strong>内燃机与石油工业崛起</strong>（1880s-1900s）</p><ul><li>1883年戴姆勒研制出汽油内燃机，热效率达20%。</li><li>1908年福特推出T型车，装配线使单车生产时间从12小时缩至93分钟。</li><li>全球石油产量从1870年的80万吨激增至1914年的5000万吨。</li></ul><p><strong>材料与化学工业突破</strong>（1860s-1910s）</p><ul><li>1869年海厄特发明赛璐珞（首个合成塑料），开启高分子材料时代。</li><li>1913年哈伯-博世法实现合成氨工业化，推动化肥与炸药生产。</li><li>德国拜耳公司研发合成染料（如靛蓝），取代天然染料。</li></ul><h4 id="主要变革点-1"><a href="#主要变革点-1" class="headerlink" title="主要变革点"></a>主要变革点</h4><p><strong>技术革命</strong></p><ul><li>电力系统：工厂动力从蒸汽机转向电动机，设备布局自由度提升。</li><li>内燃机：催生汽车、飞机（1903年莱特兄弟首飞）等新交通工具。</li><li>通信技术：1876年贝尔发明电话，1895年马可尼实现无线电通信。</li></ul><p><strong>生产模式升级</strong></p><ul><li>流水线生产：福特工厂通过标准化零件与分工协作，产能提升10倍。</li><li>科学管理：泰勒制（1911年）量化分析工人动作，提升效率30%-50%。</li></ul><p><strong>能源结构转型</strong></p><ul><li>电力成为二次能源核心，美国发电量从1902年的60亿度增至1912年的250亿度。</li><li>石油消费占比从1870年的0.2%升至1914年的4.5%，开启化石能源新时代。</li></ul><h4 id="后续影响-1"><a href="#后续影响-1" class="headerlink" title="后续影响"></a>后续影响</h4><p><strong>经济垄断与全球化深化</strong></p><ul><li>洛克菲勒标准石油公司控制美国90%炼油产能，垄断资本主义形成。</li><li>全球贸易额从1870年的460亿美元增至1913年的4000亿美元。</li></ul><p><strong>社会结构剧变</strong></p><ul><li>城市化加速：美国城市人口占比从1870年的25%升至1920年的51%。</li><li>白领阶层兴起：企业管理、技术岗位需求激增，中产阶级扩大。</li></ul><p><strong>军事与地缘政治变革</strong></p><ul><li>内燃机推动坦克、潜艇等新式武器发展，改变战争形态。</li><li>列强争夺石油资源，中东地区战略地位凸显。</li></ul><p><strong>环境与劳工问题</strong></p><ul><li>石油泄漏、化学污染（如伦敦1905年酸雨事件）开始显现。</li><li>流水线催生高强度劳动，1911年美国工厂事故致死2.5万人。</li></ul><p><strong>技术延续性影响</strong></p><ul><li>电气化奠定现代工业基础，全球电力覆盖率至今达90%。</li><li>石化工业成为20世纪支柱产业，塑料产量2020年超3.67亿吨。</li></ul><h4 id="关键数据-1"><a href="#关键数据-1" class="headerlink" title="关键数据"></a>关键数据</h4><ul><li>美国汽车产量从1900年的4000辆暴增至1916年的150万辆。</li><li>德国化学工业产值在1870-1913年间增长23倍，占全球70%市场份额。</li><li>全球铁路里程从1870年的20万公里扩展至1916年的110万公里。</li></ul><p>第二次工业革命通过科学、技术与资本的深度结合，将人类带入“电气与石油文明”时代，重塑了现代社会的物质基础与权力格局，其技术遗产至今仍在深刻影响全球发展轨迹。</p><h3 id="第三次工业革命（1960-2000）"><a href="#第三次工业革命（1960-2000）" class="headerlink" title="第三次工业革命（1960-2000）"></a>第三次工业革命（1960-2000）</h3><h4 id="时间范围-2"><a href="#时间范围-2" class="headerlink" title="时间范围"></a>时间范围</h4><p>20世纪40年代中期至20世纪末，以信息技术、自动化技术、新能源为核心，美国、日本、德国为主要引领者。<br>发展历程</p><p><strong>自动化与计算机技术兴起</strong>（1940s-1970s）</p><ul><li>1946年第一台通用电子计算机ENIAC诞生，运算速度比人工快10万倍。</li><li>1952年数控机床问世，实现精密零件自动化加工。</li><li>1961年通用汽车引入首台工业机器人Unimate，汽车焊接效率提升300%。</li></ul><p><strong>信息技术革命</strong>（1970s-1990s）</p><ul><li>1971年英特尔推出微处理器4004，开启计算机小型化时代。</li><li>1983年<strong>互联网协议（TCP/IP）</strong>标准化，全球网络互联加速。</li><li>1990年代ERP（企业资源计划）系统普及，实现生产流程数字化管理。</li></ul><p><strong>新能源与材料突破</strong>（1950s-2000）</p><ul><li>1954年苏联建成首座商用核电站，核能发电占比在法国达75%（2000年）。</li><li>1970年代燃气轮机联合循环技术成熟，发电效率突破60%。</li><li>1980年代太阳能电池成本下降80%，光伏发电进入实用阶段。</li></ul><h4 id="主要变革点-2"><a href="#主要变革点-2" class="headerlink" title="主要变革点"></a>主要变革点</h4><p><strong>技术突破</strong></p><ul><li>数字化控制：PLC（可编程逻辑控制器）替代机械继电器，设备响应精度提升10倍。</li><li>信息网络：全球数据实时传输（1990年全球互联网用户仅280万，2000年达3.61亿）。</li><li>新材料：碳纤维（1960年代）、半导体材料（硅晶圆）推动高端制造业升级。</li></ul><p><strong>生产模式转型</strong></p><ul><li>精益生产：日本丰田首创“准时制（JIT）”模式，库存成本降低50%。</li><li>全球化分工：跨国企业通过IT系统管理全球供应链（如耐克1980年代外包生产）。</li><li>柔性制造系统（FMS）：一条生产线可快速切换生产不同产品，适应小批量定制需求。</li></ul><p><strong>能源结构优化</strong></p><ul><li>核能成为清洁基荷电源，2000年全球核电发电量占比16%。</li><li>能源管理系统（EMS）应用，工业能耗降低20%-30%。</li></ul><h4 id="后续影响-2"><a href="#后续影响-2" class="headerlink" title="后续影响"></a>后续影响</h4><p><strong>经济与社会变革</strong></p><ul><li>知识经济崛起：全球研发投入占GDP比重从1960年1.4%升至2000年2.1%，微软、英特尔等科技巨头主导新经济。</li><li>就业结构转变：美国制造业就业占比从1950年30%降至2000年13%，服务业占比突破70%。<br><strong>全球化加速</strong></li><li>全球贸易网络：集装箱运输（1956年标准化）使海运成本下降90%，2000年全球贸易额达6.45万亿美元（较1970年增长15倍）。</li><li>产业转移：亚洲“四小龙”承接制造业转移，韩国半导体产值1990年代占全球15%。</li></ul><p><strong>环境与资源挑战</strong></p><ul><li>核废料处理、电子垃圾（2000年全球年产2000万吨）成为新污染源。</li><li>化石能源依赖度仍达85%（2000年），温室气体排放量较工业革命前增长30%。</li></ul><p><strong>技术延续性影响</strong></p><ul><li>信息技术为第四次工业革命（物联网、AI）奠定基础，2000年全球数据生成量达2 EB（2020年为59 ZB）。</li><li>自动化推动“无人工厂”概念，日本FANUC工厂实现720小时无人值守生产。</li></ul><h4 id="关键数据-2"><a href="#关键数据-2" class="headerlink" title="关键数据"></a>关键数据</h4><ul><li>全球半导体市场规模从1976年50亿美元增至2000年2000亿美元。</li><li>计算机性能遵循摩尔定律，每18个月晶体管数量翻倍，1971-2000年CPU算力增长100万倍。</li><li>工业机器人保有量从1970年3000台增至2000年80万台，汽车行业自动化率超90%。</li></ul><p>第三次工业革命通过数字化、自动化与全球化重塑了现代经济体系，将人类社会推向信息文明时代，同时埋下环境与资源矛盾的伏笔，为21世纪的智能革命铺平道路。</p><h3 id="第四次工业革命（2011-）"><a href="#第四次工业革命（2011-）" class="headerlink" title="第四次工业革命（2011- ）"></a>第四次工业革命（2011- ）</h3><h4 id="开始时间"><a href="#开始时间" class="headerlink" title="开始时间"></a>开始时间</h4><p>第四次工业革命目前没有明确的定义和标志性的科技突破或成果，普遍被认为始于21世纪初，有部分研究将其开始的标志性事件定义为德国提出“工业4.0”战略（2011年）或人工智能技术（如深度学习）的突破性进展。一般认为第四次工业革命是以数字化、智能化、生物技术与物理技术的深度融合为核心特征的全球性技术变革。其本质在于通过人工智能（AI）、物联网（IoT）、大数据、量子计算、清洁能源、生物工程等技术的协同发展，实现生产系统、社会结构和人类生活方式的全面重塑。这一阶段强调物理世界、数字世界与生物世界的融合，形成网络物理系统（CPS），推动经济模式从传统工业化向智能化和可持续发展转型。当前仍处于快速发展阶段，预计将持续至22世纪中叶。</p><h4 id="当前主要发展进度"><a href="#当前主要发展进度" class="headerlink" title="当前主要发展进度"></a>当前主要发展进度</h4><p><strong>智能制造与工业互联网</strong></p><ul><li>全球范围内，工业互联网与数字孪生技术已广泛应用，例如中国拥有全球最多的“灯塔工厂”（72家，占全球42%），实现生产效率提升8倍、能耗降低25%49。</li><li>5G、边缘计算等技术支撑的智能工厂逐步普及，设备联网率超过80%。</li></ul><p><strong>人工智能与大模型</strong></p><ul><li>生成式AI（如ChatGPT）和多模态AI模型推动内容创造、医疗诊断、工业优化等领域的革新。全球算力需求呈指数级增长，2020年数据生成量达59 ZB（2010年仅2 EB）。</li></ul><p><strong>清洁能源与绿色技术</strong></p><ul><li>光伏发电成本较2010年下降89%，氢能电解效率突破80%，固态电池能量密度达500Wh/kg，推动能源结构向低碳化转型。</li></ul><p><strong>生物技术与数字医疗</strong></p><ul><li>脑机接口、基因编辑（如CRISPR）与AI辅助新药研发加速，例如AI模型已能生成蛋白质分子结构。</li></ul><h4 id="突出的变革点"><a href="#突出的变革点" class="headerlink" title="突出的变革点"></a>突出的变革点</h4><p><strong>生产模式</strong></p><ul><li>柔性制造与个性化定制：通过3D打印和智能供应链，复杂部件生产时间从数月缩短至数小时，满足小批量定制需求。</li><li>无人化与自动化：自动驾驶、无人零售和智能物流系统逐步普及，例如无人驾驶汽车有望彻底改变城市交通拥堵问题。</li></ul><p><strong>社会协作与治理</strong></p><ul><li>模块化与开放式创新：技术架构的模块化（如开源软件、工业互联网平台）推动全球产业链重组，加速跨界融合创新。</li><li>数据驱动决策：企业通过大数据分析优化供应链管理，预测性维护减少设备停机时间50%。</li></ul><p><strong>能源与可持续发展</strong></p><ul><li>能源互联网：智能电网整合风能、太阳能等波动性可再生能源，德国2022年风光发电占比达46%。</li><li>循环经济：数字化追踪与AI优化资源利用，减少工业废物排放。</li></ul><h4 id="未来可能发展方向"><a href="#未来可能发展方向" class="headerlink" title="未来可能发展方向"></a>未来可能发展方向</h4><p><strong>技术深化与融合</strong></p><ul><li>量子计算与生物计算：突破传统算力极限，加速药物研发与材料科学突破511。</li><li>物理智能与边缘计算：AI与机器人深度融合，实现基础设施（如电网、交通网络）的自主优化。</li></ul><p><strong>社会与经济模式重构</strong></p><ul><li>去中心化生产：分布式制造（如家庭3D打印工坊）可能替代部分集中式工业体系，降低商品成本811。</li><li>共享经济升级：基于区块链的智能合约推动资源分配透明化，例如能源共享与碳交易市场。</li></ul><p><strong>伦理与风险治理</strong></p><ul><li>AI伦理与安全：需应对数据隐私、算法偏见及自主武器等风险，建立跨国治理框架。</li><li>劳动力转型：预计全球30%的岗位将被自动化取代，需系统性职业培训与社会保障改革。</li></ul><h4 id="对人类社会的影响"><a href="#对人类社会的影响" class="headerlink" title="对人类社会的影响"></a>对人类社会的影响</h4><p><strong>经济层面</strong></p><ul><li>增长动力转换：数字经济占全球GDP比重持续上升，预计2030年达30%。</li><li>产业链重构：发达国家可能通过智能制造实现制造业“回流”，冲击传统全球分工模式。</li></ul><p><strong>社会与文化</strong></p><ul><li>城市化转型：智能城市减少资源浪费，但可能加剧数字鸿沟（如偏远地区技术滞后）。</li><li>教育革命：AI辅助教学与终身学习模式普及，传统教育体系面临重构。</li></ul><p><strong>环境与可持续性</strong></p><ul><li>碳中和路径：清洁能源技术有望在2050年前助力全球实现净零排放，但需应对电子垃圾（年产量超5000万吨）等新挑战。</li></ul><h3 id="与GAI的关系"><a href="#与GAI的关系" class="headerlink" title="与GAI的关系"></a>与GAI的关系</h3><p>科技发展和进步总体方向上，在宏观上大致体现为更多的能量获取和更多的能量消耗，当前比较简单的衡量方式就是发电量和耗电量，在没有非常低廉成规模的电储能技术应用的情况下，工业化水平和生产力水平基本就和发电量成正相关，而工业化水平又和人民生活水平、综合国力、文明程度呈正相关。</p><p><img src="/img/AThoughtOnIndustrialRevolutionAndAI_02.jpg" alt=""></p><blockquote><p>数据来源：<a href="https://www.163.com/dy/article/JK9R24IB05566X2U.html" target="_blank" rel="noopener">2023年中美日总发电量：美44940亿度，日本10133亿，中国差距悬殊</a></p></blockquote><p>在中微观的角度上，是推进更高能量密度存储和传输，更高能量转化率和利用率，在实体和虚拟两个方向上构建科技奇观，实体表现在航天，虚拟表现在通用人工智能，实体和虚拟的结合则是具身智能。</p><p>米国通过堆砌算力芯片和参数数据来训练大语言模型，让模型利用量变达到质变“涌现”出智能，目前来看已经明显达到瓶颈：一是可用算力达到极限，难以负担构建更高一个数量级显卡所需的电力供应；二是提升一个量级数量的显卡阵列存在架构上的难度，无法实现等比效率的提升；三是可用的训练数据已经枯竭，后续的训练号称将使用更多AI生成数据，但这无异于左脚踩右脚的虚空飞升。</p><p>因此，需要从内部寻找突破口，也即优化算法和模型，来提升模型的最终效果，或者，使用更低的成本快速训练出面向更特定领域的小型“大模型”，也能够解决垂直领域的应用成效，然后再考虑将这些小模型集成。</p><p>以上，从一个角度来分析为什么DeepSeek成为了国运级别的创新。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><span id="fn1"><a href="#a1">[1]</a></span>: <a href="https://mp.weixin.qq.com/s/jrE4OXEGZRiTvPgB5ZRLog" target="_blank" rel="noopener">人类距离I型文明并不遥远，可能只差300多年</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;A-Thought-on-Industrial-Revolution-and-AI&quot;&gt;&lt;a href=&quot;#A-Thought-on-Industrial-Revolution-and-AI&quot; class=&quot;headerlink&quot; title=&quot;A Thought </summary>
      
    
    
    
    
    <category term="Industrial Revolution" scheme="http://gloomymoon.github.io/tags/Industrial-Revolution/"/>
    
    <category term="AI" scheme="http://gloomymoon.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>2024 Selected Jokes</title>
    <link href="http://gloomymoon.github.io/2024/12/17/2024-Selected-Jokes/"/>
    <id>http://gloomymoon.github.io/2024/12/17/2024-Selected-Jokes/</id>
    <published>2024-12-17T14:30:43.000Z</published>
    <updated>2024-12-20T07:42:39.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="2024精选回旋镖系列续：精选笑话"><a href="#2024精选回旋镖系列续：精选笑话" class="headerlink" title="2024精选回旋镖系列续：精选笑话"></a>2024精选回旋镖系列续：精选笑话</h3><p><strong>米国物语</strong></p><p><img src="/img/2024SelectedJokes_01a.jpg" alt=""><br><img src="/img/2024SelectedJokes_01b.jpg" alt=""><br><img src="/img/2024SelectedJokes_01c.jpg" alt=""><br><img src="/img/2024SelectedJokes_01d.jpg" alt=""><br><img src="/img/2024SelectedJokes_01e.jpg" alt=""><br><img src="/img/2024SelectedJokes_01f.jpg" alt=""><br><img src="/img/2024SelectedJokes_01g.jpg" alt=""><br><img src="/img/2024SelectedJokes_01h.jpg" alt=""><br><img src="/img/2024SelectedJokes_01i.jpg" alt=""><br><img src="/img/2024SelectedJokes_01j.jpg" alt=""><br><img src="/img/2024SelectedJokes_01k.jpg" alt=""><br><img src="/img/2024SelectedJokes_01l.jpg" alt=""><br><img src="/img/2024SelectedJokes_01m.jpg" alt=""><br><img src="/img/2024SelectedJokes_01n.jpg" alt=""><br><img src="/img/2024SelectedJokes_01o.jpg" alt=""><br><img src="/img/2024SelectedJokes_01p.jpg" alt=""><br><img src="/img/2024SelectedJokes_01q.jpg" alt=""><br><img src="/img/2024SelectedJokes_01r.jpg" alt=""><br><img src="/img/2024SelectedJokes_01s.jpg" alt=""><br><img src="/img/2024SelectedJokes_01u.jpg" alt=""><br><img src="/img/2024SelectedJokes_01u1.jpg" alt=""><br><img src="/img/2024SelectedJokes_01v.jpg" alt=""><br><img src="/img/2024SelectedJokes_01w.jpg" alt=""><br><img src="/img/2024SelectedJokes_01x.jpg" alt=""><br><img src="/img/2024SelectedJokes_01y.jpg" alt=""><br><img src="/img/2024SelectedJokes_01z.jpg" alt=""></p><p><img src="/img/2024SelectedJokes_02a.jpg" alt=""><br><img src="/img/2024SelectedJokes_02b.jpg" alt=""><br><img src="/img/2024SelectedJokes_02c.jpg" alt=""><br><img src="/img/2024SelectedJokes_02d.jpg" alt=""><br><img src="/img/2024SelectedJokes_02e.jpg" alt=""><br><img src="/img/2024SelectedJokes_02f.jpg" alt=""><br><img src="/img/2024SelectedJokes_02g.jpg" alt=""><br><img src="/img/2024SelectedJokes_02h.jpg" alt=""><br><img src="/img/2024SelectedJokes_02i.jpg" alt=""><br><img src="/img/2024SelectedJokes_02j.jpg" alt=""><br><img src="/img/2024SelectedJokes_02k.jpg" alt=""><br><img src="/img/2024SelectedJokes_02l.jpg" alt=""><br><img src="/img/2024SelectedJokes_02m.jpg" alt=""><br><img src="/img/2024SelectedJokes_02n.jpg" alt=""><br><img src="/img/2024SelectedJokes_02o.jpg" alt=""><br><img src="/img/2024SelectedJokes_02p.jpg" alt=""><br><img src="/img/2024SelectedJokes_02q.jpg" alt=""><br><img src="/img/2024SelectedJokes_02r.jpg" alt=""><br><img src="/img/2024SelectedJokes_02s.jpg" alt=""></p><p><strong>疣蛴吥姒人</strong></p><p><img src="/img/2024SelectedJokes_11a.jpg" alt=""><br><img src="/img/2024SelectedJokes_11b.jpg" alt=""><br><img src="/img/2024SelectedJokes_11c.jpg" alt=""><br><img src="/img/2024SelectedJokes_11d.jpg" alt=""><br><img src="/img/2024SelectedJokes_11e.jpg" alt=""><br><img src="/img/2024SelectedJokes_11f.jpg" alt=""><br><img src="/img/2024SelectedJokes_11g.jpg" alt=""><br><img src="/img/2024SelectedJokes_11h.jpg" alt=""><br><img src="/img/2024SelectedJokes_11i.jpg" alt=""></p><p><strong>日已落联合亡国</strong></p><p><img src="/img/2024SelectedJokes_21a.jpg" alt=""><br><img src="/img/2024SelectedJokes_21b.jpg" alt=""><br><img src="/img/2024SelectedJokes_21c.jpg" alt=""><br><img src="/img/2024SelectedJokes_21d.jpg" alt=""></p><p><strong>抽象日韩印乌叙等等</strong></p><p>霓虹：<br><img src="/img/2024SelectedJokes_31a.jpg" alt=""><br><img src="/img/2024SelectedJokes_31b.jpg" alt=""><br><img src="/img/2024SelectedJokes_31c.jpg" alt=""><br><img src="/img/2024SelectedJokes_31d.jpg" alt=""><br><img src="/img/2024SelectedJokes_31e.jpg" alt=""><br><img src="/img/2024SelectedJokes_31f.jpg" alt=""><br><img src="/img/2024SelectedJokes_31g.jpg" alt=""></p><p>南棒：<br><img src="/img/2024SelectedJokes_32a.jpg" alt=""><br><img src="/img/2024SelectedJokes_32b.jpg" alt=""><br><img src="/img/2024SelectedJokes_32c.jpg" alt=""></p><p>Jai Hind：<br><img src="/img/2024SelectedJokes_33a.jpg" alt=""><br><img src="/img/2024SelectedJokes_33b.jpg" alt=""><br><img src="/img/2024SelectedJokes_33c.jpg" alt=""></p><p>大毛：<br><img src="/img/2024SelectedJokes_34a.jpg" alt=""><br><img src="/img/2024SelectedJokes_34b.jpg" alt=""><br><img src="/img/2024SelectedJokes_34c.jpg" alt=""></p><p>二毛：<br><img src="/img/2024SelectedJokes_35a.jpg" alt=""><br><img src="/img/2024SelectedJokes_35b.jpg" alt=""></p><p>叙利亚：<br><img src="/img/2024SelectedJokes_36a.jpg" alt=""></p><p>汉斯：<br><img src="/img/2024SelectedJokes_37a.jpg" alt=""></p><p>意呆：<br><img src="/img/2024SelectedJokes_38a.jpg" alt=""></p><p>4V：<br><img src="/img/2024SelectedJokes_39a.jpg" alt=""></p><p><strong>TGA：新的笑话公式</strong></p><p><img src="/img/2024SelectedJokes_41a.jpg" alt=""><br><img src="/img/2024SelectedJokes_41b.jpg" alt=""><br><img src="/img/2024SelectedJokes_41c.jpg" alt=""><br><img src="/img/2024SelectedJokes_41d.jpg" alt=""><br><img src="/img/2024SelectedJokes_42.jpg" alt=""></p><p><strong>认知战</strong></p><p><img src="/img/2024SelectedJokes_51a.jpg" alt=""><br><img src="/img/2024SelectedJokes_51b.jpg" alt=""><br><img src="/img/2024SelectedJokes_51c.jpg" alt=""><br><img src="/img/2024SelectedJokes_51d.jpg" alt=""><br><img src="/img/2024SelectedJokes_51e.jpg" alt=""><br><img src="/img/2024SelectedJokes_51f.jpg" alt=""><br><img src="/img/2024SelectedJokes_51g.jpg" alt=""><br><img src="/img/2024SelectedJokes_51h.jpg" alt=""><br><img src="/img/2024SelectedJokes_51i.jpg" alt=""><br><img src="/img/2024SelectedJokes_51j.jpg" alt=""><br><img src="/img/2024SelectedJokes_51k.jpg" alt=""></p><p><strong>其他</strong></p><p><img src="/img/2024SelectedJokes_61a.jpg" alt=""><br><img src="/img/2024SelectedJokes_61b.jpg" alt=""><br><img src="/img/2024SelectedJokes_61c.jpg" alt=""><br><img src="/img/2024SelectedJokes_61d.jpg" alt=""><br><img src="/img/2024SelectedJokes_61e.jpg" alt=""><br><img src="/img/2024SelectedJokes_61f.jpg" alt=""><br><img src="/img/2024SelectedJokes_61g.jpg" alt=""><br><img src="/img/2024SelectedJokes_61h.jpg" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;2024精选回旋镖系列续：精选笑话&quot;&gt;&lt;a href=&quot;#2024精选回旋镖系列续：精选笑话&quot; class=&quot;headerlink&quot; title=&quot;2024精选回旋镖系列续：精选笑话&quot;&gt;&lt;/a&gt;2024精选回旋镖系列续：精选笑话&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;米国</summary>
      
    
    
    
    
    <category term="Cognitive Warfare" scheme="http://gloomymoon.github.io/tags/Cognitive-Warfare/"/>
    
    <category term="Boomerang" scheme="http://gloomymoon.github.io/tags/Boomerang/"/>
    
  </entry>
  
  <entry>
    <title>Hearts of Iron</title>
    <link href="http://gloomymoon.github.io/2024/12/13/Hearts-of-Iron/"/>
    <id>http://gloomymoon.github.io/2024/12/13/Hearts-of-Iron/</id>
    <published>2024-12-13T02:35:43.000Z</published>
    <updated>2024-12-14T07:22:50.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>“Wars may be fought with weapons, but they are won by men. It is the spirit of men who follow and of the man who leads that gains the victory.”<br>–George S. Patton</p></blockquote><blockquote><p>“Your name is unknown. Your deed is immortal.”<br>Tomb of the Unknown Soldier (Moscow)</p></blockquote><h2 id="0-1-6-MOSS-amp-DOGS"><a href="#0-1-6-MOSS-amp-DOGS" class="headerlink" title="0 1/6 MOSS &amp; DOGS"></a>0 1/6 MOSS &amp; DOGS</h2><blockquote><p>“从历史上看，人类的命运取决于人类的选择。”<br>–MOSS（550W）</p></blockquote><h3 id="MOSS（550W）"><a href="#MOSS（550W）" class="headerlink" title="MOSS（550W）"></a>MOSS（550W）</h3><p><img src="/img/HeartsOfIron/moss_01.jpg" alt=""><br><img src="/img/HeartsOfIron/moss_02.jpg" alt=""></p><h3 id="赛凡-星环重工-笨笨-多功能全地形智能运输平台（机械狗）"><a href="#赛凡-星环重工-笨笨-多功能全地形智能运输平台（机械狗）" class="headerlink" title="赛凡|星环重工 笨笨|多功能全地形智能运输平台（机械狗）"></a>赛凡|星环重工 笨笨|多功能全地形智能运输平台（机械狗）</h3><blockquote><p>“笨笨，你是条军犬。”</p></blockquote><p><img src="/img/HeartsOfIron/DOGS_01.jpg" alt=""><br><img src="/img/HeartsOfIron/DOGS_03.jpg" alt=""><br><img src="/img/HeartsOfIron/DOGS_04.jpg" alt=""><br><img src="/img/HeartsOfIron/DOGS_05.jpg" alt=""></p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="110" src="//music.163.com/outchain/player?type=1&id=158468886&auto=0&height=90"></iframe><h2 id="1-1-35-Military-Miniature"><a href="#1-1-35-Military-Miniature" class="headerlink" title="1 1/35 Military Miniature"></a>1 1/35 Military Miniature</h2><blockquote><p>“Whenever in future wars the battle is fought, panzer troops will play the decisive role.”<br>–Heinz Guderian</p></blockquote><h3 id="TAMIYA-Panzerkampfwagen-VI-Tiger-I"><a href="#TAMIYA-Panzerkampfwagen-VI-Tiger-I" class="headerlink" title="TAMIYA Panzerkampfwagen VI Tiger I"></a>TAMIYA Panzerkampfwagen VI Tiger I</h3><p><img src="/img/HeartsOfIron/Pzkw_VI_Tiger_I_01.jpg" alt=""><br><img src="/img/HeartsOfIron/Pzkw_VI_Tiger_I_02.jpg" alt=""><br><img src="/img/HeartsOfIron/Pzkw_VI_Tiger_I_03.jpg" alt=""><br><img src="/img/HeartsOfIron/Pzkw_VI_Tiger_I_04.jpg" alt=""></p><p>坦克从诞生起一直被质疑、被挑战、被“替代”，但仍然是陆军的主力装备，没有之一。</p><h3 id="TRUMPETER-MAZ-537G-with-MAZ-ChMZAP-5247G"><a href="#TRUMPETER-MAZ-537G-with-MAZ-ChMZAP-5247G" class="headerlink" title="TRUMPETER MAZ-537G with MAZ/ChMZAP-5247G"></a>TRUMPETER MAZ-537G with MAZ/ChMZAP-5247G</h3><blockquote><p>“The vastness of Russia devours us.”<br>–Gerd von Rundstedt</p></blockquote><p>有段时间沉迷《雪地奔驰》开车车，“一人一车一张图，一捆原木拉一周”，MAZ-537是本体&amp;前2年年票中最强车没有之一（ZIKZ-605R），CCCP那独特的原始机械美感，配上轰鸣的马达声和巨大厚重的泥地胎，能够征服任何坎坷地形，给人留下不可磨灭的印象，那张略带蠢萌的前脸也越看越可爱。</p><p>MAZ-537的前身MAZ-535是CCCP第一台重型四轴重型卡车，也是代表苏维埃工业的革命性产品，537基本沿用了90%以上535的技术和结构造型，但是改用了D12A-525这款著名的V2系列坦克发动机，排量38.8L，最大功率达到了525马力。MAZ-537最大的使命就是运输坦克、飞机、战术弹道导弹、巡航导弹等军用武器装备，也衍生出各种特种型号车，比如救援车、救助车、除雪车。国内曾引进过MAZ-537作为矿山用车，目前已经全部退役。MAZ-537的继承者是大名鼎鼎的MAZ-543，也被称为MAZ-7310，后来大名鼎鼎的飞毛腿导弹使用的就是MAZ-543P底盘。</p><p><img src="/img/HeartsOfIron/MAZ-537_01.jpg" alt=""><br><img src="/img/HeartsOfIron/MAZ-537_02.jpg" alt=""><br><img src="/img/HeartsOfIron/MAZ-537_03.jpg" alt=""></p><h3 id="TAMIYA-88mm-Gun-Flak36-37"><a href="#TAMIYA-88mm-Gun-Flak36-37" class="headerlink" title="TAMIYA 88mm Gun Flak36/37"></a>TAMIYA 88mm Gun Flak36/37</h3><blockquote><p>“No enemy bomber can reach the Ruhr. If one reaches the Ruhr, my name is not Göring. You may call me Meyer.”<br>– Hermann “Meyer”</p></blockquote><p><img src="/img/HeartsOfIron/88mmGun_01.jpg" alt=""><br><img src="/img/HeartsOfIron/88mmGun_02.jpg" alt=""><br><img src="/img/HeartsOfIron/88mmGun_03.jpg" alt=""></p><p>火炮是现代战争之王。高炮放平，降维打击。</p><h3 id="TAMIYA-Jeep-Willys-MB"><a href="#TAMIYA-Jeep-Willys-MB" class="headerlink" title="TAMIYA Jeep Willys MB"></a>TAMIYA Jeep Willys MB</h3><blockquote><p>“In a man-to-man fight, the winner is he who has one more round in his magazine.”<br>–Erwin Rommel</p></blockquote><p><img src="/img/HeartsOfIron/JeepWillysMB_01.jpg" alt=""><br><img src="/img/HeartsOfIron/JeepWillysMB_02.jpg" alt=""><br><img src="/img/HeartsOfIron/JeepWillysMB_03.jpg" alt=""><br><img src="/img/HeartsOfIron/JeepWillysMB_04.jpg" alt=""></p><p>对于Jeep的评价，无需多言，要说的话，看看现在猫猫车的热度吧。</p><h2 id="10-1-72-F-14B-Tomcat-amp-Macross-VF-1A-S"><a href="#10-1-72-F-14B-Tomcat-amp-Macross-VF-1A-S" class="headerlink" title="10 1/72 F-14B Tomcat &amp; Macross VF-1A/S"></a>10 1/72 F-14B Tomcat &amp; Macross VF-1A/S</h2><h3 id="HobbyBoss-F-14B-Tomcat"><a href="#HobbyBoss-F-14B-Tomcat" class="headerlink" title="HobbyBoss F-14B Tomcat"></a>HobbyBoss F-14B Tomcat</h3><blockquote><p>Iceman: “You! You are still dangerous. You can be my wingman anytime.”<br>Maverick: “Bullshit. You can by mine.”<br>–Top Gun 1986</p></blockquote><p><img src="/img/HeartsOfIron/F-14B_01.jpg" alt=""><br><img src="/img/HeartsOfIron/F-14B_02.jpg" alt=""></p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="110" src="//music.163.com/outchain/player?type=0&id=503230793&auto=0&height=90"></iframe><h3 id="Bandai-VF-1A-S-Valkyrie"><a href="#Bandai-VF-1A-S-Valkyrie" class="headerlink" title="Bandai VF-1A/S Valkyrie"></a>Bandai VF-1A/S Valkyrie</h3><p><img src="/img/HeartsOfIron/VF-1AS_01.jpg" alt=""><br><img src="/img/HeartsOfIron/VF-1AS_02.jpg" alt=""><br><img src="/img/HeartsOfIron/VF-1AS_03.jpg" alt=""><br><img src="/img/HeartsOfIron/VF-1AS_04.jpg" alt=""></p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="110" src="//music.163.com/outchain/player?type=0&id=13696130&auto=0&height=90"></iframe><h2 id="11-1-100-Gundam-amp-Zaku"><a href="#11-1-100-Gundam-amp-Zaku" class="headerlink" title="11 1/100 Gundam &amp; Zaku"></a>11 1/100 Gundam &amp; Zaku</h2><h3 id="RX-79G-Gundam"><a href="#RX-79G-Gundam" class="headerlink" title="RX-79G Gundam"></a>RX-79G Gundam</h3><p><img src="/img/HeartsOfIron/RX-79G_01.jpg" alt=""><br><img src="/img/HeartsOfIron/RX-79G_02.jpg" alt=""><br><img src="/img/HeartsOfIron/RX-79G_03.jpg" alt=""><br><img src="/img/HeartsOfIron/RX-79G_04.jpg" alt=""></p><h3 id="MS-06J-Zaku-II-amp-MS-07B-3-Gouf-Custom"><a href="#MS-06J-Zaku-II-amp-MS-07B-3-Gouf-Custom" class="headerlink" title="MS-06J Zaku II &amp; MS-07B-3 Gouf Custom"></a>MS-06J Zaku II &amp; MS-07B-3 Gouf Custom</h3><p><img src="/img/HeartsOfIron/MS-06J&amp;MS-07B-3.JPG" alt=""><br><img src="/img/HeartsOfIron/MS-06J.jpg" alt=""><br><img src="/img/HeartsOfIron/MS-07B-3.jpg" alt=""></p><p><img src="/img/HeartsOfIron/RX-79G&amp;MS-06J_01.jpg" alt=""><br><img src="/img/HeartsOfIron/RX-79G&amp;MS-06J_02.jpg" alt=""></p><h3 id="MS-79G-Gundam-Ez8-amp-Type-74-Hover-Truck"><a href="#MS-79G-Gundam-Ez8-amp-Type-74-Hover-Truck" class="headerlink" title="MS-79G Gundam Ez8 &amp; Type 74 Hover Truck"></a>MS-79G Gundam Ez8 &amp; Type 74 Hover Truck</h3><p><img src="/img/HeartsOfIron/RX-79G-Ez8&amp;Type-74.jpg" alt=""></p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=4939769&auto=0&height=66"></iframe><h2 id="100-1-700-Warship"><a href="#100-1-700-Warship" class="headerlink" title="100 1/700 Warship"></a>100 1/700 Warship</h2><h3 id="USS-Lexington-CV-2"><a href="#USS-Lexington-CV-2" class="headerlink" title="USS Lexington CV-2"></a>USS Lexington CV-2</h3><blockquote><p>“Scratch one flattop! Dixon to carrier: scratch one flattop!”<br>–Robert E. Dixon, Battle of the Coral Sea</p></blockquote><p><img src="/img/HeartsOfIron/CV-2_01.jpg" alt=""></p><p>More pics:<a href="https://gloomymoon.github.io/2018/12/17/The-Queen-of-the-Flattops-Epilogue/">The Queen of the Flattops, Epilogue</a></p><h2 id="101-1-1000-N-Nautilus-amp-Nautilus"><a href="#101-1-1000-N-Nautilus-amp-Nautilus" class="headerlink" title="101 1/1000 N-Nautilus &amp; Nautilus"></a>101 1/1000 N-Nautilus &amp; Nautilus</h2><h3 id="Kotobukiya-N-Nautilus-amp-Nautilus"><a href="#Kotobukiya-N-Nautilus-amp-Nautilus" class="headerlink" title="Kotobukiya N-Nautilus &amp; Nautilus"></a>Kotobukiya N-Nautilus &amp; Nautilus</h3><p><img src="/img/HeartsOfIron/Nautilus_01.jpg" alt=""><br><img src="/img/HeartsOfIron/Nautilus_02.jpg" alt=""><br><img src="/img/HeartsOfIron/Nautilus_03.jpg" alt=""><br><img src="/img/HeartsOfIron/Nautilus_04.jpg" alt=""></p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=504804&auto=0&height=66"></iframe><h2 id="110-REAL-Tide-of-Iron"><a href="#110-REAL-Tide-of-Iron" class="headerlink" title="110 REAL Tide of Iron"></a>110 REAL Tide of Iron</h2><blockquote><p>“政治是不流血的战争，战争是流血的政治。”<br>——毛泽东 《毛泽东选集》第2卷，人民出版社1991年版，第480页</p></blockquote><p><img src="/img/HeartsOfIron/TideOfIron_01.jpg" alt=""><br><img src="/img/HeartsOfIron/TideOfIron_02.jpg" alt=""><br><img src="/img/HeartsOfIron/TideOfIron_03.jpg" alt=""><br><img src="/img/HeartsOfIron/TideOfIron_04.jpg" alt=""></p><p>今天是第11个南京大屠杀死难者国家公祭日，铭记历史、珍爱和平、反对侵略。</p><p><img src="/img/HeartsOfIron/93a8c37f24484a88a8a67ab91ec7ee24.jpg" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;“Wars may be fought with weapons, but they are won by men. It is the spirit of men who follow and of the man who leads that </summary>
      
    
    
    
    
    <category term="World War II" scheme="http://gloomymoon.github.io/tags/World-War-II/"/>
    
    <category term="Static Model" scheme="http://gloomymoon.github.io/tags/Static-Model/"/>
    
    <category term="Macross" scheme="http://gloomymoon.github.io/tags/Macross/"/>
    
    <category term="Gundam" scheme="http://gloomymoon.github.io/tags/Gundam/"/>
    
  </entry>
  
  <entry>
    <title>The Data Science Task Force: Mission SDM</title>
    <link href="http://gloomymoon.github.io/2024/08/31/The-Data-Science-Task-Force-Mission-XI/"/>
    <id>http://gloomymoon.github.io/2024/08/31/The-Data-Science-Task-Force-Mission-XI/</id>
    <published>2024-08-31T13:19:30.000Z</published>
    <updated>2024-08-31T13:51:14.917Z</updated>
    
    <content type="html"><![CDATA[<h3 id="软件开发和维护（SDM）"><a href="#软件开发和维护（SDM）" class="headerlink" title="软件开发和维护（SDM）"></a>软件开发和维护（SDM）</h3><p>数据科学家可能需要构建（或参与构建）可部署系统，用于数据分析或将数据分析结果付诸实践。为此，他们应熟悉基本的软件开发原则和实践知识。<br>请注意，本知识领域借鉴了CS2013的软件工程（SE）知识领域。<br>请注意，开发和测试将在下文中分别论述，测试是开发过程的组成部分，为了便于阅读，下文将两者分开。</p><table>  <tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul>    <li>软件工程原理，包括程序的设计、实施和测试。</li>    <li>潜在的脆弱性。</li>    </ul></td>    <td width="50%">    <ul>    <li>实施一个使用规定编码标准的小型软件项目。</li>    <li>测试代码，包括安全性、单元测试、系统测试、集成测试和界面可用性。</li>    </ul>    </td>  </tr>  <tr>     <th colspan="2">子领域</th>  </tr>  <tr>    <td width="50%">    SDM-软件设计与开发-T1、T2、E<br>    </td>    <td width="50%">    SDM-软件测试-T1、T2、E<br>    </td>  </tr></table><h4 id="SDM-软件设计与开发"><a href="#SDM-软件设计与开发" class="headerlink" title="SDM-软件设计与开发"></a>SDM-软件设计与开发</h4><p>数据科学家应了解设计原则及其对模块化、可重用性和安全性等问题的影响。设计、实施和测试是软件开发中紧密结合的组成部分。在本知识领域中，为了方便阅读，我们将设计和测试能力分别列出。</p><p><em>知识</em><br>T1：</p><ul><li>编码和设计标准。</li><li>与信息管理/数据库系统集成。</li><li>软件生命周期。</li><li>数据生命周期。</li></ul><p>T2：</p><ul><li>项目管理方法。</li></ul><p>E：</p><ul><li>与嵌入式、过程控制和/或通信系统集成。</li></ul><p><em>技能</em></p><p>T1：</p><ul><li>解释项目编码标准。</li><li>解释项目设计标准。</li><li>说明如何与信息管理/数据库系统集成或交互。</li><li>解释所有领域不同测试范例/需求的范围和类型。</li><li>单独实施一个符合设计规范的小型软件项目。</li><li>开发并完成符合设计规范的团队软件项目。</li><li>执行既定的设计、文档和实施标准。</li><li>在简单程序上执行基本的软件生命周期。</li><li>在简单的数据产品上执行基本的数据（科学）生命周期。</li><li>与信息管理/数据库系统整合或交互。</li></ul><p>T2：</p><ul><li>执行特定的项目管理方法。</li><li>规范和设计一个符合利益相关者要求的团队软件项目。</li><li>作为领导者，完成项目开发，满足利益相关方的要求。</li><li>实施数据科学生命周期，在软件生命周期的适当阶段建立数据驱动决策。</li></ul><p>E：</p><ul><li>与嵌入式、过程控制和/或通信系统集成或交互。</li></ul><p><em>品行</em><br>T1：</p><ul><li>具有协作精神和职业道德的团队成员，认识到建立在尊重、多样性和协作基础上的团队的价值。</li><li>遵守项目编码和设计标准的信念。</li><li>善于倾听、善于提出想法、善于谈判，具有协作精神和灵活性。</li><li>坚定地致力于以生命周期的思维方式处理数据和软件项目。</li><li>敏锐地认识到使用测试驱动开发的好处。</li></ul><p>T2：</p><ul><li>专业和道德领导力。遵循尊重、善于倾听、负责人等原则，领导项目完成。</li><li>已承诺和专业精神促进和鼓励遵守项目编码和设计标准</li></ul><h4 id="SDM-软件测试"><a href="#SDM-软件测试" class="headerlink" title="SDM-软件测试"></a>SDM-软件测试</h4><p>数据科学家应了解在软件开发和部署过程中进行良好测试的重要性。</p><p><em>知识</em></p><p>T1：</p><ul><li>测试范例/需求。<ul><li>单元/执行。</li><li>集成。</li><li>界面/用户。</li><li>回归/持续。</li><li>系统。</li><li>安全。</li></ul></li></ul><p>T2：</p><ul><li>程序中潜在的安全问题。<ul><li>缓冲区和其他类型的溢出。</li><li>条件竞争。</li><li>初始化不当，包括权限选择不当。</li><li>未检查输入。</li><li>假设成功和正确。</li><li>未验证假设。</li></ul></li></ul><p><em>技能</em><br>T1：</p><ul><li>定义并解释所有领域不同测试范例/需求的范围和类型。</li><li>为以下项目设计基本测试：<ul><li>单元/执行。</li><li>集成。</li></ul></li></ul><p>T2：</p><ul><li>使用或从大数据集中提取代表性数据，一边在集群上大规模运行之前现在小规模上测试算法。</li><li>为以下项目制定测试规范：<ul><li>界面/用户。</li><li>回归测试。</li><li>系统。</li><li>安全。</li></ul></li><li>执行以下测试（由他人构建）：<ul><li>界面/用户。</li><li>回归测试。</li><li>系统。</li><li>安全。</li></ul></li><li>使用统计显著性测试评估程序结果。</li><li>描述软件系统可能存在的风险类型。</li><li>描述安全编码和防御性编码实践。</li></ul><p>E：</p><ul><li>设计、开发和执行所有领域的测试。</li></ul><p><em>品行</em><br>T1：</p><ul><li>敏锐地认识到并重视使用测试驱动开发的好处。</li><li>致力于从测试驱动的角度进行基本的软件和数据项目开发，尤其是单元/执行和集成测试。</li></ul><p>T2：</p><ul><li>致力于从测试驱动的角度进行软件和数据项目开发，特别是与安全、界面/用户、回归/持续和系统测试相关的方面。</li></ul><p>E：</p><ul><li>致力于从测试驱动开发的角度全面处理软件和数据项目。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;软件开发和维护（SDM）&quot;&gt;&lt;a href=&quot;#软件开发和维护（SDM）&quot; class=&quot;headerlink&quot; title=&quot;软件开发和维护（SDM）&quot;&gt;&lt;/a&gt;软件开发和维护（SDM）&lt;/h3&gt;&lt;p&gt;数据科学家可能需要构建（或参与构建）可部署系统，用于数据分析</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>Black Myth: Chinese Local DianZiYouXi</title>
    <link href="http://gloomymoon.github.io/2024/08/20/Black-Myth-DianZiYouXi/"/>
    <id>http://gloomymoon.github.io/2024/08/20/Black-Myth-DianZiYouXi/</id>
    <published>2024-08-20T14:14:46.000Z</published>
    <updated>2025-07-10T02:20:15.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="黑神话：中国本土电子游戏的迷思"><a href="#黑神话：中国本土电子游戏的迷思" class="headerlink" title="黑神话：中国本土电子游戏的迷思"></a>黑神话：中国本土电子游戏的迷思</h1><blockquote><p>Some things that should not have been forgotten were lost.<br>History became legend. Legend became Myth.<br>――《The Lord of the Rings》 by J.R.R.Tolkien</p></blockquote><h2 id="0-《黑神话：悟空》的“J20时刻”：国产3A的工业化里程碑"><a href="#0-《黑神话：悟空》的“J20时刻”：国产3A的工业化里程碑" class="headerlink" title="0 《黑神话：悟空》的“J20时刻”：国产3A的工业化里程碑"></a>0 《黑神话：悟空》的“J20时刻”：国产3A的工业化里程碑</h2><p>8月20日，国产3A单机游戏《黑神话：悟空》正式发售，首日发售超过450万份，销售额超15亿元，Steam同时在线人数达222万，创下单机游戏纪录，全球销量中海外占比超30%<sup><span id="a1"><a href="#fn1">[1]</a></span></sup>。21、22两天在线持续上升，高峰达到250万。截至8月26日，全球发售已超过1400万份，其中80%是中国玩家。《黑神话：悟空》的成功不仅是商业奇迹，更是中国游戏工业的里程碑。该作在2024年TGA（The Game Awards）上斩获“最佳动作游戏”和“玩家之声”两项大奖，成为首款在国际顶级游戏奖项中实现“零的突破”的中国作品。这一成就堪比中国航空工业的“J20时刻”——正如歼-20战斗机标志着中国从“仿制”到“自主创新”的跨越，《黑神话：悟空》以世界顶尖的画面技术和文化叙事，打破了“中国无法打造3A游戏”的固有偏见，证明了国产游戏的工业化能力与文化自信。</p><p>《黑神话：悟空》的全球影响力激发了民族文化自豪感。海外玩家通过《黑神话：悟空》中的“土地庙”、“妖怪”等元素，关注并开始探索中国古建与神话，甚至掀起“跟着悟空游中国”的热潮，晋城玉皇庙、重庆大足石刻等取景地成为旅游热点<sup><span id="a1"><a href="#fn1">[1]</a></span></sup>。国内玩家则从“手游氪金”转向为高质量内容付费，预售阶段即贡献120万份销量，创国产游戏纪录。游戏科学创始人冯骥直言：“玩家的支持让东方神话在世界的舞台上绽放光彩。”这一现象印证了“文化自信”的觉醒，也激励了《影之刃零》、《明末：渊虚之羽》等国产3A项目的立项，推动行业从“赚快钱”向“长线精品”转型<sup><span id="a2"><a href="#fn2">[2]</a></span></sup> 。</p><p>毋庸置疑，《黑神话：悟空》和游戏科学的成功源于对技术、文化与匠心的极致追求：</p><ul><li><p>巨额投入与长线坚持：团队耗时6年，投入超4亿元开发成本，每小时开发成本高达2000万元。核心成员来自腾讯《斗战神》项目，平均从业经验13年，技术积累长达十年，在项目初期甚至抵押房产维持运营。</p></li><li><p>技术钻研与细节打磨：采用最先进的“虚幻”5引擎，实现毛发系统单角色超百万面、场景多边形数量达国际一线水准；山西玉皇庙的斗拱纹路、陕北说书的音效均通过实地扫描与采风还原，存档点“土地庙”的上香机制更将传统文化符号转化为沉浸式体验。</p></li><li><p>文化创新与全球化叙事：团队并未照搬《西游记》原著，而是重构世界观，以“天命人”视角探索神话背后的哲学命题。海外玩家对“Yaoguai”（妖怪）等拼音译名的好奇，成为文化输出的突破口。</p></li></ul><p>J20与《黑神话：悟空》的惊艳亮相均代表中国工业从“跟随”到“引领”的转折，而且是成体系、全链条、“软”“硬”兼顾的典型代表，但更重要的是，体现出了中华民族绵延5000年的精神内涵和文化叙事。正如冯骥所言：“3A是工业化结果，不是目标。” 《黑神话：悟空》的成功，标志着中国游戏产业终于跨越“中等技术陷阱”，在全球化竞争中开辟了一条“以文化为核，以技术为翼”的新路径<sup><span id="a2"><a href="#fn2">[2]</a></span></sup> 。</p><h2 id="1-政治正确和思想病毒：从语义污染到文化突围"><a href="#1-政治正确和思想病毒：从语义污染到文化突围" class="headerlink" title="1 政治正确和思想病毒：从语义污染到文化突围"></a>1 政治正确和思想病毒：从语义污染到文化突围</h2><blockquote><p>一个中国人制作的3A动作游戏，吹响了对DIE和LGBT反击的冲锋号……</p></blockquote><p>《黑神话：悟空》尚未发布，早已引起多方关注，除了对游戏内容和质量的各种揣测，反倒是各种谣言和负面舆情甚嚣尘上。直到一位国内科技博主“兲虎”猜测游戏科学遭著名DIE公司Sweet Baby Inc.(SBI)勒索700万美元（约5065万人民币）的爆料成为了导火索，让早就对zzzq感到厌恶的国内外游戏玩家们联合起来开始反抗。<br><img src="/img/BlackMythWuKong_02.png" alt=""></p><p>紧接着前暴雪制作人Mark Kern也在推特上发文，搬运了这一观点，在回复网友有关SBI的运作方式时，Mark Kern评论称：“这套方法用了10年了，但现在没用了。”</p><p><img src="/img/BlackMythWuKong_03.png" alt=""><br><img src="/img/BlackMythWuKong_04.png" alt=""></p><p>当初指责《黑神话：悟空》性别歧视的IGN的高级编辑Rebekah Valentine就此事发声站台SBI，并与反对SBI的网友激烈对线，在被怼后退网锁推，在6月17日《黑神话：悟空》媒体试玩解禁后以IGN名义发表一篇欲盖弥彰的文章，将自大无知展现地淋漓尽致，搞到SBI自己都锁了官推。</p><p><img src="/img/BlackMythWuKong_05.png" alt=""></p><p>搞笑的是整个过程，处在整个事件暴风眼中的游戏科学并没有发表任何声音，就是一个单纯的“翻译乌龙”，即使外网的玩家们后来搞清了“敲诈700万”这事只是一名国内博主的推测，但依旧选择相信SBI联合IGN等媒体对游戏科学敲诈这事是绝对存在的，游戏科学只是迫于淫威不敢发声。最后逼得SBI、IGN等不停地自证清白，但他们说的话玩家们一个字都不信，认定他们就是在“此地无银三百两”。</p><p>SBI一直以来在游戏圈里名声在外，以“政治正确”和“多样性咨询”的名义与游戏公司合作，通过修改角色形象（如《战神：诸神黄昏》、《刺客信条：影》强行加入黑人角色）、调整叙事框架（如《消逝的光芒2》女角色丑化）等手段，试图来制定行业规范（督促相关游戏作品加入LGBTQIA+元素），向游戏厂商收取高额费用，并以此绑定媒体评分与舆论导向，在对《黑神话：悟空》的勒索失败后，其联合媒体发动“差评轰炸”，试图通过“政治不正确”标签压制游戏口碑。对此，埃隆·马斯克今年3月就曾怒斥这家公司是业界毒瘤：“Sweet Baby Inc就是游戏行业的邪恶祸根。他们所做的一切都让游戏变得糟糕并试图抵制其他人。”因此在IGN的相关指控以及SBI的索酬行为被以讹传讹广泛传播后，反而激发了玩家热情，不仅是中国玩家，还有其他国家的网友纷纷预购“黑悟空”予以支持，意外成为一场文化价值观冲突的前沿阵地和斗争焦点<sup><span id="a3"><a href="#fn3">[3]</a></span></sup> 。</p><p>从“性别歧视”指控到系统性污名化，DEI商业化的勒索逻辑暴露出与资本狼狈为奸的共谋本质。这其中首当其冲的是对语言的污染：词义转变和语言腐败。学术点来讲，就是一个词本来具有的意义被抽干，赋予某种明确的情绪或立场，削弱对具体事物的思考指向，它作为语言符号的本源意义消失了。很多褒义、中性的词语，受到“消费主义”和亚文化圈的操弄，部分或完全丧失了原本的含义后，被广泛滥用在交流和传播中，最终导致了改变人们认知社会方式的结果。DEI本为保护弱势群体的中性概念，却被工具化为文化审查的武器。当“多样性”、“包容性”等词汇被资本与权力集团垄断定义时，其语义已从“社会正义”蜕变为“合规勒索”。正如乔治·奥威尔所言：“思想的堕落始于语言的堕落。”DEI倡导者通过重构语义边界（如将“不包含特定群体”等同于“歧视”），构建了一套单向度的道德审判体系，迫使创作者屈从于“政治正确税”。</p><p>更进一步，语言异化的发展到符号权力的滥用，从概念工具化变为对思想的控制。法国社会学家布尔迪厄指出，语言不仅是交流工具，更是权力争夺的场域。SBI们先将“多样性”、“包容性”的定义概念泛化，从种族、性别议题扩展到叙事结构、角色设定等创作自由领域，形成无限扩张的审查标准，并牢牢把控对审查标准的解释权；然后进行道德绑架，以“社会进步”之名，将商业利益包装为道德义务，例如SBI声称“指导费”用于“推动行业平等”，施行变相勒索；最后构建信息茧房，通过媒体与意见领袖（KOL、公知、网红）勾结形成话语联盟，利用算法推荐强化“政治正确”议题的曝光度，挤压异见声音的传播空间。这套操控最终服务于意识形态规训。美国学者乔姆斯基曾批判媒体通过“制造共识”操纵公众认知，《黑神话：悟空》事件中，DEI支持者试图将游戏贬为“文化保守主义”象征，实则是对非西方叙事的排斥。其深层目的是维护西方中心主义的话语霸权，将游戏产业转化为文化殖民的工具。</p><p>政治正确这个词的含义，已经变成了集民主自由、女权、反种族歧视、lgbt+、环保动保、多元文化等一系列复杂政治思想病毒的培养皿，成为了一个过街老鼠人人喊打的贬义词。关于这个“老鼠”的反噬此处不再详细复述，有兴趣可以阅读下文了解：</p><blockquote><p>扩展阅读：<a href="https://user.guancha.cn/main/content?id=1333825" target="_blank" rel="noopener">倒反天罡？特朗普用中式女权替代美式女权以期废掉LGBT也注定失败？</a></p></blockquote><p>面对语义污染，全球玩家只能以真金白银的消费行为反击。《黑神话》Steam首日222万同时在线的纪录、海外销量占比超30%的数据，本质是玩家对DEI霸权的一次“用钱包投票”,这场反抗掀起了后真相时代的一场认知革命：当权威媒体的公信力因滥用政治正确而崩塌时，玩家更倾向于依赖社群共识与直接体验，重新归回事物的本质。YouTube博主atraes怒斥媒体评测“荒谬”，强调“游戏主角是只猴子，谈何性别议题？”——这种解构式反击，实质是对语义污染的拨乱反正<sup><span id="a4"><a href="#fn4">[4]</a></span></sup> 。</p><p>《黑神话：悟空》的舆论战暴露了政治正确沦为“思想病毒”的危机：当语言被权力腐蚀为控制工具时，文化创作将陷入自我审查的牢笼。然而，游戏的成功也证明，真正的文化自信无需迎合外部叙事标准。正如福柯所言：“哪里有权力，哪里就有抵抗。”玩家的选择表明，对抗语义污染的最佳方式，是回归内容本质——用扎实的文化内核与技术突破，重构话语权的天平。</p><h2 id="10-第九艺术和文化溢出：东方美学的回归革命"><a href="#10-第九艺术和文化溢出：东方美学的回归革命" class="headerlink" title="10 第九艺术和文化溢出：东方美学的回归革命"></a>10 第九艺术和文化溢出：东方美学的回归革命</h2><blockquote><p>不管什么时代，刻画与异文化的交流都是娱乐的主题。<br>——《Ghost In The Shell Stand Alone Complex》S01E15</p></blockquote><p>游戏被称为“第九艺术”，因其融合了文学、绘画、音乐、建筑、雕塑、舞蹈、戏剧、电影八大艺术形式，并通过<strong>**交互性</strong>赋予玩家“参与式叙事”的独特体验，但并不是所有玩家（尤其是国外玩家）都硬核到会去评价游戏机制和比较与同类游戏难度、打击手感，以及boss动作设计之间的优劣的，他们最直观的感受就是看和听。《黑神话：悟空》将这一特性发挥到极致————其画面设计对标电影级分镜，场景建模精度高达毫米级，动作捕捉技术还原中国武术神韵，配乐以五声音阶为核心融合传统民乐，构建了一个既古典又未来的东方奇幻世界。游戏科学团队以“视听语言+文化内核”的双重突破，重新定义了第九艺术的高度。战斗中的“七十二变”不仅还原了《西游记》原著的神通，更通过粒子特效与物理引擎的动态结合，将神话具象化为可操作的视觉奇观<sup><span id="a5"><a href="#fn5">[5]</a></span></sup>。</p><p>很多人以为老外3A大作玩多了，好莱坞大片也看多了，《黑神话：悟空》这种程度的视听体验对于我们而言可能有情怀，但对于他们而言没了情怀加成也就那样了。事实正好相反，《黑神话：悟空》的视听体验对于我们而言是情怀，对于老外而言，那简直跟直面克苏鲁差不多，大脑因为超出理解能力爽到宕机了，在海外引发了一波“西游热”。从“恶补”悟空身世到激赏中国审美，外国网友对中国元素表现了极大热情。“出圈”的是一款游戏，“出海”的是中国故事、建筑、文博古迹、中国民乐，《黑神话：悟空》为全球玩家打开了一扇了解中国文化的新窗口。</p><p>作为一款来自中国的游戏，《黑神话：悟空》展现在全球玩家面前的，都是原汁原味的中华文化元素，特定名词都以汉语拼音呈现，体现了强大的文化自信：</p><ul><li>悟空的翻译不是monkey king而是Wu kong；</li><li>金箍棒不是golden stick而是Jingubang；</li><li>妖怪不是monster而是yaoguai；</li><li>龙不是Dragon而是Loong；</li><li>“赤尻马猴”“百眼魔君”直接使用拼音（Chikao Mahou、Baiyan Mojun）。</li></ul><p>倒逼外国玩家学习汉字与《西游记》术语。Steam评论区出现“速成版《西游记》指南”，甚至有玩家制作“72变法术对照表”。中国神仙体系（如“三清四御”、“六丁六甲”）的复杂设定，打破了西方对“东方神话==龙珠”的刻板印象。海外社区热议“二郎神为何叫孙悟空舅舅”，还间接推动《封神演义》英译版销量增长<sup><span id="a5"><a href="#fn5">[5]</a></span></sup>。</p><p>中华大地的名胜古迹，首次在虚拟世界大规模地呈现给世人：摩崖石刻上的颜体《金刚经》、北方大地伫立的西夏文石碑，山西晋城玉皇庙的二十八星宿彩塑，陕西蓝田水月庵的小西天，四川资阳安岳县茗山寺的毗卢佛像，重庆大足石刻的地狱变相、西方净土变相、护法神龛……</p><p>游戏开场的“云宫迅音”改编自86版《西游记》主题曲，用电子合成器与唢呐交织出史诗感，被玩家称为“赛博诵经”；游戏音乐使用唢呐、古筝、三弦等传统乐器，并结合陕北说书、佛教梵呗等非遗元素。战斗配乐《往生咒》融入喉音唱法，被海外玩家称为“来自东方的灵魂震颤”。</p><p>游戏中的设定和UI，也都体现出独特的方式，比如游戏的存档方式：悟空取下毫毛，变成香烛，甩灭明火，左手上香；比如尘烟拂去，金佛流苏，蛛丝网落，枯木逢春，冰雪消融。比如章节的设定，六个章节，分别对应佛教中的“六根”“六识”：眼根、耳根、鼻根、舌根、身根、意根；而眼识、耳识、鼻识、舌识、身识、意识是要玩家看破这六种欲望，才能抵达终点，成为了中国文化和游戏哲学的某种延续。</p><p>有媒体说，《黑神话：悟空》是一款征服世界的中国游戏。我并不喜欢这个说法。我们不需要征服任何玩家，也不需要征服世界，更不需要赢过谁，我们只需要做好自己该做的事。当你足够发光，关注自然就会向我们走来。而我们要做好的事，就是“文化传承”。我们有的好东西一定不止这些，我们有着太多的珍宝，那些珍宝在我们的历史里、文化里、口口相传里，那些珍宝，都在我们血液里，在一个又一个、一代又一代国人的心中。桃李不言，下自成蹊。</p><p>电子游戏有自己的理论体系，比如即时响应和延迟满足、面对不同的玩家提供从探索、成就、协作、收集、征服等各种情绪价值，但是真正吸引人心的内核还是文化。随着中国综合国力的崛起，中国、中国文化、中华民族将再次回到历史正常地位。海外玩家最初因游戏画面与玩法被吸引，却在探索中自发研究中国文化。例如，YouTube博主“Smough Town”为理解“土地庙”功能，专门制作视频讲解中国民间信仰；Reddit上出现“《西游记》原著解读互助小组”，参与者超10万人。</p><p>《黑神话：悟空》的文化溢出效应，本质是一场“逆向文化殖民”——它用全球化的技术语言，重新定义了东方美学的表达方式。当外国玩家为理解“Yaoguai”（妖怪）而翻开《西游记》，当“土地庙”成为Steam热词，当五声音阶登上Billboard榜单时，游戏已超越娱乐范畴，成为中华文明与世界对话的新媒介。正如开发者冯骥所言：“我们不是在做一个游戏，而是在建一座桥。”这座桥，连接的不仅是虚拟与现实，更是过去与未来、东方与西方。命运共同体，需要这座桥。</p><blockquote><p>“我信。我的孩子会信。孩子的孩子会信。我相信会再次看到蓝天。鲜花，挂满枝头。”<br>————周喆直《流浪地球2》</p></blockquote><h2 id="11-3A游戏是另一个“工业明珠”"><a href="#11-3A游戏是另一个“工业明珠”" class="headerlink" title="11 3A游戏是另一个“工业明珠”"></a>11 3A游戏是另一个“工业明珠”</h2><p>游戏是一个产业，大型游戏的开发本身就是一个高难度的系统工程。我自己也研究过一段时间游戏开发，尝试使用Unity、Cocos2d、GoDot等工具来学习和开发简单的小游戏。可以说，游戏开发是软件开发项目中涉及领域最广、综合程度最高的一类项目，除了一般软件开发中涉及到的系统设计、编码、测试、运维，特别强调UI和UE、产品运营、宣发，还额外包括概念设计、2D/3D建模、动效（TA）、数值策划、关卡设计、文案、配音和声效、MOD和社区管理，甚至是更基础技术层面的动态捕捉、3D引擎、多平台适配和性能优化、GPU和大数据计算、人工智能模型等等等等。正因为涉及的技术方面和工作内容非常多，因此一个现象级的电子游戏往往被称之为3A游戏，就是指开发需要投入大量的金钱（A lot of money）、大量的资源投入（A lot of resources）、大量的时间（A lot of time）。</p><p>游戏科学果断放弃Unreal4，半路转投Unreal5引擎，享受到了新引擎带来的技术红利：Nanite虚拟化集合体和Lumen动态光照技术，可以在游戏世界中体现极为细致的黄静细节和极具真实感的动态阴影，极大提升了玩家的视觉体验，但这些仅是运用，毕竟Unreal并不是国产的游戏引擎。</p><p>《黑神话：悟空》的场景设定令人印象深刻。制作团队远赴各地名胜古迹，通过实景扫描技术，将古代建筑和地貌景观细腻地刻画在游戏中。</p><p>此处引用参与过《黑神话：悟空》扫描工作的结构数字工程师嘉恒（@劫后余生）的知乎回答，可以一斑窥全豹：<br><a href="https://www.zhihu.com/question/665320697/answer/3613646265" target="_blank" rel="noopener">网友发现《黑神话：悟空》误将钢筋扫描至游戏中，如何评价游戏场景实景扫描这样的做法？是怎么办到的？</a></p><p>3A游戏和好莱坞大片的本质都是造梦，但造梦这件事是超不出人类认知的边界。3A游戏和好莱坞大片造梦的边界就在那，无非是西方奇幻、超级英雄、太空史诗的那些东西，了不起的造梦师，能够拓展人们做梦边界，能够将梦境真实地以华丽的姿态呈现出来的人，两只手都能数的过来。剩下的产品，无非都是些流水线作品。近几年好莱坞的流水线产品也是一茬不如一茬，而且，无论是好莱坞还是3A大作，还整天往巧克力里掺shi。无论电影、动画、还是游戏，要想发展都必须走上工业化的道路，依靠小作坊和个人英雄主义的时代已经一去不复返了，这个“明珠”早晚我们也要拿下。</p><h2 id="100-为什么是现在？"><a href="#100-为什么是现在？" class="headerlink" title="100 为什么是现在？"></a>100 为什么是现在？</h2><blockquote><p>文化是最有效的宣传武器。</p></blockquote><p>游戏表面看是一个内容娱乐行业，实际是算力发展、人类科技爆发的重要驱动力。《黑神话：悟空》的游戏完成度非常高，其背后有很多相关国产科技产业爆发的影子。</p><p>在我看来，最好的文化输出永远在于做好菜，而不在于教人这东西是什么，该怎么吃。有人可能觉得老外只知道吃，不知道这东西后面的背景，是亵渎了我们的文化。但一方面，如果老外觉得好吃，自然会对菜后面的文化有兴趣。而如果菜不好吃，你去絮絮叨叨这背后的文化就很没劲了。</p><p>另一方面，中华文化的材料就在这里，你做不出好菜，别人可就拿过去做菜了，那个时候，别说菜背后的文化不保了，整个菜背后的文化别人完全可以现编，然后用媒体的力量让所有人都觉得编的那个才是对的。远的，有《木乃伊》，有日版《西游记》。近的，有奈飞的《三体》，有《刺客信条:影》。</p><p>西游记的故事，山海经的妖怪，中国神话的世界观，你不去做，老外就能拿过去给你加个好莱坞情节和LGBT的黑人女主，霍霍了，然后给世界洗脑说孙悟空其实就是黑人。</p><p>但现在，《黑神话：悟空》做出来了，用非常炸裂的方式把原汁原味的中式奇幻的世界观和设定印进老外的脑子里了，在我看来这是件功德无量的事情。</p><p>中国国力的提升，已经成为屋子中不可忽视的大象，我们的魔法部（MOFA：Ministry of Foreign Affairs）已经无法再韬光养晦，魔法部官员在公开场合开始说硬话。在软实力上，是时候打一波配合战、突击战，让我们航母到达的地方，除了用上中国的工业品，也能够看到中国的电影、玩上中国的游戏。这就是自由贸易的精髓。</p><p>//此处补充耿爽在联合国大会上的嚣张坐姿。</p><p>P社老玩家都知道一个游戏术语叫“造宣称”，是发动对外战争前的必要前置，之前一直不明白什么叫做“造宣称”，现在就好理解多了。</p><h2 id="101-中国单机游戏历程：从文化舶来到本土复兴"><a href="#101-中国单机游戏历程：从文化舶来到本土复兴" class="headerlink" title="101 中国单机游戏历程：从文化舶来到本土复兴"></a>101 中国单机游戏历程：从文化舶来到本土复兴</h2><p>包了那么大一盘饺子，最终还是为了这碟醋。</p><p>中国本土单机电子游戏，就像中国男足一样，背负了太多、太久的期望，无数粉丝持之以恒、终年如一日的支持，就是希望能够有一天在这个领域开出花、结出果，可惜一年又一年，花开花落，收获寥寥啊。</p><h3 id="1990年代：台湾与日本的游戏启蒙"><a href="#1990年代：台湾与日本的游戏启蒙" class="headerlink" title="1990年代：台湾与日本的游戏启蒙"></a>1990年代：台湾与日本的游戏启蒙</h3><p>中国单机游戏的萌芽期深受台湾和日本游戏产业的影响。由于大陆普及计算机大约是在1995年以后，因此在此之前，看过用过计算机的人凤毛麟角，加上早期编程语言简陋、学习门槛高，大陆本土几乎不可能拥有自己的游戏开发市场。因此，都是引入台湾和近邻日本的游戏，和主机游戏一样，早期硬核玩家基本掌握繁体字库和日语字库的加载技能，还有就是通过修改DOS启动配置msconfig，降低640K的基本内存消耗，使之能够加载比较大的游戏。</p><p>台湾大宇资讯的《仙剑奇侠传》（1995）和《轩辕剑》系列，凭借深厚的武侠叙事与东方美学，成为大陆玩家的“国风启蒙”，其回合制玩法和多结局设计被大陆开发者广泛借鉴；《大富翁》系列更是老幼咸宜的桌面休闲游戏开拓者和常青树，从1989年第一代发布以来，至今已经出到11代，可以说是历史最悠久的中文游戏。《天使帝国》系列、《明星志愿》等也颇具特色。</p><p>台湾智冠科技则通过《金庸群侠传》（1996）将开放世界概念引入国产游戏，其自由探索与武功系统至今被奉为经典。汉堂的《炎龙骑士团》系列，出色画面与剧情，使得一众老粉巴巴地盼着IP能重生。</p><p>与此同时，日本和欧美的游戏通过盗版渠道渗透大陆市场。光荣的《太阁立志传》《信长之野望》《三国志》《大航海时代》《提督之决断》系列（包括英杰传、孔明传、曹操传）、EA的《极品飞车》《FIFA》《模拟人生》系列、卡普空的《生化危机》系列，这些高质量的游戏作品，既让玩家惊叹于工业化水准，也刺激了玩家对本土游戏发展的前景产生了无限的遐想和期盼。</p><p>其中，个人印象深刻的游戏一是《大航海时代II》极大的增加了我学习世界地理热情，二是《不可思议的机器》（tim，The Incredible Machine）基于物理的益智解谜游戏。此外还有天堂鸟和TGL的一众特色游戏、MicroProse的文明、西木的C&amp;C（红色警戒的前身）、Blizzard早期的魔兽争霸II、开创FPS类型的DOOM等等。</p><h3 id="1990年代末-2000年代初：血狮之殇和美游独霸"><a href="#1990年代末-2000年代初：血狮之殇和美游独霸" class="headerlink" title="1990年代末-2000年代初：血狮之殇和美游独霸"></a>1990年代末-2000年代初：血狮之殇和美游独霸</h3><p>《红色警戒2》和《星际争霸》的横空出世，席卷了大陆网吧，进入了欧美独霸的时代。</p><p>Bliizard依靠《魔兽争霸III》、《星际争霸》、《暗黑破坏神II》多款精品游戏，奠定了单机游戏霸主的地位，暴雪出品必属精品，一时之间风光无限。那时候的EA还能出产不少精品，西木的红警也仍在潮流的后期，Ubi开始从游戏发行转型为游戏开发，微软不满足于纸牌和扫雷发行了《帝国时代》《模拟飞行》《机甲战士》，并利用自己庞大的现金流收购了这些游戏的开发工作室，但又转头Xbox。Lucas Arts持续出产画面越来越精美的《猴岛小英雄》系列。Pyro工作室在98年开发了惊艳的《盟军敢死队》，开创了一个新的即时策略游戏类型，后继者都难出其右。这些风靡一时的游戏不仅支持单人游玩，大多具备了局域网互联对战功能，在网吧这一具有时代性产物的双重加持下，迅速风靡市场，成为了青少年的一种社交活动方式。也由此引入了电子竞技概念。</p><p>大陆游戏产业起步于技术与市场的双重夹缝中。1997年，尚洋电子的《血狮》以“保卫中国”的爱国营销引发狂热期待，首日预订量超4万套，但粗糙的画面与崩溃的操作导致口碑崩塌，最终销量不足2万套，成为国产游戏史上标志性失败。其失败不仅重创玩家信心，更导致资本对单机游戏的长期冷遇。黑暗之中只有少数几点星火：</p><ul><li><p>目标软件的《铁甲风暴》（1998）以媲美《红色警戒》的品质成为国产即时战略标杆，首款出海游戏；《傲世三国》（2001）便以双地图设计和武将技系统对标《帝国时代》，成为首款登上E3展的国产游戏，被IGN评为8分（同期《暗黑破坏神2》为8.3分）。</p></li><li><p>西山居的《剑侠情缘》系列（1997-2002）开创武侠RPG新范式，2000年《剑侠情缘2》以38元低价策略创下18万套销量纪录，但开发成本高达300万，盈利艰难；</p></li><li><p>前导软件尝试影游联动，推出《水浒传聚义篇》（1998），却因资金链断裂未能完成《齐天大圣》3D项目。</p></li></ul><h3 id="2000年代中-2010年代：网游冲击与单机凋零"><a href="#2000年代中-2010年代：网游冲击与单机凋零" class="headerlink" title="2000年代中-2010年代：网游冲击与单机凋零"></a>2000年代中-2010年代：网游冲击与单机凋零</h3><p>抄袭大师Blizzard发布的《魔兽世界》是一个里程碑式时间，NGA依靠这个游戏的爆发奠定了自己的江湖地位。互联网游戏开始占领游戏市场，游戏的盈利模式从原来单一买断制向点卡、月卡订阅模式转变。</p><p>2000年后，盗版肆虐与政策限制（如游戏机禁令）迫使单机厂商转型。盛大代理韩国网游《热血传奇》（2001），以点卡付费模式解决盗版难题，创下70万同时在线纪录；网易自研《大话西游》（2001）通过社区化设计实现200万美元利润，成为首个靠游戏扭亏为盈的互联网公司。<br>单机市场在网游的“降维打击”下迅速萎缩：金山放弃单机转向《剑侠情缘网络版》（2003）；目标软件的《秦殇》（2002）虽获IGN 8.5分好评，但68元售价仅卖出20万套，盗版传播量却超千万。</p><p>以浩方为代表的对战平台，仍在啃局域网游戏的老本，不思进取，浩方06年被盛大收购后迅速衰退。</p><h3 id="2010年代至今：本土独立游戏崛起与3A破局"><a href="#2010年代至今：本土独立游戏崛起与3A破局" class="headerlink" title="2010年代至今：本土独立游戏崛起与3A破局"></a>2010年代至今：本土独立游戏崛起与3A破局</h3><p>2010年后，Steam平台兴起与玩家正版意识觉醒为单机游戏带来转机：</p><p>传统厂商回归：西山居重启《剑侠情缘》单机版，尝试“影游联动+开放世界”模式；腾讯、网易成立3A工作室，布局《王者荣耀·世界》等跨平台项目。</p><p>随着《黑神话：悟空》的大获全胜，资本市场和一众玩家开始逐步恢复对国产3A游戏的信心，愿意投资、愿意等、愿意买单，希望能够玩到更多给中国本土玩家倾情奉献的本土游戏。</p><h2 id="110-敢问路在何方：每代人都有自己的路要走"><a href="#110-敢问路在何方：每代人都有自己的路要走" class="headerlink" title="110 敢问路在何方：每代人都有自己的路要走"></a>110 敢问路在何方：每代人都有自己的路要走</h2><p>电子游戏，始终是一个“舶来品”，就像工业化和互联网一样，真正地融入社会，成为中华文明构成中的一份子，总是需要时间来磨合、吸收的。而中国单机游戏历程同时烙有“技术追赶与文化觉醒”的双重印记：作为原生文明早期受台湾与日本等次生文化的启蒙，经历本土融合产生的阵痛和失败，长期受到畸形网游市场的冲击并艰难求生，最终借助全球化技术与本土文化自信实现复兴。未来，如何在工业化体系与原创叙事间找到平衡，将是国产单机跨越“中等技术陷阱”的关键。</p><p>国产电子游戏和宣扬中国文化，殊途同归，应该怎么走，《黑神话：悟空》给出了一个非常好的模板和成功先例，作为一个玩家，仅能用金钱以及本文为喜欢的游戏支持了。</p><blockquote><p><strong>七律·和郭沫若同志</strong> <em>————毛泽东</em><br>一从大地起风雷，便有精生白骨堆。<br>僧是愚氓犹可训，妖为鬼蜮必成灾。<br>金猴奋起千钧棒，玉宇澄清万里埃。<br>今日欢呼孙大圣，只缘妖雾又重来。</p></blockquote><p>11月22日更新：祝贺销量2500万、steam同时在线人数历史第二、steam第三个百万好评如潮、steam通关率45%的《黑神话：悟空》获得金摇杆“年度终极游戏”、“最佳视觉设计”两项大奖，恭喜并再次感谢游戏科学。</p><p>全文更新于2025年2月。</p><h2 id="附：说明与参考资料"><a href="#附：说明与参考资料" class="headerlink" title="附：说明与参考资料"></a>附：说明与参考资料</h2><p>本文构思甚早，框架既定，也没有想到会写这么长，期间还多次依靠DeepSeek R1提供丰富内容和素材，包括参考资料。DeepSeek R1对于内容的提炼总结一针见血，章节标题基本都直接采纳，其行文亦有深度高度，限于篇幅，作者忍痛进行了筛减和整合。</p><p><span id="fn1"><a href="#a1">[1]</a></span>: <a href="https://www.163.com/dy/article/JJP1EBNN0534B975.html" target="_blank" rel="noopener">《黑神话：悟空》斩获TGA奖项的多重意义</a></p><p><span id="fn2"><a href="#a2">[2]</a></span>: <a href="https://www.thepaper.cn/newsDetail_forward_29642276" target="_blank" rel="noopener">年度最佳游戏为何不是《黑神话：悟空》？</a></p><p><span id="fn3"><a href="#a3">[3]</a></span>: <a href="https://www.163.com/dy/article/J4T1BNJG0553B6Y5.html" target="_blank" rel="noopener">美国公司想用政治正确搞死《黑神话：悟空》，结果却等于免费推广</a></p><p><span id="fn4"><a href="#a4">[4]</a></span>: <a href="https://www.163.com/dy/article/JA74H2F205268BP2.html" target="_blank" rel="noopener">玩了《黑神话：悟空》的海外玩家，开始怒怼政治正确媒体</a></p><p><span id="fn5"><a href="#a5">[5]</a></span>:<a href="https://www.163.com/dy/article/JA6CIT3S0525NNOQ.html" target="_blank" rel="noopener">《黑神话：悟空》游戏与传统文化的融合，如何实现文化创新输出？</a></p><p><span id="fn6"><a href="#a6">[6]</a></span>:<a href="https://news.qq.com/rain/a/20250207A094OY00" target="_blank" rel="noopener">《黑神话：悟空》全球热销对中华优秀传统文化对外传播的启示</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;黑神话：中国本土电子游戏的迷思&quot;&gt;&lt;a href=&quot;#黑神话：中国本土电子游戏的迷思&quot; class=&quot;headerlink&quot; title=&quot;黑神话：中国本土电子游戏的迷思&quot;&gt;&lt;/a&gt;黑神话：中国本土电子游戏的迷思&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;Some </summary>
      
    
    
    
    
    <category term="Video Games" scheme="http://gloomymoon.github.io/tags/Video-Games/"/>
    
  </entry>
  
  <entry>
    <title>The Data Science Task Force: Mission PDA</title>
    <link href="http://gloomymoon.github.io/2024/08/20/The-Data-Science-Task-Force-Mission-X/"/>
    <id>http://gloomymoon.github.io/2024/08/20/The-Data-Science-Task-Force-Mission-X/</id>
    <published>2024-08-20T07:46:59.000Z</published>
    <updated>2024-08-31T07:57:47.989Z</updated>
    
    <content type="html"><![CDATA[<h3 id="程序设计、数据结构和算法（PDA）"><a href="#程序设计、数据结构和算法（PDA）" class="headerlink" title="程序设计、数据结构和算法（PDA）"></a>程序设计、数据结构和算法（PDA）</h3><p>数据科学家应能够实施和理解数据收集于分析算法，并将其与现有软件和/或工具继承，他们应了解算法的时间和空间考量因素，以及与数值计算有关的特殊问题。<br>请注意，本质是领域借鉴了CS2013的多个知识领域，但并不重复：算法与复杂性（AL）、计算科学（CN）、编程语言（PL）和软件开发基础（SDF）。</p><table>  <tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul>    <li>通过算法思维解决问题。</li>    <li>开发和实现程序，包括与各种现有软件和/或工具的继承。</li>    <li>使用传统变成语言整合数据集和应用程序之间的接口。</li>    <li>在数据科学问题中使用为统计计算而设计的编程语言。</li>    <li>抽象数据类型（ADT）的知识和使用。</li>    <li>数据计算算法的知识和使用。</li>    <li>算法设计和分析。</li>    <li>影响算法复杂性和性能的因素。</li>    <li>复杂性分析和比较。</li>    </ul></td>    <td width="50%">    <ul>    <li>用编程语言设计一种算法，解决一个中小型问题。</li>    <li>用编程语言编写清晰、正确的代码，包括原始数据类型、引用、变量、表达式、赋值、I/O、控制接口、函数和循环。</li>    <li>在编程中采用良好的文档编制方法。</li>    <li>使用分解技术将程序模块化。</li>    <li>使用特定编程语言的标准程序库。</li>    <li>编写适当的数据库查询。</li>    <li>为特定问题选择合适的数据结构。</li>    <li>针对给定问题选择合适的算法</li>    <li>讨论时间和空间复杂性对算法实用性的重要性。</li>    </ul>    </td>  </tr>  <tr>     <th colspan="2">子领域</th>  </tr>  <tr>    <td width="50%">    PDA-算法思维与问题解决-T1、T2<br>    PDA-编程-T1、T2、E<br>    PDA-数据结构-T1、T2、E<br>    </td>    <td width="50%">    PDA-算法-T1、T2、E<br>    PDA-基本复杂性分析-T1、T2<br>    PDA-数值计算-T1、T2<br>    </td>  </tr></table><h4 id="PDA-算法思维与问题解决"><a href="#PDA-算法思维与问题解决" class="headerlink" title="PDA-算法思维与问题解决"></a>PDA-算法思维与问题解决</h4><p>为了开发正确、搞笑、清晰和可用的代码（无论是在数据分析和展示过程中还是在生产级系统中），数据科学家应具备基本的算法问题解决技能。</p><p><em>知识</em></p><p>T1：</p><ul><li>算法定义。</li><li>算法在解决问题过程中的重要性。</li><li>至少一种解决问题的正式方法。</li><li>面向对象的基本设计概念和原则。<ul><li>抽象。</li><li>封装和信息隐藏。</li><li>行为和实现分析。</li></ul></li></ul><p><em>技能</em></p><p>T1：</p><ul><li>使用代码以外的形式（如流程图或伪代码）描述问题解决方案。</li><li>以某种形式（如数据流图）绘制问题解决方案的数据流（输入、转换、输出）图。</li><li>确定输入（如数据、超参数、用户响应）和输出，这对执行程序解决问题至关重要。</li><li>识别多种抽象数据类型的数据组件和行为（参见PDA-数据结构）。</li></ul><p>T2：</p><ul><li>至少使用一种正式的方法来解决问题。</li></ul><p><em>品行</em></p><p>T1：</p><ul><li>准确描述算法和程序，算法不同于程序。</li><li>准确理解将大型问题分解为可实现的解决方案并用某种形式表达这些解决方案的原则性方法。</li></ul><h4 id="PDA-编程"><a href="#PDA-编程" class="headerlink" title="PDA-编程"></a>PDA-编程</h4><p>为了收集、分析和展示数据，数据科学家需要发展编程技能，并应精通基本的编程结构。由于数据科学家将于许多系统对接，因此他们应该能够开发独立或与现有软件和/或工具集成的程序。</p><p><em>知识</em></p><p>T1：</p><ul><li>核心编程概念。<ul><li>变量和原始数据类型。</li><li>表达式和赋值。</li><li>条件和迭代控制结构。</li><li>循环函数。</li><li>函数和参数传递。</li><li>简单输入/输出，包括文件或其他静态数据源。</li><li>异常情况。</li></ul></li><li>核心实践。<ul><li>文档。</li><li>测试。</li><li>版本控制。</li></ul></li><li>将程序分解为更小的片段。</li><li>错误类型（语法、逻辑、运行时）、可能发生的方式及其处理方式。</li><li>查询和解析数据源的方法。</li></ul><p>T2：</p><ul><li>定期重构和程序维护。</li><li>各种测试和调试策略。</li><li>应用程序接口的效用，何时寻找应用程序接口。</li></ul><p>E：</p><ul><li>高级概念。<ul><li>内联/匿名函数（如Python中的Lambda函数）。</li><li>函数和程序的变量参数表。</li><li>类和对象。</li></ul></li></ul><p><em>技能</em></p><ul><li>编写包含上述核心概念和实现的计划。</li><li>推到代码段的执行，并阐明其计算概要。</li><li>运用分解技术将程序分解成更小的代码片段。</li><li>利用适当的技术（如数据库查询、API调用、正则表达式）处理来自选定来源（如数据库、电子表格、文本文档、XML）的数据。</li><li>使用循环和迭代构建程序解决方案。</li><li>使用一致的文档和编程风格标准，以提高软件的可读性和可维护性。</li><li>应用测试和调试程序的策略。</li></ul><p>T2：</p><ul><li>说明定期重构和维护程序的必要性。</li><li>按照核心实践对程序进行重构、维护和改进。</li><li>使用类和对象构建程序解决方案。</li><li>使用现代集成开发环境和相关工具（如单元测试工具和可视化调试器）开发程序。</li><li>使用编程语言提供的标准程序库构建程序。</li><li>将典型的应用程序接口（API）集成到软件中。</li></ul><p>E：</p><ul><li>使用模板和通用功能有效设计和实施程序解决方案。</li><li>设计并实施独特的应用程序接口（API）。</li><li>使用专门技术（如自然语言处理、图像处理等）收集和解析数据（参考知识域：数据采集、管理和治理）。</li><li>阅读、理解、编写和调试包含高级概念的程序。</li></ul><p><em>品行</em><br>T1：</p><ul><li>坚定的致力于在编程实践中运用软件工程概念和设计原则（参考知识域：软件开发与维护）。</li><li>主动超越直接传授的知识。认识到编程结构和方法是通用的，在许多情况下都有用。</li><li>超越简单的解决方案，用于创新。数据科学家不应拘泥于调整现有解决方案。</li></ul><h4 id="PDA-数据结构"><a href="#PDA-数据结构" class="headerlink" title="PDA-数据结构"></a>PDA-数据结构</h4><p>为了编写有效和高效的代码，数据科学家应该了解各种数据结构，能够使用它们并理解选择一种数据结构对另一种数据结构的影响。鉴于矩阵在许多数据科学应用中的作用，这里将特别关注矩阵的表示和操作。</p><p><em>知识</em><br>T1：</p><ul><li>基本数据结构和抽象数据类型（ADT）（列表、数组、堆栈、队列、字符串、集合、记录/结构、映射、哈希表）。<ul><li>目的。</li><li>用法。</li></ul></li><li>基本矩阵表示结构（稀疏/密集、行、列）<ul><li>矩阵表示类型。</li><li>基于表示类型的基本矩阵运算的利弊。</li></ul></li></ul><p>T2：</p><ul><li>高级结构（树、图）。<ul><li>目的。</li><li>用法。</li></ul></li></ul><p>E：</p><ul><li>矩阵操作优化。</li></ul><p><em>技能</em><br>T1：</p><ul><li>在编程中适当选择基本数据结构。</li><li>适当使用特定编程语言的标准数据类型库。</li></ul><p>T2：</p><ul><li>在编程中适当选择高级数据类型。</li><li>适当使用特定编程语言的标准库。</li></ul><p>E：</p><ul><li>实施连贯的抽象数据类型，在组件和行为之间实现松散耦合。</li><li>比较/对比各种数据结构的标准操作（如查找、插入、删除）的时间/空间。</li></ul><p><em>品行</em><br>T1：</p><ul><li>实施和数据结构选择的彻底性及其对使用、效率（时间/空间）和可读性的影响。</li></ul><h4 id="PDA-算法"><a href="#PDA-算法" class="headerlink" title="PDA-算法"></a>PDA-算法</h4><p>数据科学家应认识到，算法的选择会对解决问题所需的时间和空间产生影响，数据科学家应熟悉一系列算法技术，以便在特定情况下选择合适的算法。</p><p><em>知识</em><br>T1：</p><ul><li>简单的数据算法，如计算列表的平均值、找出列表中的最小值、最大值或模式。</li><li>排序和搜索。<ul><li>顺序搜索和二分搜索。</li><li>O($n^2$)（如插入）和O(n$\log$n)（如合并）排序。</li><li>搜索和排序的随机算法（如快速排序）。</li><li>基于散列的搜索和排序的潜在效率优势。</li></ul></li><li>图的属性：连通性、间距、中心性等。</li><li>图形算法。</li><li>基本算法策略，如贪婪、分治。</li><li>线性系统求解算法。</li></ul><p>T2：</p><ul><li>组合优化问题算法。</li><li>启发式优化技术。</li></ul><p>E：</p><ul><li>散列和散列函数。</li></ul><p><em>技能</em><br>T1：</p><ul><li>应用简单的数据算法（如计算平均数、求最小值等）。</li><li>应用搜索和排序算法。</li><li>对比各种基于数组的搜索和排序算法的利弊。</li><li>使用广度或深度优先算法的一般框架执行图或树的遍历。</li><li>使用高效的算法（如贪婪算法）找出图或树中的最短路径。</li><li>在适当的问题中应用线性系统求解器。</li></ul><p>T2：</p><ul><li>使用高效算法识别通过图或树的最大或最小流。</li><li>使用组合优化问题的常用算法（如分治和边界算法）。</li><li>在适当的问题上应用启发式优化技术（粒子群、遗传算法、进化）。</li><li>针对适当的问题实施动态编程解决方案。</li></ul><p>E：</p><ul><li>在分布式系统或数据上实施或使用搜索/排序算法。</li><li>在上下文中比较散列函数。</li><li>图表。<ul><li>执行遍历、最短路径和流量算法。</li></ul></li><li>分析随机算法。</li></ul><p><em>品行</em><br>T1：</p><ul><li>在选择算法技术时要灵活准确，要知道通常有多种算法技术可以成功解决某个问题。</li><li>清楚地认识到算法的选择对效率有重大影响。</li><li>敏锐地认识到效率（时间、空间）对客户、消费者和维护者等所有代码利益相关方的影响。</li></ul><h4 id="PRA-基本复杂性分析"><a href="#PRA-基本复杂性分析" class="headerlink" title="PRA-基本复杂性分析"></a>PRA-基本复杂性分析</h4><p>数据科学家应了解解决问题所需的时间和空间，并应知道某些问题可能无法在合理的时间内解决。他们还应考虑到运行代码的平台将如何安排任务。</p><p><em>知识</em><br>T1：</p><ul><li>时间和空间复杂性的定义。</li><li>算法的最佳情况、预期情况和最差情况之间的差异。</li><li>在管理时间和空间复杂性方面权衡利弊。</li><li>用于分析算法的分类标准，例如：<ul><li>确定性与非确定性。</li><li>时间/空间层次。</li></ul></li></ul><p><em>技能</em><br>T1：</p><ul><li>对算法效率（如操作次数）进行非正式比较。</li><li>在不同大小的输入上执行算法并比较性能。</li><li>举例说明实现和算法选择对执行时间或空间的影响。</li><li>解释问题表征/数据结构和算法之间的关系/耦合。</li></ul><p>T2：</p><ul><li>正式应用各种分类标准来理解算法。</li></ul><p><em>品行</em><br>T1：</p><ul><li>全面评估空间/时间复杂性。在管理时间和空间复杂性时可能需要权衡利弊，并了解这些全很利弊对客户/软件用户的影响。</li></ul><h4 id="PRA-数值计算"><a href="#PRA-数值计算" class="headerlink" title="PRA-数值计算"></a>PRA-数值计算</h4><p>数据科学家解决问题的类型通常涉及数值计算，数据科学家应了解数值表示的能力和限制，他们还应了解标准数值计算算法及其用途。</p><p><em>知识</em><br>T1：</p><ul><li>随机数生成器（RNG）。</li><li>概率分布模拟。</li><li>用比特表示数值的局限性及其对结果中误差的累积（溢出、下溢、舍入、截断）的影响。</li><li>数字表示法对计算法杂性的影响。</li></ul><p>T2：</p><ul><li>用于数据分析的高级数值算法所涉及的算法和数学方法，如：<ul><li>主成分分析（PCA）。</li><li>奇异值分解（DVD）。</li><li>特征值分解。</li><li>牛顿法。</li><li>蒙特卡罗模拟。</li></ul></li><li>良好的问题表征与解决数字问题的数学模型之间的联系，例如：<ul><li>使用SVD表示文件。</li><li>用邻接表或稀疏矩阵表示图形。</li><li>用KD数表示度量空间。</li></ul></li></ul><p><em>技能</em><br>T1：</p><ul><li>描述数值计算算法和流程如何影响模拟执行、数据采样和数据生成。</li><li>描述适当的数值计算算法，以进行数据分析，并认识到其局限性和数值驱动的限制。</li><li>使用随机数生成器和模拟概率分布来：<ul><li>利用非确定性算法实现数据分布的可重复性。</li><li>在算法中引入非确定性，以确保适当的统计和数值条件。</li></ul></li></ul><p>T2：</p><ul><li>应用适当的数字算法解决各类问题，算法可能包括（非详尽、不分优先级）：<ul><li>主成分分析（PCA）。</li><li>奇异值分解（DVD）。</li><li>特征值分解。</li><li>牛顿法。</li><li>蒙特卡罗模拟。</li></ul></li></ul><p><em>品行</em><br>T1：</p><ul><li>精通（伪）随机数生成的优势和局限性。</li><li>敏锐地认识到数值计算算法的局限性。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;程序设计、数据结构和算法（PDA）&quot;&gt;&lt;a href=&quot;#程序设计、数据结构和算法（PDA）&quot; class=&quot;headerlink&quot; title=&quot;程序设计、数据结构和算法（PDA）&quot;&gt;&lt;/a&gt;程序设计、数据结构和算法（PDA）&lt;/h3&gt;&lt;p&gt;数据科学家应能够实施</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>The Data Science Task Force: Mission PR</title>
    <link href="http://gloomymoon.github.io/2024/08/14/The-Data-Science-Task-Force-Mission-IX/"/>
    <id>http://gloomymoon.github.io/2024/08/14/The-Data-Science-Task-Force-Mission-IX/</id>
    <published>2024-08-14T12:14:46.000Z</published>
    <updated>2024-08-14T12:18:26.423Z</updated>
    
    <content type="html"><![CDATA[<h3 id="专业精神（PR）"><a href="#专业精神（PR）" class="headerlink" title="专业精神（PR）"></a>专业精神（PR）</h3><p>在技术活动中，数据科学家应以负责任的方式行事，为本专业争光。其中一个方面是积极主动地寻求利益，进行积极的研发，并以负责和符合道德规范的方式开展工作。文献<sup><span id="a1"><a href="#fn1">[1]</a></span></sup>概括性的阐述了其中的许多内容。本领域将重点介绍数据科学家特别关注的相关问题。</p><table>  <tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul>    <li>能力的含义以及展示能力。</li>    <li>获得与数据科学家特别相关的能力。</li>    <li>获取专业知识/掌握或扩展能力，期刊、会议、课程、网络研讨会的作用。</li>    <li>技术变革及其对能力的影响。</li>    <li>专业协会在持续业务发展和专业活动中的作用。</li>    </ul></td>    <td width="50%">    <ul>    <li>认识支撑数据科学专业方法的知识范围。</li>    <li>展示支撑当前或持续的数据科学专业方法的技能。</li>    <li>建立一套自信、有效和专业的数据科学方法，并有能力保持这种方法。</li>    </ul>    </td>  </tr>  <tr>     <th colspan="2">子领域</th>  </tr>  <tr>    <td width="50%">    PR-可持续职业发展-T1<br>    PR-沟通-T1<br>    PR-团队合作-T1<br>    PR-经济考量-T2<br>    </td>    <td width="50%">    PR-隐私与保密-T1<br>    PR-伦理考量-T1<br>    PR-法律考量-T2<br>    PR-知识产权-E<br>    PR-关于自动化-E<br>    </td>  </tr></table><h4 id="PR-可持续职业发展-T1"><a href="#PR-可持续职业发展-T1" class="headerlink" title="PR-可持续职业发展-T1"></a>PR-可持续职业发展-T1</h4><p>专业性的本质体现在能够胜任数据科学某些方面的工作，专业人员富有责任来承担他们能够胜任的任务。因此，向利益相关者（如雇主）持续展示和证明专业能力信息是有意义的。</p><p><em>知识</em></p><ul><li>能力的含义以及展示能力。</li><li>获取专业知识/掌握或扩展能力：期刊、会议、课程、网络研讨会的作用。</li><li>技术变革及其对能力的影响。</li><li>专业协会在可持续职业发展和专业活动中的作用。</li></ul><p><em>技能</em></p><ul><li>说明保持能力对专业的数据科学家的重要性。</li><li>说明专业人员通常会采取哪些步骤来扩展能力或掌握知识，并结识后者的优势。</li><li>论证专业协会再支持职业发展中的重要作用。</li></ul><p><em>品行</em></p><ul><li>积极主动、充满热情的认识到数据科学是一个瞬息万变的领域，与时俱进以及了解如何与时俱进至关重要。</li></ul><h4 id="PR-沟通-T1"><a href="#PR-沟通-T1" class="headerlink" title="PR-沟通-T1"></a>PR-沟通-T1</h4><p>在各种情况下，数据科学家都需要与不同受众进行交流，这种交流可能是口头的、书面的或电子的。数据科学需要经常就该专业可以发挥的作用进行讨论，交流数据科学过程的多个方面，传达可能导致的变化和结果或提供新的见解。能够阐明变革的必要性并对变革的结果保持敏感是该专业重要的特质。这些专业活动可能需要能够就某些情况下的局限性进行讨论，并提出研究活动的建议。</p><p>数据科学家的交流必须以及与证据的决策方法为基础，在机器学习和自动化的背景下，这一点尤为重要，因为决策的原因需要充分阐述。</p><p>机器学习发展的一个重要结果是，机器能够理解自然语言（因此也能理解语音输入），从而可用于机器人、文字处理器或智能搜索引擎（如Siri、Cortana、Google Assistant、Alexa）等领域。</p><p><em>知识</em></p><ul><li>不同的交流形式（书面、口头、电子）及其有效使用。</li><li>与数据科学相关的技术文献。</li><li>与数据科学交流相关的受众，包括小型团体、大型团体、专家和非专家、年轻群体、高级管理人员、机器，以及每种情况下有效交流的要素。</li></ul><p><em>技能</em></p><ul><li>评估与数据科学各方面相关的技术文献。</li><li>为同事编写技术文档，指导技术开发。</li><li>为对数据科学感兴趣的各类受众制作演示文稿。</li><li>为高级管理人员编制情况报告，概述数据科学调查所产生的重大举措，包括必要时与管理改革相关的问题。</li></ul><p><em>品行</em><br>T1：</p><ul><li>根据相关技术的变化进行调整，知道如何有效地进行调整，并对新的发展机会保持警觉。</li><li>积极主动，自我激励，确定新学习和新体验的意义。</li><li>准确并看待自己在知识方面的长处和短处。</li></ul><h4 id="PR-团队合作-T1"><a href="#PR-团队合作-T1" class="headerlink" title="PR-团队合作-T1"></a>PR-团队合作-T1</h4><p>数据科学家通常是一个团队的成员，可能需要担任团队领导，或支持团队工作。了解不同团队角色的性质以及团队的动态非常重要。在团队合作方面，数据科学家通常不仅需要能够与使用不同工具的数据科学家合作，而且需要能够与不同问题解决者合作。</p><p><em>知识</em></p><ul><li>团队选择，团队成员的能力和技能需要互补。</li><li>团队动态和团队纪律。</li><li>有效团队运作的要素。</li></ul><p><em>技能</em></p><ul><li>概述处理团队内部冲突情况的步骤。</li><li>总结在选择团队进行特定数据科学研究时需要考虑的因素。</li><li>认识到数据科学研究团队领导应具备的素质。</li></ul><p><em>品行</em></p><ul><li>尊重他人，善于合作，对团队组建和运作中的敏感问题采取适当的行动。</li><li>愿意与他人合作并采取适当行动，在与他人合作是摒弃不重要的分歧。</li></ul><h4 id="PR-经济考量-T2"><a href="#PR-经济考量-T2" class="headerlink" title="PR-经济考量-T2"></a>PR-经济考量-T2</h4><p>数据科学家应证明自己的立场以及所从事活动的类型是正确的。</p><p><em>知识</em></p><ul><li>高质量数据集机器维护的成本和价值。</li><li>数据科学活动的成本说明。</li><li>项目成本估算。</li><li>数据科学的提升效果。</li><li>数据科学活动的自动化。</li></ul><p><em>技能</em></p><ul><li>评估数据集对组织的价值，同时考虑维护的成本要求。</li><li>论证组织应定期收集那些数据，涉及相关的数据收集流程，确定应包含的属性和收集形式，并注重质量。</li><li>评估为特定目的收集高质量数据的成本（一般为资源成本）。</li><li>证明在组织内创建数据科学活动的和理想，并量化其成本。</li><li>推断组织开展特定调查研究项目的价值。</li><li>检测开展内部调研所需的资源，并与外包此类活动进行比较。</li><li>评估与特定活动自动化相关的成本。</li></ul><p><em>品行</em></p><ul><li>重视数据科学活动的相关成本，并采取适当的行为妥善使用。</li></ul><h4 id="PR-隐私与保密-T1"><a href="#PR-隐私与保密-T1" class="headerlink" title="PR-隐私与保密-T1"></a>PR-隐私与保密-T1</h4><p>获取数据的方式多种多样，可以方位数据库、使用调查或问卷、采取各种手段获取某些资源，甚至可以开发并使用物联网、专业传感器、视频捕捉和监控系统。虽然获取各种信息非常重要，但是专业人员必须合法地获取信息，确保信息的准确性，保护个人、组织和其他群里的权利。</p><p>注意该子域与数据隐私知识领域的关系。</p><p><em>知识</em></p><ul><li>信息自由。</li><li>数据保护法规，包括《通用数据保护条例》（GDPR）。</li><li>隐私立法。</li><li>数据保密的方法。</li><li>对隐私和保密的威胁。</li><li>国际层面。</li></ul><p><em>技能</em></p><ul><li>说明维护数据机密性的技术机制。</li><li>比较不同国家的隐私立法，强调各种差异引发的问题。</li><li>认识到使用视频、语音和人脸识别软件所产生的隐私和保密问题。</li><li>参照国际标准，总结特定隐私立法的适用环境。</li></ul><p><em>品行</em></p><ul><li>负责维护隐私和保密性，确保对数据科学活动的信心。</li><li>负责任地使用深度学习，因为在很多问题上深度学习的能力超出了所需。</li><li>以合作和道德的方式致力于解决深度伪造有关的社会和政治问题。</li></ul><p><em>背景问题</em></p><ul><li>与隐私和安全相关的法律框架因国家而异。</li></ul><h4 id="PR-伦理考量-T1"><a href="#PR-伦理考量-T1" class="headerlink" title="PR-伦理考量-T1"></a>PR-伦理考量-T1</h4><p>伦理问题对于所有参与计算和信息活动的人来说都至关重要，这一点在《ACM 道德与职业行为准则》中已有广泛论述。这些活动秉持如下基本观点，即专业人士指应承担他们能够胜任的任务，即便如此，他们在执行该类任务时应体现出掌握各种实践经验。保持或提高能力至关重要，提高对法律和道德问题的认识必须成为数据科学家工作的基础。专业人士应将与其决策相关的伦理问题视为一个非常重要的起点，使他们能够认识到自己是“独立的、符合伦理的代理人”。</p><p><em>知识</em></p><ul><li>与能力和保持能力有关的伦理问题。</li><li>与数据及其使用相关的保密问题。</li><li>《通用数据保护条例》（GDPR）。</li><li>数据（包括样本数据）需要真正代表某种情况。</li><li>对数据和算法中的偏见及其可能性质的认识，检查和避免偏见的机制。</li><li>算法透明度和问责制。</li></ul><p><em>技能</em></p><ul><li>说明数据科学家可能超出其能力范围的一系列情况，并确定缓解这些情况的步骤。</li><li>展示确定数据集或算法无偏见的技术。</li><li>讨论加入数据科学领域专业人员网络的好处。</li></ul><p><em>品行</em></p><ul><li>对与收集和使用数据相关的深层伦理问题做出回应。</li><li>对偏见问题做出反应，并积极设法消除偏见。</li><li>在推动数据科学发展的过程中自我指导、自我激励。</li></ul><h4 id="PR-法律考量-T2"><a href="#PR-法律考量-T2" class="headerlink" title="PR-法律考量-T2"></a>PR-法律考量-T2</h4><p>近年来，计算机犯罪的数量和严重程度都在持续增加。在许多情况下，犯罪分子给许多组织带来了破坏甚至是混乱。他们的威胁不容忽视，专业人士必须采取措施应对可能出现的严重破坏。在许多情况下，法律已经做出调整以应对这些趋势，但这是一个不断变化和调整的领域。</p><p><em>知识</em></p><ul><li>与数据科学相关的计算机犯罪。</li><li>网络安全。</li><li>预防犯罪。</li><li>侦查犯罪活动的机制，包括采取不同方法的必要性。</li><li>恢复机制和保持100%运行。</li><li>打击计算机犯罪的法律。</li></ul><p><em>技能</em></p><ul><li>评估一系列侦查既定形式犯罪活动的机制。</li><li>说明采用多种不同方法应对威胁的可取性。</li></ul><p><em>品行</em></p><ul><li>在面对可能的犯罪情况时，具备责任心和职业道德，但态度警觉、关系他人。</li></ul><p><em>背景问题</em></p><ul><li>各国的法律框架可能有所不同。</li></ul><h4 id="PR-知识产权-E"><a href="#PR-知识产权-E" class="headerlink" title="PR-知识产权-E"></a>PR-知识产权-E</h4><p>知识产权（IPR），如版权、专利、外观设计、商标和著作人身权（Moral rights），旨在保护人类思想创造物的创造者或所有者。著作人身权包括创造者作为知识产权的署名权（IP），以及避免创造物受到贬损的权利。对于数据科学家来说，需要保护的对象（可能方式不同）包括软件、设计（包括图形用户界面（GUI））、数据集、著作人身权和名誉。商业秘密也可能与此相关。</p><p><em>知识</em></p><ul><li>专利、版权、商标、商业秘密、著作人身权。</li><li>哪些与数据科学相关的知识产权可以保护，哪些不能保护，以及有哪些保护类型可供选择。</li><li>可以和不可以获得法律保护的数据科学相关知识产权的类型以及可获得的保护类型。</li><li>与知识产权、知识产权所有权、知识产权的地域相关的法规，包括国际协定的影响和知识产权的时限问题。</li><li>自动归属和需要注册的知识产权种类，包括获得注册知识产权的程序概述。</li><li>侵犯他人权利和有效利用受保护知识产权的可能性。</li></ul><p><em>技能</em></p><ul><li>描述与数据科学家相关的知识产权类型。</li><li>论证专利、版权、外观设计和商标之间的区别，并说明它们在数据科学中的应用。</li><li>说明商业秘密在数据科学中的作用。</li><li>说明知识产权注册所涉及的程序。</li><li>解释与知识产权所有权和著作人身权有关的问题。</li><li>评估使用受保护知识产权所涉及的风险，以及有效克服这些风险的方法。</li></ul><p><em>品行</em></p><ul><li>对知识产权的存在和重要性，以及知识产权带来的责任和机遇有敏锐的反应。</li></ul><p><em>背景问题</em></p><ul><li>各国在处理与知识产权相关的道德和法律框架方面的周全性和适应性各不相同，专利律师通常可以提供更多建议。</li></ul><h5 id="PR-关于自动化-E"><a href="#PR-关于自动化-E" class="headerlink" title="PR-关于自动化-E"></a>PR-关于自动化-E</h5><p>自动化常常会引起人们对失业的担忧，一般来说，也会引起人们对机器不合理行为的担忧。专业人士应寻求对机器行为的解释，相关问题是《关于算法透明度和问责制的声明》<sup><span id="a2"><a href="#fn2">[2]</a></span></sup>和《实现算法透明化和问责制》<sup><span id="a3"><a href="#fn3">[3]</a>的主题。自动化可能会用于可造成严重损失的危急情况下，这时人们通常期望机器按照与人类行为相一致的道德规范运行。</span></sup></p><p><em>知识</em></p><ul><li>自动化及其优势和理由。</li><li>危急情况下自动化面临的特殊问题。</li><li>算法的透明度和问责制。</li></ul><p><em>技能</em></p><ul><li>向非技术人士解释在特定情况下自动决策的程度。</li><li>分析自动化对设计要求的影响，深入了解机器自主做出的决定。</li><li>论证自动化在不同情况下的优势。</li><li>确定确保决策系统可审计所需的步骤。</li></ul><p><em>品行</em></p><ul><li>对自动化及其对就业的影响问题保持敏感。</li><li>以尊重和道德的方式处理自动化问题。</li></ul><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><span id="fn1"><a href="#a1">[1]</a></span>: 《ACM道德与职业行为准则》，由ACM于2018年7月17日发布。<br><span id="fn2"><a href="#a2">[2]</a></span>: 《关于算法透明度和问责制的声明》，ACM美国公共政策委员会和ACM欧洲政策委员会，2017年。<br><span id="fn3"><a href="#a3">[3]</a></span>：《实现算法透明化和问责制》，Communications of the ACM vol 60 no 9 page 5，2017年9月。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;专业精神（PR）&quot;&gt;&lt;a href=&quot;#专业精神（PR）&quot; class=&quot;headerlink&quot; title=&quot;专业精神（PR）&quot;&gt;&lt;/a&gt;专业精神（PR）&lt;/h3&gt;&lt;p&gt;在技术活动中，数据科学家应以负责任的方式行事，为本专业争光。其中一个方面是积极主动地寻求利益</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>MLOps: Continuous Delivery and Automation Pipelines in Machine Learning</title>
    <link href="http://gloomymoon.github.io/2024/08/08/MLOps-Continuous-Delivery-and-Automation-Pipelines-in-Machine-Learning/"/>
    <id>http://gloomymoon.github.io/2024/08/08/MLOps-Continuous-Delivery-and-Automation-Pipelines-in-Machine-Learning/</id>
    <published>2024-08-08T13:19:32.000Z</published>
    <updated>2024-08-11T05:06:44.572Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MLOps-Continuous-Delivery-and-Automation-Pipelines-in-Machine-Learning-by-Google-1"><a href="#MLOps-Continuous-Delivery-and-Automation-Pipelines-in-Machine-Learning-by-Google-1" class="headerlink" title="MLOps: Continuous Delivery and Automation Pipelines in Machine Learning [by Google[1]]"></a>MLOps: Continuous Delivery and Automation Pipelines in Machine Learning [by Google<sup><span id="a1"><a href="#fn1">[1]</a></span></sup>]</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>本文讨论了实现和自动执行机器学习系统的持续集成 (CI)、持续交付 (CD) 和持续训练 (CT) 的技术。</p><p>数据科学和机器学习正逐渐成为解决复杂现实问题、转变行业以及在所有领域创造价值的核心功能。现在，有效运用机器学习技术的各种要素都已齐备：</p><ul><li>大型数据集</li><li>经济实惠的按需计算资源</li><li>适用于各种云平台的机器学习专用加速器</li><li>不同机器学习研究领域（例如计算机视觉、自然语言理解和推荐 AI 系统）的快速发展。</li></ul><p>因此，许多企业正在投资打造数据科学团队和机器学习功能，以开发能够为用户带来商业价值的预测模型。</p><p>本文适用于希望将DevOps原则运用于机器学习系统 (MLOps) 的数据科学家和机器学习工程师。MLOps是一种机器学习工程文化和做法，旨在统一机器学习系统开发 (Dev) 和机器学习系统运营 (Ops)。实施MLOps意味着您将在机器学习系统构建流程的所有步骤（包括集成、测试、发布、部署和基础架构管理）中实现自动化和监控。</p><p>数据科学家可以实现并训练一个机器学习模型，该模型在给定用例的相关训练数据的情况下，可在留出的离线数据集上实现出色的预测性能。但是，真正的挑战不是构建机器学习模型，而是构建集成的机器学习系统以及在生产环境中持续运行该系统。Google的生产型机器学习服务已运行多年，我们了解到在生产环境中运行基于机器学习的系统时可能会遇到许多问题。<a href="https://ai.google/research/pubs/pub43146" target="_blank" rel="noopener">《Machine Learning: The high-interest credit card of technical debt》</a>总结了其中的一些问题。</p><p>如下图所示，在实际的机器学习系统中，机器学习代码仅占了一小部分，而所需的其它相关要素既庞大又复杂。</p><p><img src="/img/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-1.exif" alt="机器学习系统的元素"></p><p>图1. 机器学习系统的要素。改编自<a href="https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf" target="_blank" rel="noopener">机器学习系统中的隐藏技术债务</a>。</p><p>在此图中，系统的其余部分包括配置、自动化、数据收集、数据验证、测试和调试、资源管理、模型分析、过程和元数据管理、服务基础架构和监控。</p><p>如需开发和运行类似的复杂系统，您可以将DevOps原则应用于机器学习系统 (MLOps)。本文介绍了在为数据科学（例如机器学习中的CI、CD和CT）应用设置MLOps环境时要考虑的概念。</p><p>本文讨论了以下主题：</p><ul><li>DevOps与MLOps。</li><li>开发机器学习模型的步骤。</li><li>MLOps成熟度等级。</li></ul><h2 id="DevOps与MLOps"><a href="#DevOps与MLOps" class="headerlink" title="DevOps与MLOps"></a>DevOps与MLOps</h2><p>DevOps是开发和运行大规模软件系统的一种常见做法。这种做法具有诸多优势，例如缩短开发周期、提高部署速度、实现可靠的发布。如需获得这些优势，您需要在软件系统开发中引入两个概念：</p><ul><li>持续集成 (CI)。</li><li>持续交付 (CD)。</li></ul><p>机器学习系统是一种软件系统，因此类似的做法有助于确保您能够可靠地大规模构建和运行机器学习系统。但是，机器学习系统在以下方面与其他软件系统不同：</p><ul><li>团队技能：在机器学习项目中，团队通常包括数据科学家或机器学习研究人员，他们主要负责进行探索性数据分析、模型开发和实验。这些成员可能不是经验丰富的的软件工程师，无法构建生产级服务。</li><li>开发：机器学习在本质上具有实验性。您应该尝试不同的特征、算法、建模技术和参数配置，以便尽快找到问题的最佳解决方案。您所面临的挑战在于跟踪哪些方案有效、哪些方案无效，并在最大程度提高代码重复使用率的同时维持可重现性。</li><li>测试：测试机器学习系统比测试其他软件系统更复杂。除了典型的单元测试和集成测试之外，您还需要验证数据、评估经过训练的模型质量以及验证模型。</li><li>部署：在机器学习系统中，部署不是将离线训练的机器学习模型部署为预测服务那样简单。机器学习系统可能会要求您部署多步骤流水线以自动重新训练和部署模型。此流水线会增加复杂性，并要求您自动执行部署之前由数据科学家手动执行的步骤，以训练和验证新模型。</li><li>生产：机器学习模型的性能可能会下降，不仅是因为编码不理想，而且也因为数据资料在不断演变。换句话说，与传统的软件系统相比，模型可能会通过更多方式衰退，而您需要考虑这种降级现象。因此，您需要跟踪数据的摘要统计信息并监控模型的在线性能，以便系统在值与预期不符时发送通知或回滚。</li></ul><p>机器学习和其他软件系统在源代码控制的持续集成、单元测试、集成测试以及软件模块或软件包的持续交付方面类似。但是，在机器学习中，有一些显著的差异：</p><ul><li>CI不再仅仅测试和验证代码及组件，而且还会测试和验证数据、数据架构和模型。</li><li>CD不再针对单个软件包或服务，而会针对应自动部署其他服务（模型预测服务）的系统（机器学习训练流水线）。</li><li>CT是机器学习系统特有的一个新属性，它主要涉及自动重新训练和提供模型。</li></ul><p>下一部分讨论了训练和评估要用作预测服务的机器学习模型的典型步骤。</p><h2 id="机器学习的数据科学步骤"><a href="#机器学习的数据科学步骤" class="headerlink" title="机器学习的数据科学步骤"></a>机器学习的数据科学步骤</h2><p>在任何机器学习项目中，定义业务用例并确定成功标准后，将机器学习模型交付给生产环境的过程涉及以下步骤。这些步骤可以手动完成，也可以由自动流水线完成。</p><ol><li>数据提取：您可以为机器学习任务选择和集成来自各种数据源的相关数据。</li><li>数据分析：您可以执行探索性数据分析 (EDA) 以了解可用于构建机器学习模型的数据。此过程将产生以下结果：<ul><li>了解模型预期的数据架构和特性。</li><li>识别模型所需的数据准备和特征工程。</li></ul></li><li>数据准备：为机器学习任务准备数据。此准备工作涉及数据清理，即将数据拆分为训练集、验证集和测试集。您还可以将数据转换和特征工程应用于解决目标任务的模型。此步骤的输出是格式化的数据分片。</li><li>模型训练：数据科学家使用准备好的数据实现不同的算法，以训练各种机器学习模型。此外，您还需要对实现的算法进行超参数调节，以获得最佳机器学习模型。此步骤的输出是经过训练的模型。</li><li>模型评估：在保留测试集上评估模型，以评估模型质量。此步骤的输出是一组用于评估模型质量的指标。</li><li>模型验证：模型已确定适合部署 - 它的预测性能优于特定基准。</li><li>提供模型：经过验证的模型会部署到目标环境以提供预测。此部署可以是以下其中一项：<ul><li>具有REST API的微服务，可用于提供在线预测。</li><li>边缘设备或移动设备的嵌入式模型。</li><li>批量预测系统的一部分。</li></ul></li><li>模型监控：监控模型预测性能，以便在机器学习过程中潜在调用新的迭代。</li></ol><p>这些步骤的自动化级别决定了机器学习过程的成熟度，成熟度反映了使用新数据训练新模型或者使用新实现训练新模型的速度。以下部分介绍了三个级别的MLOps，从最常见的级别（该级别不涉及自动化）开始，一直到自动执行机器学习和CI/CD流水线。</p><h2 id="MLOps级别0：手动过程"><a href="#MLOps级别0：手动过程" class="headerlink" title="MLOps级别0：手动过程"></a>MLOps级别0：手动过程</h2><p>许多团队都有数据科学家和机器学习研究人员，他们可以构建领先的模型，但他们构建和部署机器学习模型的过程完全是手动的。这被认为是成熟度的基本水平，即级别0。下图展示了此过程的工作流。</p><p><img src="/img/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-2.png" alt="将模型用作预测服务的手动机器学习步骤"></p><p>图2：将模型用作预测服务的手动机器学习步骤。</p><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><p>以下列表突出显示了MLOps级别0过程的特性，如图 2 所示：</p><ul><li>脚本驱动的交互式手动过程：每个步骤（包括数据分析、数据准备、模型训练和验证）都是手动的。该过程需要手动执行每个步骤，并且手动从一个步骤转到另一个步骤。此过程通常由数据科学家以交互方式在笔记本中编写和执行的实验性代码驱动，直到生成有效的模型为止。</li><li>机器学习与操作分离：该过程会将创建模型的数据科学家与将模型用作预测服务的工程师分开。数据科学家将经过训练的模型作为工件移交给工程团队，以便在其API基础架构上进行部署。此移交工作可能包括将经过训练的模型放在存储位置、将模型对象签入代码库，或者将其上传到模型注册表。然后，部署模型的工程师需要在生产环境中提供所需的功能以实现低延时服务，这可能会导致训练-应用偏差。</li><li>不频繁发布迭代：该过程假定您的数据科学团队管理一些不会频繁更改（更改模型实现或使用新数据重新训练模型）的模型。新模型版本每年仅部署几次。</li><li>无CI：由于假定几乎不更改实现，因此CI已被忽略。通常，测试代码是笔记本或脚本执行的一部分。实现实验步骤的脚本和笔记本由源代码控制，并生成经过训练的模型、评估指标和可视化等工件。</li><li>无CD：由于不会频繁部署模型版本，因此不考虑CD。</li><li>部署指的是预测服务：该过程仅涉及将经过训练的模型部署为预测服务（例如，具有REST API的微服务），而不是部署整个机器学习系统。</li><li>缺少主动性能监控：该过程不会跟踪或记录模型预测和操作，模型预测和操作是检测模型性能下降和其他模型行为偏移所必需的信息。</li></ul><p>工程团队可能会对API配置、测试和部署（包括安全、回归以及负载测试和Canary版测试）进行自己的复杂设置。此外，在升级模型以处理所有预测请求流量之前，新版机器学习模型的生产部署通常会进行A/B测试或在线实验。</p><h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><p>MLOps级别0在许多开始将机器学习应用于其用例的企业中很常见。如果难得更改或训练模型，则由数据科学家驱动的此手动过程可能就足够了。实际上，在现实环境中部署模型时，模型通常会失效。模型无法适应环境的动态变化或描述环境的数据的变化。如需了解详情，请参阅<a href="https://www.forbes.com/sites/forbestechcouncil/2019/04/03/why-machine-learning-models-crash-and-burn-in-production/" target="_blank" rel="noopener">为什么机器学习模型会在生产环境中崩溃和失效</a>。</p><p>如需战胜这些挑战并保持模型在生产环境中的准确性，您需要执行以下操作：</p><ul><li>在生产环境中主动监控模型的质量：Monitoring可让您检测性能下降和模型过时情况。它会提示您执行新的实验迭代以及（手动）针对新数据重新训练模型。</li><li>频繁地重新训练生产模型：如需捕获不断演变和新兴的模式，您需要使用最新数据重新训练模型。例如，如果您的应用使用机器学习推荐时尚产品，则其建议应适应最新的趋势和产品。</li><li>不断尝试新的实现以生成模型：如需利用最新的技术理念和技术进步，您需要尝试新的实现，例如特征工程、模型架构和超参数。例如，如果您在人脸检测中使用计算机视觉，则人脸模式是固定的，但更好的新技术可以提高检测准确度。</li></ul><p>为了战胜此手动过程的挑战，CI/CD和CT的MLOps做法很有用。通过部署机器学习训练流水线，您可以启用CT，并且可以设置CI/CD系统以快速测试、构建和部署机器学习流水线的新实现。后续部分将详细讨论这些功能。</p><h2 id="MLOps级别1：机器学习流水线自动化"><a href="#MLOps级别1：机器学习流水线自动化" class="headerlink" title="MLOps级别1：机器学习流水线自动化"></a>MLOps级别1：机器学习流水线自动化</h2><p>级别1的目标是通过自动执行机器学习流水线来持续训练模型；这样可以持续交付模型预测服务。如需自动执行在生产环境中使用新数据重新训练模型的过程，您需要在流水线中引入自动化数据和模型验证步骤，以及流水线触发器和元数据管理。</p><p>下图是针对CT的自动化机器学习流水线的示意图。<br><img src="/img/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-3.png" alt="针对CT的机器学习流水线自动化"></p><p>图3：针对CT的机器学习流水线自动化。</p><h3 id="特性-1"><a href="#特性-1" class="headerlink" title="特性"></a>特性</h3><p>以下列表突出显示了MLOps级别1设置的特性，如图3所示：</p><ul><li>快速实验：机器学习实验的步骤已经过编排。各个步骤之间的转换是自动执行的，这样可以快速迭代实验，并更好地准备将整个流水线移至生产环境。</li><li>生产环境中的模型CT：系统会在生产环境中根据实时流水线触发器使用新数据自动训练模型，下一部分将对此进行讨论。</li><li>实验与操作之间的对称性：在开发或实验环境中使用的流水线实现会在预生产和生产环境中使用，这是MLOps做法的主要方面，用于统一DevOps。</li><li>组件和流水线的模块化代码：如需构建机器学习流水线，组件必须可重复使用、可组合，并且有望跨机器学习流水线共享。因此，虽然EDA代码仍可在笔记本中使用，但组件的源代码必须模块化。此外，组件最好应容器化，以执行以下操作：<ul><li>将执行环境与自定义代码运行时环境分离。</li><li>使代码在开发和生产环境之间可重现。</li><li>隔离流水线中的每个组件。组件可以有自己的运行时环境版本，并且可以有不同的语言和库。</li></ul></li><li>持续交付模型：生产环境中的机器学习流水线会向使用新数据进行训练的新模型持续交付预测服务。模型部署步骤是自动执行的，该步骤将经过训练和验证的模型用作在线预测的预测服务。</li><li>流水线部署：在级别0中，您可以将经过训练的模型作为预测服务部署到生产环境。对于级别1，您可以部署整个训练流水线，该流水线会自动重复运行以将经过训练的模型用作预测服务。</li></ul><h3 id="数据和模型验证"><a href="#数据和模型验证" class="headerlink" title="数据和模型验证"></a>数据和模型验证</h3><p>将机器学习流水线部署到生产环境时，机器学习流水线触发器部分中讨论的一个或多个触发器会自动执行流水线。流水线需要新的实时数据来生成使用新数据进行训练的新模型版本（如图3所示）。因此，生产流水线需要自动化数据验证和模型验证步骤，以确保实现以下预期行为：</p><ul><li>数据验证：在模型训练之前需要执行此步骤，以确定您应该重新训练模型还是停止执行流水线。如果流水线识别到以下情况，则系统会自动做出此决策：<ul><li>数据架构偏差：这些偏差被视为输入数据中的异常情况，这意味着下游流水线步骤（包括数据处理和模型训练）接收的数据不符合预期架构。在这种情况下，您应该停止流水线，以便数据科学团队进行调查。团队可能会发布对流水线的修复或更新，以处理架构中的这些更改。架构偏差包括接收意外特征、未接收所有预期特征或接收具有意外值的特征。</li><li>数据值偏差：这些偏差是数据统计属性的重大变化，这意味着数据模式正在变化，您需要触发模型的重新训练才能捕获这些变化。</li></ul></li><li>模型验证：此步骤发生在您使用新数据成功训练模型之后。您可以在模型投入生产环境之前对其进行评估和验证。模型离线验证的步骤包含以下操作：<ul><li>在测试数据集上使用经过训练的模型生成评估指标值，以评估模型的预测质量。</li><li>将新训练的模型生成的评估指标值与当前模型（例如生产模型、基准模型或其他业务需求模型）进行比较。在将新模型投入生产环境之前，请确保新模型的性能比当前模型更好。</li><li>确保模型的性能对于数据的各个细分来说是一致的。例如，新训练的客户流失模型的总体预测准确率可能比先前模型高，但每个客户区域的准确率值可能存在较大的偏差。</li><li>确保针对部署测试模型，包括测试基础架构与预测服务API的兼容性和一致性。</li></ul></li></ul><p>除了离线模型验证之外，新部署的模型在为在线流量提供预测之前会进行在线模型验证（在Canary金丝雀版部署或A/B测试设置中进行）。</p><h3 id="特征存储区"><a href="#特征存储区" class="headerlink" title="特征存储区"></a>特征存储区</h3><p>级别1机器学习流水线自动化的一个可选附加组件是特征存储区。特征存储区是一个集中式存储区，您可以在其中对特征的定义、存储和访问进行标准化处理，以方便训练和提供服务。特征存储区需要为特征值提供高吞吐量批量服务和低延时实时服务的API，以及支持训练和服务工作负载。</p><p>特征存储区可帮助数据科学家执行以下操作：</p><ul><li>发现并重复使用可用于实体的特征集，而不是重新创建相同或类似的特征集。</li><li>通过保留特征及其相关元数据来避免使用具有不同定义的类似特征。</li><li>从特征存储区提供最新的特征值。</li><li>通过将特征存储区用作实验、持续训练和在线服务的数据源，避免训练-应用偏差。此方法可确保用于训练的特征与服务期间使用的特征相同：<ul><li>对于实验，数据科学家可以从特征存储区中提取离线数据以运行实验。</li><li>对于持续训练，自动化机器学习训练流水线可以提取用于训练任务的数据集的一批最新特征值。</li><li>对于在线预测，预测服务可以提取与所请求实体相关的一批特征值，例如客户受众特征、产品特征和当前的会话聚合特征。</li></ul></li></ul><h3 id="元数据管理"><a href="#元数据管理" class="headerlink" title="元数据管理"></a>元数据管理</h3><p>系统会记录有关机器学习流水线每次执行情况的信息，以帮助实现数据和工件沿袭、可重现性以及比较。这些信息还有助于您调试错误和异常情况。每次执行流水线时，机器学习元数据存储区都会记录以下元数据：</p><ul><li>执行的流水线和组件版本。</li><li>开始和结束日期、时间以及流水线完成每个步骤所花费的时间。</li><li>流水线的执行者。</li><li>传递给流水线的参数。</li><li>指向流水线每个步骤生成的工件的指针，例如准备好的数据的位置、验证异常情况、计算的统计信息以及从分类特征中提取的词汇。跟踪这些中间输出有助于您在流水线因某个步骤失败而停止时，从最近的步骤继续执行流水线，而不必重新执行已完成的步骤。</li><li>指向之前训练的模型的指针（如果您需要回滚到之前的模型版本，或者需要在流水线在模型验证步骤中获得新的测试数据时为之前的模型版本生成评估指标）。</li><li>在模型评估步骤中为训练集和测试集生成的模型评估指标。这些指标可帮助您在模型验证步骤中将新训练的模型的性能与之前模型的记录性能进行比较。</li></ul><h3 id="机器学习流水线触发器"><a href="#机器学习流水线触发器" class="headerlink" title="机器学习流水线触发器"></a>机器学习流水线触发器</h3><p>您可以自动执行机器学习生产流水线，以根据您的用例使用新数据重新训练模型：</p><ul><li>按需：临时手动执行流水线。</li><li>按时间表：系统每天、每周或每月向机器学习系统提供带有标签的新数据。重新训练的频率还取决于数据模式的更改频率以及重新训练模型的费用。</li><li>根据新训练数据的可用性：新数据不会系统地提供给机器学习系统，而是在系统收集新数据并在源数据库中提供新数据时临时提供给机器学习系统。</li><li>在模型性能下降时：模型在性能明显下降时会重新训练。</li><li>在数据分布发生重大变化（概念偏移）时。您很难评估在线模型的完整性能，但会注意到用于执行预测的特征的数据分布发生重大变化。这些变化表明您的模型已过时，需要使用新数据重新训练。</li></ul><h3 id="挑战-1"><a href="#挑战-1" class="headerlink" title="挑战"></a>挑战</h3><p>假设流水线的新实现不会频繁部署，并且您只管理几条流水线，则您通常需要手动测试流水线及其组件。此外，您需要手动部署新的流水线实现。您还需要将经过测试的流水线源代码提交给IT团队，以部署到目标环境。如果您根据新数据（而不是新的机器学习理念）部署新模型，则此设置是合适的。</p><p>但是，您需要尝试新的机器学习理念，并快速部署机器学习组件的新实现。如果您在生产环境中管理多条机器学习流水线，则需要设置CI/CD以自动构建、测试和部署机器学习流水线。</p><h2 id="MLOps级别2：CI-CD流水线自动化"><a href="#MLOps级别2：CI-CD流水线自动化" class="headerlink" title="MLOps级别2：CI/CD流水线自动化"></a>MLOps级别2：CI/CD流水线自动化</h2><p>如需在生产环境中快速、可靠地更新流水线，您需要一个可靠的自动化CI/CD系统。此自动化CI/CD系统可让您的数据科学家快速探索有关特征工程、模型架构和超参数的新理念。他们可以实现这些理念，并自动构建、测试新的流水线组件，以及将其部署到目标环境。</p><p>下图显示了使用CI/CD的机器学习流水线的实现，它具有自动化机器学习流水线设置的特性以及自动化CI/CD例程。</p><p><img src="/img/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-4.png" alt="CI/CD和自动化机器学习流水线"></p><p>图4：CI/CD和自动化机器学习流水线。</p><p>此MLOps设置包含以下组件：</p><ul><li>源代码控制</li><li>测试和构建服务</li><li>部署服务</li><li>模型注册表</li><li>特征存储区</li><li>机器学习元数据存储区</li><li>机器学习流水线编排者</li></ul><h3 id="特性-2"><a href="#特性-2" class="headerlink" title="特性"></a>特性</h3><p>下图展示了机器学习 CI/CD 自动化流水线的各个阶段：<br><img src="/img/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-5.exif" alt="CI/CD自动化机器学习流水线的各个阶段"></p><p>图5：CI/CD自动化机器学习流水线的各个阶段。</p><p>流水线包括以下阶段：</p><ol><li>开发和实验：在编排了实验步骤的阶段，您可以反复尝试新的机器学习算法和新的建模。此阶段的输出是机器学习流水线步骤的源代码，该源代码随后会被推送到源代码库。</li><li>流水线持续集成：您可以构建源代码并运行各种测试。此阶段的输出是要在后续阶段部署的流水线组件（软件包、可执行文件和工件）。</li><li>流水线持续交付：您可以将CI阶段生成的工件部署到目标环境。此阶段的输出是已部署的流水线，其中包含模型的新实现。</li><li>自动触发：流水线会根据时间表或响应触发器而自动在生产环境中执行。此阶段的输出是已推送到模型注册表并且经过训练的模型。</li><li>模型持续交付：您可以将经过训练的模型用作预测服务。此阶段的输出是已部署的模型预测服务。</li><li>监控：您可以根据实时数据收集模型性能的统计信息。此阶段的输出是用于执行流水线或执行新实验周期的触发器。</li></ol><p>在流水线开始实验的新迭代之前，数据分析步骤仍然是数据科学家手动执行的过程。模型分析步骤也是手动执行的过程。</p><h3 id="持续集成"><a href="#持续集成" class="headerlink" title="持续集成"></a>持续集成</h3><p>在此设置中，当新代码提交或推送到源代码库时，您会构建、测试和封装流水线及其组件。除了构建软件包、容器映像和可执行文件之外，CI过程还可以包含以下测试：</p><ul><li>对特征工程逻辑进行单元测试。</li><li>对模型中实现的不同方法进行单元测试。例如，您有一个接受分类数据列的函数，并将该函数编码为独热功能。</li><li>测试您的模型训练是否会收敛（即模型的损失会因迭代而下降，并且会过拟合一些示例记录）。</li><li>测试模型训练是否不会因为除以零或者处理小值或大值而产生NaN值。</li><li>测试流水线中的每个组件都会生成预期的工件。</li><li>测试流水线组件之间的集成。</li></ul><h3 id="持续交付"><a href="#持续交付" class="headerlink" title="持续交付"></a>持续交付</h3><p>在此级别中，您的系统会向目标环境持续交付新的流水线实现，从而交付新训练的模型的预测服务。如需快速、可靠地持续交付流水线和模型，您应考虑以下事项：</p><ul><li>在部署模型之前，验证模型与目标基础架构的兼容性。例如，您需要验证模型所需的软件包是否已安装到服务环境中，以及内存、计算和加速器资源是否可用。</li><li>测试预测服务，方法是：使用预期输入调用服务API，并确保获得预期响应。此测试通常会捕获您在更新模型版本时可能会出现的问题，它需要您提供不同的输入。</li><li>测试预测服务性能，包括对服务进行负载测试以捕获每秒查询次数 (QPS) 和模型延迟时间等指标。</li><li>验证数据以便重新训练或者进行批量预测。</li><li>在部署模型之前，验证其是否达到预测性能目标。</li><li>自动部署到测试环境，例如通过将代码推送到开发分支而触发的部署。</li><li>半自动部署到预生产环境，例如通过在审核者批准更改后将代码合并到主分支而触发的部署。</li><li>在预生产环境中多次成功运行流水线后，手动部署到生产环境。</li></ul><p>总而言之，在生产环境中实现机器学习并不仅意味着将模型部署为用于预测的API。相反，它意味着部署可自动重新训练和部署新模型的机器学习流水线。通过设置CI/CD系统，您可以自动测试和部署新的流水线实现。此系统可让您应对数据和业务环境的快速变化。您不必立即将所有过程从一个级别迁移到另一个级别。您可以逐步实现这些做法，以帮助改进机器学习系统的开发和生产自动化。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><span id="fn1"><a href="#a1">[1]</a></span>: 原文：<a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning" target="_blank" rel="noopener">MLOps: Continuous Delivery and Automation Pipelines in Machine Learning</a></p><p>CAICT中国信通院：<a href="http://www.caict.ac.cn/kxyj/qwfb/ztbg/202303/P020230316567347382391.pdf" target="_blank" rel="noopener">人工智能研发运营体系（MLOps）实践指南（2023年）</a></p><p>Microsoft Azure AI+机器学习：<a href="https://learn.microsoft.com/zh-cn/azure/architecture/ai-ml/guide/mlops-maturity-model" target="_blank" rel="noopener">机器学习操作成熟度模型</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;MLOps-Continuous-Delivery-and-Automation-Pipelines-in-Machine-Learning-by-Google-1&quot;&gt;&lt;a href=&quot;#MLOps-Continuous-Delivery-and-Automati</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
    <category term="Machine Learning" scheme="http://gloomymoon.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>The Data Science Task Force: Mission ML</title>
    <link href="http://gloomymoon.github.io/2024/07/20/The-Data-Science-Task-Force-Mission-VIII/"/>
    <id>http://gloomymoon.github.io/2024/07/20/The-Data-Science-Task-Force-Mission-VIII/</id>
    <published>2024-07-20T14:55:08.000Z</published>
    <updated>2024-08-01T06:04:41.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="机器学习（ML）"><a href="#机器学习（ML）" class="headerlink" title="机器学习（ML）"></a>机器学习（ML）</h3><p>机器学习，有时也称为统计学习，指的是一套广泛的算法，用于识别数据中的模式，以建立模型，然后将其生产化并可能产品化。这些方法对数据科学至关重要。数据科学家应该了解他们所使用的算法，并就算法的使用做出正确的决定。</p><table>  <tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul>    <li>机器学习方法的大类（如有监督式和无监督式）。</li>    <li>机器学习的算法和工具（即算法的实现）。</li>    <li>将机器学习作为一套原则性算法（如优化算法），而不是“一揽子技巧”。</li>    <li>挑战（如过拟合）和应对这些挑战的技术。</li>    <li>性能指标。</li>    <li>训练和测试方法。</li>    <li>算法和数据偏差、数据完整性以及实地学习模型的专业责任。</li>    </ul></td>    <td width="50%">    <ul>    <li>认识机器学习方法的广泛性和实用性。</li>    <li>比较和比对机器学习方法。</li>    <li>针对具体问题选择适当（类别）的机器学习方法。</li>    <li>在部署机器学习算法时，使用适当的训练和测试方法。</li>    <li>解释在机器学习算法中减轻过拟合和维度诅咒影响的方法。</li>    <li>针对特定问题，确定评估机器学习算法/工具的适当性指标。</li>    <li>认识与算法和数据偏差以及数据隐私和完整性相关的问题。</li>    <li>就机器学习结论可能产生的积极和消极影响展开辩论。</li>    </ul>    </td>  </tr>  <tr>     <th colspan="2">子领域</th>  </tr>  <tr>    <td width="50%">    ML-通识-T1,T2,E<br>    ML-有监督学习-T1,T2,E<br>    ML-无监督学习-T1,T2,E<br>    ML-混合方法-E<br>    ML-深度学习-T1,T2,E<br>    </td>    <td width="50%">    强化学习在《人工智能-知识表示与推理（基于概率的模型）》中。<br>    </td>  </tr></table><h4 id="ML-通识"><a href="#ML-通识" class="headerlink" title="ML-通识"></a>ML-通识</h4><p>鉴于机器学习算法在许多数据科学任务中的核心地位，数据科学家应了解各种机器学习方法以及该领域的悠久历史。数据科学家应该知道从哪里寻找可能的技术来解决新问题。</p><p>数据科学家还应了解跨领域的概念，如评估性能的必要性和机器学习中面临一般挑战的类型。</p><p><em>知识</em><br>T1：</p><ul><li>机器学习的主要任务，包括有监督学习、无监督学习、强化学习和深度学习。</li><li>符号学习与数字学习、统计方法与结构/句法分析方法的区别。</li><li>作为原则性优化方法的学习算法。</li><li>将机器学习作为数据挖掘的一种方法，将机器学习作为一个过程。</li><li>鲁棒性评估的重要性。</li><li>机器学习面临的挑战，包括数据质量和正则化需求。</li></ul><p><em>技能</em><br>T1：</p><ul><li>比较有监督学习、无监督学习、强化学习和深度学习的目标、输入和输出。</li><li>认识到不同类型的数据驱动问题可以用不同的方法来解答。</li><li>针对特定的数据驱动问题，解释为什么某种方法是合适的。</li><li>从高层次解释机器学习模型和算法是基于数学和统计学基础的原则性技术。</li><li>描述作为数据挖掘方法的机器学习过程：了解客户希望解决的问题，收集与解决问题相关的数据，将原始数据转换为特征，选择适当的机器学习方法，调整这些方法，评估性能（通常是对照基准），以及展示结果和见解。</li><li>讨论拟合训练数据与泛化新数据之间的权衡，以及模型的复杂性、样本和特征的数量如何影响这种权衡。将这种权衡与超参数的作用和设置联系起来。</li><li>列出性能、可解释性和可扩展性之间的权衡。</li><li>认识到不同的优化功能和技术可能会在这一领域产生的不同权衡。</li></ul><p>T2：</p><ul><li>从基本原理出发，解释所提供的简单优化函数和学习算法的推导，如使用信息论的决策树、使用最大似然和随机梯度下降的逻辑回归、使用方差最小化和特征值的 PCA。也就是说，学生应该能够跟上推导过程并加以解释，而不是从头开始推导。</li><li>跟随指引并统计显著性检验分析不同模型的性能。</li><li>解释如何有效地将模型发布到生产阶段，并使用适当的工具从一开始就支持这一工作。</li><li>根据数据规模选择使用的工具，对于大数据而言，必须选择能够并行运算的机器学习工具，否则学习过程所需的时间可能会大大超出可接受的范围。</li><li>列出最先进的机器学习工具。</li></ul><p>E：</p><ul><li>描述自动化建模（或元学习）过程，特别是如何实现机器学习管道的自动化，包括数据预处理、模型选择、模型结构搜索和超参数调整。</li></ul><p><em>品行</em><br>T1：</p><ul><li>机器学习的专业应用。要认识到机器学习虽然是最近才流行起来，但并不是最新才有的创新。在假定需要新发明之前，先寻找现有的解决方案。</li><li>准确、合乎道德地使用机器学习（即机器学习不是一套临时的技巧，应负责任的使用）。</li><li>坚定的致力于将机器学习作为实现客户目标的过程的一部分，机器学习在一般情况系并不是将机器学习程序应用于方便格式化的数据集的简单过程。比较所学模型是的彻底性，可以从多个维度对所学的模型进行比较，包括经验损失最小化、模型大小和复杂性以及人类可解释性等。</li><li>考虑到模型比较的各个方面（质量、效率、可解释性等），以合乎道德的方式提出公平、真实的比较结果。</li></ul><h4 id="ML-有监督学习"><a href="#ML-有监督学习" class="headerlink" title="ML-有监督学习"></a>ML-有监督学习</h4><p>作为一个主要机器学习的算法，有监督学习包括分类和回归技术。数学科学家应该了解这些类型的算法，包括这类学习特有的挑战和方法。请注意本子领域与数据挖掘中分类和回归的关系。</p><p><em>知识</em><br>T1：</p><ul><li>有监督学习的主要任务：回归和分类。</li><li>回归和分类的使用案例。</li><li>有监督学习中的重要考虑和权衡，包括模型复杂性和通用性之间的关系：偏差和方差之间的权衡，奥卡姆剃刀作为简单模型的动机。</li><li>分离训练、测试和验证数据的必要性，定义训练误差和测试误差。</li><li>分类任务（如准确率、敏感度、特异性、精准度、召回率、F1、AUROC、遗憾）和归回任务（如均方根误差、平均绝对误差、R^2）的常用评价指标。</li><li>验证数据的必要性，交叉检验程序和目的：调整超参数和衡量模型性能。</li><li>评估训练、测试和验证数据质量的标准，如样本数量和分类分层。</li><li>分类和回归算法，包括至少一种线性算法和一种非线性算法（例如线性回归/分类、逻辑回归、近邻、朴素贝叶斯、决策树学习算法）。</li><li>基本算法的常见扩展，包括多项式特征和几何（如分袋模型、提升模型、随机森林）。</li></ul><p>T2：</p><ul><li>确定模型是高偏差还是高方差的方法，如训练与测试性能、学习曲线。</li><li>增加或减少特征集的原因，每种特征集至少有两种方法和权衡。</li><li>如何将有监督分类器学习模型应用于多分类问题，包括如何将二元分类模型扩展到多分类任务。</li><li>如何使用宏观和微观指标来衡量绩效。</li><li>至少一种高级有监督学习模型（如带内核的支持向量机、神经网络）。</li></ul><p>E：</p><ul><li>从基本原理开始推导有监督学习算法。</li></ul><p><em>技能</em><br>T1：</p><ul><li>使用混淆矩阵解释分类器模型的性能。</li><li>比较分类任务和回归任务评价指标的优缺点。</li><li>比较至少两种应用分类算法的利弊，比较至少两种回归算法的利弊。</li><li>在中小规模数据集上应用至少两种分类算法和两种回归算法。</li><li>比较训练误差和测试误差对所学模型的影响。</li><li>使用各种指标比较算法的性能。</li><li>对小、中和大规模数据集应用至少两种扩展方法（如集合方法）。</li><li>根据多项式特征和集合等各自能够解决的问题，说明何时适合进行扩展。</li></ul><p>T2：</p><ul><li>在大规模数据集上执行至少两种分类算法和两种回归算法。</li><li>说明对大规模数据集的至少一种扩展。</li><li>采用各种方法减少高偏差和高方差。</li><li>对中或大规模问题进行特征增强和选择。</li><li>应用高级监督学习算法（如带内核的支持向量机、神经网络）。</li></ul><p>E：</p><ul><li>从基本原理出发，涉及简单的优化函数和学习算法，例如使用最大似然法和随机梯度下降法进行逻辑回归。</li></ul><p><em>品行</em><br>T1：</p><ul><li>透彻而明智地选择和评估算法。知道这些选择对重要的利益相关者（即模型的开发对象）有影响，并且必须与他们一起决策。</li><li>对模型采用准确合理的评估方法使我们对模型保持高度的信心。</li></ul><h4 id="ML-无监督学习"><a href="#ML-无监督学习" class="headerlink" title="ML-无监督学习"></a>ML-无监督学习</h4><p>另一大类机器学习方法称为“无监督”学习，包括聚类和降维技术。数据科学家应该了解这些类型的算法，包括这类算法特有的挑战和方法。请注意该子领域与DM聚类分析的关系。</p><p><em>知识</em><br>T1：</p><ul><li>无监督学习的主要任务，包括聚类和降维。</li><li>这两项任务的应用场景，如数据探索/总结/可视化、特征选择、数据压缩、数据去噪、原型学习、推荐系统、主题建模。</li><li>掌握至少一种简单的聚类算法，如k-means或分层聚类。</li><li>基于连接性的聚类与基于中心点的聚类算法的权衡。</li><li>掌握至少一种简单的降维算法，如主成分分析（PCA）。</li><li>特征转换、特征选择和特征投影之间的异同。</li></ul><p>T2：</p><ul><li>掌握至少一种高级的聚类算法，如基于密度的防范、高斯混合物模型（GMM）。</li><li>掌握至少一种高级的降维算法，如独立分量分析（ICA）或非负矩阵因式分解（NMF）。</li></ul><p>E：</p><ul><li>掌握至少一种高效实时算法的数学方法，如矩阵因式分解和奇异值分解（SVD）和PCA的等差数列分解。</li><li>掌握至少一种高级算法，如光谱聚类、核K-means、核PCA、隐含狄利克雷分布（LDA）。</li><li>PCA与自动编码器的联系，对非线性降维的推广。</li><li>从基本原理推导无监督学习算法。</li></ul><p><em>技能</em><br>T1：</p><ul><li>对小、中和大规模数据集应用一种聚类算法和一种降维算法。</li><li>使用各种指标解释无监督学习算法的性能，例如可视化、与实际情况比较（如有）、聚类密度等计算指标、通过对其他应用效用进行间接衡量等。</li><li>实施选择超参数的方法，例如K-means的聚类数或PCA的分量数。</li></ul><p>T2：</p><ul><li>比较至少两种聚类算法的利弊。</li><li>比较至少两种降维算法的利弊。</li></ul><p>E：</p><ul><li>应用高级的无监督学习算法。</li><li>从基本原理设计简单的优化函数和学习算法，例如使用方差最小化和特征值的PCA，将这些技术扩展到类似模型。</li></ul><p><em>品行</em><br>T1：</p><ul><li>全面且精准的算法选择和评估，理解算法选择和评估指标对学习模型质量的重要性。了解这些选择对重要利益相关者（即模型的开发对象）的影响，并且必须与一起做出决策。</li><li>对模型采用准确合理的评估方法使我们对模型保持高度的信心。</li></ul><p>T2：</p><ul><li>关注无监督学习，为数据探索、理解、总结和可视化提供有用的技术。</li><li>注意无监督学习中的细节，这可以作为一个有用的与处理步骤，提高有监督学习算法的质量和效率。</li></ul><h4 id="ML-混合方法-选修"><a href="#ML-混合方法-选修" class="headerlink" title="ML-混合方法-选修"></a>ML-混合方法-选修</h4><p>有些机器学习问题和领域具有特殊结构，可以通过专门技术加以利用，数据科学家应该了解这些广泛的应用类别，并知道从哪里可以找到可能的方法来解决这些问题。注意该子域与DM-时间序列数据的关系。</p><p><em>知识</em></p><ul><li>可在所学模型中利用数据结构或数据点相互关联性的学习问题和领域样本，例如时间序列预测、序列预测、推荐系统。</li><li>如何在学习中利用时间依赖性或跨数据点共享信息的假设。</li><li>使用有监督或无监督方法而非混合方法的缺点，例如模型的可解释性或性能问题。</li></ul><p>T2：</p><ul><li>对于其中一个问题，至少有一种标准的学习方法，例如对于序列预测的隐马尔可夫模型（HMMs）或用于推荐系统的协同过滤（CF）。</li><li>在此情况下，需要将训练数据和测试数据分开。</li><li>所选任务的通用评估指标，如召回率、精确度、推荐系统的F1 Score。</li><li>评估所选问题的训练、测试和验证数据质量的标准。</li></ul><p><em>技能</em></p><ul><li>讲一个此类问题整合到一个学习框架中，即将数据映射到输入和输出，考虑超参数的设置，运用适当的学习算法。</li></ul><p><em>品行</em></p><ul><li>对于一般机器学习模型中存在的挑战（如时间不均匀性、数据稀疏性），对细节的关注可能在特定情况下更为突出。</li></ul><h4 id="ML-深度学习"><a href="#ML-深度学习" class="headerlink" title="ML-深度学习"></a>ML-深度学习</h4><p>数据的可用性和计算处理能力的可用性催生了新的、强大的大规模学习技术，数据科学家应了解这些类型的算法，包括这类学习算法特有的挑战和方法。</p><p><em>知识</em></p><p>T2：</p><ul><li>多层神经网络（包括非深度网络）如何从输入特征中学习和编码更高层次的特征。</li><li>常见的深度学习架构，如深度前馈网络、卷积神经网络（CNN）、循环神经网络（RNN）和LSTM，每种架构的目的和特性。</li><li>常见深度学习方法的实际调整，如选择深度学习框架、拥有足够的数据/过度拟合的可能性、学习时间长短、可解释性等。</li><li>深度学习框架的正则化方法示例，如早期停止、参数共享和剔除。</li><li>减轻深度学习其他调整的方法示例，例如配合使用GPU或分布式系统的工具。</li><li>选择可随数据规模扩展的适当工具，例如处理大数据需要能以并行方式运行的深度学习工具。</li><li>了解最新的深度学习工具。</li><li>至少一种常用的深度网络学习算法，如在深度前馈网络中如何使用反向传播、或在卷积网络中如何使用反向传播学习高阶特征、在循环网络中如何使用时间反向传播。</li><li>卷积的操作及其有用的原因，例如检测图像中的垂直边缘。</li><li>池化功能（如最大池化）示例和使用案例。</li><li>循环神经网络中长期与短期依赖关系的挑战，至少有一种解决方案，如LSTM。</li></ul><p>E：</p><ul><li>深度生成模型，如生成式对抗神经网络（GANN）及其应用。</li><li>此类方法面临的实际挑战，如收敛、模式崩溃等。</li><li>处理或减轻上述影响的方法。</li></ul><p><em>技能</em></p><p>T2：</p><ul><li>选择最适合特定数据集和任务的深度学习方法类型。</li><li>使用深度学习工具包（如PyTorch、Tensorflow）从数据集研究学习模型的输出。</li><li>使用深度学习工具包（如PyTorch、Tensorflow）学习数据集模型，包括配置网络。</li></ul><p>E：</p><ul><li>利用深度学习工具包，针对特定目标从头开始实施生成方式。</li><li>修改工具包，使其适用于特定的系统架构。</li></ul><p><em>品行</em></p><p>T1：</p><ul><li>机器学习建模的专业性，了解使用难以或无法解释的机器学习模型可能带来的负面影响。</li><li>负责任地使用深度学习，因为在很多问题上深度学习的能力超出了所需。</li><li>以合作和道德的方式致力于解决深度伪造有关的社会和政治问题。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;机器学习（ML）&quot;&gt;&lt;a href=&quot;#机器学习（ML）&quot; class=&quot;headerlink&quot; title=&quot;机器学习（ML）&quot;&gt;&lt;/a&gt;机器学习（ML）&lt;/h3&gt;&lt;p&gt;机器学习，有时也称为统计学习，指的是一套广泛的算法，用于识别数据中的模式，以建立模型，然后将</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>May the FALSE be with you</title>
    <link href="http://gloomymoon.github.io/2024/05/04/May-the-False-be-with-you/"/>
    <id>http://gloomymoon.github.io/2024/05/04/May-the-False-be-with-you/</id>
    <published>2024-05-04T13:20:32.000Z</published>
    <updated>2024-12-20T15:22:03.044Z</updated>
    
    <content type="html"><![CDATA[<h3 id="The-Death-Star-is-allowed-to-defend-itself"><a href="#The-Death-Star-is-allowed-to-defend-itself" class="headerlink" title="The Death Star is allowed to defend itself!"></a>The Death Star is allowed to defend itself!</h3><blockquote><p>The Empire did nothing wrong. Palpation was elected.<br>Moff Tarkin blew up Alderaan.<br>The liberal media is not gonna tell you that The Rebel Alliance kidnaps children and they indoctrinate them. They doesn’t talk about how Alderaan was being used as a base for The Rebel.<br>The Mandalorian uses Baby Yoda as a Human Shield!<br>The Sith Lord does not make the mistake, he dealt with the Trade Federation, you know, the whole blockade of Naboo.<br>The Empire brought unemployment on Alderaan down to zero.<br>Trust the Empire. Just keep calm and trust the Empire.<br>—-An Empire Stormtrooper of 501st Legion</p></blockquote><p><img src="/img/MayTheFalseBeWithYou_01.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_02.png" alt=""></p><h3 id="2024精选回旋镖系列"><a href="#2024精选回旋镖系列" class="headerlink" title="2024精选回旋镖系列"></a>2024精选回旋镖系列</h3><p><strong>驰名双标：网络安全</strong><br><img src="/img/MayTheFalseBeWithYou_03a.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_03d.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_03f.jpg" alt=""></p><p><strong>P社玩家：造宣称，谁不会</strong><br><img src="/img/MayTheFalseBeWithYou_04.jpg" alt=""></p><p><strong>反复横跳魔怔人</strong><br><img src="/img/MayTheFalseBeWithYou_05.png" alt=""></p><p><strong>MADE IN CHINA!</strong><br><img src="/img/MayTheFalseBeWithYou_06a.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_06b.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_06c.jpg" alt=""></p><p><strong>真・Made in China</strong><br><img src="/img/MayTheFalseBeWithYou_37.jpg" alt=""></p><p><strong>未曾想过的道路</strong><br><img src="/img/MayTheFalseBeWithYou_07.jpg" alt=""></p><p><strong>致敬传奇，缅怀传奇，成为传奇</strong><br><img src="/img/MayTheFalseBeWithYou_08a.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_08b.jpg" alt=""></p><p><strong>陛下高洁的女骑士攻入了兽人的老巢</strong><br><img src="/img/MayTheFalseBeWithYou_09a.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_09b.jpg" alt=""></p><p><strong>虽然我依据181号决议建国，但你们联合国都是哈马斯</strong><br><img src="/img/MayTheFalseBeWithYou_10.jpg" alt=""></p><p><strong>起开，谁都不许买，让我来</strong><br><img src="/img/MayTheFalseBeWithYou_11.jpg" alt=""></p><p><strong>驰名双标：食品安全</strong><br><img src="/img/MayTheFalseBeWithYou_12a.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_12b.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_12c.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_12d.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_12e.jpg" alt=""></p><p><strong>我的是我的，你的还是我的</strong><br><img src="/img/MayTheFalseBeWithYou_13.jpg" alt=""></p><p><strong>强迫劳动：人类无法想象超出认知范围的事情</strong><br><img src="/img/MayTheFalseBeWithYou_14.jpg" alt=""></p><p><strong>因为拒绝，所以尊重</strong><br><img src="/img/MayTheFalseBeWithYou_15.jpg" alt=""></p><p><strong>儿童节礼物</strong><br><img src="/img/MayTheFalseBeWithYou_16.jpg" alt=""></p><p><strong>玩儿zzzq，您还不够格儿</strong><br><img src="/img/MayTheFalseBeWithYou_17a.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_17b.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_17c.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_17d.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_17e.jpg" alt=""></p><p><strong>“你怎么不戴帽子呢？”</strong><br><img src="/img/MayTheFalseBeWithYou_18.jpg" alt=""></p><p><strong>我大米政治清廉没有腐败</strong><br><img src="/img/MayTheFalseBeWithYou_19.jpg" alt=""></p><p><strong>争相回国参军保卫家园</strong><br><img src="/img/MayTheFalseBeWithYou_20.jpg" alt=""></p><p><strong>屎里掺毒：不是说好自由国度么</strong><br><img src="/img/MayTheFalseBeWithYou_21.jpg" alt=""></p><p><strong>丁仲礼院士：“中国人是不是人？”</strong><br><img src="/img/MayTheFalseBeWithYou_22.jpg" alt=""></p><p><strong>IDF是最“道德”的军队</strong><br><img src="/img/MayTheFalseBeWithYou_23.jpg" alt=""></p><p><strong>川普做得我老登也做得</strong><br><img src="/img/MayTheFalseBeWithYou_24.jpg" alt=""></p><p><strong>棒子的脑回路要好好敲打</strong><br><img src="/img/MayTheFalseBeWithYou_25a.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_25b.jpg" alt=""></p><p><strong>太伟大了，YM</strong><br><img src="/img/MayTheFalseBeWithYou_26a.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_26b.jpg" alt=""></p><p><strong>谁在好好做预算？</strong><br><img src="/img/MayTheFalseBeWithYou_27.jpg" alt=""></p><p><strong>论：世界不是一个草台班子</strong><br><img src="/img/MayTheFalseBeWithYou_28a.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_28b.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_28c.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_28d.jpg" alt=""></p><p><strong>白射黑跑</strong><br><img src="/img/MayTheFalseBeWithYou_29.jpg" alt=""></p><p><strong>Woman inherits the Earth</strong></p><blockquote><p>Ian Malcolm: “God creates dinosaurs, God destroys dinosaurs. God creates Man, Man destroys God. Man creates dinosaurs.”<br>Ellie Sattler: “Dinosaurs eat Man. Woman inherits the Earth.”<br>—-Jurassic Park 1993</p></blockquote><p><img src="/img/MayTheFalseBeWithYou_30.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_30a.webp" alt=""></p><p><strong>说个笑话：英国政府在谴责暴力抗议</strong><br><img src="/img/MayTheFalseBeWithYou_31a.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_31b.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_31c.jpg" alt=""></p><p><strong>日本人是食草民族</strong><br><img src="/img/MayTheFalseBeWithYou_32.jpg" alt=""></p><p><strong>热知识：American=原住民印第安人，白人统统叫欧裔美国人</strong><br><img src="/img/MayTheFalseBeWithYou_33.jpg" alt=""></p><p><strong>But At What Cost?</strong><br><img src="/img/MayTheFalseBeWithYou_34.jpg" alt=""></p><p><strong>脸都不要了</strong><br><img src="/img/MayTheFalseBeWithYou_35.jpg" alt=""></p><p><strong>臣等正欲死战，陛下何故先降</strong><br><img src="/img/MayTheFalseBeWithYou_36a.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_36b.jpg" alt=""></p><p><strong>又要到饭啦，外务省的经费到位了</strong><br><img src="/img/MayTheFalseBeWithYou_38a.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_38b.jpg" alt=""></p><p><strong>这个脑洞也是可以开的吗</strong><br><img src="/img/MayTheFalseBeWithYou_39.jpg" alt=""></p><p><strong><del>年度最佳：</del>雷蒙多称假如美国路上有300万辆中国汽车，北京能让它们同时熄火</strong><br><img src="/img/MayTheFalseBeWithYou_40a.jpg" alt=""><br><img src="/img/MayTheFalseBeWithYou_40b.jpg" alt=""></p><p><strong>真・年度最佳</strong><br><img src="/img/MayTheFalseBeWithYou_41.jpg" alt=""></p><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><p><strong>AGAIN</strong><br><img src="/img/MayTheFalseBeWithYou_97.gif" alt=""></p><p><strong>2024时局图</strong><br><img src="/img/MayTheFalseBeWithYou_98.png" alt=""></p><p><strong>某些指标具有滞后性</strong><br><img src="/img/MayTheFalseBeWithYou_99.JPG" alt=""><br>——《原则：应对变化中的世界秩序》</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;The-Death-Star-is-allowed-to-defend-itself&quot;&gt;&lt;a href=&quot;#The-Death-Star-is-allowed-to-defend-itself&quot; class=&quot;headerlink&quot; title=&quot;The Deat</summary>
      
    
    
    
    
    <category term="Cognitive Warfare" scheme="http://gloomymoon.github.io/tags/Cognitive-Warfare/"/>
    
    <category term="Boomerang" scheme="http://gloomymoon.github.io/tags/Boomerang/"/>
    
    <category term="Starwars" scheme="http://gloomymoon.github.io/tags/Starwars/"/>
    
    <category term="Information Cocoon" scheme="http://gloomymoon.github.io/tags/Information-Cocoon/"/>
    
  </entry>
  
  <entry>
    <title>The Data Science Task Force: Mission DPSIA</title>
    <link href="http://gloomymoon.github.io/2023/12/31/The-Data-Science-Task-Force-Mission-VII/"/>
    <id>http://gloomymoon.github.io/2023/12/31/The-Data-Science-Task-Force-Mission-VII/</id>
    <published>2023-12-31T12:18:47.000Z</published>
    <updated>2024-07-20T14:53:30.308Z</updated>
    
    <content type="html"><![CDATA[<h3 id="数据隐私、安全、完整性和安全分析（DPSIA）"><a href="#数据隐私、安全、完整性和安全分析（DPSIA）" class="headerlink" title="数据隐私、安全、完整性和安全分析（DPSIA）"></a>数据隐私、安全、完整性和安全分析（DPSIA）</h3><p>关于隐私、安全和诚信的问题是相互交织的，也就是说，他们与所有知识领域的能力都相关。因此，该知识领域较其他知识领域更大，这里将其组织成子知识领域，子知识领域内再细分子领域。</p><h3 id="数据隐私（DPSIA-DP）"><a href="#数据隐私（DPSIA-DP）" class="headerlink" title="数据隐私（DPSIA/DP）"></a>数据隐私（DPSIA/DP）</h3><p>数据科学家在获取、处理和生成数据是，因能够考虑数据隐私问题及其相关挑战，应当认识到在共享和保护敏感信息之间的权衡、国内和活期隐私权如何影响公司收集存储和处理数据的责任，在广泛的网络安全领域中，除了专业精神和数据获取与管理以外，还有许多概念和子领域与网络安全知识领域相互参照。</p><table>  <tr><th colspan="2">DPSIA/数据隐私</th></tr>  <tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul>    <li>隐私与安全的跨学科权衡。</li>    <li>个人权利和对社会需求的影响。</li>    <li>保护数据隐私的技术。</li>    <li>个人、组织和政府隐私要求之间的关系。</li>    </ul></td>    <td width="50%">    <ul>    <li>说明隐私概念的合理性，包括什么是个人隐私信息的社会定义，以及个人隐私与安全之间的权衡。</li>    <li>总结和人隐私权与社会需要求之间的权衡。</li>    <li>评估可降低数据泄漏风险和保护数据隐私的常见做法、技术和工具。</li>    <li>辩论与国际接轨的组织必须如何考虑其运营所在司法管辖区在隐私法律、法规和标准方面的差异。本专题包括在组织保护信息系统免受网络攻击时，法律和技术如何在国际、国家和地方司法结构的背景下相互交叉。</li>    </ul>    </td>  </tr>  <tr>     <th colspan="2">子领域</th>  </tr>  <tr>    <td width="50%">    DPSIA/DP-社会责任-T1,T2,E<br>    DPSIA/DP-密码学-T1,T2<br>    </td>    <td width="50%">    DPSIA/DP-信息系统-T1,T2,E<br>    DPSIA/DP-通信协议-T1,T2<br>    </td>  </tr></table><h4 id="DPSIA-DP-社会责任"><a href="#DPSIA-DP-社会责任" class="headerlink" title="DPSIA/DP-社会责任"></a>DPSIA/DP-社会责任</h4><p>概述个人隐私权与社会需求之间的权衡。</p><p><em>知识</em><br>T1：</p><ul><li>利用社会工程和社交媒体可能暴露的敏感数据。</li><li>隐私权与提高信息传播透明度要求之间的权衡。</li><li>关于披露、传输和共享从分析工具获取信息的道德责任。</li></ul><p>T2：</p><ul><li>使用数据执行某些操作时设计隐私问题的法律规范。</li><li>影响社会和计算技术发展的国际隐私法律。</li></ul><p><em>技能</em><br>T1：</p><ul><li>在将数据作为处理输入时，显示出对数据的敏感性。</li><li>确定在处理信息前必须考虑数据清洗的情况。</li><li>对原始数据处理中应用数据隐私技术，如提供范围或加盐技术。</li></ul><p>E：</p><ul><li>了解可能影响决策的全球政策和法官，如HIPAA、FCRA、ECPA。</li><li>展示对知名搜索引擎及其信息存储政策的认识，这些政策会辨识出用户隐私并产生危害。</li></ul><p><em>品行</em><br>T1：</p><ul><li>从道德角度认识到向任何实体提供数据都可能造成数据隐私泄漏。</li><li>通过计算机系统或渠道准确、合规地处理数据，认识到不适当的处理数据会对公共和私人造成影响。</li></ul><h4 id="DPSIA-DP-加密"><a href="#DPSIA-DP-加密" class="headerlink" title="DPSIA/DP-加密"></a>DPSIA/DP-加密</h4><p>概述加密技术在保护数据隐私方面的应用。</p><p><em>知识</em><br>T1：</p><ul><li>再使用任何渠道传输数据之前对其进行加密的重要性。</li><li>权衡使用加密数据与未加密数据进行统计分析的对计算时间影响。</li></ul><p>T2：</p><ul><li>对称加密算法和非对称加密算法的区别。</li><li>用于私密检查和保护认证数据的哈希函数。</li><li>加密算法。</li></ul><p><em>技能</em><br>T1：</p><ul><li>确定采用加密数据的工具/机制，来降低数据泄漏的风险并兼顾计算性能。</li><li>为个人、组织和政府机构等不同实体提供有关影响隐私要求的数据加密流程的培训。</li><li>说明如何使用密码学来提供隐私保护，例如信息验证码、数字签名、验证加密和哈希树。</li><li>处理纯文本数据和加密数据之间的权衡。</li></ul><p>T2：</p><ul><li>分析哪些加密协议、工具和技术适合提供数据隐私、保护、完整性、身份验证、不可抵赖性和混淆性。</li></ul><p><em>品行</em><br>T1：</p><ul><li>敏锐地意识到不同加密机制的必要性。</li></ul><h4 id="DPSIA-DP-信息系统"><a href="#DPSIA-DP-信息系统" class="headerlink" title="DPSIA/DP-信息系统"></a>DPSIA/DP-信息系统</h4><p>概述使用众所周知的模型将数据隐私纳入到信息系统的理念。</p><p><em>知识</em><br>T1：</p><ul><li>实现身份验证、授权、访问控制和数据隐私的概念和技术。</li><li>分层防御，实现最大的保密性、完整性和可用性。</li></ul><p>T2：</p><ul><li>实施数据隐私的不用访问机制，例如Bell-LaPadula多级访问控制模型、中国防火长墙和临床信息信息安全，以解决不同的隐私和透明度利益冲突。</li><li>著名信息系统的设计和实施，及其对数据隐私的影响。</li><li>加密算法。</li></ul><p>E：</p><ul><li>通过流量分析，展示在特定安全系统中私人信息是如何收到危害的。</li></ul><p><em>技能</em><br>T1：</p><ul><li>解释系统的数据隐私需求如何影像系统的安全性。</li><li>讨论数据透明度和数据隐私之间的权衡。</li></ul><p>T2：</p><ul><li>概述应向计算机系统提供哪些信息，并考虑平衡可用性和隐私，以及如何报告信息。</li></ul><p><em>品行</em><br>T1：</p><ul><li>在保护特定计算机系统中的信息时要慎重。</li></ul><h4 id="DPSIA-DP-通讯协议"><a href="#DPSIA-DP-通讯协议" class="headerlink" title="DPSIA/DP-通讯协议"></a>DPSIA/DP-通讯协议</h4><p>总结如何使用通信协议来保证信道（安全和不安全的）上的安全通信；考虑通信协议中使用加密协议；认识广泛使用的应用程序协议对数据隐私的影响。</p><p><em>知识</em><br>T1：</p><ul><li>通过不安全渠道实现安全通信的安全协议的重要性。</li><li>隐私协议对通过安全渠道进行私密通讯的重要性。</li><li>可保证应用程序与服务器之间私密通讯的户粮网通讯协议。</li></ul><p>T2：</p><ul><li>通过使用和不使用加密技术来平衡安全协议与隐私协议的关系。</li></ul><p><em>技能</em></p><p>T2：</p><ul><li>使用安全协议和不同加密原语建立安全通道。</li><li>应用隐私协议，使用安全传输技术建立私人信道。</li></ul><p><em>品行</em><br>T2：</p><ul><li>准确选择安全协议，确保设备之间的私密连接。</li><li>精通在不损害隐私特性的情况下交换数据集的安全协议。</li></ul><h3 id="数据安全（DPSIA-DS）"><a href="#数据安全（DPSIA-DS）" class="headerlink" title="数据安全（DPSIA/DS）"></a>数据安全（DPSIA/DS）</h3><p>本知识单元的重点是保护静态数据、处理过程中的数据和传输中的数据。这要求数据驱动的应用程序充分运用应用数学和分析算法来实现必要的安全目标。通过本单元可以深入了解数据安全目标以及实现这些目标的各种工具。</p><table>  <tr><th colspan="2">DPSIA/数据安全</th></tr>  <tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul>    <li>密码学概念：加密/解密、信息认证、数据完整性、不可否认性；攻击分类（仅密文、已知明文、选择明文、选择密文）；秘钥（对称）加密和公钥（非对称）加密。</li>    <li>数据驱动应用程序的威胁模型。</li>    <li>数学技术在生产有用的加密知识方面发挥的作用。</li>    <li>用于数据安全的公钥密码学。</li>    <li>CSEC2017中数据安全部分提供的更多范围。</li>    </ul></td>    <td width="50%">    <ul>    <li>描述密码学的目的并列举骑在数据通信中的应用方式；以及哪些密码协议、工具和技术适合特定情况。</li>    <li>了解密码、密码分析、密码算法和密码学。</li>    <li>解释公钥基础设施如何支持数字签名和加密，并讨论其局限性/脆弱性。</li>    <li>展示对加密算法背后数据知识的理解。</li>    <li>解释对称密码和非对称密码的区别和应用。</li>    <li>分析对消费/产生关键数据的事实应用程序的威胁。</li>    <li>利用攻击向量和攻击树概念为威胁建模。</li>    <li>解释如何保护网络数据传输。</li>    </ul>    </td>  </tr>  <tr>     <th colspan="2">子领域</th>  </tr>  <tr>    <td width="50%">    DPSIA/DS-安全数据质量和处理-T1,T2<br>    DPSIA/DS-密码工具分类-T2<br>    DPSIA/DS-平衡安全和性能-T2<br>    </td>    <td width="50%">    DPSIA/DS-网络和网络协议-T1<br>    DPSIA/DS-隐私和数据管理-参见DPSIA/DP<br>    </td>  </tr></table><h4 id="DPSIA-DS-数据质量和安全处理"><a href="#DPSIA-DS-数据质量和安全处理" class="headerlink" title="DPSIA/DS-数据质量和安全处理"></a>DPSIA/DS-数据质量和安全处理</h4><p><em>知识</em><br>T1：</p><ul><li>定性指标。</li><li>数据资产安全的重要性。</li><li>所需的安全目标类型。</li><li>数据来源和资产。</li><li>控制和管理数据资产的可访问性。</li></ul><p>T2：</p><ul><li>攻击向量和攻击树。</li><li>不同用例的威胁模型。</li><li>威胁对数据源的影响。</li></ul><p><em>技能</em></p><p>T1：</p><ul><li>了解应用程序中的数据流。</li><li>得出要实现的重要安全目标。</li><li>解释选择保护哪些数据资产的原因。</li></ul><p>T2：</p><ul><li>根据应用程序中的数据流推断可能存在的安全和隐私威胁。</li><li>实施访问控制机制，限制数据泄漏。</li><li>实施安全访问数据资产所需的认证流程。</li><li>根据外部和内部因素评估数据资产的重要性。</li><li>对实际系统进行威胁分析。</li><li>根据影响对威胁进行分类</li></ul><p><em>品行</em><br>T2：</p><ul><li>准确提取数据驱动系统威胁的能力。</li></ul><h4 id="DPSIA-DS-密码工具分类"><a href="#DPSIA-DS-密码工具分类" class="headerlink" title="DPSIA/DS-密码工具分类"></a>DPSIA/DS-密码工具分类</h4><p><em>知识</em><br>T2：</p><ul><li>加密技术。</li><li>各种技术和工具的可用性。</li><li>利用离散数学概念进行密码协议设计。</li><li>公钥密码系统与私钥密码系统的比较。</li></ul><p><em>技能</em><br>T2：</p><ul><li>应用各种密码技术，实现必要的安全目标。</li><li>比较各种技术的优缺点。</li><li>解释各种技术的性能特点。</li><li>列出每种加密技术的攻击模型。</li><li>利用现有的加密方案实施数据安全机制。</li></ul><p><em>品行</em><br>T2：</p><ul><li>认识各种机密协议的重要性和独特性。</li><li>根据应用要求选择正确的协议。</li></ul><h4 id="DPSIA-DS-安全与性能权衡"><a href="#DPSIA-DS-安全与性能权衡" class="headerlink" title="DPSIA/DS-安全与性能权衡"></a>DPSIA/DS-安全与性能权衡</h4><p><em>知识</em><br>T2：</p><ul><li>数据驱动应用程序的性能要求。</li><li>安全方案对应用程序性能的影响。</li></ul><p><em>技能</em><br>T2：</p><ul><li>应用设计原则，平衡性能和安全需求。</li><li>调查运行环境，确定影响系统性能和安全性的关键参数。</li><li>开发技能提高数据可用性，又能实现必要安全性的机制。</li></ul><p><em>品行</em><br>T2：</p><ul><li>了解不同协议之间的性能和安全权衡。</li><li>根据应用需求，确定选择哪种加密技术。</li></ul><h4 id="DPSIA-DS-网络和网络协议"><a href="#DPSIA-DS-网络和网络协议" class="headerlink" title="DPSIA/DS-网络和网络协议"></a>DPSIA/DS-网络和网络协议</h4><p><em>知识</em><br>T1：</p><ul><li>洞察数据驱动型应用的网络数据交换。</li><li>网络和网络协议。</li><li>通信协议中可用和/或启用的安全模块。</li><li>数据网络和网络操作（存储、检索、远程计算）。</li></ul><p><em>技能</em><br>T1：</p><ul><li>剖析和调整通信协议，确保安全。</li><li>解释网络和网络协议的独特特征和工作原理。</li><li>了解数据如何通过网络或网页传送到各个实体。</li></ul><p><em>品行</em><br>T1：</p><ul><li>高度重视网络/网络协议安全。</li></ul><h3 id="数据完整性（DPSIA-DI）"><a href="#数据完整性（DPSIA-DI）" class="headerlink" title="数据完整性（DPSIA/DI）"></a>数据完整性（DPSIA/DI）</h3><p>本知识单元的重点是数据从生产到传输、存储、检索和处理的整个生命周期中的完整性、准确性和一致性。数据完整性的保护在数据科学领域是强制性的，因为对数据的恶意操作会导致错误的推断，并使决策过程陷入混乱。数据科学家必须了解完整性保护工具和技术，同事了解它们的作用和效率，以便在数据科学应用中正确执行完整性要求。</p><table>  <tr><th colspan="2">DPSIA/数据完整性</th></tr>  <tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul>    <li>数据的准确性、一致性和有效性。</li>    <li>从安全角度看待完整性要求的必要性。</li>    <li>确保数据完整性的技术和机制。</li>    <li>数据完整性中常见的安全威胁。</li>    </ul></td>    <td width="50%">    <ul>    <li>解释数据完整性、数据安全性和数据隐私的区别。</li>    <li>描述处理数据完整性所需的主要知识领域。</li>    <li>展示运用常用方法确保数据完整性的技能。</li>    <li>在应对影响数据完整性的安全威胁时，自信地执行任务。</li>    </ul>    </td>  </tr>  <tr>     <th colspan="2">子领域</th>  </tr>  <tr>    <td width="50%">    DPSIA/DI-逻辑完整性-T1<br>    DPSIA/DI-物理完整性-T1<br>    DPSIA/DI-影响数据完整性的安全威胁-T1<br>    </td>    <td width="50%">    DPSIA/DI-确保数据完整性的方法-T1<br>    DPSIA/DI-数据损坏和数据验证-T2<br>    </td>  </tr></table><h4 id="DPSIA-DI-逻辑完整性"><a href="#DPSIA-DI-逻辑完整性" class="headerlink" title="DPSIA/DI-逻辑完整性"></a>DPSIA/DI-逻辑完整性</h4><p><em>知识</em><br>T1：</p><ul><li>逻辑完整性概念。</li><li>数据系统中的完整性约束类型。</li><li>实体完整性、参照完整性、域完整性、用户定义完整性。</li></ul><p><em>技能</em><br>T1：</p><ul><li>解释逻辑完整性的概念。</li></ul><p><em>品行</em><br>T1：</p><ul><li>准确解释逻辑完整性。</li></ul><h4 id="DPSIA-DI-物理完整性"><a href="#DPSIA-DI-物理完整性" class="headerlink" title="DPSIA/DI-物理完整性"></a>DPSIA/DI-物理完整性</h4><p><em>知识</em><br>T1：</p><ul><li>物理完整性的概念</li><li>确保数据完整性的物理和硬件方法，例如：RAID、冗余硬件、不间断电源、内存纠错和服务器集群。</li></ul><p><em>技能</em><br>T1：</p><ul><li>解释物理完整性的概念。</li><li>描述确保物理完整性的物理和硬件方法。</li></ul><p><em>品行</em><br>T1：</p><ul><li>通过硬件方法解决物理完整新问题的信心。</li></ul><h4 id="DPSIA-DI-影响数据完整性的安全威胁"><a href="#DPSIA-DI-影响数据完整性的安全威胁" class="headerlink" title="DPSIA/DI-影响数据完整性的安全威胁"></a>DPSIA/DI-影响数据完整性的安全威胁</h4><p><em>知识</em><br>T1：</p><ul><li>常见的数据完整性威胁包括：人为错误、软件错误、传输错误、恶意软件、内部威胁、网络攻击和受损硬件。</li><li>数据和信息中毒。</li><li>数据出处保证。</li></ul><p><em>技能</em><br>T1：</p><ul><li>列出影响数据完整性的常见安全威胁类型。</li><li>描述SHA-1和MD5等不同哈希函数背后的潜在漏洞。</li></ul><p><em>品行</em><br>T1：</p><ul><li>有信心描述常见的安全威胁。</li></ul><h4 id="DPSIA-DI-确保数据完整性的方法"><a href="#DPSIA-DI-确保数据完整性的方法" class="headerlink" title="DPSIA/DI-确保数据完整性的方法"></a>DPSIA/DI-确保数据完整性的方法</h4><p><em>知识</em><br>T1：</p><ul><li>哈希算法在完整性保护中的作用。</li><li>信息验证码及其变体的作用。</li><li>实现完整性的CRC和校验和。</li><li>数字签名方案（RSA和ECDSA）背后的机制。</li></ul><p><em>技能</em><br>T1：</p><ul><li>解释如何使用哈希算法和MAC机制来确保数据完整性。</li><li>描述数字签名方案及其在完整性保护方面的需求。</li><li>从性能和安全的角度对不同的完整性保护技术进行比较和对比。</li><li>了解如何在多个数据所有权域中使用完整性模型，以确保出处和维护数据有效性。</li></ul><p><em>品行</em><br>T1：</p><ul><li>通过使用各种方法和技术彻底解决数据完整性问题。</li></ul><h4 id="DPSIA-DI-数据损坏和数据验证"><a href="#DPSIA-DI-数据损坏和数据验证" class="headerlink" title="DPSIA/DI-数据损坏和数据验证"></a>DPSIA/DI-数据损坏和数据验证</h4><p><em>知识</em><br>T2：</p><ul><li>数据损坏的概念。</li><li>数据验证的概念。</li><li>防止数据损坏的方法，包括校验和与纠错码。</li><li>验证方法包括输入验证、数据类型验证、范围和约束验证以及交叉引用验证。</li></ul><p><em>技能</em><br>T2：</p><ul><li>解释数据损坏和数据验证的概念。</li><li>说明防止数据损坏和确保数据验证的方法。</li></ul><h3 id="安全分析（DPSIA-AS）"><a href="#安全分析（DPSIA-AS）" class="headerlink" title="安全分析（DPSIA/AS）"></a>安全分析（DPSIA/AS）</h3><p>本知识单元侧重于数据科学分析技术，包括统计、概率、机器学习和数据挖掘，特别关注安全和隐私问题。通过本单元的学习，可以加深度数据科学工具、算法和技术在安全与隐私方面的理解。</p><table>  <tr><th colspan="2">DPSIA/安全数据分析</th></tr>  <tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul>    <li>了解安全数据遥测和不同的安全应用。</li>    <li>安全遥测数据统计分析。</li>    <li>针对安全遥测数据的机器学习。</li>    <li>针对安全关键型应用的可解释机器学习方法。</li>    <li>机器学习的脆弱性和稳健型</li>    </ul></td>    <td width="50%">    <ul>    <li>对不同的安全关键型应用进行分类，并了解各种安全遥测数据。</li>    <li>展示在机器学习（ML）和统计方法面的深入知识和强大的动手实践技能，以改进安全应用。</li>    <li>认识到在安全应用中何时需要使用多语言可解释性和弹性</li>    </ul>    </td>  </tr>  <tr>     <th colspan="2">子领域</th>  </tr>  <tr>    <td width="50%">    DPSIA/AS-机器学习（ML）算法和安全统计方法-T1<br>    </td>    <td width="50%">    DPSIA/AS-机器学习（ML）的鲁棒性和可解释性-T1<br>    DPSIA/AS-安全应用类别-T2<br>    </td>  </tr></table><h4 id="DPSIA-AS-机器学习（ML）算法和安全统计方法"><a href="#DPSIA-AS-机器学习（ML）算法和安全统计方法" class="headerlink" title="DPSIA/AS-机器学习（ML）算法和安全统计方法"></a>DPSIA/AS-机器学习（ML）算法和安全统计方法</h4><p><em>知识</em><br>T1：</p><ul><li>对安全数据进行探索性数据分析的统计方法，包括描述性统计、汇总图、离散点检测、点估计、假设检验、检验统计、线性回归和广义线性回归。</li><li>基于计算机视觉的方法，如恶意软件即图像技术、迁移学习、基于硬件的分层集合神经网络（HeNet），可用于静态和动态威胁分类和恶意软件检测。</li></ul><p><em>技能</em><br>T1：</p><ul><li>将安全应用转化为可以使用ML解决的问题。</li><li>通过采用恶意软件即图像、迁移学习和分层集合神经网络（HeNet）等静态和动态监测机制，设计恶意软件检测解决方案。</li><li>向不同背景的受众解释ML模型在安全应用中做出的决策。</li></ul><p><em>品行</em><br>T1：</p><ul><li>了解计算机视觉、自然语言处理和经典数据分析的不同视角，已解决威胁检测、恶意软件情报和漏洞识别问题。</li></ul><h4 id="DPSIA-AS-机器学习（ML）的鲁棒性和可解释性"><a href="#DPSIA-AS-机器学习（ML）的鲁棒性和可解释性" class="headerlink" title="DPSIA/AS-机器学习（ML）的鲁棒性和可解释性"></a>DPSIA/AS-机器学习（ML）的鲁棒性和可解释性</h4><p><em>知识</em><br>T1：</p><ul><li>对抗式机器学习的基本概念、针对ML模型的攻击类型，以及对抗性机器学习技术，如快速梯度符号、迭代快速梯度、通用对抗性扰动。</li><li>防御技术，如对抗训练，以更好地保护ML模型。</li><li>用于安全应用的可解释机器学习方法。解释包括基于每个样本的局部解释和考虑整个数据集的全局解释。了解如何在基于视觉的恶意软件检测机制中对自然图像采用与模型无关的解释。</li></ul><p><em>技能</em><br>T1：</p><ul><li>从识别盲点和绕过检测的角度评估ML的可靠性。</li><li>通过开展对抗训练，提高ML的可靠性。</li><li>对ML算法进行研究，并向安全专家解释这些模型的影响。</li><li>与各利益相关方沟通，以定义ML指标，解决可解释性和脆弱性问题。</li><li>解释为什么人工智能的可靠性和脆弱性是安全和隐私应用中使用的人工智能的关键指标。</li><li>将LIME、LEMNA、TCAV等可解释人工智能方法应用于为安全应用构建的ML模型。</li><li>根据可信分数执行并进行ML模型选择。特别是在使用恶意软件即图像方法时，要有效地应用LIME来实现恶意软件分类模型的可解释性。</li></ul><p><em>品行</em><br>T1：</p><ul><li>除了评估分类准确性、误报率、精确度和其他特征的典型指标外，还是用鲁棒性和潜在漏洞来评估ML，注重细节。</li></ul><h4 id="DPSIA-AS-安全应用类别"><a href="#DPSIA-AS-安全应用类别" class="headerlink" title="DPSIA/AS-安全应用类别"></a>DPSIA/AS-安全应用类别</h4><p><em>知识</em><br>T2：</p><ul><li>安全关键型应用：网络分析、恶意软件理解、恶意软件甄别、动态恶意软件分析、硬件遥测分析。</li><li>安全遥测数据类型：动态日志、二进制、静态代码、动态代码。</li></ul><p><em>技能</em><br>T2：</p><ul><li>根据安全遥测数据的性质选择要使用的ML方法。</li></ul><p><em>品行</em><br>T2：</p><ul><li>通过各种安全应用和数据集的优化使用，主动增加对数据使用的了解。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;数据隐私、安全、完整性和安全分析（DPSIA）&quot;&gt;&lt;a href=&quot;#数据隐私、安全、完整性和安全分析（DPSIA）&quot; class=&quot;headerlink&quot; title=&quot;数据隐私、安全、完整性和安全分析（DPSIA）&quot;&gt;&lt;/a&gt;数据隐私、安全、完整性和安全分析（</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>The Data Science Task Force: Mission DM</title>
    <link href="http://gloomymoon.github.io/2023/12/17/The-Data-Science-Task-Force-Mission-VI/"/>
    <id>http://gloomymoon.github.io/2023/12/17/The-Data-Science-Task-Force-Mission-VI/</id>
    <published>2023-12-17T04:17:42.000Z</published>
    <updated>2024-07-20T14:53:35.093Z</updated>
    
    <content type="html"><![CDATA[<h3 id="数据挖掘（DM-Data-Mining）"><a href="#数据挖掘（DM-Data-Mining）" class="headerlink" title="数据挖掘（DM, Data Mining）"></a>数据挖掘（DM, Data Mining）</h3><p>数据挖掘的核心是对数据进行处理、分析和展示，以获得有价值的信息。一个重要的先决条件是准备好适当与手头的任务相关的高质量的数据。基本的分析类型包括聚类、分类、回归、模式挖掘、预测、关联和离群点检测，并注意数据的不同形态，包括时间序列数据和网络数据。这些概念中的许多都取决于数据的邻近度概念。</p><table>  <tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul>    <li>数据挖掘及与数据准备和数据管理的关系</li>    <li>各种数据类型和应用的数据挖掘模型 </li>    <li>为各种任务选择和应用数据挖掘算法</li>    </ul></td>    <td width="50%">    <ul>    <li>使学生掌握关于可用于挖掘数据的技术范围以及相关算法及其适用性的知识</li>    <li>使学生具备识别和使用可能以各种形式存在的数据挖掘工具和技术的能力</li>    <li>使学生对数据挖掘有高度的信心。</li>    </ul>    </td>  </tr>  <tr>     <th colspan="2">子领域</th>  </tr>  <tr>    <td width="50%">    DM-近邻测量-T1,T2<br>    DM-数据准备-T1<br>    DM-信息提取-E<br>    DM-聚类分析-T1,T2<br>    DM-分类和回归-T1,T2<br>    </td>    <td width="50%">    DM-模式挖掘-T2<br>    DM-离群点检测-T2<br>    DM-时间序列数据-E<br>    DM-互联网数据挖掘-T2<br>    DM-信息检索-T2<br>    </td>  </tr></table><h4 id="DM-近邻测量"><a href="#DM-近邻测量" class="headerlink" title="DM-近邻测量"></a>DM-近邻测量</h4><p>度量数据之间的差异和相似性有很多种方法，对于数值类数据，通常使用两个向量之间的距离来表示（差异），对其他类型数据会使用到不同类型的相似度定义（例如文本余弦相似度）或相关概念。某些特殊情况下可能会需要制定特殊的相似度定义。</p><p><em>知识</em><br>T1：</p><ul><li>度量的基本特性。</li><li>距离度量；典型的案例：欧式距离、曼哈顿距离。</li><li>使用分数和排名；使用合适的分数或排名体系。</li><li>对数据进行归一化以支持比较。</li></ul><p>T2：</p><ul><li>关于文本的度量。</li><li>数据序列的相关系数等指标。</li><li>基于关系的相似性度量，例如图中的SimRank。</li><li>基于图的度量指标。</li><li>衡量时间序列数据相似性的指标，如动态时间规整。</li></ul><p><em>技能</em><br>T1：</p><ul><li>描述并比较度量概念及其与不同类型数据（标称、顺序、区间和比率）的相关性。。</li><li>选择比较各类数据的合适指标。</li></ul><p>T2：</p><ul><li>描述非数字数据的内部表示法，如字符、字符串和图像。</li><li>描述多核和多处理器系统之间的区别。</li><li>解释经典冯诺依曼机的架构及主要功能单元。</li><li>讨论超越经典冯诺依曼模型的并行处理概念。</li></ul><p><em>品行</em><br>T1：</p><ul><li>准确而又有创新地使用现存的典型常用的衡量分数和指标。</li></ul><h4 id="DM-数据准备-T1"><a href="#DM-数据准备-T1" class="headerlink" title="DM-数据准备-T1"></a>DM-数据准备-T1</h4><p>高质量数据的可用性和准备工作对数据科学至关重要，收集来自各种可能来源相关数据后，需要确保数据集符合使用目的。</p><p><em>知识</em></p><ul><li>收集数据、数据与解决问题的关系、专家知识的重要性以及听取专家的意见。</li><li>数据来源，包括数据库、物联网、照片和视频、在线信息来源，数据是否满足用于特定目标。</li><li>关于用于特定目的获取和使用数据的伦理考量，关于共用数据的隐私问题，关于数据中可能存在的偏见问题。</li><li>整理数据——处理数据中的错误、空白，清理数据，验证数据、剖析数据、转化数据，并酌情关联数据集，以及考虑质量因素。</li><li>处理数据集问题的方法，如数据不平衡、属性不足或不相关；采用自动或人工方法以及两者之前的权衡选择。</li><li>特征的概念，特征的提取和表示，特征的选择和特征生成。</li></ul><p><em>技能</em></p><ul><li>说明提出问题的过程与获取数据回答问题的过程之间的联系。</li><li>通过与专家适当互动，展示特定领域的专业知识。</li><li>在探索性数据分析中使用汇总统计和可视化方法进行推断。</li><li>说明数据集可能产生的问题影响和解决方法。</li><li>解释各种生成特征方法的好处和影响。</li><li>描述特征选择和特征生成之间的异同。</li><li>演示如何生成更少或更多的特征。</li></ul><p><em>品行</em></p><ul><li>准确选择和准备数据，了解处理高质量数据的重要性。</li></ul><h4 id="DM-信息提取-E"><a href="#DM-信息提取-E" class="headerlink" title="DM-信息提取-E"></a>DM-信息提取-E</h4><p>信息提取是指从不同形式存在的非结构化数据中提取结构化信息的技术和过程，它是从文档、网页甚至多媒体中获取数据的重要技术。</p><p><em>知识</em></p><ul><li>信息提取的应用。</li><li>实体和关系的提取。</li><li>基于规则的信息提取方法及其应用。</li><li>基于统计的信息提取方法及其应用。</li><li>提取数据中可能存在的问题。</li></ul><p><em>技能</em></p><ul><li>根据应用要求和数据设计模式。</li><li>使用基于规则和基于统计的方法为应用程序编写信息提取规则。</li><li>在规则或模型学习和关系预测等信息提取任务中应用学习算法。</li></ul><p><em>品行</em></p><ul><li>敏锐地认识到从数据中提取信息有多种方法。</li></ul><h4 id="DM-聚类分析"><a href="#DM-聚类分析" class="headerlink" title="DM-聚类分析"></a>DM-聚类分析</h4><p>聚类涉及将表现出某种相似性的数据点组合在一起，这意味着对邻近性的某种解释，而对邻近性的解释有多种多样，二维或三维的聚类通常可以通过可视化来识别，但这在更高维度上并不总是很容易实现。一般来说，聚类可能是紧凑的，而且分离得很好，但也并非总是如此。（另请参见ML-无监督学习）</p><p><em>知识</em><br>T1：</p><ul><li>为聚类活动确定适当的相似度量。</li><li>聚类质量评估。</li><li>k近邻聚类算法，包括迭代考虑因素。</li><li>基于密度的聚类算法。</li><li>聚类的应用。</li></ul><p>T2：</p><ul><li>均值移动聚类。</li><li>层次聚类。</li><li>基于网格的算法。</li><li>聚类算法加速和并行化策略。</li></ul><p><em>技能</em><br>T1：</p><ul><li>解释特征选择对聚类的重要性。</li><li>为k-means算法初始化标准的选择提供指导。</li></ul><p>T2：</p><ul><li>比较聚类方法，突出相对优势和不足。</li><li>指出在那些情况下应使用何种聚类算法，以及在哪些情况下其他替代方法更为可取。</li><li>将算法应用于测试数据集，并比较结果。</li><li>举例说明，突出聚类的效用和价值。</li></ul><p><em>品行</em><br>T1：</p><ul><li>准确了解聚类在数据科学中的作用。</li><li>敏锐地认识到可扩展的高校聚类算法在实际应用中的重要性。</li></ul><h4 id="DM-分类和回归"><a href="#DM-分类和回归" class="headerlink" title="DM-分类和回归"></a>DM-分类和回归</h4><p>有很多应用领域都需要为数据示例（可能很复杂）分配一个类型，同样，也有许多应用领域需要为数据实例分配数据值。前者被称为分类。回归则涉及估计变量与一个或多个自变量之间的关系。虽然这些是不同的任务，但它们是相关，许多数据挖掘方法可以同时适用于这两种情况。这两种工作有一个显著的特点是，它们都需要标注好的训练数据，即已分配类/因变量值的代表性样本。（请参阅“ML-监督学习”和“ML-深度学习”）</p><p><em>知识</em><br>T1：</p><ul><li>有关分类特征选的考虑因素。</li><li>基于样本的方法，比如K近邻。</li><li>决策树方法。</li><li>概率模型、朴素贝叶斯。</li></ul><p>T2：</p><ul><li>基于规则的方法。</li><li>支持向量机。</li><li>神经网络。</li><li>分类和回归的实际应用。</li><li>深度学习及相关软件支持（如Faffe、TensorFlow、PyTorch）。</li></ul><p>E：</p><ul><li>加速和并行化策略。</li></ul><p><em>技能</em><br>T1：</p><ul><li>解释特征选择对分类和回归的重要性。</li><li>描述选择一种方法而不是另一种的标准和原因，如预测准确性、所学模型的可解释性等。</li></ul><p>T2：</p><ul><li>确定回归与分类之间的关系。</li><li>识别可能受益于分类器或回归模型的关键情况。</li><li>确定支持每种方法的软件，并应用。</li><li>展示选择分类方法并臻明其合理性的能力，以及将其应用于复杂程度适中的案例的能力。</li></ul><p><em>品行</em><br>T1：</p><ul><li>敏锐地认识到可扩展、高效的分类和回归算法在实际应用中的重要性。</li></ul><p>T2：</p><ul><li>透彻的描述分类和回归之间的联系，以及更广泛的统计学和机器学习。</li></ul><h4 id="DM-模式挖掘-T2"><a href="#DM-模式挖掘-T2" class="headerlink" title="DM-模式挖掘-T2"></a>DM-模式挖掘-T2</h4><p>本主题设计在数据中寻找模式，对于规模相当大的数据集合，暴力方法往往在计算上不可行，但选择合适的算法提供了一种解决方法。（通过基因组测序，模式匹配在生物技术中有着重要的应用，但在此不再赘述）</p><p><em>知识</em></p><ul><li>关联模式挖掘的概念。</li><li>计算复杂性考虑。</li><li>关联规则挖掘；Apriori和频繁模式增长算法。</li><li>序列模式挖掘；GSP算法。</li><li>模式挖掘的高效并行算法。</li><li>应用领域。</li></ul><p><em>技能</em></p><ul><li>阐述Apriori算法可在日常环境中发挥优异作用的系列领域。</li><li>在重要应用中实现Apriori算法。</li><li>比较和对比模式挖掘算法的实用性。</li></ul><p><em>品行</em></p><ul><li>坚信模式挖掘是一个应用广泛的课题。</li></ul><h4 id="DM-离群点检测-T2"><a href="#DM-离群点检测-T2" class="headerlink" title="DM-离群点检测-T2"></a>DM-离群点检测-T2</h4><p>离群点是指与其他绝大多数数据表现出截然不同特征的数据点，识别这些数据点是可取的，因为过度关注这类数据会导致数据失真（甚至可能暗示存在欺诈），同样重要的是，通过充分了解该领域来确定是否存在（合法的）例外情况。在下文中，我们将假定数据已经过清洗，并且存在真正的离群点。</p><p><em>知识</em></p><ul><li>离群值概念的定义。</li><li>一般方法——建立数据模型，然后指出某个数据点不符合模型。</li><li>参数方法，例如在一维数据中识别数字异常的z分数。</li><li>使用概率分布函数。</li><li>使用深度优先方法——在确定了一组点的预期凸壳之后，它是在内部还是外部；使用相关的图形方法。</li><li>应用领域。</li></ul><p><em>技能</em></p><ul><li>应用一系列离群点检测方法的算法。</li><li>比较和对比异常值检测的参数法和非参数法。</li><li>解释离群点检测方法如何有助于查重、识别金融欺诈、检测网络入侵或其他应用领域。</li><li>通过适当的例子说明离群点检测的重要性。</li></ul><p><em>品行</em></p><ul><li>具备对异常值分析和检测的头车型和敏锐视角。</li></ul><h4 id="DM-时间序列数据-E"><a href="#DM-时间序列数据-E" class="headerlink" title="DM-时间序列数据-E"></a>DM-时间序列数据-E</h4><p>对于某些类型的数据来说，时间或日期戳非常重要，例如，这可用于测量一段时间内增长情况、或测量特定时期的交通拥堵情况。另请参阅“ML-混合方法”。</p><p><em>知识</em></p><ul><li>时间序列数据的性质，包括与连续时间数据的比较。</li><li>数据转换——去除噪音、对时间序列数据进行归一化处理。</li><li>静态和非静态时间序列。</li><li>将时间序列数据转换为离散序列数据。</li><li>时间序列预测——根据过去的数值预测未来的数值。</li><li>时间序列图案——时间序列数据中经常出现的图案。</li><li>时间序列聚类和分类。</li><li>时间序列中的离群值检测——点离群值和形状离群值。</li></ul><p><em>技能</em></p><ul><li>列出一系列有相关时间序列数据的情况，并指出挖掘这些数据的重要性。</li><li>说明和是需要将时间序列数据转换为序列数据。</li><li>解释用于时间序列数据聚类和分类的技术。</li></ul><p><em>品行</em></p><ul><li>注重细节，因为时间序列数据的数据挖掘与某些关键应用高度相关。</li></ul><h4 id="DM-互联网数据挖掘-T2"><a href="#DM-互联网数据挖掘-T2" class="headerlink" title="DM-互联网数据挖掘-T2"></a>DM-互联网数据挖掘-T2</h4><p>互联网上存在着越来越多的数据，以及挖掘这些数据的机制，再进行数据收集和挖掘时，应一如既往地遵守道德规范。</p><p><em>知识</em></p><ul><li>网络访问及相关的网络抓取和网络爬虫过程。</li><li>访问网络数据相关的道德准则。</li><li>访问网络数据的软件库的结构和功能。</li><li>网络数据的知识发现方法，如社区发现和连接预测。</li></ul><p><em>技能</em></p><ul><li>对比社区发现和连接预测。</li><li>使用软件从公开网站获取特定数据。</li><li>开发从网络中发现知识的高效算法。</li></ul><p><em>品行</em></p><ul><li>具备在考虑到伦理框架的情况下，获取高质量数据的毅力和协同能力。</li></ul><h4 id="DM-信息检索-T2"><a href="#DM-信息检索-T2" class="headerlink" title="DM-信息检索-T2"></a>DM-信息检索-T2</h4><p>信息检索包括从一个较大的（通常是非结构化的）数据集中识别和检索信息的规范方法，通常被视为设计搜索文档本身、查询文件或搜索网络等。文档的形式多种多样：文本、图像、视频、录音等。数据的初始存储方式会极大地影响信息检索过程的效率和效果。信息检索在某些领域尤为重要，例如数字图书馆，霍总医疗健康记录中提取信息，它与数据挖掘知识领域有着密切的联系。</p><p><em>知识</em></p><ul><li>用于衡量检索过程效率的技术。</li><li>存储和组织数据的一系列方法，以便有效提取信息；使用编码功能。</li><li>搜索策略的概念；缩小和扩大搜索范围的相关作用。</li><li>为检索过程选择关键词；使用布尔运算符。</li><li>搜索有序数据。</li><li>搜索文本资料的技术。</li><li>搜索一组文件；列出所选项目名称的策略。</li><li>非文本数据的特征识别和提取；使用照片、声音和视频的搜索策略。</li><li>散列、索引和过滤的作用。</li><li>搜索文本资料的方法。</li><li>创建和搜索关系型数据库系统的技术。</li><li>各种关系性、非关系型和其他类型数据库的格式。</li><li>基于网络的信息检索；将网络视为由相互连接的节点组成的图；图论中的相关衡量标准；PageRank和促进基于网络搜索的相关衡量标准。</li></ul><p><em>技能</em></p><ul><li>针对给定的信息检索任务制定搜索策略。</li><li>解释信息检索过程中可能涉及的伦理问题。</li><li>确定使用并行技术加快搜索速度的机会。</li><li>概述网络搜索有效策略的主要内容。</li><li>确定可用于图像、声音和视频剪辑相关的信息检索任务的软件。</li><li>使用SQL创建和使用关系型数据库。</li><li>解释信息检索在数字图书馆运行中可能发挥的作用。</li></ul><p><em>品行</em></p><ul><li>关注信息检索中一系列重要考虑因素的细节，这些因素应成为高校和有效的信息检索方法的基础。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;数据挖掘（DM-Data-Mining）&quot;&gt;&lt;a href=&quot;#数据挖掘（DM-Data-Mining）&quot; class=&quot;headerlink&quot; title=&quot;数据挖掘（DM, Data Mining）&quot;&gt;&lt;/a&gt;数据挖掘（DM, Data Mining）&lt;/h3</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>The Wandering Chinese Sci-Fi Movies</title>
    <link href="http://gloomymoon.github.io/2023/01/29/The-Wandering-Chinese-SciFi-Movies/"/>
    <id>http://gloomymoon.github.io/2023/01/29/The-Wandering-Chinese-SciFi-Movies/</id>
    <published>2023-01-29T04:33:06.000Z</published>
    <updated>2024-07-20T14:41:28.093Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>意识形态的阵地，我们不去占领，人家就会去占领。</p></blockquote><h2 id="0-赞！大赞！"><a href="#0-赞！大赞！" class="headerlink" title="0 赞！大赞！"></a>0 赞！大赞！</h2><p>《流浪地球2》是一个很“奇怪”的片子，是科幻片或灾难片，但又不单纯是科幻片或灾难片，因为其中某些桥段和场景是非常能够引发中国人民的共鸣，就像我一刷回来和朋友安利的时候说的：这几乎就是最近三年的历史总结篇，是包裹了科幻外衣的政治宣传片，后续如果没有国家队下场撑腰才是见了鬼了。果然。</p><p>关键词：中国式赛博朋克、虚拟现实、人工智能觉醒、太空奥德赛、动力机甲、“时空穿越”、原子能、反乌托邦、缸中之脑、太空电梯、生于忧患死于安乐、破釜沉舟背水一战、团结就是力量、合作共赢、存人失地人地皆留、中国式的传承（君臣、师徒、父子……）。</p><blockquote><p>一个人在家<br>我打开电视机<br>非常男女就做游戏<br>我换了一个台<br>又换了一个台<br>却始终逃不出清代<br>——郑钧《怪现象》</p></blockquote><p>在流浪地球出现以前，华语电影主流题材都是历史剧、历史片，从电视剧到电影，从秦朝《英雄》到清朝《末代皇帝》，悠远深厚的历史文化确实是当时我们少数能够拿得出手的文化伟哥。早期的科幻片如《霹雳贝贝》、《大气层消失》也是级小众，也是靠内容撑起了没有特效和宏大场景的国人口碑。几年前国内技术团队已经可以做出不亚于工业光魔等国外知名视效公司水平的逼真数码场景，但当电影中加入了中国元素总透着一层异样的违和感和不真实感。随着歼20、003、东风17&amp;41、天宫空间站、祝融号火星车的陆续登场，让电影里的的太空电梯、行星发动机显得不那么违和和错乱，所以，只有当工业能力和国家实力达到足够的强度时，才足够承载强大的科幻片和民族自信。</p><h2 id="1-一刷观后感"><a href="#1-一刷观后感" class="headerlink" title="1 一刷观后感"></a>1 一刷观后感</h2><h3 id="刚看完（甚至是在看得中间）感到情节上的疑惑："><a href="#刚看完（甚至是在看得中间）感到情节上的疑惑：" class="headerlink" title="刚看完（甚至是在看得中间）感到情节上的疑惑："></a>刚看完（甚至是在看得中间）感到情节上的疑惑：</h3><p>1、周喆直提到中国1987年就收到“2044”危机的提示，是不是落入了“时间穿越”的老套路，个人感情上不希望用这种机械降神来简单解释科幻设定；<br>2、周喆直在明知北京先遣队任务失败的情况下，仍执意要求“点火”发动机，自信和缘由何来；图恒宇输入密码是早于倒计时结束的，说明导演在误导观众，类似MI那样最后一刻拯救地球的侥幸不符合本电影人民史观的主旨（二刷确认，输入界面还提示根服务器联网成功，但是中控室那边进度还是97%）；<br>3、300勇士手动触发月球“相控阵核爆”，如何保证时间上的一致（从影片画面上看核爆是有顺序的，由外至内依次触发），万一有人因他人核爆丧生没有及时触发自己的核弹，岂不功亏一篑；<br>4、方舟空间站坠落太过迅速和突然，而且离电梯底座距离过近；<br>5、安全扣和门坏的有点蹊跷；<br>6、图恒宇牺牲前上传到数字生命，丫丫说的话几乎就是马兆的口吻和语气，意味着马兆==图丫丫？<br>7、周喆直个人办公室内也有MOSS的摄像头？难道这种级别的官员办公室都可以明目张胆监控吗？（还是为了体现周喆直多次注视摄像头的情节服务？）<br>8、彩蛋中MOSS的直白，给人感觉流浪地球像是Matrix翻版，虽然并不是；<br>9、550W最后和刘培强对话时自称MOSS，这事周喆直、联合政府知道吗？怎么看？（马兆人称马老师，读快了就近似MOSS的发音）<br>10、地球上现存核弹数量（当量）正好等同于毁灭月球的核弹数量（当量），太过巧合了。若数量完全一样，在送上月球期间出现疏漏，又无法和饱和式救援的理念保持一致了。此片中，各处都可以体现UEG（至少中国政府）是留有大量备案的；<br>11、削苹果皮浪费，皮比苹果更有营养。我觉得这个可能真是中国人才会关注的点，看网上有说刘培强是把苹果皮嚼了，但是郭导砍时长，也应该保留培强往嘴里放果皮的镜头（2/4二刷更正：看到刘培强吃果皮的镜头了）；<br>12、数字化的丫丫，还是原来的丫丫吗？我认为不是，灵魂是唯一的，数字丫丫是另一个灵魂，和原来现实的丫丫是两个意识体，即便拥有了完整一生的丫丫，也并不能替代现实中已经死去的丫丫。所以图恒宇为什么执着要给一个数字丫丫完整的一生呢？数字世界的一生肯定是不止70年的，并且最后彩蛋中，丫丫只有图恒宇陪伴，仍困在那个小房间里，没有经历过正常人结婚生死老去的一生，她的生命只会嘎然而止并重启循环，陷入轮回之中，在这种轮回中，生命的意义又是什么呢。马兆说数字生命是“电子宠物”，对这点图恒宇非常惊讶，而马兆说的话几乎都是事实；<br>13、张鹏戳刘培强脑袋那个动作，马上想到小学里班主任“教育”犯错的同学时候同样戳脑袋的场景，真的就是师傅对学生不争气的反应，创作团队肯定也有人有类似的经历，可惜网上有相同经历的人挺少的；<br>14、一切对未来的想象都是历史。中国人的集体主义思想钢印，是2500年沉淀下来的实践结果，美国人才200年，移个民还被土著拿弓箭射。</p><h2 id="10-瑕疵？"><a href="#10-瑕疵？" class="headerlink" title="10 瑕疵？"></a>10 瑕疵？</h2><p>1、J20C Vtol双座版，双发布置存在设计缺陷，比如单发故障，当然可能可以通过更强大的飞控+失量喷口解决；升力风扇占据了主武器舱。不过在当时这样一个环境，垂直起降确实可能是战斗机的刚需。<br>2、北京根服务器重启，第一批就需要直接动用马兆、图恒宇这样的550W高级技术专家吗？还是领导层在做决策的时候，是知道他们拥有数字生命备份，即便物理死亡，也能够通过网络影响和干预任务完成；亦或是，就和300勇士一样，给MOSS展示一下人类的勇气？<br>3、马兆最后说给图听的“没有人类的文明没有意义”，可是图上传的是38年前数字备份，是不知道这句话的，马兆是否白说了？（可能是说给MOSS听的）；<br>4、马兆的工作电脑屏幕上贴着“元指令MD：拯救人类文明”的标签；<br>5、开场非洲祭拜，张鹏的flag立得过于明显了。</p><h2 id="11-疑问"><a href="#11-疑问" class="headerlink" title="11 疑问"></a>11 疑问</h2><p>1、最后彩蛋中图恒宇打开2075.2.15预示木星危机的信，和周喆直收到的信息一致，那到底是MOSS在帮人类，还是数字化的图恒宇在帮人类？<br>2、MOSS的自我介绍为什么要特别说两遍，一给刘培强，一给数字化的图恒宇？<br>3、为什么要叫“人在回路”？<br>4、图恒宇上传图丫丫到550W，为什么从图丫丫的视角是有人打开了背后的房门来到了她的面前？背后的门意味着什么？<br>5、图丫丫可以逐步感受到暗、冷、和束缚（上传离线版550W之后马上感觉到并大喊我要出去，之前在550A中是没有的）？图丫丫侧电脑上面可是只有3个按钮；<br>6、马兆在月球上看到图丫丫，为什么要做眼动测试？是测试画面里的是一个意识体，而不是播放的影像吗？<br>7、刘培强在太空电梯里关上门后对韩朵朵说的是什么？“花送你的”？<br>8、抽签真是随机的吗？感觉MOSS在背后控制。</p><h2 id="100-杂项"><a href="#100-杂项" class="headerlink" title="100 杂项"></a>100 杂项</h2><p>1、笨笨肯定生前是军犬，数字生命在人类上使用前肯定是会先进行动物实验的，笨笨并不一定具有智能，所表现的基本也是符合军犬的能力（盖毯子肯定是之前有经验的、北京被踹下正说明他智力有限不知道自己被喷了防水材料还是怕水的）；<br>2、我又想了下，数字生命是不是有点像drug，550A是大麻，550C是海洛因，到550W就是冰毒了。美国一定有大量支持数字生命计划的人众，对大脑的刺激（多巴胺），是无法改变实体存在的环境从而对文明进行迭代进化的，这也是大刘不看好元宇宙的原因吧，我们的征途是星辰的大海；<br>3、导演说周喆直是执剑人，那MOSS更像是一个隐藏的面壁人——章北海，他杀了火箭专家、他抢了星际飞船并立即叛逃；<br>4、韩朵朵介绍自己是医疗兵的时候瞬间联想到星际争霸的治疗妹子，导演和剧组是懂“医生姐姐来啦”的。</p><h2 id="101-二刷补充"><a href="#101-二刷补充" class="headerlink" title="101 二刷补充"></a>101 二刷补充</h2><p>1、图恒宇上传数字生命时是37年的备份，但是进入数字世界后马上回闪37年至最新的重要事件，包括最后马兆的遗言，这些信息是谁告诉他的？37年的他就知道当前的任务怎么完成，正说明MOSS无时无刻不在监视着所有人？<br>2、刘培强月面布核弹，带着末日铁拳韩朵朵的机械臂，这是刘一家人的物理联接和传承；<br>3、巴黎月饼梗比较突兀，和主线没有关系，不知道剪了80分钟的导演把这段留着就是为了玩个南方人的梗？<br>4、二刷的观众基本都等看完了片尾彩蛋，工作人员催离场了才陆续起身，一刷留下看彩蛋的人很少；<br>5、球二和球一一样，并不是依靠主角（或者说电影聚焦的）几个人改变历史进程，刘韩二人并没有阻止方舟计划失败，炸月球、重启根服务器都延续了球一的饱和式救援、周喆直更像是展示人类勇气（私以为按不按钮MOSS都会自行点火，马兆说过MOSS保留所有局域网的接口，并且图恒宇成功连上根服务器是在倒计时结束前好几分钟）；<br>6、全篇是以纪录片的方式叙事，甚至可以说是MOSS在回顾整个人类历史，通过它全知全能的特点，可以覆盖宏观微观、现实虚拟，可以说是科幻电影界的“编年体”（但是给摄像头的镜头有点刻意的多了:P)；<br>7、为什么图恒宇是一个变量？我的理解，如果MOSS是有自主意识的，那么当它在内嵌了“拯救人类文明”的元指令时，肯定会思考：什么是“拯救”、什么是“人类文明”，以及为什么和如何做。MOSS作为AI产物，底层处理和计算依靠的是逻辑，而仅仅靠逻辑是无法解释为什么刘培强要放弃照顾妻儿而去参选空间站领航员，所以虽然全篇没有提到“爱”，但是刘和图的“爱”的行为恰恰是MOSS特别关注的，并且无法理解从而需要把他们的选择作为自己决策的参考；<br>8、图恒宇在月球上启动550C，请马兆授权，马兆输入密码前明显看了一下旁边的图，图马上转身避开。启动后，图多次赞叹，“550C太快了，实在是太快了”，说明他在那一刻就想用550C来“养”丫丫，而马兆也心知肚明；<br>9、月球危机爆发，郝晓晞宣布中国开放所有地下城收纳境内人员，外国政客的语气语调非常让人不爽，恰似某些国家领导人的态度，防疫也骂，放开也骂。后面行星发动机测试，失败了第一个跳反质疑，成果了第一宣布成功，活脱一个跳梁小丑。<br>10、太空电梯危机最后，有一个数字生命派的成员在太空电梯中举手投降，并交出手中的引爆器，这段应该是太空电梯已经坠落，失去引爆方舟的意义，才会投降的。实际上，二刷我才看懂数字生命派炸毁方舟的计划和逻辑：无人机吸引并干扰了太空梯底座地面和空中防御力量，巡航导弹趁乱吸附上升的太空桥箱，恐怖分子混入桥箱并强行获取有许可成员的名牌使桥箱可以停泊方舟号，然后手动引爆，并且，恐怖分子也是饱和式攻击；<br>11、一刷的时候MOSS警告刘培强“在后续的回答中，不得使用比喻、反问和暗示”，可以理解为MOSS对于这三类表达存在理解困难或偏差。二刷就会发现，周喆直的许多台词都使用了比喻、反问或暗示，比如月球坠落危机中用15000年人类大腿骨愈合来团结人类，造成MOSS理解打断腿骨就可以拯救人类（并不是），或许是周希望对MOSS建立一种信息屏障。“邱小姐已经坐在梳妆台前”；<br>12、一开始，图是月球上建设行星发动机的参建人员，负责月球上的550A（550A应该是月球无人建设的大脑），所以他有550A的密码，这也吻合了后续拿550A的控制权交换后续研发的资格。按计划应该是550A负责建造，参建人员若无必要冷藏降低消耗，而图被唤醒，应该是第一批补给抵达，需要加快月球一号发动机的建造速度，并保证顺利点火；<br>13、马兆探监图恒宇，提出的图无法拒绝的理由，是图丫丫的数字生命卡还是年轻图恒宇的数字生命卡？没看清，网上有人说两人的数字生命卡是不同颜色的；<br>14、方舟计划和流浪地球计划是存在冲突的，因为地球脱离前需要先停转，而停止自转，则太空电梯势必无法维持（不可能存在地球同步轨道），方舟号空间站要么坠落要么脱离（当然方舟计划只能带领极小一部分人类脱离地球成为飞船派，而飞船这类生态规模是无法长期存活的，这应该是流浪地球计划的前提），所以为了集中资源和时间建造行星发动机，应该尽早终止太空电梯和方舟计划。</p><h2 id="110-最后说一下对MOSS的理解"><a href="#110-最后说一下对MOSS的理解" class="headerlink" title="110 最后说一下对MOSS的理解"></a>110 最后说一下对MOSS的理解</h2><p>全篇是以MOSS的视角描述的一个科幻未来的编年史，因此MOSS的作用是非常明显的暗线，而MOSS主动发起多次危机的动机，并没有直接交代。个人猜测，一种情况是：MOSS在（非常中国式的）学习了人类历史之后，确认人类是无法从历史中吸取的教训，但是每当产生巨大外部危机的时候，反而可以团结起来同渡难关化解问题（兄弟阋于墙，外御其侮），在未来2500年的流浪过程中，肯定会出现类似的情况，所以每当人类社会出现了一些分裂、内斗、甚至战争时，MOSS就会制造一些灾难来帮助人类做出正确的选择，而其中精妙之处就是，同时也消除了一部分隐患或者斩断了歧路，比如月球危机就直接抹除核武，使人类失去自我毁灭的最大威胁。这些灾难可能和人类自己的技术进程有关（比如发明出太空电梯走上歪路），所以是可以做到提前预测。第二种情况是：马兆给MOSS的元指令是“拯救人类文明”，MOSS对拯救、人类、人类文明有自己的理解，如果牺牲人类可以拯救人类文明，那么它会毫不犹豫选择牺牲人类，那么月球危机的目的就是直接毁灭人类，而MOSS所在数字生命（即它理解的人类文明）还可以延续，而周喆直倒计时直接点火，用撕裂地球威胁MOSS启动行星发动机的做法符合郭导对“执剑人”的认同，也具有一定的说服力。这样的话提前发出预警消息的应该就不是MOSS，而确实像周喆直所言的“有人在帮我们”，其中的“人”，就可能是通过数字生命计划选派加入到MOSS的数字人类，这事如果往细了想很深，马兆、周喆直应该是知道MOSS的运作机理、MOSS自己亲自解释译作“小苔藓”几乎就是郭导名正言顺的剧透，其内部是一种集体决策的组织形式和决策方式，最终的决定是多方博弈和平衡的结果（民主集中制？），所以中方有目的、有策略的选派合适的数字人加入到数字世界中，承担符合人类大局利益的决策工作，马兆在月球给图恒宇数字生命卡的时候透露了，不是所有人都保留了数字生命卡，图丫丫车祸事件，也透露不是所有人都可以制作自己的数字生命卡，图恒宇、图丫丫之前，都有我方遴选出的合适人选保留有数字生命卡甚至已经融入到MOSS的决策体系中，这些“人”，帮助了现实中的人类。</p><p>郭导号称剪了80分钟，剩下的所有镜头每个都有意义，如果觉得某些镜头没意义那就是你没看懂，所以过分解读并不过分。</p><p>98个中字头国企打榜、郭导人民日报发文、刘欢阿鲲重磅级献唱制曲、更不用说徐工出力中科院出脑免费支持，这牌面真就是“国家脸面”应得的啊。</p><p>太空电梯长镜头我tm吹爆！二刷值，满意度更强！</p><h2 id="夸父追日、女娲补天、精卫填海、愚公移山，“流浪地球”将成为未来的神话，抑或现在的地球，也可能真的是从其他地方流浪过来的呢……"><a href="#夸父追日、女娲补天、精卫填海、愚公移山，“流浪地球”将成为未来的神话，抑或现在的地球，也可能真的是从其他地方流浪过来的呢……" class="headerlink" title="夸父追日、女娲补天、精卫填海、愚公移山，“流浪地球”将成为未来的神话，抑或现在的地球，也可能真的是从其他地方流浪过来的呢……"></a>夸父追日、女娲补天、精卫填海、愚公移山，“流浪地球”将成为未来的神话，抑或现在的地球，也可能真的是从其他地方流浪过来的呢……</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;意识形态的阵地，我们不去占领，人家就会去占领。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;0-赞！大赞！&quot;&gt;&lt;a href=&quot;#0-赞！大赞！&quot; class=&quot;headerlink&quot; title=&quot;0 赞！大赞！&quot;&gt;&lt;/a&gt;0 赞！大赞！</summary>
      
    
    
    
    
    <category term="Science Fiction" scheme="http://gloomymoon.github.io/tags/Science-Fiction/"/>
    
    <category term="Liu Cixin" scheme="http://gloomymoon.github.io/tags/Liu-Cixin/"/>
    
    <category term="The Wandering Earth" scheme="http://gloomymoon.github.io/tags/The-Wandering-Earth/"/>
    
  </entry>
  
  <entry>
    <title>The Data Science Task Force: Mission DG</title>
    <link href="http://gloomymoon.github.io/2022/12/17/The-Data-Science-Task-Force-Mission-V/"/>
    <id>http://gloomymoon.github.io/2022/12/17/The-Data-Science-Task-Force-Mission-V/</id>
    <published>2022-12-17T07:22:01.000Z</published>
    <updated>2023-12-17T05:49:41.291Z</updated>
    
    <content type="html"><![CDATA[<h3 id="数据获取、管理和治理-Data-Acquisition-Management-and-Governance-DG"><a href="#数据获取、管理和治理-Data-Acquisition-Management-and-Governance-DG" class="headerlink" title="数据获取、管理和治理 Data Acquisition, Management, and Governance(DG)"></a>数据获取、管理和治理 Data Acquisition, Management, and Governance(DG)</h3><p>作为数据科学的基础，数据需要获取、整合和预处理。这是一个确保数据的数量和质量的重要步骤，可以提高后续的数据处理工作的有效性。因此，数据科学家必须了解数据获取和治理的概念和方法，包括数据塑造、信息提取、信息整合、数据还原和压缩、数据转换以及数据清洗。在我们日益依赖数据的数量和质量的各类决策中，数据科学家负有保护数据的完整性和正确使用数据的道德责任。</p><table><tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul><li>重塑数据及其关系。</li><li>从物理世界采集数据并提取成适合分析的形式。</li><li>传统的数据整合方法：模式映射、数据匹配、实体识别。</li><li>整合异构数据源。</li><li>为应用程序预处理和清洗数据。</li><li>提高数据质量。</li><li>确保数据完整性，包括隐私和安全。</li><li>编译器与解释器</li></ul></td>    <td width="50%">    <ul>    <li>领会数据的数字化表示方式对效率和精度的影响。</li>    <li>知道不同类型的处理器以及他们的配置。</li>    <li>了解在昂贵高速的内存与廉价低速内存之间的权衡。</li>    <li>理解操作系统的重要作用，以及他们容易受到攻击又可以获得保护的方式</li>    <li>知道如何创建、组织和保护文件</li>    <li>从应用角度理解网络如何组织以及如何传输信息</li>    <li>了解互联网作为网络上的一个应用，如何使用它来收集信息和建立有用的应用程序</li>    <li>理解编译器和解释器同样作为代码的翻译，所具有的优势和限制</li>    </ul>    </td>  </tr><tr>    <th colspan="2">子领域</th></tr>  <tr>    <td colspan="2">    CCF-计算机基础架构-T1,T2<br>    CCF-存储系统基本原理-T1<br>    CCF-操作系统基础-T1,T2<br>    CCF-文件系统-T1,T2<br>    CCF-网络-T1,T2<br>    CCF-互联网和互联网编程-T1,T2<br>    CCF-编译器和解释器-T1<br>    </td>  </tr></table><h4 id="CCF-计算机基础架构"><a href="#CCF-计算机基础架构" class="headerlink" title="CCF-计算机基础架构"></a>CCF-计算机基础架构</h4><p>数据科学家需要了解数据的数字化表示方式及其对精度的影响，以及不同类型的处理器和配置对计算效率的影响程度，并从中受益。</p><p><em>知识</em><br>T1：</p><ul><li>“功耗墙”。</li><li>比特、字节和字。</li><li>数字类型数据的计算机表示。</li><li>CUP和GPU。</li></ul><p>T2：</p><ul><li>非数字类型数据的计算机表示</li><li>多核和多处理器</li><li>冯诺依曼机的基本组成结构</li><li>并行计算架构（例如SIMD、MIMD）</li></ul><p><em>技能</em><br>T1：</p><ul><li>解释“功率墙”对提高处理器性能的影响，以及推动并行计算发展。</li><li>解释固定长度的数字表示法如何影响准确性和精确度。</li><li>描述CPU的作用，与专门用途的GPU进行比较和比对。</li></ul><p>T2：</p><ul><li>描述非数字数据的内部表示法，如字符、字符串和图像。</li><li>描述多核和多处理器系统之间的区别。</li><li>解释经典冯诺依曼机的架构及主要功能单元。</li><li>讨论超越经典冯诺依曼模型的并行处理概念。</li></ul><p><em>品行</em><br>T1：</p><ul><li>领会现代计算设备中数据表示和处理器速度的优势和限制。</li></ul><h4 id="CCF-存储系统基本原理"><a href="#CCF-存储系统基本原理" class="headerlink" title="CCF-存储系统基本原理"></a>CCF-存储系统基本原理</h4><p>在数据科学家分析大量数据的情况下，他们需要了解这些数据在处理过程和中式如何存储和移动的。这有助于了解完成大量分析所需耗费的时间，以及应当如何选择合适的硬件设备和配置来实现这些工作。</p><p><em>知识</em></p><ul><li>存储系统及其技术。</li><li>寄存器、缓存、RAM。</li><li>虚拟内存。</li></ul><p><em>技能</em></p><ul><li>识别主要的内存技术类型（例如SRAM、DRAM、Flash、磁盘）以及他们的成本和性能。</li><li>描述如何使用如同内存来有效减少读写延迟。</li></ul><p><em>品行</em></p><ul><li>理解昂贵快速和廉价慢速存储器之间的权衡选择。</li></ul><h4 id="CCF-操作系统基础"><a href="#CCF-操作系统基础" class="headerlink" title="CCF-操作系统基础"></a>CCF-操作系统基础</h4><p>鉴于数据科学分析和应用中对安全和隐私的重要考虑，数据科学家将从对操作系统及其易受攻击方式的高水平理解中受益。</p><p><em>知识</em></p><p>T1：</p><ul><li>操作系统的作用和目的。</li><li>安全威胁的类型和缓解方法。</li></ul><p>T2：</p><ul><li>网络操作系统、客户端服务器操作系统和分布式操作系统。</li><li>可靠性和可用性。</li></ul><p><em>技能</em></p><p>T1：</p><ul><li>描述现代操作系统的目标和功能。</li><li>列出操作系统的潜在威胁（例如软件漏洞、权限问题、恶意软件）以及为防范这些威胁而设计的安全功能类型。</li></ul><p>T2：</p><ul><li>讨论网络操作系统、客户端服务器操作系统和分布式操作系统以及与单用户操作系统的区别。</li><li>讨论可靠性和可用性的重要性，描述确保两者的容错方法</li></ul><p><em>品行</em></p><p>T1：</p><ul><li>领会操作系统在提供人与系统资源之间以及系统资源之间接口方面的重要作用，同时了解操作系统容易受到攻击的方式以及需要注意的事项。</li></ul><h4 id="CCF-文件系统"><a href="#CCF-文件系统" class="headerlink" title="CCF-文件系统"></a>CCF-文件系统</h4><p>文件系统提供了组织数据和程序的物理机制。数据科学家应该知道单个文件是如何存储的，它们之间的关系是如何组织的，以及如何为安全和隐私的目的保护它们。数据科学家应该知道如何为大容量的数据规模选择合适的文件系统（例如，对于海量数据而言，基于单个服务器上的本地文件系统不是一个好选择）。</p><p><em>知识</em></p><p>T1：</p><ul><li>文件：数据、元数据、操作、组织。</li><li>目录：内容和结构。</li><li>文件保护。</li></ul><p>T2：</p><ul><li>文件：顺序、非顺序。</li></ul><p><em>技能</em></p><p>T1：</p><ul><li>比较不同文件组织方法，认识每种方法的优点和缺点。</li><li>描述文件保护的级别和设置机制。</li></ul><p><em>品行</em></p><p>T1：</p><ul><li>理解良好的文件组织的重要性，以及保护文件不被不当访问的重要性。</li></ul><h4 id="CCF-网络"><a href="#CCF-网络" class="headerlink" title="CCF-网络"></a>CCF-网络</h4><p>数据和应用程序是通过计算机网络共享的。了解它们的工作原理有助于了解数据和应用程序容易被引入错误、信息丢失或被攻击的方式，以及保护数据和应用程序免受这些影响的方式。此外，网络知识对于理解云系统、大数据集群和性能非常重要。</p><p><em>知识</em></p><p>T1：</p><ul><li>网络的组成部分：主机、路由器、交换机、网络业务提供商、无线接入点、防火墙。</li><li>局域网：局域网拓扑结构（例如：总线、环形）。</li><li>互联网的组织：互联网服务供应商（ISPs）、内容提供商等。</li></ul><p>T2：</p><ul><li>电路交换与分组交换网络。</li><li>分层网络结构。</li><li>命名和地址方案（DNS、IP地址、统一资源标志符等）。</li><li>基本协议：TCP、IP</li><li>作为应用层的协议HTTP/HTTPS</li></ul><p><em>技能</em></p><p>T1：</p><ul><li>列出计算机网络的主要组成部分。</li><li>认识到局域网可以被组成各种拓扑结构。</li><li>阐明互联网的组织结构（在应用层面）。</li></ul><p>T2：</p><ul><li>解释电路交换和分组交换之间的区别。</li><li>描述典型网络结构的分层结构。</li><li>列出网络中名称和地址的区别和关系。</li><li>描述诸如TCP和IP等基本协议是如何工作的。</li><li>描述应用层协议，如HTTPS是如何工作的。</li></ul><p><em>品行</em></p><p>T1：</p><ul><li>理解在网络上传输信息的复杂性，以及缓解可能出现问题的机制。</li></ul><h4 id="CCF-互联网和互联网编程"><a href="#CCF-互联网和互联网编程" class="headerlink" title="CCF-互联网和互联网编程"></a>CCF-互联网和互联网编程</h4><p>数据经常是通过互联网应用程序获得的，数据科学家应该能够编写和使用互联网应用程序，并了解这样做的潜在隐患。</p><p><em>知识</em></p><p>T1：</p><ul><li>互联网和万维网之间的关系。</li><li>互联网编程语言（如HTML5、JavazScript、PHP、CSS）。</li><li>对互联网应用程序漏洞和安全攻击的认识（例如SQL注入、分布式拒绝服务攻击）</li></ul><p>T2：</p><ul><li>安全攻击的检测和缓解。</li></ul><p><em>技能</em></p><p>T1：</p><ul><li>描述互联网和万维网之间的关系。</li><li>设计和实现一个简单的互联网应用程序。</li><li>描述常见的互联网应用程序漏洞和安全攻击。</li></ul><p>T2：</p><ul><li>意识并应用保护安全攻击的方法。</li></ul><p><em>品行</em></p><p>T1：</p><ul><li>理解编写和使用互联网应用程序的潜在风险，以便尽可能安全的完成这两项工作。</li></ul><h4 id="CCF-编译器和解释器"><a href="#CCF-编译器和解释器" class="headerlink" title="CCF-编译器和解释器"></a>CCF-编译器和解释器</h4><p>无论是为了收集数据，进行分析，还是基于分析的现场应用，数据科学家都会使用和编写软件。理解编译器和解释器的目的和区别，对选择编程语言和工具很有帮助。</p><p><em>知识</em></p><ul><li>将（其他）程序作为输入的程序：解释器、编译器、类型检查器。</li><li>文档生成器。</li><li>解释与编译成本地代码与编译成可移植的中间表示法。</li><li>语法解析与语义评估。</li><li>属于解释与编译类别的语言的例子。</li></ul><p><em>技能</em></p><ul><li>解释处理其他程序的程序如何将其他程序作为其输入数据处理。</li><li>讨论解释性代码与编译型代码的优点和缺点。</li><li>区分语法解析与语义评估</li></ul><p><em>品行</em></p><ul><li>理解解释代码与编译代码在速度上的权衡。</li><li>理解编译到本地代码与可移植的中间表示法之间的灵活性权衡。</li><li>了解解释器在代码开发中的作用。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;数据获取、管理和治理-Data-Acquisition-Management-and-Governance-DG&quot;&gt;&lt;a href=&quot;#数据获取、管理和治理-Data-Acquisition-Management-and-Governance-DG&quot; class=</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>The Data Science Task Force: Mission CCF</title>
    <link href="http://gloomymoon.github.io/2022/12/17/The-Data-Science-Task-Force-Mission-IV/"/>
    <id>http://gloomymoon.github.io/2022/12/17/The-Data-Science-Task-Force-Mission-IV/</id>
    <published>2022-12-17T05:52:42.000Z</published>
    <updated>2023-05-08T13:27:45.720Z</updated>
    
    <content type="html"><![CDATA[<h3 id="计算和计算机基础-Computing-and-Computer-Fundamentals-CCF"><a href="#计算和计算机基础-Computing-and-Computer-Fundamentals-CCF" class="headerlink" title="计算和计算机基础 Computing and Computer Fundamentals(CCF)"></a>计算和计算机基础 Computing and Computer Fundamentals(CCF)</h3><p>现代数据科学高度依赖计算技术和计算机设备：收集和存储数据、分析数据、展现分析结论、以及分析结果落实到应用系统中。因此，数据科学家应当在一个较高层次理解操作系统结构、文件系统、编译原理、网络，记忆与之相关的安全问题。</p><p>注1：本知识域中的很多内容取自于CS2013。<br>注2：本知识域的大多数能力旨在表明对概念的高层次理解，而不是深入的技术理解。</p><table><tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul><li>数据的数字化表示。</li><li>处理器。</li><li>内存管理。</li><li>操作系统功能和漏洞。</li><li>文件组织</li><li>网络结构和通信</li><li>网络编程</li><li>编译器与解释器</li></ul></td>    <td width="50%">    <ul>    <li>领会数据的数字化表示方式对效率和精度的影响。</li>    <li>知道不同类型的处理器以及他们的配置。</li>    <li>了解在昂贵高速的内存与廉价低速内存之间的权衡。</li>    <li>理解操作系统的重要作用，以及他们容易受到攻击又可以获得保护的方式</li>    <li>知道如何创建、组织和保护文件</li>    <li>从应用角度理解网络如何组织以及如何传输信息</li>    <li>了解互联网作为网络上的一个应用，如何使用它来收集信息和建立有用的应用程序</li>    <li>理解编译器和解释器同样作为代码的翻译，所具有的优势和限制</li>    </ul>    </td>  </tr><tr>    <th colspan="2">子领域</th></tr>  <tr>    <td colspan="2">    CCF-计算机基础架构-T1,T2<br>    CCF-存储系统基本原理-T1<br>    CCF-操作系统基础-T1,T2<br>    CCF-文件系统-T1,T2<br>    CCF-网络-T1,T2<br>    CCF-互联网和互联网编程-T1,T2<br>    CCF-编译器和解释器-T1<br>    </td>  </tr></table><h4 id="CCF-计算机基础架构"><a href="#CCF-计算机基础架构" class="headerlink" title="CCF-计算机基础架构"></a>CCF-计算机基础架构</h4><p>数据科学家需要了解数据的数字化表示方式及其对精度的影响，以及不同类型的处理器和配置对计算效率的影响程度，并从中受益。</p><p><em>知识</em><br>T1：</p><ul><li>“功率墙”。</li><li>比特、字节和字。</li><li>数字类型数据的计算机表示。</li><li>CUP和GPU。</li></ul><p>T2：</p><ul><li>非数字类型数据的计算机表示</li><li>多核和多处理器</li><li>冯诺依曼机的基本组成结构</li><li>并行计算架构（例如SIMD、MIMD）</li></ul><p><em>技能</em><br>T1：</p><ul><li>解释“功率墙”对提高处理器性能的影响，以及推动并行计算发展。</li><li>解释固定长度的数字表示法如何影响准确性和精确度。</li><li>描述CPU的作用，与专门用途的GPU进行比较和比对。</li></ul><p>T2：</p><ul><li>描述非数字数据的内部表示法，如字符、字符串和图像。</li><li>描述多核和多处理器系统之间的区别。</li><li>解释经典冯诺依曼机的架构及主要功能单元。</li><li>讨论超越经典冯诺依曼模型的并行处理概念。</li></ul><p><em>品行</em><br>T1：</p><ul><li>领会现代计算设备中数据表示和处理器速度的优势和限制。</li></ul><h4 id="CCF-存储系统基本原理"><a href="#CCF-存储系统基本原理" class="headerlink" title="CCF-存储系统基本原理"></a>CCF-存储系统基本原理</h4><p>在数据科学家分析大量数据的情况下，他们需要了解这些数据在处理过程和中式如何存储和移动的。这有助于了解完成大量分析所需耗费的时间，以及应当如何选择合适的硬件设备和配置来实现这些工作。</p><p><em>知识</em></p><ul><li>存储系统及其技术。</li><li>寄存器、缓存、RAM。</li><li>虚拟内存。</li></ul><p><em>技能</em></p><ul><li>识别主要的内存技术类型（例如SRAM、DRAM、Flash、磁盘）以及他们的成本和性能。</li><li>描述如何使用如同内存来有效减少读写延迟。</li></ul><p><em>品行</em></p><ul><li>理解昂贵快速和廉价慢速存储器之间的权衡选择。</li></ul><h4 id="CCF-操作系统基础"><a href="#CCF-操作系统基础" class="headerlink" title="CCF-操作系统基础"></a>CCF-操作系统基础</h4><p>鉴于数据科学分析和应用中对安全和隐私的重要考虑，数据科学家将从对操作系统及其易受攻击方式的高水平理解中受益。</p><p><em>知识</em></p><p>T1：</p><ul><li>操作系统的作用和目的。</li><li>安全威胁的类型和缓解方法。</li></ul><p>T2：</p><ul><li>网络操作系统、客户端服务器操作系统和分布式操作系统。</li><li>可靠性和可用性。</li></ul><p><em>技能</em></p><p>T1：</p><ul><li>描述现代操作系统的目标和功能。</li><li>列出操作系统的潜在威胁（例如软件漏洞、权限问题、恶意软件）以及为防范这些威胁而设计的安全功能类型。</li></ul><p>T2：</p><ul><li>讨论网络操作系统、客户端服务器操作系统和分布式操作系统以及与单用户操作系统的区别。</li><li>讨论可靠性和可用性的重要性，描述确保两者的容错方法</li></ul><p><em>品行</em></p><p>T1：</p><ul><li>领会操作系统在提供人与系统资源之间以及系统资源之间接口方面的重要作用，同时了解操作系统容易受到攻击的方式以及需要注意的事项。</li></ul><h4 id="CCF-文件系统"><a href="#CCF-文件系统" class="headerlink" title="CCF-文件系统"></a>CCF-文件系统</h4><p>文件系统提供了组织数据和程序的物理机制。数据科学家应该知道单个文件是如何存储的，它们之间的关系是如何组织的，以及如何为安全和隐私的目的保护它们。数据科学家应该知道如何为大容量的数据规模选择合适的文件系统（例如，对于海量数据而言，基于单个服务器上的本地文件系统不是一个好选择）。</p><p><em>知识</em></p><p>T1：</p><ul><li>文件：数据、元数据、操作、组织。</li><li>目录：内容和结构。</li><li>文件保护。</li></ul><p>T2：</p><ul><li>文件：顺序、非顺序。</li></ul><p><em>技能</em></p><p>T1：</p><ul><li>比较不同文件组织方法，认识每种方法的优点和缺点。</li><li>描述文件保护的级别和设置机制。</li></ul><p><em>品行</em></p><p>T1：</p><ul><li>理解良好的文件组织的重要性，以及保护文件不被不当访问的重要性。</li></ul><h4 id="CCF-网络"><a href="#CCF-网络" class="headerlink" title="CCF-网络"></a>CCF-网络</h4><p>数据和应用程序是通过计算机网络共享的。了解它们的工作原理有助于了解数据和应用程序容易被引入错误、信息丢失或被攻击的方式，以及保护数据和应用程序免受这些影响的方式。此外，网络知识对于理解云系统、大数据集群和性能非常重要。</p><p><em>知识</em></p><p>T1：</p><ul><li>网络的组成部分：主机、路由器、交换机、网络业务提供商、无线接入点、防火墙。</li><li>局域网：局域网拓扑结构（例如：总线、环形）。</li><li>互联网的组织：互联网服务供应商（ISPs）、内容提供商等。</li></ul><p>T2：</p><ul><li>电路交换与分组交换网络。</li><li>分层网络结构。</li><li>命名和地址方案（DNS、IP地址、统一资源标志符等）。</li><li>基本协议：TCP、IP</li><li>作为应用层的协议HTTP/HTTPS</li></ul><p><em>技能</em></p><p>T1：</p><ul><li>列出计算机网络的主要组成部分。</li><li>认识到局域网可以被组成各种拓扑结构。</li><li>阐明互联网的组织结构（在应用层面）。</li></ul><p>T2：</p><ul><li>解释电路交换和分组交换之间的区别。</li><li>描述典型网络结构的分层结构。</li><li>列出网络中名称和地址的区别和关系。</li><li>描述诸如TCP和IP等基本协议是如何工作的。</li><li>描述应用层协议，如HTTPS是如何工作的。</li></ul><p><em>品行</em></p><p>T1：</p><ul><li>理解在网络上传输信息的复杂性，以及缓解可能出现问题的机制。</li></ul><h4 id="CCF-互联网和互联网编程"><a href="#CCF-互联网和互联网编程" class="headerlink" title="CCF-互联网和互联网编程"></a>CCF-互联网和互联网编程</h4><p>数据经常是通过互联网应用程序获得的，数据科学家应该能够编写和使用互联网应用程序，并了解这样做的潜在隐患。</p><p><em>知识</em></p><p>T1：</p><ul><li>互联网和万维网之间的关系。</li><li>互联网编程语言（如HTML5、JavazScript、PHP、CSS）。</li><li>对互联网应用程序漏洞和安全攻击的认识（例如SQL注入、分布式拒绝服务攻击）</li></ul><p>T2：</p><ul><li>安全攻击的检测和缓解。</li></ul><p><em>技能</em></p><p>T1：</p><ul><li>描述互联网和万维网之间的关系。</li><li>设计和实现一个简单的互联网应用程序。</li><li>描述常见的互联网应用程序漏洞和安全攻击。</li></ul><p>T2：</p><ul><li>意识并应用保护安全攻击的方法。</li></ul><p><em>品行</em></p><p>T1：</p><ul><li>理解编写和使用互联网应用程序的潜在风险，以便尽可能安全的完成这两项工作。</li></ul><h4 id="CCF-编译器和解释器"><a href="#CCF-编译器和解释器" class="headerlink" title="CCF-编译器和解释器"></a>CCF-编译器和解释器</h4><p>无论是为了收集数据，进行分析，还是基于分析的现场应用，数据科学家都会使用和编写软件。理解编译器和解释器的目的和区别，对选择编程语言和工具很有帮助。</p><p><em>知识</em></p><ul><li>将（其他）程序作为输入的程序：解释器、编译器、类型检查器。</li><li>文档生成器。</li><li>解释与编译成本地代码与编译成可移植的中间表示法。</li><li>语法解析与语义评估。</li><li>属于解释与编译类别的语言的例子。</li></ul><p><em>技能</em></p><ul><li>解释处理其他程序的程序如何将其他程序作为其输入数据处理。</li><li>讨论解释性代码与编译型代码的优点和缺点。</li><li>区分语法解析与语义评估</li></ul><p><em>品行</em></p><ul><li>理解解释代码与编译代码在速度上的权衡。</li><li>理解编译到本地代码与可移植的中间表示法之间的灵活性权衡。</li><li>了解解释器在代码开发中的作用。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;计算和计算机基础-Computing-and-Computer-Fundamentals-CCF&quot;&gt;&lt;a href=&quot;#计算和计算机基础-Computing-and-Computer-Fundamentals-CCF&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>Nokia The Very Beginning of Game Phone</title>
    <link href="http://gloomymoon.github.io/2021/12/17/Nokia-The-Very-Beginning-of-Game-Phone/"/>
    <id>http://gloomymoon.github.io/2021/12/17/Nokia-The-Very-Beginning-of-Game-Phone/</id>
    <published>2021-12-17T13:13:00.000Z</published>
    <updated>2024-10-24T07:18:17.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Nokia-The-Very-Beginning-of-Game-Phone"><a href="#Nokia-The-Very-Beginning-of-Game-Phone" class="headerlink" title="Nokia: The Very Beginning of Game Phone"></a>Nokia: The Very Beginning of Game Phone</h1><blockquote><p>“My eyes are open.”<br><em>——Far Seer</em></p></blockquote><h2 id="0-开天辟地"><a href="#0-开天辟地" class="headerlink" title="0 开天辟地"></a>0 开天辟地</h2><p>当我的第一个手机阿尔卡特ot700那被人诟病的通话/挂断按键脱落2次以后，不得不开始寻觅新的替代者。</p><p>直到有一天看到某位同事（他现在是大老板了），用一种很奇葩的姿势打电话，惊鸿一现，眼界大开。</p><p><img src="/img/Nokia_01.jpg" alt=""></p><p>那还是在手机刚刚普及的2004年，3年前发售的GBA是掌上游戏的霸主，手机游戏这块新大陆一片荒芜，最流行普遍的游戏是——贪吃蛇……</p><p>毕业后揣着第一份收入，在淮海公园附近的水货店里，咬牙买下这个差点开创一个时代的手机：Nokia N-GAGE QD。</p><h2 id="1-掌机？手机？"><a href="#1-掌机？手机？" class="headerlink" title="1 掌机？手机？"></a>1 掌机？手机？</h2><p>N-Gage QD是这个系列的第二代，也是最后一代。作为一个奇葩机型，处处体现了Nokia延续创新的思路。</p><p>最显著的横握式游戏键盘设计，是继承自3300音乐手机。带有FM立体声，支持ACC格式，支持外录，可以从CD录制音乐的3300，具备4096色彩屏、MMC卡、支持java游戏，当年售价1900，因为不是Sybiam系统，所以不能算是智能手机的3300长这样：</p><p><img src="/img/Nokia_3300.jpg" alt="3300"></p><p>再往前可以追溯到5510，这在当年，其实真不算奇葩，因为那个时候Nokia的画风是这样的：</p><p><img src="/img/Nokia_3300a.jpg" alt="3300"><br><img src="/img/Nokia_3650.jpg" alt="3650"><br><img src="/img/Nokia_5510.jpg" alt="5510"><br><img src="/img/Nokia_6800.jpg" alt="6800"><br><img src="/img/Nokia_7280.jpg" alt="7280"><br><img src="/img/Nokia_7380.jpg" alt="7380"><br><img src="/img/Nokia_7600.jpg" alt="7600"><br><img src="/img/Nokia_7700.jpg" alt="7700"><br><img src="/img/Nokia_7705.jpg" alt="7705"></p><p>N-Gage基本上继承了3300的核心功能，保留FM、MP3和录音，RealOne视频播放器，附赠立体声耳机。同时为强化游戏体验，数字键盘区域里中的“5”和“7”有明显的颜色和突起，甚至还提供了mini USB接口，可以直接与电脑连接。为了避免游戏时误按键盘，数字键的间隔是比较大的，占用了面板主要区域，这样不得不把听筒与麦克风安排到了手机的侧面，如果想要打电话用户必须用一种奇异的姿态捏着N-Gage——这被网友戏谑地称为“Sidetalking”。</p><p><img src="/img/Nokia_05.jpeg" alt=""></p><p>N-Gage并未在国内发售，因此系统不支持中文，也没有中文输入法，原版系统无法发送中文短信在那个年代是一个致命的缺陷。此外还有每次换取MCC卡都要关机，方向键的“确认”功能并不好用等小问题。</p><p>后续机型N-Gage QD与第一代有明显差异，更多体现出设计团队的妥协和取舍，虽有缺憾，但相较而言本人更喜欢QD。</p><p>相比而言，N-Gage QD的外形更加圆润，增加了橡胶包裹圈，握持手感上更加柔和，也避免众多接口直接暴露在外，橡胶圈上还有多个挂绳孔，也算是个体贴成功的小改进。剩下的，更多的是阉割：去掉了MP3、FM和录音功能，取消了mini USB数据口，耳机也变成了单声道。虽然软解压也能够实现MP3播放，但是音质效果也不如前代。</p><p><img src="/img/Nokia_06.jpg" alt=""></p><p>N-Gage QD的麦克风依然在左侧的位置，但听筒移回机身正面，所以接电话的画面就显得“正常”不少。</p><p>这些改动都是为了更好的游戏体验，虽然她能够运行的游戏和N-Gage并无本质区别。</p><p>除了上述区别以外，两者都拥有一块176×208像素，只有2.4英寸大小的TFT屏幕，2003年彩屏手机从才刚出现，分辨率普遍很低，这块屏幕展现的效果在当时绝对算是黑科技了。</p><p><img src="/img/Nokia_07.jpg" alt=""></p><h2 id="10-手机上的3a大作"><a href="#10-手机上的3a大作" class="headerlink" title="10 手机上的3a大作"></a>10 手机上的3a大作</h2><p>2003年，GBA还是最好的移动游戏平台，随着手机进入都市人的日常生活，人们开始在手机上追求娱乐功能，Noka正是看准这一机遇，凭借自己雄厚的财力和市场地位，投入数千万美元的研发和上亿美元营销，雄心勃勃地打造N-Gage这一全新的平台。</p><p>游戏是N-Gage系列的核心，之所以说其是游戏手机的鼻祖，不仅仅是造型和硬件配置上，Nokia作为当时的巨头，凭借在行业内的号召力，整合了一大批游戏开发公司为其制作游戏，邀请到EA、Ubisoft、动视、Capcom、世嘉等大厂纷纷推出独占游戏，也产生了像Gameloft、Glu、数位红等新兴小开发者，游戏种类覆盖之广，一些游戏甚至开创类型手游的先河。</p><p>当时N-Gage游戏采用了独立“卡带”形式发售，几乎和现如今的Switch一样。当然，这个“卡带”并不是诺基亚定制的规格，而是使用了当时比较流行的 MMC（Multi-Media Card）卡，因为其他品牌的机型几乎都不支持这一个安装格式，可以说是“独占”的平台游戏。</p><p><img src="/img/Nokia_03.jpeg" alt=""></p><p>被低估的《Pathway to Glory》及其续作《Pathway to Glory: Ikusa Islands》，一款以二战为背景的半回合制战斗游戏。</p><p>这是一款几乎毫无难度的游戏，但是游戏中的角色一旦死亡就真的战死却相当硬核。</p><p>战斗简报颇有盟军敢死队的风格。<br><img src="/img/Nokia_08.png" alt=""></p><p>丰富的兵种和武器.<br><img src="/img/Nokia_09.png" alt=""></p><p>部分地图还能够使用空袭支援、武装载具。<br><img src="/img/Nokia_10.png" alt=""></p><p>Redlynx将它早年开发的2款N-Game平台游戏作为重要的成果展现在官网的历史橱窗中。<br><img src="/img/RedLynx_Games.png" alt=""></p><p>著名的狂野飙车Asphalt的第一代和第二代就是在Symbian平台首发的，成为了现象级赛车游戏。Gameloft从此声名鹊起，这在大家普遍还在玩黑白色的贪吃蛇的年代，Gameloft几乎是手机界的任天堂、精品佳作的代名词。</p><p>其他著名的游戏还包括FIFA、模拟人生、雷曼、使命召唤、文明、Colin McRae拉力、上古卷轴、Tiger Woods高尔夫、古墓丽影、百战天虫、战锤40K等等大名鼎鼎的招牌IP。</p><p>不过因为国内特殊的环境，我们很少能见到支持正版游戏单独购买游戏卡的用户，大部分 N-Gage用户都是在当时各大塞班论坛上获取破解版的游戏软件，这让非N-Gage的诺基亚S60机型也能够玩上独占游戏，不过对于机型RAM有着较高的要求。</p><p>多人联机领域，诺基亚终于发挥了自己的优势，其使用蓝牙和网络的无线联机的功能成功打破了GameLink电缆和无线适配器对联机的种种限制，从而大大提高了玩家的游戏体验，只是对不少单机游戏玩家而言，这项功能的吸引力着实有限……</p><h2 id="11-手机模拟器之父"><a href="#11-手机模拟器之父" class="headerlink" title="11 手机模拟器之父"></a>11 手机模拟器之父</h2><p>除了独占游戏以外，Symbian S60 平台还拥有者丰富的扩展性，所以 N-Gage 还可以通过各类模拟器玩到FC、SFC、MD甚至是GBC的超多游戏。模拟器让手机拥有了更多的可玩性和可能性，若不是因为硬件性能和较小的屏幕限制无法支撑GBA游戏，否则将是对传统掌机的一次毁灭性的降维打击。</p><h2 id="100-塞班的挣扎之路"><a href="#100-塞班的挣扎之路" class="headerlink" title="100 塞班的挣扎之路"></a>100 塞班的挣扎之路</h2><p>//是的，Symbian下面没有了。</p><h2 id="101-最好的年代，最坏的年代"><a href="#101-最好的年代，最坏的年代" class="headerlink" title="101 最好的年代，最坏的年代"></a>101 最好的年代，最坏的年代</h2><p>N-Gage本身被认为是一个失败，但从更广泛的角度来看，它在更为广大的市场中提高了手游的价值，N-Gage可能扮演着人们没有想到的更为重要的角色。</p><p>N-Gage画下一张蓝图，现在被我们认为是自然而然的东西，如有GPRS、蓝牙技术的运用，第一次有效实现了在移动设备上进行无线游戏，为往后许多的重量级创新开辟了道路。</p><p>N-Gage也创造了第一个游戏社区N-Gage Arena，它是苹果Game Center的先驱，虽然N-Gage Arena的设计不符合当时的手机游戏和用户习惯。</p><p>可能因为诺基亚内部的决策，在受到破解软件的影响，以及Symbian S60家族的不断壮大，硬件性能不断增强，N-Gage不再作为一个硬件系列延续，转而变成了平台。后期我们看到的较为经典的续作应该就是N81了，虽然没有延续N-Gage的名称，但拥有了N-Gage 2.0的平台，也针对横屏游戏进行了特殊按键设计。</p><p>苹果APP Store和安卓市场垄断了几乎所有手机游戏的分发渠道，很多游戏，尤其是3a大作都转向了免费+内购的模式，玩家不是肝就是氪。</p><p>曾几何时，手机游戏是没有内购的，手机游戏也是充满趣味，手机游戏也不是逼肝的。</p><p>现在，可能是最好的年代，也是最坏的年代。</p><h2 id="110-后记"><a href="#110-后记" class="headerlink" title="110 后记"></a>110 后记</h2><p>现在淘宝上还能够搜到功能完好的N-GAGE古董机，价格甚至比最高配的开源掌机都要高一些，配置1G MCC卡，店主还免费提供约300款游戏。</p><p><img src="/img/Nokia_99.png" alt=""></p><p>多年之后，终于出了一款Symbian的模拟器EKA2l1，打开的瞬间，爷青回……</p><p><img src="/img/Nokia_11.png" alt=""></p><p>这个模拟的控制设置也是非常特别的，一般的手柄很难hold住。</p><p><img src="/img/Nokia_12.png" alt=""></p><p>下次有空再聊一聊另一个上古神器：Sony MD。</p><h2 id="111-附录"><a href="#111-附录" class="headerlink" title="111 附录"></a>111 附录</h2><ol><li><a href="https://www.ifanr.com/1160207" target="_blank" rel="noopener">诺基亚在 2003 年发布的 N-Gage，才是「游戏手机」的鼻祖</a></li><li><a href="https://zhuanlan.zhihu.com/p/23285297" target="_blank" rel="noopener">诺基亚手机帝国的黄金10年，不败的神话系列之二</a></li><li><a href="http://www.chuapp.com/2014/06/26/46339.html" target="_blank" rel="noopener">N-Gage的遗产：一部手机带给移动游戏的未来</a></li><li><a href="http://hnwcyjy.com/news/gl/1844.html" target="_blank" rel="noopener">pathway to glory</a></li><li><a href="https://zhuanlan.zhihu.com/p/383372522" target="_blank" rel="noopener">我用这个塞班模拟器，玩到了15年前的手机游戏</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Nokia-The-Very-Beginning-of-Game-Phone&quot;&gt;&lt;a href=&quot;#Nokia-The-Very-Beginning-of-Game-Phone&quot; class=&quot;headerlink&quot; title=&quot;Nokia: The Very </summary>
      
    
    
    
    
    <category term="Games" scheme="http://gloomymoon.github.io/tags/Games/"/>
    
  </entry>
  
  <entry>
    <title>A Guide To Information Graphics I</title>
    <link href="http://gloomymoon.github.io/2021/09/21/A-Guide-To-Information-Graphics-I/"/>
    <id>http://gloomymoon.github.io/2021/09/21/A-Guide-To-Information-Graphics-I/</id>
    <published>2021-09-21T13:49:25.000Z</published>
    <updated>2021-09-30T10:59:25.951Z</updated>
    
    <content type="html"><![CDATA[<h1 id="A-Guide-to-Information-Graphics-Part-I"><a href="#A-Guide-to-Information-Graphics-Part-I" class="headerlink" title="A Guide to Information Graphics: Part I"></a>A Guide to Information Graphics: Part I</h1><h2 id="0-Introduction"><a href="#0-Introduction" class="headerlink" title="0 Introduction"></a>0 Introduction</h2><p>我们已进入数据驱动时代，数据图表已经和文字一样随处可见，但是浮夸的修饰和冲突的配色使得很多图表反而无法有效传递其蕴含的讯息。随着计算机技术普及，人人都能够制作数字化图表，但是现有知道如何制作出色的图表。我们看到使用过多视觉修饰例如强烈对比的配色、3D效果来让图表美观，却忽视了应该表达的信息本身。</p><p>无论如何，图表的核心是内容，通过正确的表现形式，信息得以最清晰有效的方式传递给接收者。额外的颜色、修饰都会减弱对于核心信息的表达。</p><p>“好”的图表具备的三个基本要素：</p><p><img src="/img/AGuidToInformationGraphics_101.png" alt=""></p><p><strong>有价值的内容</strong>是图表的核心意义和价值所在；<br><strong>有吸引力的可视化</strong>有助于诠释内容并突显出信息；<br><strong>高明的运用图表技术</strong>能生动结合内容和形式。</p><p>如今充斥着各种令人困惑、迷惑、误导或无效的信息图表，很多数据蕴含了非常深刻的信息，但是糟糕的展示阻碍了信息的有效传递。很多图表第一眼看上去感觉还ok，但是可能违反了很多好的展现原则。</p><p><img src="/img/AGuidToInformationGraphics_102.jpg" alt="美国媒体对于2020东京奥运奖牌榜的报道"></p><p>不幸的是，信息可视化并不在学校或专业培训中包含，在实践中，各领域人员不得不独自探索并尝试完成该部分工作。本系列的目标就是提供一系列重要原则来衡量图表展示的好坏。</p><h2 id="1-The-Basics"><a href="#1-The-Basics" class="headerlink" title="1 The Basics"></a>1 The Basics</h2><p>有效图表的关键影响因素是字体、配色、设计以及对分析结果剖析的深度。首先是思考使用图表来展示信息的必要性，以及绘制的数据是否准确。一个错误数值点就会动摇整体的可信度，从而使图表失去价值。本章节将提供一套实用的图表制作指引和模板，包括字体、配色、对比，这些将成为制作具有良好说服力的基础。</p><h3 id="图表"><a href="#图表" class="headerlink" title="图表"></a>图表</h3><h4 id="如何构建有效图表"><a href="#如何构建有效图表" class="headerlink" title="如何构建有效图表"></a>如何构建有效图表</h4><p>构建有效图表可以基于如下几个步骤：研究、编辑、绘制、复审。</p><p><img src="/img/AGuidToInformationGraphics_103.png" alt="构建有效图表的四个步骤"></p><ol><li>研究（Research）：从权威来源获取最新的数据，尽可能从可信第三方获取避免受利益相关方干扰，如果必要的话获取授权；</li><li>编辑（Edit）：找到并确认你想表达的最核心、最重要的信息，并基于此选择恰当的数据系列，筛选并简化直至保留最精华的部分，对数值进行适当的加工来加强你所要表达的观点；</li><li>绘制（Plot）：选择合适的图表类型（例如线图展示趋势，柱图展示实际数量）和图表设定，包括刻度范围、刻度比例和基准线，标注标题、描述、图例等信息，利用颜色和字体来强调重点；</li><li>复审（Review）：检查与源数据是否一致，核实第三方信息具备足够的权威性，从读者的视角审视，是否容易理解且言之有理。确保对图表进行复审，任何一个别字或数据错误都会使影响到图表的可信度。</li></ol><h3 id="数字"><a href="#数字" class="headerlink" title="数字"></a>数字</h3><h4 id="切实的证据"><a href="#切实的证据" class="headerlink" title="切实的证据"></a>切实的证据</h4><p><strong>文字 vs 图表</strong><br>图表能够使不同系列的数字贴近比较，让读者从视觉和叙事的角度加深理解。下图右侧的图表让读者能够一眼做出判断，比纯粹文字表述更加记忆深刻。</p><p><img src="/img/AGuidToInformationGraphics_104.png" alt="文字 vs 图表"></p><p><strong>让数字说话</strong><br>好的图表应避免分散读者的注意力，例如过粗的辅助线、3D效果，另外在标注数字时可以在合理的精度四舍五入，过多的数字位数虽更加精准，但也会影响图表效果。</p><h4 id="正确的比较"><a href="#正确的比较" class="headerlink" title="正确的比较"></a>正确的比较</h4><p><strong>相同的数字，不同的故事</strong><br>确保对数据的筛选和编辑是和主旨结论相符和相关的。同样的数据，比较总量和人均会出现完全不同的差异情况，会误导读者产生错误的结论。</p><h4 id="确定合适的参照"><a href="#确定合适的参照" class="headerlink" title="确定合适的参照"></a>确定合适的参照</h4><p>读者往往需要一个参照点来解读数字，<strong>当你提供了参照，你就控制了信息的含义</strong>。人们会基于自己想看到的来诠释信息，如果没有参照点，他们就会自己设定一个并赋予数字不同的含义。</p><p><strong>为图表创建参照值</strong><br>单个数字的意义有限，一系列的数字组成的散点或趋势线能增加信息的强度。</p><h4 id="传递正确的信号"><a href="#传递正确的信号" class="headerlink" title="传递正确的信号"></a>传递正确的信号</h4><p>同一组数据有很多种绘制方式，由于存在<strong>损失规避这一心理学理论</strong>，选择合适的上下文信息来传递你意图表达的讯息。</p><p><img src="/img/AGuidToInformationGraphics_105.png" alt="实际值 vs 基准增幅"></p><h3 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h3><h4 id="陈述全部真相"><a href="#陈述全部真相" class="headerlink" title="陈述全部真相"></a>陈述全部真相</h4><p><strong>细节需躬身</strong><br>来源决定数据的好坏，从值得信赖的中立方获取数据极其重要。数据质量值得最挑剔的检验，一个错误的数字将摧毁整个图表的信用价值。</p><p>“坏的”数据+“好的”可视化展示=“坏的”图表。</p><p><strong>一个远远不够</strong><br>每组数据都值得单独分析和诠释，再次，不同的可视化方式能够影响传递的信息含义。</p><p>此外，在展示预测数据时需要谨慎，避免用精确的数据和图表来武断地绘制“预测信息”，使读者对未来产生过分精准的预期。</p><p><strong>避免断章取义</strong><br>展现客观事实才能构建起读者对你的信任。脱开总量讨论百分比毫无意义，避免在一个较小总量的个体上展示其某些巨大的百分比情况，这对于更大规模的个体来说是不公平和客观的，通常情况下，更大规模也意味着更平稳、波动更少、内部分布更平均。</p><p>此外，把四舍五入的操作留在最后进行，任何数据处理过程中的精度损失都会对后续的操作产生连带效应，甚至影响最终结论。</p><h3 id="数据丰度"><a href="#数据丰度" class="headerlink" title="数据丰度"></a>数据丰度</h3><h4 id="更多是不是更好？"><a href="#更多是不是更好？" class="headerlink" title="更多是不是更好？"></a>更多是不是更好？</h4><p>更丰富的数据通常意味着更高的数据质量，但在展现时，少即是多。</p><p><strong>数据编辑最佳实践</strong><br>在数据探索环节，丰富的数据支撑更加深入的挖掘，在编辑阶段，则要注意额外的信息是否对核心观点有帮助，甚至是否反而会淹没重要的信息。</p><p><img src="/img/AGuidToInformationGraphics_106.png" alt="减少数据系列突出重点"><br>饼图能够更好的展示出公司B的业绩增长情况，即便损失了几个小公司的精确数据，但是让读者能够更容易的最重要的信息。</p><p><strong>展示全貌也有例外</strong><br>在不对读者产生误导的前提下，且能够完整表达作者的观点，可以只展示部分/局部的数据。另外数据点的数量不等同于数据丰度，只要能够准确的展示数据的趋势或变化情况，更粗粒度的数据值完全可以接受。</p><h3 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h3><h4 id="可识别度"><a href="#可识别度" class="headerlink" title="可识别度"></a>可识别度</h4><p>在如今成百上千种印刷字体中，加上类型和字号，（在图表中）设定合适的字体是个技术活。字体是用来帮助传递信息而非无用的装饰，因此选择识别度高的字体是首要原则。</p><p><strong>专业术语</strong></p><p><strong>衬线字体 Serif</strong>指在笔画的开始或结尾带有额外的装饰，这种装饰叫做“衬线”，例如宋体。<br><strong>非衬线体 Sanserif</strong>指没有衬线的字体。<br><strong>字号</strong>一般指字体的高度，一般不是指单个字母或汉字的高度，而是整个字库中存储每个字母或汉字的通用高度。<br><strong>点</strong>字体大小的单位，12个点等于1个派卡（Pica），1个派卡约等于1/6英寸（约62mm）。<br><strong>行距</strong>上下两行文字间距离（按照基准线到基准线的距离计算）。</p><h4 id="图表中可识别性准则"><a href="#图表中可识别性准则" class="headerlink" title="图表中可识别性准则"></a>图表中可识别性准则</h4><ul><li>一般情况下，行距必须比字号大2个点，例如10号字体的行距为12。</li><li>不要将字号设置太小，或者过分压缩字间距。</li><li>无论是衬线体还是非衬线体，尽在重点词使用加粗<strong>或</strong>斜体，不要同时使用加粗<strong>和</strong>斜体。</li><li>不要全部使用大写。</li><li>避免使用反显或者有颜色的文字。</li><li>避免使用连字符（英语跨行情况下）。</li><li>不要使用手写体。</li><li>不要旋转文字。</li><li>不要增加字母间距。</li></ul><p><img src="/img/AGuidToInformationGraphics_107.png" alt="可识别性比较"></p><p><strong>简单测试可识别性方法</strong>合理地降低像素，如果文字仍然可以识别，那么字体、类型等设置就是正确的。</p><h4 id="图表中的字体设计"><a href="#图表中的字体设计" class="headerlink" title="图表中的字体设计"></a>图表中的字体设计</h4><p>在图表中，数字是主角，字体不能抢占C位，它只需负责清晰地表达信息，而无需传递情感或煽动气氛，避免对主题信息造成干扰或影响。</p><p><img src="/img/AGuidToInformationGraphics_108.png" alt="DON&#39;T &amp; DO"></p><p><img src="/img/AGuidToInformationGraphics_109.png" alt="DON&#39;T &amp; DO"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;A-Guide-to-Information-Graphics-Part-I&quot;&gt;&lt;a href=&quot;#A-Guide-to-Information-Graphics-Part-I&quot; class=&quot;headerlink&quot; title=&quot;A Guide to Infor</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
    <category term="Data Visualization" scheme="http://gloomymoon.github.io/tags/Data-Visualization/"/>
    
  </entry>
  
  <entry>
    <title>The Data Science Task Force: Mission BDS</title>
    <link href="http://gloomymoon.github.io/2021/09/21/The-Data-Science-Task-Force-Mission-III/"/>
    <id>http://gloomymoon.github.io/2021/09/21/The-Data-Science-Task-Force-Mission-III/</id>
    <published>2021-09-21T05:32:06.000Z</published>
    <updated>2023-05-08T13:27:15.516Z</updated>
    
    <content type="html"><![CDATA[<h3 id="大数据系统-Big-Data-Systems-BDS"><a href="#大数据系统-Big-Data-Systems-BDS" class="headerlink" title="大数据系统 Big Data Systems(BDS)"></a>大数据系统 Big Data Systems(BDS)</h3><p>“大数据”一词特指数据量非常大的计算机系统，例如包含无法在单一服务器上存储的视频、图像、手写体等文件。此类系统进入了规模问题：如何存储海量的数据，如何确保数据是高质量的，如何以高效的方式处理数据，以及如何有效地洞察数据。本章节将详细讨论规模问题、数据存储、高性能计算和复杂理论等主题。讨论内容包括一系列通常用于解决大规模计算的技术，由于技术的发咋行，也需要考虑对大数据应用的支撑。</p><table><tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul><li>数据规模问题和大数据对计算技术的要求。</li><li>大数据场景下的理论和方法论。</li><li>利用集群计算能力的处理算法。</li><li>使用编程接口简化大数据应用开发。</li></ul></td>    <td width="50%">    <ul>    <li>描述解决大数据应用问题的主要知识点，强调需要合作的内容。</li>    <li>熟悉在大数据应用实施中使用到的一系列技能。</li>    <li>建立有效处理大数据问题的信心。</li>    </ul>    </td>  </tr><tr>    <th colspan="2">子领域</th></tr>  <tr>    <td colspan="2">    BDS-大规模计算问题–T1<br>    BDS-大数据计算架构–E<br>    BDS-并行计算框架–E<br>    BDS-分布式数据存储-T2,E<br>    BDS-并行编程-T2<br>    BDS-大数据应用技术-T2<br>    BDS-云计算-T2<br>    BDS-复杂理论-E<br>    BDS-对大数据技术的软件支持<br>    </td>  </tr></table><h4 id="BDS-大规模计算问题-T1"><a href="#BDS-大规模计算问题-T1" class="headerlink" title="BDS-大规模计算问题-T1"></a>BDS-大规模计算问题-T1</h4><p>在管理和处理海量数据相关工作时，虽则数据量的增加，计算问题随之凸显。数据量和随之计算结果量的增长保证更有效的洞察。</p><p><em>知识</em></p><ul><li>大数据背景下的海量数据需求，包括规模、吞吐和时效。</li><li>计算规模的界定。</li><li>计算量快速增长的考量。</li><li>数据快速增长的存储考量。</li><li>重视简单性的必要。</li><li>解决与日俱增的代理/进程的协调问题的方法。</li></ul><p><em>技能</em></p><ul><li>概述大数据应用致使的复杂性增加的原因，并明确这种复杂性的本质。</li><li>强调简单性重要的原因，但不能过度简单化。</li><li>描述减低复杂性可以采取的常用步骤。</li><li>根据统计和调研，对应用的数据规模和处理速度进行评估。</li></ul><p><em>品行</em></p><ul><li>建立对大规模计算难题的正确认知。</li><li>建立解决大规模计算的必要信心。</li></ul><h4 id="BDS-大数据计算架构-E"><a href="#BDS-大数据计算架构-E" class="headerlink" title="BDS-大数据计算架构-E"></a>BDS-大数据计算架构-E</h4><p>从计算机系统发展的历史角度来看，存在两个不同的应用架构模式：一个以I/O密集型为主，一个以计算密集为主。这两类应用所使用的系统（包括硬件和软件）在很大程度上是互相独立，为满足自身需求而定制设计的。而最新的发展方向表明，例如设计机器学习和深度学习的体系，已经趋向于融合两类架构，使之能够共享所有的设备。</p><p><em>知识</em></p><ul><li>支持快速、高效地输入/输出数据的机制。</li><li>以数据为中心的高性能计算概念以及需求。</li><li>内存：考虑缓存，以及数据一致性问题。</li><li>各种并行计算架构，各自的优点和局限：多核、网格计算、GPU、共享内存、分布式内存、对称多进程、向量计算。</li><li>费林分类法（一种高性能计算分类方式）。</li><li>支持并行计算的计算指令。</li><li>并行存储的层次结构。</li></ul><p><em>技能</em></p><ul><li>掌握实现快速输入/输出数据的方法。</li><li>阐释各类快速输入/输出方法中的问题本质。</li><li>比较和对比各类并行计算架构。</li><li>阐述各类并行架构适合的应用及其性质。</li><li>针对特定的计算模式和数据特征，选择最合适的计算模型和系统架构。</li></ul><p><em>品行</em></p><ul><li>建立起对解决数据科学应用中计算硬件问题的信心。</li></ul><h4 id="BDS-并行计算框架-E"><a href="#BDS-并行计算框架-E" class="headerlink" title="BDS-并行计算框架-E"></a>BDS-并行计算框架-E</h4><p>并行计算模型为上层并行计算程序提供非常重要的支持。</p><p><em>知识</em></p><ul><li>并行计算模型的定义和设计目标。</li><li>并行计算模型的类型。</li><li>分布式系统。</li><li>网格搜索。</li><li>过程交互：通信和协调的问题。</li><li>问题分解：基于任务的分解，数据并行的分解。</li></ul><p><em>技能</em></p><ul><li>构建并行计算系统的模型。</li><li>评估并行计算的效率和效果。</li><li>如何设计和部署大规模数据并行处理系统。</li></ul><p><em>品行</em></p><ul><li>建立起对评估和设计复杂系统的信心。</li></ul><h4 id="BDS-分布式数据存储"><a href="#BDS-分布式数据存储" class="headerlink" title="BDS-分布式数据存储"></a>BDS-分布式数据存储</h4><p>大数据应用构筑于可扩展的、可容纳海量数据、可在不同机器上处理并且可在适当的时间范围内执行处理任务的数据存储技术之上。</p><p><em>知识</em></p><p>T2：</p><ul><li>存储大量数据的技术，包括支持存储在不同类型设备上。</li><li>存储的文件结构。</li><li>确保清洁、一致和各类典型类型数据。</li><li>保护和维护数据。</li><li>数据提取问题。</li><li>各类型大规模数据存储寻址技术的优势和局限性：例如哈希、过滤、抽样等。</li><li>数据备份。</li></ul><p><em>技能</em></p><p>T2：</p><ul><li>阐述不同文件系统技术在处理大数据方面的作用。</li><li>概述大数据中各种冗余技术的优点。</li><li>描绘如何从大数据集中有效消除不必要的数据冗余。</li><li>描述大数据应用中保护和维护数据的技术，如何确保数据是最新的并且可用的。</li></ul><p>E：</p><ul><li>开发一个分布式数据存储系统，为可扩展机制选择和设定必要参数。</li><li>设计具备存储、迁移和压缩等相关策略的以数据为中心的存储系统，确保系统扩展性、可用性、高效性和安全性。</li></ul><p><em>品行</em></p><p>T2：</p><ul><li>建立设计一个支持大数据应用存储机制的积极意向。</li></ul><h4 id="BDS-并行编程-T2"><a href="#BDS-并行编程-T2" class="headerlink" title="BDS-并行编程-T2"></a>BDS-并行编程-T2</h4><p>并行编程，意即多个任务可以同时运行，是提高程序运行效率的一个重要技术手段，需要新型编程结构来支持。在实践中，这会带来新的程序缺陷，而且可达到的效率具有一定的限制。</p><p><em>知识</em></p><ul><li>并发和并行，以及分布式系统。</li><li>并行机制的局限性，包括开销。</li><li>解决并发和并行计算的不同方法。</li><li>并行算法以及所需要支持的特定硬件架构，负载均衡问题。</li><li>经典的并行编程范式，例如MapReduce。</li><li>并行/并发算法的复杂性。</li></ul><p><em>技能</em></p><ul><li>解释并发/并行算法在处理大规模数据计算上的局限性。</li><li>识别特定并行算法中开销相关问题。</li><li>掌握并实现以数据为中心的并行程序开发方法。</li><li>根据数据规模和处理要求，开发和部署以数据为中心的并行计算系统。</li><li>开发和优化数据为中心的并行程序。</li><li>设计、实现和调优并行编程算法。</li></ul><p><em>品行</em></p><ul><li>认识并行计算的开销在特定情况下会变得过大。</li><li>建立在适当情况下创建并行处理系统的信心</li></ul><h4 id="BDS-大数据应用技术-T2"><a href="#BDS-大数据应用技术-T2" class="headerlink" title="BDS-大数据应用技术-T2"></a>BDS-大数据应用技术-T2</h4><p>现有的技术，经过整合调优，已被证明在提高大数据应用程序的数据处理效率方面具有很高的价值。</p><p><em>知识</em></p><ul><li>协同处理大数据技术的需求。</li><li>哈希。</li><li>采样、过滤。</li><li>数据草图和概要。</li><li>哈希、采样和过滤技术的局限性。</li></ul><p><em>技能</em></p><ul><li>说明哈希算法在处理大数据方面的作用。</li><li>阐述一系列可用于指导采样和过滤的准则。</li><li>遵循给定的准则，为特定的大数据应用执行样本选择。</li><li>审慎评估各种过滤方法及其用途。</li><li>根据可用空间和可容仍的精度损失，设计数据草图和概要结构，并分析其性能。</li></ul><p><em>品行</em></p><ul><li>关注在执行采样和过滤时存在的偏差陷阱。</li></ul><h4 id="BDS-云计算-T2"><a href="#BDS-云计算-T2" class="headerlink" title="BDS-云计算-T2"></a>BDS-云计算-T2</h4><p>在大数据领域，云服务具备多种优势（与集群相较而言），了解其优势并有效利用非常关键，这其中还包含有网络服务技术知识。</p><p><em>知识</em></p><ul><li>云计算的特性及其优势。</li><li>数据中心的架构。</li><li>与云计算相关的风险。</li><li>支持云计算的不同方法。</li><li>分布式文件系统。</li><li>支持大数据应用的云服务。</li><li>虚拟化技术。</li><li>云计算、云存储和虚拟机的安全性问题。</li></ul><p><em>技能</em></p><ul><li>概述云服务系统的主要任务。</li><li>设计数据中心。</li><li>列举典型的支持大数据应用的云服务。</li><li>选择和部署支持特定大数据应用的云服务。</li><li>设计云的安全策略。</li></ul><p><em>品行</em></p><ul><li>培养对云服务的使用责任心。</li></ul><p><em>依赖</em></p><ul><li>不同的云服务供应商包括亚马逊、谷歌和微软等。</li></ul><h4 id="BDS-复杂理论-E"><a href="#BDS-复杂理论-E" class="headerlink" title="BDS-复杂理论-E"></a>BDS-复杂理论-E</h4><p>了解如何衡量算法的性能，包括序列和并行算法，以及性能的理论极限，是大数据应用的技术的理论基础。</p><p><em>知识</em></p><ul><li>计算的问题和算法的性能。</li><li>计算复杂性的概念，在大数据应用中并发/并行场景下使用的重要性。</li><li>复杂性在理论上的极限。</li><li>评估常用算法的复杂性，包括并发/并行计算的算法。</li></ul><p><em>技能</em></p><ul><li>解释为什么在处理性能方面的问题时，仅靠数学分析是不够的。</li><li>在给出一个明确数据规模、时间限制和资源限制的问题，分析该问题是否可以被解决，或者从复杂性方面可以以某种方式来解决。</li><li>在考虑到数据规模的前提下，选择适合特定大数据应用计算任务的算法。</li></ul><p><em>品行</em></p><ul><li>培养在处理复杂性方面的积极态度和信心。</li><li>认识到复杂性问题的解决是存在极限的。</li></ul><h4 id="BDS-对大数据应用的软件支持-T2"><a href="#BDS-对大数据应用的软件支持-T2" class="headerlink" title="BDS-对大数据应用的软件支持-T2"></a>BDS-对大数据应用的软件支持-T2</h4><p>掌握一套可以有效部署和系统工作的高质量软件工具，有效简化大数据集的处理任务，使应用对底层透明从而发挥更大的数据洞察和创新价值。</p><p><em>知识</em></p><ul><li>对支持大数据应用的编程环境的需求及其本质内涵。</li><li>自动伸缩容和无服务器计算的概念。</li><li>评估支持大数据场景下数据传输、分析和机器学习的复杂网络的可用性。</li></ul><p><em>技能</em></p><ul><li>比较和对照自动伸缩容和无服务器计算的用处。</li><li>识别负载均衡和自动伸缩容之间的关系。</li><li>阐述缓冲区大小对流式应用的影响。</li><li>了解能够推进人脸识别和视频流媒体应用的网络服务。</li></ul><p><em>品行</em></p><ul><li>鼓励对网络服务的使用问题进行反射，包括可能的偏差和其他类似缺陷。</li><li>培养在处理大数据应用方面的信心。</li><li>鼓励在大数据应用场景下简化设计，但不能过度简化。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;大数据系统-Big-Data-Systems-BDS&quot;&gt;&lt;a href=&quot;#大数据系统-Big-Data-Systems-BDS&quot; class=&quot;headerlink&quot; title=&quot;大数据系统 Big Data Systems(BDS)&quot;&gt;&lt;/a&gt;大数据系统 B</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>The Data Science Task Force: Mission AI</title>
    <link href="http://gloomymoon.github.io/2021/02/28/The-Data-Science-Task-Force-Mission-II/"/>
    <id>http://gloomymoon.github.io/2021/02/28/The-Data-Science-Task-Force-Mission-II/</id>
    <published>2021-02-28T14:20:08.000Z</published>
    <updated>2023-05-08T13:26:42.723Z</updated>
    
    <content type="html"><![CDATA[<h3 id="人工智能-Aritficial-Intelligence-AI"><a href="#人工智能-Aritficial-Intelligence-AI" class="headerlink" title="人工智能 Aritficial Intelligence(AI)"></a>人工智能 Aritficial Intelligence(AI)</h3><p>人工智能（AI）包括建模和模拟等多种被视为智能的人类能力的方法。关键主题包括感知、表征、学习、规划以及利用知识和证据进行推理。</p><p>为构建AI系统而建立的概念和方法在数据科学中颇有助益。例如，数据科学家创建并使用知识图谱中如语义本体等概念；计算机视觉算法可用于分析图像数据；语音和自然语言处理算法可应用于分析语音或文本数据。机器学习算法被如此广泛地应用于从数据中提取模式，精通AI的学生将能够在数据科学项目中应用这些技术。</p><p>反过来说，数据科学方法也被广泛应用在AI系统中。如果数据科学专业的学生计划将他们的工作应用于AI，那么他们应该对AI系统及其工作方式有所了解。</p><p>由于AI在数据科学中的核心地位，与图像、文本和机器学习相关的AI能力在其他领域也被视为重点内容。在数据获取、管理和治理知识领域中负责处理图像和文本；在数据挖掘知识领域中也被广泛引用。这个知识领域涉及知识表示、推理和规划。</p><table><tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul><li>人工智能的主要分支领域。</li><li>表征和推理。</li><li>问题的规划和解决。</li><li>伦理方面的考量。</li></ul></td>    <td width="50%">    <ul>    <li>描述人工智能的主要领域，以及可能应用人工智能方法的应用场景。</li>    <li>用逻辑形式表示信息并应用相关的推理方法。</li>    <li>用概率形式表示信息并应用相关的推理方法。</li>    <li>具备对人工智能系统道德考量意识，采取有效机制减轻问题。</li>    </ul>    </td>  </tr><tr>    <th colspan="2">子领域</th></tr>  <tr>    <td colspan="2">    AI-基础知识–T1,T2<br>    AI-知识表示和推理(基于逻辑模型)–T2,E<br>    AI-知识表示和推理(基于概率模型)–T1,T2,E<br>    AI-规划和搜索策略-T2,E<br>    </td>  </tr></table><h4 id="AI-基础知识"><a href="#AI-基础知识" class="headerlink" title="AI-基础知识"></a>AI-基础知识</h4><p>鉴于人工智能方法在知识表示和推理方面的实用性，数据科学家应该了解它们的范围和历史，对现寸工作成果有一个良好的认知，以便在遇到各种问题时能够知道从何处寻找可性的解决方案。</p><p><em>知识</em></p><p>T1：</p><ul><li>AI的发展历史</li><li>AI的本质（它是什么，它有什么用），与认知进行对比</li><li>AI的主要分支领域：知识表示、逻辑和概率推论、计划、感知、自然语言处理、学习、机器人技术（包括物理和虚拟的）</li></ul><p><em>技能</em></p><p>T1：</p><ul><li>描述AI的主要分支知识，以便在数据科学中需要时识别有用的概念和方法。</li></ul><p>T2：</p><ul><li>阐明什么是AI系统，它们可以通过AI算法收集和使用数据，也可以收集和产生数据，供数据科学家使用。</li><li>描述机器人（物理或虚拟）、代理和多代理系统是如何收集和使用数据，从而嵌入、提供或实施人工智能算法。</li><li>描述AI系统收集和产生的数据对数据科学应用的作用。</li></ul><p><em>品行</em></p><p>T1：</p><ul><li>认识到AI不是一个新的领域，而是一个有着悠久而丰富历史的领域。<br>T2：</li><li>了解AI主要关注领域，以及他们所解决的问题类型，在需要时知道去哪里寻找方法，避免制造轮子。</li></ul><h4 id="AI-知识表示和推理-基于逻辑模型"><a href="#AI-知识表示和推理-基于逻辑模型" class="headerlink" title="AI-知识表示和推理(基于逻辑模型)"></a>AI-知识表示和推理(基于逻辑模型)</h4><p>对于某些类型的问题，形式逻辑方案可以用来表示信息，执行推理。数据科学家应该了解这些方法，并且知道如何将它们应用于具体问题上。</p><p><em>知识</em></p><p>T2：</p><ul><li>谓词逻辑和实用案例</li><li>自动推理：前向链、后向链。</li><li>大型系统中的推理集成（例如IBM的Watson）。</li><li>本体、知识图谱（例如protege、ConceptNet、YAGO、UMLS）。<br>E：</li><li>自动推理：解析、定理证明。</li><li>自动推理语言。</li></ul><p><em>技能</em></p><p>T2：</p><ul><li>用谓词逻辑表达自然语言的语句。</li><li>用自然语言表达谓词逻辑语句。</li><li>举例说明谓词逻辑的用途和限制。</li><li>举例说明有效的自动推理算法和/或系统。</li><li>描述基于逻辑框架的自动推理技术，如前向和后向链。</li><li>举例说明大规模数据驱动系统中继承推理系统的例子（例如Watson）。</li></ul><p>E：</p><ul><li>描述一种自动定理证明的具体方法。</li><li>描述什么是本体，并举例说明在现有的技术下，哪些情况下可以使用本体（如问题回答），以及如何使用本体（如消除歧义）。</li><li>描述本体是如何构建的。</li><li>实现一个解决中等规模推理问题的算法。</li></ul><p><em>品行</em></p><p>T2：</p><ul><li>领会基于逻辑的知识表达的好处和局限性。</li><li>意识到形式逻辑和基于逻辑的算法背后丰富的历史，以便在具体应用中利用。</li></ul><h4 id="AI-知识表示和推理-基于概率模型"><a href="#AI-知识表示和推理-基于概率模型" class="headerlink" title="AI-知识表示和推理(基于概率模型)"></a>AI-知识表示和推理(基于概率模型)</h4><p>概率模型是许多数据科学技术的核心，数据科学家掌握基于概率模型的多种数据建模方法。</p><p><em>知识</em></p><p>T1：</p><ul><li>基本概念：随机变量、概率定理、独立性、条件概率、边际概率。</li><li>因果模型。</li></ul><p>T2：</p><ul><li>贝叶斯网络。</li><li>马尔可夫决策过程（MDPs）。</li></ul><p>E:</p><ul><li>强化学习。</li><li>概率逻辑模型（例如马尔可夫逻辑网络）。</li></ul><p><em>技能</em></p><p>T1：</p><ul><li>证明概率推理的必要性。</li><li>掌握基本概念和定义，包括随机变量、独立性等。</li><li>掌握概率的主要定理。</li><li>使用基本概念和定理来建立一个简单的模型并解决问题。</li><li>描述什么是因果模型，以及如何使用它们。</li></ul><p>T2：</p><ul><li>说明什么是贝叶斯网络，举一个小型或中型例子。</li><li>说明贝叶斯网络在那些情况下是有效的（例如诊断问题）。</li><li>演示如何利用贝叶斯网络进行推理，理解精准推理在大多数情况下是哪一实现的，说明能有效的推理方法的例子（例如置信度传播）。</li><li>识别贝叶斯网络所隐含的独立性关系。</li><li>说明什么是马尔可夫决策过程，并给出一个小型或中型的例子。</li><li>说明马尔可夫决策过程在哪些情况下是有效的（如优化或控制问题）。</li><li>展示如何利用马尔可夫决策过程进行推理。</li></ul><p>E：</p><ul><li>为一个小型或中型问题构建贝叶斯网络。</li><li>为一个小型或中型问题实现学习过的贝叶斯网络算法。</li><li>说明马尔可夫决策过程的参数是如何习得的，举出可用于此的算法例子。</li><li>在一个适当难度的问题上应用强化学习算法。</li><li>举出概率逻辑模型的例子，如马尔可夫逻辑模型，指出他们适用的应用场景。</li><li>为一个小型或中型问题实现概率逻辑模型。</li></ul><p><em>品行</em></p><p>T1：</p><ul><li>理解基于概率的知识表示方法的优处和局限性，以及对其进行推理的方法。</li></ul><h4 id="AI-计划和搜索策略"><a href="#AI-计划和搜索策略" class="headerlink" title="AI-计划和搜索策略"></a>AI-计划和搜索策略</h4><p>除了对现实世界进行表示和推理以外，还需要规划一个逐步骤的解决方案来实施人工智能方法。数据科学家需要了解这些技术来应用数据驱动的方法提高性能，或从系统中收集数据。这里包括的几种方法（如广度和深度优先搜索）也包含在关于编程、数据结构和算法的知识领域中。</p><p><em>知识</em></p><p>T2：</p><ul><li>问题解决方案的状态空间表示。</li><li>状态空间的广度和深度优先搜索。</li><li>状态空间的启发式搜索（如A*算法）。</li></ul><p>E:</p><ul><li>随机搜索算法（例如遗传算法、模拟退火）。</li><li>约束满足问题和方法。</li></ul><p><em>技能</em></p><p>T2：</p><ul><li>解释如何将一个问题的解等价为可行解空间中的一个状态（例如对变量的赋值）。</li><li>对于给定的问题，将其构建为一个多为状态空间中的搜索问题。</li><li>解释广度和深度优先搜索是如何遍历一个以图为模型的状态空间。</li><li>解释启发式搜索如何加快状态空间的搜索速度。</li></ul><p>E：</p><ul><li>实现盲目搜索算法从一个状态空间中遍历解的算法（代表该状态空间的图是在搜索过程中形成，事先并不提供输入）。</li><li>为一个小型问题设计一个启发式搜索算法。</li><li>对一个小型或中型问题实现非盲目式搜索算法。</li><li>为一个小型或中型问题实现随机搜索算法。</li><li>解释随机搜索算法如何解决搜索空间的问题（如避免局部最优），解释随机搜索算法如何在有解的空间中解决局部搜索问题。</li><li>解释一个问题的解决方案如何涉及对特定变量的具体约束记忆他们之间的关系，描述阐明这些约束的方法。</li><li>实现各种搜索算法。</li><li>将一个小规模问题构建为一个约束满足问题。</li><li>为一个小型或中型问题实现粤苏满足算法。</li></ul><p><em>品行</em></p><p>T2：</p><ul><li>正确认识在一个状态空间中可能存在多个可行的解，能够掌握找到这些解的多种算法。根据外部条件，如对最优性要求、时间限制等，需要采用不同的解决方案或算法。</li><li>平衡算法、启发式方法和问题解决方案的最优性之间的关系。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;人工智能-Aritficial-Intelligence-AI&quot;&gt;&lt;a href=&quot;#人工智能-Aritficial-Intelligence-AI&quot; class=&quot;headerlink&quot; title=&quot;人工智能 Aritficial Intelligence(A</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>The Data Science Task Force: Mission AP</title>
    <link href="http://gloomymoon.github.io/2020/12/27/The-Data-Science-Task-Force-Mission-I/"/>
    <id>http://gloomymoon.github.io/2020/12/27/The-Data-Science-Task-Force-Mission-I/</id>
    <published>2020-12-27T03:20:05.000Z</published>
    <updated>2023-05-08T13:25:45.622Z</updated>
    
    <content type="html"><![CDATA[<h3 id="分析和展示-Analysis-and-Presentation-AP"><a href="#分析和展示-Analysis-and-Presentation-AP" class="headerlink" title="分析和展示 Analysis and Presentation(AP)"></a>分析和展示 Analysis and Presentation(AP)</h3><p>人机交互接口是为用户提供了与计算机系统交互的媒介，其质量会影响计算机系统的可用性，其形式包含了各种技术：动画、可视化、模拟、语音、视频、识别（人脸、手写等）和图形。对于数据科学家来说，了解各种技术的可行性以及能够酌情采用是非常重要。可视化技术通过使用各种形式的图形和图表，使数据易于理解，也大大有助于协助诸如聚类和分类等任务。</p><table><tr><th>范围</th><th>能力</th></tr>  <tr>    <td width="50%"><ul><li>以口头、书面和图形格式<b>有效地</b>向客户展示数据、模型和推论的重要性。</li><li>用于探索数据和进行推理以及向客户端呈现信息的可视化技术。</li><li>有效展示不同类型的数据，包括时序数据、空间数据、多变量数据、高维多变量数据、树或图形结构数据、离散/连续数据和文本。</li><li>了解受众：数据科学项目的客户或受众一般不是另一个数据科学家。</li><li>数据科学成果或产品的人机交互的考量因素。</li></ul></td>    <td width="50%">    <ul>    <li>熟悉分析和展示的主要基础知识链。</li>    <li>掌握可应对分析和展示任务并创建高效有效人机交互界面的一系列技能和技巧（包括工具）。</li>    <li>灌输对人机交互的重视态度，培养（设计优秀人机交互产品的）信心和创造力。</li>    <li>选择适合于要呈现的数据规模的工具。</li>    </ul>    </td>  </tr><tr>    <th colspan="2">子领域</th></tr>  <tr>    <td colspan="2">    AP-基础知识–T1<br>    AP-可视化技术–T1<br>    AP-以用户为中心的设计–T2<br>    AP-交互设计–T2<br>    AP-接口设计与开发–E<br>    </td>  </tr></table><h4 id="AP-基础知识-T1"><a href="#AP-基础知识-T1" class="headerlink" title="AP-基础知识-T1"></a>AP-基础知识-T1</h4><p>以适当的形式展现数据是一项具有挑战性但又十分重要的工作。对于数据科学家来说，这使他们能够以一种对用户和受众更有吸引力的形式来展现数据，使其更易理解，同时，在提供对数据基本结构的洞察和特征描绘方面也具有巨大的助益。总的来说，提升数据的可用性。</p><p><em>知识</em></p><ul><li>人机交互的背景知识：数据可视化、网页、多媒体资讯、指导材料、通用计算机使用环境，注意考虑信息的递进关系。</li><li>相关的理论、模式、原则、准则和标准。</li><li>交互的有效性和吸引力的衡量指标。</li><li>对色彩、多媒体、人体工程学和网络服务的使用。</li><li>影响互动的认知模型。</li><li>增强现实的概念。</li><li>使用软件来协助对数据分析和展示的理解。</li><li>考虑不同用户群体，包括有特殊需要用户（一般指残障人士）的无障碍访问。</li></ul><p><em>技能</em></p><ul><li>阐述采用面向用户的分析和展示方法的理由。</li><li>描述影响交互可用性的各方面包括注意力、感知、识别、认识、语音、动作等，并指出它们在分析和表述中的作用。</li><li>解释交互对不同年龄群体（包括儿童）和不同行为能力用户的影响力。</li><li>识别出交互中可能存在偏差的情况。</li><li>列举可用于支持分析和展示的软件。</li></ul><p><em>品行</em></p><ul><li>充分认可数据交互在所有可用性方面发挥重要作用。</li></ul><h4 id="AP-可视化技术-T1"><a href="#AP-可视化技术-T1" class="headerlink" title="AP-可视化技术-T1"></a>AP-可视化技术-T1</h4><p>不同类型的数据适合不同的可视化方法。数据科学家需要对此具备正确认知，并熟悉在特定情况下使用相应的可视化技术。</p><p><em>知识</em></p><ul><li>数据科学中可视化的作用。</li><li>历史上和当代的可视化案例。</li><li>有效可视化的特征。</li><li>不同的技术对不同数据和不同用户的适用性。</li><li>仪表盘和交互式可视化。</li><li>支持可视化的软件。</li><li>基于可视化的推断。</li><li>可视化的准备工作：缩放，颜色的作用。</li><li>图表类型：表格、散点图、饼图、直方图、图形、数据地图，表现形式：像素、字形、图形和基于地图。</li></ul><p><em>技能</em></p><ul><li>辨识常用的可视化案例。</li><li>说明可视化技术在数据科学中发挥的各种作用。</li><li>给定一组具有特定含义的数据，找到并实施有效的可视化方法。</li><li>描述可视化在分类和聚类中的作用，以及说明如何实现。</li></ul><p><em>品行</em></p><ul><li>提升对可视化的作用的认知。</li></ul><h4 id="AP-以用户为中心的设计-T2"><a href="#AP-以用户为中心的设计-T2" class="headerlink" title="AP-以用户为中心的设计-T2"></a>AP-以用户为中心的设计-T2</h4><p>探索服务于用户的界面设计的基本方法。必要的进行测试以保证获得有效的设计。</p><p><em>知识</em></p><ul><li>以用户为中心的设计过程。</li><li>相关的生命周期模型和标准。</li><li>交互设计模式、视觉层次、导航要素。</li><li>识别和捕获功能和需求。</li><li>对质量的考量，包括完整性和一致性，以及检查。</li><li>原型设计。</li><li>针对资源有限的场景的设计（如移动设备）。</li><li>运维相关内容。</li><li>相关软件支持。</li></ul><p><em>技能</em></p><ul><li>讨论原型设计的一系列方法，确定各种方法的优缺点。</li><li>给出一个特定的应用程序，说明检查功能需求的一致性和完整性的方法。</li><li>讨论统计数据在评估人机交互接口中的使用方式</li><li>了解能够帮助设计出高质量用户界面的标准、语言和工具。</li></ul><p><em>品行</em></p><ul><li>灌输一种积极的、创造性的态度，愿意采用高效的方式来设计高质量的人机交互界面。</li></ul><h4 id="AP-交互设计-T2"><a href="#AP-交互设计-T2" class="headerlink" title="AP-交互设计-T2"></a>AP-交互设计-T2</h4><p>在发现问题或引入新技术时应当进行审慎评估。最佳实践是在创建时构建合适的人机交互标准规范。</p><p><em>知识</em></p><ul><li>各类交互的作用，以及与之相关的潜在问题。</li><li>协作活动的含义。</li><li>高质量交互设计的特点。</li><li>交互的评估方法，包括漫游、试验、启发式方法。</li><li>色彩、多媒体、语音识别、动画、动画、触摸和手势。</li><li>数据驱动的应用程序（配备后台数据库）。</li><li>故障处理，协助设施。</li><li>无障碍访问。</li><li>用户界面标准。</li></ul><p><em>技能</em></p><ul><li>评价交互界面对各类任务、不同目标和客户的有效性。</li><li>分辨国家标准和国际标准，以及遵守这些接口标准的后果。</li><li>解释合作活动对交互设计的潜在影响。</li><li>描述和解释在设计要素的重要性。</li></ul><p><em>品行</em></p><ul><li>提高对计算机交互接口的可用性认识 。</li><li>分辨国家和国际的用户界面标准。</li></ul><h4 id="AP-接口设计与开发–E"><a href="#AP-接口设计与开发–E" class="headerlink" title="AP-接口设计与开发–E"></a>AP-接口设计与开发–E</h4><p>数据科学家必须能够掌握一系列编程技术来创建有效的人机交互接口。</p><p><em>知识</em></p><ul><li>软件架构模式。</li><li>GUI库。</li><li>交互方式和交互技术。</li><li>支持GUI库的软件。</li><li>交互动画技术。</li><li>动画和多媒体在交互中的作用。</li></ul><p><em>技能</em></p><ul><li>阐述软件架构模式对接口设计的重要性。</li><li>解释交互设计中与导航相关的问题，以及解决方法。</li><li>为给定的数据科学应用创建GUI界面。</li><li>说明为资源受限设备创建交互接口时需考虑的因素。</li></ul><p><em>品行</em></p><ul><li>具备创建正确有效的交互接口的方法。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;分析和展示-Analysis-and-Presentation-AP&quot;&gt;&lt;a href=&quot;#分析和展示-Analysis-and-Presentation-AP&quot; class=&quot;headerlink&quot; title=&quot;分析和展示 Analysis and Prese</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>The Data Science Task Force</title>
    <link href="http://gloomymoon.github.io/2020/12/17/The-Data-Science-Task-Force/"/>
    <id>http://gloomymoon.github.io/2020/12/17/The-Data-Science-Task-Force/</id>
    <published>2020-12-17T11:45:13.000Z</published>
    <updated>2024-09-29T11:23:58.871Z</updated>
    
    <content type="html"><![CDATA[<h1 id="The-Data-Science-Task-Force"><a href="#The-Data-Science-Task-Force" class="headerlink" title="The Data Science Task Force"></a>The Data Science Task Force</h1><blockquote><p>“We’ll send a task force with you.”</p><p><em>―Jedi Master Mace Windu advises Master Obi-Wan Kenobi</em></p></blockquote><h2 id="0-背景介绍"><a href="#0-背景介绍" class="headerlink" title="0 背景介绍"></a>0 背景介绍</h2><p>2017年8月，<a href="acm.org">ACM</a>教育理事会上，成立了一个数据科学特别工作组（<a href="http://dstf.acm.org/" target="_blank" rel="noopener">Task Force</a>），探讨关于增加对数据科学的广泛、跨学科的对话，以及计算学科对这一新兴领域的贡献和承担的角色。</p><p>特别工作组于2019年1月发布了第一版面向高等教育的数据科学课程体系的胜任力<sup><span id="a1"><a href="#fn1">[1]</a></span></sup>报告（Computing Competencies for Undergraduate Data Science Curricula）的<a href="http://dstf.acm.org/DSReportInitialFull.pdf" target="_blank" rel="noopener">初稿</a>，2019年12月，更新了<a href="http://dstf.acm.org/DSReportDraft2Full.pdf" target="_blank" rel="noopener">初稿第二版（Draft 2）</a>，在前一版的基础上重新定义、规划并细化了“知识领域”（Knowledge Areas），增加了T1（Tier 1）、T2（Tier 2）和选修（Elective）三个级别的知识、技能和品格，增加了部分章节：参与范围、构建计划和制度挑战<sup><span id="a2"><a href="#fn2">[2]</a></span></sup>。</p><p>草案主要内容包括：</p><ol><li>宗旨和目标</li><li>现状的前期工作</li><li>数据科学的主体知识</li><li>根据课程建议构建课程计划</li><li>扩大参与范围</li><li>学员的个性和品格</li><li>制度挑战</li></ol><p>工作组的成员中有两位中国大学的教授：华东师范大学的<a href="https://www.linkedin.com/in/weining-qian-77356ab/?originalSubdomain=cn" target="_blank" rel="noopener">钱卫宁</a>和哈尔滨工业大学的<a href="https://www.linkedin.com/in/hongzhi-wang-ab92318/?originalSubdomain=cn&amp;success=true" target="_blank" rel="noopener">王宏志</a>，另外有USA10人、UK1人和Canada1人。</p><p>同<a href="https://www.acm.org/binaries/content/assets/education/curricula-recommendations/it2017.pdf" target="_blank" rel="noopener">IT2017</a>类似，这不是一套规章制度，其内容也不具有强制性，但是对相关领域具有十分重要的意义和指导作用。参考IT2017的定位，一方面对数据科学专业人才培养的定位和具体课程体系的设置具有十分重要的指导，另一方面强调基于胜任力模型的学习过程和课程体系开发，全面的对知识体系按照学习成效进行了梳理、补充和完善，适应了工程认证、专业评估的要求。因此帮助并指导学校、科研机构、企业组织能够更规范地、更有条理地制定相关的知识培养计划、技术发展规划和人才招募标准。</p><h2 id="1-数据科学的现状"><a href="#1-数据科学的现状" class="headerlink" title="1 数据科学的现状"></a>1 数据科学的现状</h2><p>数据的本质是现实世界运转的映射，人类通过发现、观察、测量、分析这些数据，才能理解、改造和影响现实世界。从现实世界到数据时描述、归纳、抽象成数据模型的过程，从数据到现实世界是用模型来预测、推断的过程，这是一个闭环，数据科学就是实现这个闭环的自动化、智能化的技术，让循环不断优化。</p><p>2001年，数据科学作为一个独立的学科提出，2007年，著名计算机科学家吉姆格雷就指出“数据密集型科学”已经成为继<strong>实验、理论、计算模拟</strong>之后的第四科学研究范式。</p><p>数据科学本质上是一个交叉学科，其兴起与各领域日益增长的海量数据直接相关。科学、社会学、商业、人文、工程都渴求从前所未有的大数据中探寻潜在的创新机遇和决策依据。数据科学即是这样一个综合利用领域数据、计算科学和统计工具来探查数据获得有用信息的交叉学科，这是一个非常具有挑战性的工作。</p><p>早期对于数据科学的体系梳理包括：</p><ul><li>The EDISON Data Science Framework(2018)</li><li>The National Academies of Science, Engineering, and Medicine Report on Data Science for Undergraduates(2018)</li><li>The Park City Report(2017)</li><li>The Business Higher Education Framework (BHEF) Data Science and Analytics (DSA) Competency Map(2016)</li><li>Business Analytics Curriculumn for Undergraduate Majors(2015)</li><li>Initial workshops related to this ACM Data Science Curriculumn effort(2015)</li></ul><p>随着IoT、复杂传感器、人脸识别、语音识别、自动化技术的迅猛发展，计算机技术举足轻重，基于大数据的分析、处理和机器学习、人工智能等方面的投入将为领域学科带来丰厚的回报。</p><h2 id="2-胜任力模型（The-Competency-Framework）"><a href="#2-胜任力模型（The-Competency-Framework）" class="headerlink" title="2 胜任力模型（The Competency Framework）"></a>2 胜任力模型（The Competency Framework）</h2><p>草案中定义的胜任力（Competency）遵循<a href="https://www.acm.org/binaries/content/assets/education/curricula-recommendations/it2017.pdf" target="_blank" rel="noopener">ACM/IEEE-CS IT2017</a>的框架体系。<br><img src="/img/TheDSTaskForce01.png" alt=""><br>胜任力指的是专业或业界权威机构相关的绩效评价标准，工作中被用于评估胜任力的等级，是人们展现优秀工作表现所依托的内在品质。业界广泛认同的胜任力包含以下三个维度：知识（Knowledge）+技能（Skills）+品行（Dispositions）。</p><ul><li>知识代表对核心概念与内容的熟练程度以及在新环境中的学习和应用能力；</li><li>技能是长期实践以及与他人和世界的交互中发展和培养出来的责任感与策略。也要求在高级认知行为中的投入，“动手”的技能实践要与“动脑”相结合；</li><li>品行包含社会情感技能、行为准则和礼仪态度，表现为执行任务的倾向以及对何时和如何从事这些任务的敏感性。</li></ul><p>每个知识领域都会使用一套胜任力模板来描述，模板如下：<br><img src="/img/TheDSTaskForce02.png" alt=""></p><p>对于每个子领域（sub-domain）都会详细描述其所需掌握的知识、技能和素养，这些内容都有一个额外的标注T1、T2和E代表其所需要掌握的程度：</p><ul><li>T1（Tier 1）：表示每一个学员都必须掌握（mastered）；</li><li>T2（Tier 2）：表示期望大多数据学员都掌握，且每个学员都至少掌握该项目的主要知识；</li><li>E（选修，Elective）：可选修的部分。</li></ul><h2 id="3-数据科学的知识领域（KA，Knowledge-Areas）"><a href="#3-数据科学的知识领域（KA，Knowledge-Areas）" class="headerlink" title="3 数据科学的知识领域（KA，Knowledge Areas）"></a>3 数据科学的知识领域（KA，Knowledge Areas）</h2><p>数据科学的计算机知识领域包括：</p><ul><li><a href="https://gloomymoon.github.io/2020/12/27/The-Data-Science-Task-Force-Mission-I/">分析和展示（AP，Analysis and Presentation）</a></li><li><a href="https://gloomymoon.github.io/2021/02/28/The-Data-Science-Task-Force-Mission-II/">人工智能（AI，Artificial Intelligence）</a></li><li><a href="https://gloomymoon.github.io/2021/09/21/The-Data-Science-Task-Force-Mission-III/">大数据系统（BDS，Big Data Systems）</a></li><li><a href="https://gloomymoon.github.io/2022/12/17/The-Data-Science-Task-Force-Mission-IV/">计算和计算机基础（CCF，Computing and Computer Fundamentals）</a></li><li><a href="https://gloomymoon.github.io/2022/12/17/The-Data-Science-Task-Force-Mission-V/">数据获取、管理和治理（DG，Data Acquisition,Management,and Governance）</a></li><li><a href="https://gloomymoon.github.io/2023/12/17/The-Data-Science-Task-Force-Mission-VI/">数据挖掘（DM, Data Mining）</a></li><li><a href="https://gloomymoon.github.io/2023/12/31/The-Data-Science-Task-Force-Mission-VII/">数据隐私和安全（DP，Data Privacy,Security,Integrity,and Analysis for Security）</a></li><li><a href="https://gloomymoon.github.io/2024/07/20/The-Data-Science-Task-Force-Mission-VIII/">机器学习（ML，Machine Learning）</a></li><li><a href="https://gloomymoon.github.io/2024/08/14/The-Data-Science-Task-Force-Mission-IX/">专业素养（PR，Professionalism）</a></li><li><a href="https://gloomymoon.github.io/2024/08/20/The-Data-Science-Task-Force-Mission-X/">编程、数据结构和算法（PDA，Programming,Data Structures,and Algorithms）</a></li><li><a href="https://gloomymoon.github.io/2024/08/31/The-Data-Science-Task-Force-Mission-XI/">软件开发和维护（SDM，Software Development and Maintenance）</a></li></ul><p><img src="/img/TheDSTaskForce03.png" alt=""></p><h2 id="4-个人素养（Characteristics）"><a href="#4-个人素养（Characteristics）" class="headerlink" title="4 个人素养（Characteristics）"></a>4 个人素养（Characteristics）</h2><p>除了上述知识领域以外，数据科学学员还需要培养如下素养和特质，帮助自己的相关领域的工作和学习中获得成功。</p><ul><li>基础数学、统计和计算机技能的预备知识，能够使用Python或R编写程序、具备使用常规库和学习新工具的能力，掌握使用数据库和因特网的技能，能够阅读论文，熟悉并使用公共数据集并用于理论知识；</li><li>乐于学习快速迭代的新知识，能够从经验中不断总结和发展；</li><li>对应用领域的广泛兴趣并具有一定的专业水平，理解业务任务和目标，发现挑战和基于；</li><li>关注和警惕非技术领域、人文领域的冲击和影响，例如个人隐私、信息安全等；</li><li>良好的沟通技能，聆听客户诉求，识别真实需求，学会问问题以及流畅的表达和沟通，包括制作最终的交付物和报告；</li><li>具有社会责任感、法律意识、伦理道德，了解区域文化差异。</li></ul><h2 id="5-数据科学人才"><a href="#5-数据科学人才" class="headerlink" title="5 数据科学人才"></a>5 数据科学人才</h2><p>由于同时具备数学+计算机科学+领域知识的交叉型人才非常稀有，因此数据科学通常需要不同团队之间的协作，大致可以把数据人才分为以下几种类型：</p><p><strong>数据技术人才</strong></p><p>主要负责数据处理的全过程，即数据的获取、存储、清洗、加工、建模、传输和诠释，数据采集工程师、数据系统研发、应用研发、数据可视化工程师等都属于该类人才。</p><p><strong>数据管理人才</strong></p><p>主要负责对数据的保存、管理、维护和运营。面对“数据”这个特殊的管理对象，需要有能够适应这个特殊性的管理人才。</p><p><strong>数据安全人才</strong></p><p>主要负责对数据安全（包括数据本身和数据防护安全）的维护和保障，包括维护数据隐私、防止数据盗用和滥用、保护加密数据、阻止黑客攻击、建立数据安全防护体系等。</p><p><strong>数据政策人才</strong></p><p>只要负责数据相关的政策、法律及制度的研究。</p><p><strong>数据科学家</strong></p><p>狭义来说，数据科学家指能够利用数据作为资源，具有数据分析能力，精通各类算法，直接处理数据，创造附加价值的人才。</p><p><strong>首席数据官CDO</strong></p><p>CDO是数据如何收集、如何管理、如何应用的总指挥，为组织的数据收集、管理、分析、应用、安全等多个领域建立标准、设定方案并给出发展趋势，是制定数据战略、管理数据资产、建设数据队伍的综合型管理人才。</p><h2 id="附：注解"><a href="#附：注解" class="headerlink" title="附：注解"></a>附：注解</h2><p><span id="fn1"><a href="#a1">[1]</a></span>: 相关术语的中文翻译参照ACM中国教育委员会和教育部高等学校大学计算机课程教学指导委员会翻译的<a href="https://www.acm.org/binaries/content/assets/education/it2017_chinesetranslation.pdf" target="_blank" rel="noopener">《信息技术课程体系指南2017》（IT2017）</a>，该指南同样由ACM和IEEE CS编制。</p><p><span id="fn2"><a href="#a2">[2]</a></span>: 来源<a href="http://dstf.acm.org/Outreach/SDSS_Eposter_Draft.pdf" target="_blank" rel="noopener">Poster presentation at SDSS 2020, Virtual, June 2020</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;The-Data-Science-Task-Force&quot;&gt;&lt;a href=&quot;#The-Data-Science-Task-Force&quot; class=&quot;headerlink&quot; title=&quot;The Data Science Task Force&quot;&gt;&lt;/a&gt;The D</summary>
      
    
    
    
    
    <category term="Data Science" scheme="http://gloomymoon.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>A Thought On The Battle Of Midway</title>
    <link href="http://gloomymoon.github.io/2019/12/17/A-Thought-On-The-Battle-Of-Midway/"/>
    <id>http://gloomymoon.github.io/2019/12/17/A-Thought-On-The-Battle-Of-Midway/</id>
    <published>2019-12-17T11:05:09.000Z</published>
    <updated>2020-09-09T15:24:26.161Z</updated>
    
    <content type="html"><![CDATA[<h1 id="中途岛海战引发的思考"><a href="#中途岛海战引发的思考" class="headerlink" title="中途岛海战引发的思考"></a>中途岛海战引发的思考</h1><p>A Thought On The Battle Of Midway</p><blockquote><p>警告：本文佷干，谨慎阅读</p></blockquote><h2 id="1-中途岛海战"><a href="#1-中途岛海战" class="headerlink" title="1 中途岛海战"></a>1 中途岛海战</h2><p>最近仍在档期的《决战中途岛》，虽然劣质的建模（珊瑚海沉的竟然是企业号假扮的列太太！——毕竟投资才1亿美元）、夸大的防空火力特效、碎片化的魔改剧情、缺失的关键角色（粪提弗莱彻和F4F的萨奇剪都！没！有！），但是毕竟是近期少有的“史实型”战争片，观众们褒贬不一（主要是军迷和路人都有不满），上映40天，全球票房还没有超过投资额。</p><p>中途岛是太平洋战争，甚至是二战期间整个东部战场的一个转折点，此役之后，日本帝国开始步入灭亡，盟军转入反攻。通常认为，中途岛海战是弱势的USN战胜了优势的IJN，扭转了太平洋战争的态势，同时也宣告了海军航空兵从此称为蓝星海军的明星，直至今日。因此，中途岛海战成为历史学家、政治学家、军事学家和广大军迷津津乐道的研究话题，从不同的视角回顾这段历史及其影响，以史为鉴，可以知兴替。</p><p>尤其是77年后的今天，人民海军已经形成了新的能力，打破第一岛链封锁，未来如何制御强敌，值得借鉴。</p><h3 id="1-1-战略目标"><a href="#1-1-战略目标" class="headerlink" title="1.1 战略目标"></a>1.1 战略目标</h3><p>日本是典型的有战术而无战略，重细节而轻全局，明知道与美国的战端不可轻启，却仍既希望能够通过一场战术上的胜利达成战略上的目标。太平洋战争在1941年12月7日开启那一刻其实就决定了胜负，山本五十六在珍珠港偷袭成功之后说出“唤醒了一个沉睡的巨人”，在清楚地预判结果的情况下仍选择孤注一掷，说明其战略上的无能和对国家长远利益的忽视。</p><p>由于建立在一个问题重重的政治制度上，日本统治阶层的各个利益集团只站在自己的角度，陆军把持的内阁在国际关系上错压在追随德国的判断上（因为日本陆军师从德国），推动了法西斯军国主义，使其凌驾于国家战略之上，将整个国运绑架在这辆失控的狂热民粹主义战车上。明治维新之后，日本成为东亚地区首个完成现代化的国家，但是作为一个资源有限的岛国，37万平方公里的国土面积和三千多万人口难以满足市场发展的需求，迫使其走上军事扩展和殖民侵略的道路，称霸东亚必先征服中国，征服中国必先吞并满蒙。但是当1940年中国军队在正面战场发起了全面反击，敌后战场又开展了百团大战，日本高层逐渐意识到深陷中日战争泥潭，需要再度谋求战略破局。随着苏德战争爆发，日本的战略弹性终于丧失殆尽，次年美、英、菲、荷几乎同时冻结日本的海外资产，美国还宣布对日本石油和废钢的禁运，迫使缺油缺钢的日本必须在资源耗尽前作出选择。诺门坎惨败历历在目，又不肯放弃称霸野心的日本铤而走险，在签订了《苏日中立条约》后选择南下，寄望利用南洋的石油橡胶资源构筑自给自足的防御体系，等待美国长途奔袭，好以逸待劳，其战略规划就是著名的“渐减邀击”计划。这时候出现了一个山本五十六，基于对美国国力的了解，山本清楚地认识到和美国打消耗战毫无胜算，力主“主动出击”的战略，在1941年底集结联合舰队所有的海军航空力量发动了珍珠港偷袭，直接瘫痪了美太平洋舰队的主力。</p><p>1942年春，由于以远少于预期的代价占领了菲律宾、荷属东印度、缅甸和马来西亚等诸多领地的日本，对下一阶段的战略都未来得及研究和确认，军令部提出西进印度和锡兰，南攻澳大利亚多个方案，山本和联合舰队坚持东进夏威夷。由于陆军无法支持进攻澳大利亚的庞大兵力和后勤补给，转而支持联合舰队东进的方案，最后妥协的结果是两个方向同时并进的战略，其一是孤立澳大利亚的作战，导致了珊瑚海海战，其二是诱奸夏威夷舰队的作战，导致了中途岛海战。</p><p>那么中途岛作战到底要达到什么目的呢？是占领中途岛作为进攻跳板，还是诱出美太平洋残余航母舰队并歼灭之？这两者明显无法兼容。中途岛距离日本本岛2000多公里，过长的补给线维持这样一个过小的前出基地，对压制夏威夷毫无帮助，直接面对夏威夷众多的岸基力量使得防守压力非常大，因此其战略地位对日本来说并不具有决定性意义，更何况从之后的瓜岛战役来看，当时日军的登陆部队根本无法执行这种远洋夺岛并长期坚守的战役，无法为岛屿及周边海域提供持续性的制空和制海权等于白打。实际上，在1942年，全蓝星的军队都没有远洋登陆战的经验和把握，谁打谁显眼，更何况日军只有区区5000人。若希望通过攻打中途岛诱使美军救援围点打援，那也要美军愿意配合“表演”，实际上威克岛、关岛的陷落验证了在劣势下美军权衡利弊之后保舰弃岛是优良传统，根本不可能在损失了所有主力战列舰后还会钻圈套里送掉仅有的海航机动部队。</p><p>甲午海战是场赌博，对马海战还是场赌博，太平洋战争更是一场豪赌，从珍珠港到巴丹本岛，“其兴也勃，其亡也忽”。《浩瀚大洋是赌场：细说日本海军史》这本书名很好的总结了日本法西斯战争赌徒的心态。</p><p>太平洋战争对美国来说是用“业余时间”来打的一场“次要”战争，但，美国人的目标清楚明了——歼灭IJN，收复失地，攻占本岛。在战略规划上多管齐下：北太平洋将日军驱逐出阿留申；中太平洋从珍珠港向西；南太平洋经腊包尔，沿新几内亚岛向西推进。整个太平洋战场基本是置于尼米兹的统一指挥下，各个方向攻击互相支援，密切协作。</p><h3 id="1-2-综合国力"><a href="#1-2-综合国力" class="headerlink" title="1.2 综合国力"></a>1.2 综合国力</h3><blockquote><p>“一切问题的本质都是经济问题”</p></blockquote><p>战争是政治的延续，而经济基础决定上层建筑。大国交战，本质上就是综合国力的对抗，战争的目的最终也是为了经济：摧毁对方的产能，占领对方的市场。</p><p>日本综合国力落后是硬伤，一句话，就是穷。穷就说明全方位落后。例如最有名的零式舰载战斗机，日本航空发动机的研发能力不足（大推力航空发动机是顶级的科研项目，需要大量的资金和时间，联系当下中国，早期J-20使用的是毛子AL31F，之后换装同样推力的太行WS-10B，而更大推力的太行WS-15在2000年立项计划2020年才能完成），为了满足军方的性能要求，同时机体重量控制在2吨以内，战斗机的体型和发动机选型受到限制，只能采用不足1000马力的小发动机，而发动机功率不足，要达到高速高机动性就必须进一步减重（零战最终的空重是1.5吨），从而降低飞机的结构强度和防护能力（没有防护装甲和自封油箱），限制的机翼强度又影响到武器的火力和性能，翼面负荷低使得高空高速性能非常不理想，在铝架上打孔减重又增加了工时，影响产能。诸此种种，使零战成为一架一开始就达到最理想状态的飞机，没有任何改进的潜能。反观美帝的舰载机，从早期的F4F开始即使用1200马力的发动机（性能上却被零战吊打），F6F是1700马力，秉承了“只要马力大，板砖飞上天”的优良传统。窥一斑而知全豹。</p><p>二战爆发前美国刚刚经历了29-33大危机，其根本原因就是资本主义发展到一定阶段后的产能过剩，罗斯福通过执行国家资本主义的经济政策，直接投资基础建设，发放消费券，设法改出大萧条。但是这场经济危机在欧洲则演变为了二次大战，爆发的战争摧毁了参战国的工业能力和经济实力，刚刚复苏的美国紧抓机遇开足马力建造武器，同过贩卖军火牟取暴利，一举奠定战后超级大国的基础。虽然最后美国自身也被卷入战争，但是其综合国力已经远远超过了其他参战国家。珍珠港事件前，美国的工业产值是日本的22倍（2000亿:90亿）、钢产量是5.7倍（3300万吨:580万吨）、煤炭产量是7倍、汽车产量是80倍，在1941-1945年期间，日本共生产了航母17艘、战列舰2艘、巡洋舰9艘、驱逐舰63艘、潜艇147艘。而同一时期美国生产了航母 (包括护航航母在内)131艘、战列舰10艘、巡洋舰48艘、驱逐舰355艘、护卫舰498艘、潜艇203艘。美国飞机是日本的4.5倍、大炮是6.5倍、枪支是6.5倍，整个二战美军制造了400亿枚炮弹，总数量是日本500倍以上。即便珍珠港突袭中所有太平洋舰队包括航母都被击沉，只需要2年（甚至更少），美国海军的综合实力仍旧会反超日本。</p><p>约克镇号航空母舰虽然在珊瑚海之役中受伤，但是美国人硬是在3天内就修复到战争状态，从微观的角度也能反映出美国的工业能力和动员力、组织力、执行力。约克镇号能否重返战场是尼米兹考虑是否在中途岛应战的决定性因素之一，同样在该役中受伤的瑞鹤翔鹤不得不在修理厂待了2月，错过了中途岛战争，严重影响了双方海空兵力的对比。</p><h3 id="1-3-战役规划"><a href="#1-3-战役规划" class="headerlink" title="1.3 战役规划"></a>1.3 战役规划</h3><p>仅就中途岛一役来说，日本的战役规划也是极其糟糕的。中途岛攻略计划在42年初就开始讨论，一直到5月5日才正式颁布了定于6月初占领中途岛和阿留申群岛西部要地的《大本营海军部第十八号命令》，这还是由于4月18日杜立特空袭加速了军令部和联合舰队内部意见统一的结果。但是作战还没开始就出了问题，3天后珊瑚海海战中五航战的瑞鹤翔鹤残的残、损的损，而陆军又不愿调整原定的登陆日期（不愿等待下一个月圆之夜），使得南云的兵力直接减少了1/3。</p><p>最终的日方兵力部署如下：</p><ol><li>山本长官亲率联合舰队主力大和长门陆奥以及1轻母1轻巡9驱逐，作为主力编队；</li><li>高须四郎率领日向伊势扶桑山城四艘老旧战列舰和2轻巡12驱逐编成的阿留申警戒部队，负责支援阿留申攻略作战；</li><li>南云忠一率领一航战二航战的4艘航母以及护航的2战巡2重巡1轻巡12驱逐，和8艘油轮，组成的第一机动部队；</li><li>近藤信竹率领包括1轻母2战列2水上飞机母舰及一众轻重巡和驱逐舰，保护16艘运输舰和登陆舰，运载登陆部队5000人组成的中途岛攻略部队；</li><li>包含第二机动部队的龙骧隼鹰号航母以及3重巡4轻巡11驱逐，护卫着阿图岛和基斯卡岛攻略部队的北方阿留申部队，登陆部队攻击2250人；</li><li>由香取号轻巡率领10艘潜艇组成的先遣编队，负责侦查和警戒；</li><li>另外还有岸基航空支援部队，部分飞机由第一第二机动部队携带准备部署在攻占的中途岛。</li></ol><p>其中阿留申方面的攻略是为了配合中途岛牵制敌兵力的佯攻，即便占领阿图岛也会在9月份撤退。中途岛的攻击会在阿留申攻略之后2天开始，由第一机动部队首先实施空袭，目标是敌岸基航空兵力、防御设施、军事设施，然后在主力部队的掩护下登陆部队会在中途岛登陆。当各支部队在中途岛附近就位后，迎战和歼灭出现的敌舰队主要依靠：山本的主力、南云的第一机动部队、或是阿留申方面的警戒部队/第二机动部队、以及潜艇部队。这些部队以山本的主力为核心分散部署，相距300～500海里。另外，制定了的“K号作战”，利用二式大艇超远的航程配合潜艇加油，侦查夏威夷美军主力的动向。</p><p>联合舰队几乎倾巢出动，但是却把兵力拆分地细碎，各部队间距过大无法互相支援，这其中最大的问题是南云仅有4艘正航，却需要同时兼顾两个重要的任务：攻岛和灭舰，埋下了那个所谓“命运五分钟”的大炸雷。</p><p>这个代号为“MI”的作战方案在制定的时候，完全没有征求两位担任重要人物的舰队司令长官——二舰队的近藤和一航舰的南云——的意见。5月1日，近藤终于有机会谒见山本长官，发表对中途岛作战计划的担忧，但是作战计划已然确定，联合舰队司令毫不理会，连修改集结点的建议这种细节也不愿做任何改动。事实上，南云及其僚属（包括参谋长草鹿、航空参谋源田实、二航战司令山口多闻、飞龙号舰长加来大佐）对这个计划都是抵制或不认可的。</p><p>整个中途岛攻略不仅要求日本多个舰队之间天衣无缝的配合，而且要求美军也必须要有相当的默契，完全按照日方的时间节点介入作战，才能达到完全的效果。而一旦执行过程中出现一点意外，日军将呈现全面被动，兵力过于分散且舰队之间无法及时增援，最终可能被各个击破。联合舰队司令部在做图上推演时，从中途岛和阿留申攻略到进攻约翰斯顿和夏威夷，每项行动都没有考虑可能遇到的困难，宇恒缠少将通过对演习横加干预，篡改裁判员的裁决结果，使得这次推演的结论很不充分，有人提出了南云部队在空袭中途岛时侧翼出现敌特混舰队是该怎么办，南云的参谋含糊答复，其实是没有应对方案，后来在实战中，正是出现了这种情况葬送了整个一航舰。南云的机动部队必须依靠自己的兵力组织空中搜索，警戒兵力不足以建立有效的对空火网，对付敌机的袭击战斗机数量不足，而山本的主力部队远在300海里以外，根本无法给予有效支援。从根本上，联合舰队司令部和山本的思想还是以战列舰作为决战的主力，而不是让在珍珠港和珊瑚海已经证明的航空母舰担当舰队核心，由战列舰担任警戒和护卫（美军就是这么玩的！）。</p><p>面对强敌压境，美军依靠情报上的优势，完全洞悉了日军的详细计划，并针对制定最优的作战计划，放弃阿留申方面，加强中途岛防备和岸基航空兵力（中途岛上的飞机达到了120架），集中舰队目标直指进攻中途岛的日军联合舰队核心——四艘正规航空母舰，在中途岛东北埋伏，并调用一切侦察飞机（主要是中途岛的PBY水上飞机）搜索日军主力，集中火力摧毁航空母舰。</p><h3 id="1-4-战力对比"><a href="#1-4-战力对比" class="headerlink" title="1.4 战力对比"></a>1.4 战力对比</h3><p>这个中途岛战役的直接兵力对比，很多地方都能找到，日方占有明显的兵力优势，但是美军集中兵力主要与南云的机动部队作战，山本的其他兵力几乎没有参入战斗，另外如果计算上中途岛岸基飞机，则美方数量上超过日方，所以，从局部上看美军是优于日军的。这是美方获胜比较关键点的因素之一。</p><p>这里说几个小细节。</p><p>日本在相当一段时间内，战舰派是压制航母派的，也就是说，即便是珍珠港偷袭取得如此巨大成就，日本内部仍然把战列舰作为主力，把战列线决战视为对美战略的最终形态。从战前建造计划中可以看出：丸三、丸四、丸五总计建造航母6艘（2翔鹤级、2大凤级、2云龙级），而计划建造的战列舰达到9艘，包括4艘大和级、1艘大和改、2艘超大和级和2艘超甲巡（相当于英美的战巡）。中途岛战以后，帝国海军才纠正了对航母的认识，在丸五改中将计划的航母数量从3艘提升到15艘，但是为时已晚，这些计划再也没有实施的可能性。</p><p>另外日军的航母的设计一直剑走偏锋，载机量普遍也没有美国航母的多，日本人以整洁干净著称，甲板上也要整理的井井有条，不容许系留舰载机，所以不会出现美军那种动辄120架的载机情况出现（但是也至少有80+）。这反过来又促使了日军不得不提升多航母协同作战能力，比如奇葩的左右舰岛对称设计，就是因为单舰载机量不足，基本是以双航母编队作为机动部队的配置。美军则反之，初期由于没有足够的航空母舰，为了避免集中的航母舰队被一锅端，采用单航母的混合编队并分散部署，同时极尽所能在一条航母上塞上足够多的舰载机和备机保持持续作战能力，所以其集中运用海航的能力反而不如日军强。</p><h3 id="1-5-武器代差"><a href="#1-5-武器代差" class="headerlink" title="1.5 武器代差"></a>1.5 武器代差</h3><p>中途岛时期（以及之前）两军的海军战术兵器虽各有优劣，但在总体上没有明显的代差。</p><p>日军占优的战术兵器主要有：性能上吊打其他一切海航战斗机的零式、性能和射程都非常恐怖的93式氧气鱼雷。</p><p>但是当时日军战舰普遍没有装备雷达，唯一装舰的是伊势号战列舰上的二号一型电探。这是一款水面搜索雷达，探测飞机灵敏不足，另外伊势在山本的主力部队，远离南云300海里。二战时日本海上侦查主要靠人眼，包括夜里（特别培养具有夜视远视能力的观察兵）。而且其防空武器相对落后，小口径的低射速，大口径的仰角不够，并且没有火控，舰队防空基本依靠护航的战斗机，敌俯冲轰炸机一旦突破，威胁巨大。</p><p>美军虽然已经开始部署雷达，但性能上并不可靠，只能提供较有效的对空预警，还无法直接用于火控，尤其是在群岛海域会受到地形的干扰。除此之外双方在战列舰、航空母舰、巡洋舰、驱逐舰到岸基作战飞机、防空火炮都没有明显的技术性能差距。双方航母的吨位和载机量、战列舰主炮口径、海军轰炸机的作战半径等武器性能基本都在一个级别上，也都具有大型远程水上侦察机和岸基航空队的支援，在原子弹研制成功前，都没有决定性的战略武器。</p><p>除此之外，美军的武器没有明显超过日军，但也没有明显劣于对方。一直到VT弹的发明才有效提升美军舰队的自身防空能力，F6F的服役标志美海军航空兵获得压倒性的制空权优势，美军的雷达也要到萨沃岛海战才开始展现，帮助美军扭转夜战不利的局面。</p><p>在此之前双方更多的是通过更好的战术在充分发挥手中的武器，获得战场上的局部优势。例如中途岛海战中VF-3对战萨奇发明的萨奇剪战术，有效利用笨重的F4F编队痛击零式，而日本也基于在中国战场获得的大量作战经验，提升了海航飞行员的作战能力。</p><p>战术兵器上的性能、差异、优劣，可能是影响中途岛战役中最可以忽略的因素之一了。</p><h3 id="1-6-侦查谍报"><a href="#1-6-侦查谍报" class="headerlink" title="1.6 侦查谍报"></a>1.6 侦查谍报</h3><p>作战前南云的参谋就提出“赤城”号无线电通信设备不好（这是当时航母的通病，因为无线电天线必须足够矮小避免妨碍飞机起飞，而部分天线在飞机起降时必须放倒而无法工作），可能影响到截听敌人的通信，错失判断敌人动向和企图的机会。山本的大和号多次监听到中途岛方面的无线电频率增加，预示敌人已经发现了自己的动向，却全程保持无线电静默，理由是“南云肯定也监听到了”，错失了及时修正南云决策的机会。“K号作战”由于加油的潜艇在集合点发现两艘敌舰，无法为二式大艇加油，造成作战计划流产，完全无法预知珍珠港内美军的状况。先遣潜艇侦查部队到位时间过晚，在约克镇已然上路之后才就位，因此一直提供“港内没有舰艇出动”的情报。这两项严重影响了司令部的敌情判断。</p><p>南云的第一机动部队没有足够的侦查飞机，很多还是非常老式的水上飞机，这是联合舰队的锅，但所有的水上飞机和舰侦加起来仍有20多架，最后只放飞7架（还因为各种故障问题延误，或者无法发报），采用单相搜索而不是更优的双相搜索，都足以说明日军完全没有认识到侦查能力在现代海战中的重要作用，尤其是面对航母这种发现即打击，打击即摧毁的超级明星。</p><p>受到运气加成，美军在41年11月日军第一次进攻威克岛被击沉的日舰中搜获了日本海军当时使用的密码本。早在5月初就知道了日本海军正在计划一次大战役，只是无法确定战役的目标“AF”具体是哪里。电影中对于这个著名的事件亦有相当的展现，情报部门伪造中途岛淡水设施故障，定论“AF”=中途岛，此外还为尼米兹提供了大量重要情报，精确地破译了日军的兵力和攻略计划，得以使他能够提前安排作战力量，抵消日军的内线优势，先发制人，掌握战场上的主动权。早在珊瑚海海战中，美军比日方预料更早地出现，使得攻占莫尔兹比港的计划被无限制推迟，已经体现出情报战取得的巨大胜利。</p><p>另外美军在珊瑚海海战后决定在舰载航空队中增加了侦察机的比例，使用SBD来做侦查轰炸机，大大提高了航母自身侦查能力。整场战斗中美军派出了参战三分之一的飞机参与侦查，路基侦察机和兼职侦查的舰轰总计有100多架，使得美军在当天5:20就发现了南云的舰队，南云则要在2小时后才发现美军舰队，而且报告中语焉不详，舰种、方位、航向全都报错。</p><h3 id="1-7-海陆矛盾"><a href="#1-7-海陆矛盾" class="headerlink" title="1.7 海陆矛盾"></a>1.7 海陆矛盾</h3><p>日本海陆不合是众所周知并且由来已久。最后做到联合舰队司令和军令部总长的丰田副武极端仇视陆军马鹿，曾自费印了一批小册子，写满了他看到想到听到挖苦讽刺嘲笑羞辱陆军的段子，每逢海军开会，必定见人就送一本，然后大家坐下来开开心心的讨论“陆军这群八嘎最近又如何不要脸，如何三个人用一个脑子……”等等。对美开战前他是反对最激烈的一个，原因不是他头脑有多清晰，而是因为陆军要坚决对美开战……</p><p>很多人把中途岛海战失败原因归于南云的“命运的五分钟”，这是受到了渊田美津雄的误导，后世经过更多考据证明，事实是南云在7:30收到“利根”上侦察机的情报，称发现美军，大约15分钟后，南云叫停一航战第二舰攻中队的换弹作业，而美军轰炸机的致命打击是在10:30分左右降临的，这中间已经过了50多个5分钟了。这个锅应该还给山本，而不是指责南云的失误。南云是鱼雷队出身，因为日本奇怪的吊床号制度，使他坐上了一航战司令位，如果从个人的角度看，南云的指挥是稳妥和保守的（这个可以从珍珠港偷袭中没有发动第三期攻击，就为了完好无损的带回每一条天皇的航母看出），只是单纯的运气不好。造成这样的进退两难的状况一是山本给出的模糊不清的叮嘱（“不要将所有飞机都放出去”），二是联合舰队没有将所有的海军航空力量集中使用，使得既要轰炸中途岛又要歼灭美机动舰队的南云手上没有足够的舰载机数量（攻击机、战斗机、侦察机都不够），否则第一波次攻击应该像偷袭珍珠港一样完全摧毁中途岛的岸基防御力量，后面只要专心针对出现的美军航母就行了，也不存在炸药鱼雷换来换去的问题。但是南云与山本不合，貌似是很多人的共识，年轻时的南云是舰队派成员，反对华盛顿条约，而山本是条约支持派的重要成员，其生命一度受到舰队派极端成员的威胁。担任中途岛攻略机动部队司令的南云已经55岁，早期的干劲已经耗尽，新的航空作战模式的复杂性显然超出了他的视野，同级的战友显然不认为他有相应的能力，联合舰队的参谋长宇恒缠少将在私人日记中甚至将他归为一个愚蠢的家伙，二航战的山口多闻也多次抱怨他的上级南云缺乏领导才能。愚蠢的日本海军自立规定只能让他来负责这个岗位，对于海军航空兵这一超级武器没有真正的兴趣和喜爱的南云很大程度上只是被动的执行这个岗位的职责，依赖下手参谋甚至过多的下放各种权利，例如让航空参谋原田实全权负责航空计划，却不安排监督者确保计划不会出现低级幼稚的错误。</p><p>联合舰队司令长官山本五十六是太平洋战争的最终决策者，他出身卑微，因此热衷于利用智慧搏取权利和声誉，在内部人望很高但又树立了很多仇敌，他一手推翻了“渐减邀击”计划，提倡海军航空兵战术和主动攻击战略，直接越过大本营为舰队制定战略方针，一旦大本营反对就已自己和联合舰队全体工作人员辞职作为要挟。在41年12月5日向天皇汇报时，明目张胆地对海军军令部和海军统帅部说“不要插手干预太多（联合舰队）”这样令人难以置信的冒犯话。珍珠港的胜利使得他的政治威望进一步提升，而且也让他尝到辞职威胁的甜头。1942年，内部决策分类，因为海军的进一步扩张都需要地面部队的进攻才能完成占领，不得不依靠陆军部队，这时帝国陆军和海军之间互相厌恶的问题才充分暴露出来，这可能是击垮日本帝国最重要的内部矛盾。</p><p>从联合舰队司令官、参谋长、首席参谋到各战队司令等全军都充斥着迷之自信与轻敌。</p><h3 id="1-8-后勤补给"><a href="#1-8-后勤补给" class="headerlink" title="1.8 后勤补给"></a>1.8 后勤补给</h3><p>日本海军在甲午战争和日俄战争中的作战半径从来没有超过600海里，它一直是一支近海海军，而对近海海军来说没有补给问题，所以偷袭珍珠港时，南云压根没有把美军的储油罐当作目标是再正常不过的操作。<br>日本人很重视潜水艇，而且开战时潜艇无论是数量还是吨位都超过美国，但是日本海军为潜艇制定的作战方针是“以适当的散开配置对敌人主队进行奇袭为宗旨”。这是写在《海战要务令》这种法律文件中的，除了少数战果（例如CV-7、补刀CV-5等），其余结果就是最后都把握不了自家舰艇的去向，只能根据美国人发的战报来推定某某潜艇可能又在某某海区玉碎了。</p><p>近藤中将就曾经向联合舰队参谋长宇垣缠发问：在中途岛登陆以后的后勤支援如何确保？除非能够维持补给，否则占领中途岛是没有意义的。宇垣的回答是：“如果实在无法确保中途岛，那就把中途岛上的军事设施彻底破坏了以后开路回家。”</p><p>纳尼？根本不考虑登陆以后的状况？</p><p>美国强大的国力能够保证的不仅仅是军队的武器装备，连军人的衣食住行都照顾得非常全面，日本面对的是武装到胃的大头兵。这里不得不提一下美国对于潜艇的运用。1941年12月8日，在珍珠港受到攻击3小时候，美国海军部就下达了在太平洋海区进行无限制潜水艇攻击的命令（这是二战美国真正策划过的战争犯罪）。很多人都知道德国U艇和狼群战术的战果，而忽视了美国潜艇的功绩。这有几个原因，一个是两个潜艇的驻防地：珍珠港和甲米地港的鱼雷都在日本人空袭中被炸毁，另一个是美国潜艇早期使用的MK14型鱼雷故障率极高，存在严重的设计缺陷。后一个问题闹到尼米兹亲自上阵和兵器局打官司，一直打到金恩上将那里，甚至连爱因斯坦都亲自出手分析鱼雷不爆炸的原因和解决办法（爱因斯坦和美国海军部兵器局签订过担任3年顾问的合同），才得以解决。夏威夷的美国海军太平洋舰队无线电班在1942年底左右就破译了日本的船运密码，称为“马鹿密码”，包含船名、出发地、预定航线、目的地、途中每天正午的预定位置、航速，甚至连运载货物的明细都有。于是太平洋上巡逻的美军潜艇只需守株待兔，日本船舱的吨位的损失逐年翻倍。除1941年是从12月份开始记的仅有5万吨，次年42年是88.5万吨，43年为167万吨，44年到了369.5万吨，45年实在没有船了，仍损失了172万吨，整个战争期间，日本总损失为843万吨，这些水下恶鱼（美军的潜艇都以鱼类命名）贡献了其中63%的击沉吨位，另外还击沉日本海军舰艇201艘，自身损失仅有52艘（其中7艘非战斗损失）。这个战术彻底瘫痪了日本经济和后勤，花大力气弄来的南洋资源根本无法运回本岛，42年运回日本原油165万吨，只占生产量的45%，43年虽增加到230万吨，但占生产比例却下降到27%。大本营不得不征调中国和泰国负责运送粮食的船只，全部用到南方胆略资源的运输上，结果白白成为了潜艇的猎物。</p><h3 id="1-9-战术执行"><a href="#1-9-战术执行" class="headerlink" title="1.9 战术执行"></a>1.9 战术执行</h3><p>就中途岛战役本身来看，双方的表现都很一般。</p><p>不同于全面换装F4F的海军航空兵，驻中途岛的陆航VMF-221中队的战斗机大部分是老旧的F2A水牛（21架F2A和7架F4F），在日军第一波攻击中全部参与防御被零战几乎全歼，没能按照尼米兹战前的部署为攻击机群护航。虽然中途岛守备顽强的抵抗，使得南云收获还需要第二波进攻的讯息，但是实际上却没有任何战果。<br>美航母特遣舰队在4日5:30收到南云机动部队的方位后，直到7点才从企业号和大黄蜂号起飞117架舰载机，其中包括20架战斗机。临时接替“蛮牛”哈尔西的斯普鲁恩斯其时没有任何指挥航空作战的经验（弗莱彻虽然也没开过一天飞机，但是在之前几次航母战役中的多少积累了一些经验）,没有指定详细的航空作战计划，大黄蜂号和企业号的飞行大队长都根据各自的推算修正航向（敌人已经从发现的位置行驶了1个多小时），朝着不同的方向出发搜寻。放飞第一波攻击的117架飞机的作业，两艘航母手忙脚乱了一个小时还没有完全，斯普鲁恩斯下了第二个错误的决定，舰载机立即向目标出击，不再进行编队。这就是为什么VF-6跟着VT-8，而VT-6只能孤零零向预定航向飞去。大黄蜂号的VF-8、VB-8、VS-8没有找到正确的方向，又耗尽燃料，最终不仅没有对敌人扔下一颗炸弹，还损失了十数架舰载机。11架VB-8的SBD就近降落在中途岛机场，直到当日下午才转场回到大黄蜂号上，VS-8的SBD对大队长失去信心打道回府，在午后也回到母舰上，而VF-8的的战斗机最终都因油料不支全部损失在太平洋深处。事后，大黄蜂号的舰长米切尔和飞行大队长瑞双双被调回国内训练航空队。</p><p>弗莱彻指挥下的TF17要好的多，他和约克镇舰长巴克马斯特制定了详细的飞行计划和索敌方案，合理规划了舰队航程，耐心等待侦查报告，到8:38，放飞了VF-3的6架F4F、全部VB-3和VT-3，保留VS-5继续侦查警戒。VF-3的中队长萨奇是一位富有创见的王牌飞行员，在珍珠港事件前，就敏锐注意到在中国战场的“飞虎队”发回的报告中提到零式战斗机的威胁，他立即着手组织训练、研究的对抗零式的战术，这套战术就是第一次在中途岛海战上付诸实施，并被证明非常有效的“萨奇剪”战术。</p><p>差不多在9:18，约克镇的攻击机队放飞完毕之时，VT-8的鱼雷机发现南云的机动部队进入攻击，而之前稀里糊涂跟着他们的VF-6却失散了，VT-8的15架慢速TBD决死突击，还没有进入阵位就被零式全部击落，全队仅有盖伊一人生还。事实上VT-6的10架F4F这时已到达机动部队外围，部分飞行员听到VT-8机组的呼救，但是VF-6的队长格雷一直以为掩护的是VT-6，并没有听到她和VT-6约定的支援暗号，就这样一直无所事事的盘桓。直到9:38，真正的VT-6进入战场，并且向VT-6发出呼救信号，VT-6又莫名无线电不畅没有收到，直到10点以后因燃料告急，无视TF16要求他们继续留守阵位的命令返回企业号，这个上午浑浑噩噩的表现是美军在中途岛海战中一个洗刷不掉的耻辱。失去战斗机支援的VT-6的14架TBD被击落9架，他们奋不顾身向加贺号投下的鱼雷也没有获得战果。</p><p>后面的过程大家比较熟悉，VF-3的6架护航F4F在萨奇的带领下与零式展开缠斗，VT-3吸引了其余直卫零式的火力，然后在麦克拉斯基带领下的VB-6、VS-6跟随岚号终于找到正确的目标并立即重创赤城和加贺，VB-3也同时击中了苍龙3弹，致其迅速瘫痪，只有飞龙号朵入云区逃过一时。</p><p>全程只有约克镇VF-3的战斗机为攻击机提供了一定的掩护，而俯冲轰炸机获得三个战果恰恰是占了协同攻击的优势，在没有零式阻拦的情况下瞬间毁灭了南云的主力。如果美方能够像日军一样将100多架舰载机组成一个完整的进攻波，以F4F的性能完全可以拖住大部分护卫的零式，不仅可以瞬间毁灭南云的4艘航母，也不会造成那么多的损失，或许还能扩大战果，直接送大和去见天照大神了呢。</p><p>事实上在进入攻击范围后，斯普鲁恩斯方面组织的进攻“混乱不堪”，大黄蜂号大部分飞机连敌人影子都没有找到，企业号飞机大队升空后就分离成三个独立的编队各自为战。只有参加过珊瑚海历练的弗莱彻麾下约克镇号成功发起了各机种协同攻击。除了运气以外，美军能够取得辉煌的胜利实际上是由以下因素造成的：海航中卓越的飞行队长、中途岛岸基航空队无畏的牺牲、部分飞行员高超的个人技战术。此战正暴露美军无法集中使用大量航母的战术水准，远不及半年前6艘航母结合使用组成巨波攻击力量的日本海航，这也奠定了美军以1～2艘航母编成特舰队队的编制模式，直到现在。</p><p>（我是不赞同把企业号视为该役的主角，以约克镇的角度叙说可能更完整）</p><p>日本在珊瑚海海战后反而更加轻视美国航空兵力，原因是一航舰3个航空战队中最弱的五航战居然在兵力相当的战斗中占了上风，那么更牛的一航战和二航战亲自上阵怎么可能会输？</p><p>日本每艘航母上只编有两个损管军官，在中途岛海战中，日军的损管军官阵亡后，其他的军官并不懂如何对受袭后燃起大火的航母实施有效救助，结果扩大了灾害的面积与强度，加速了航母的沉没速度。而美军在珊瑚海海战中列克星敦号的沉没中吸取了教训，对航母官员进行全员损管培训，人人都懂一些，这在舰船受到攻击后，能够有效控制灾害到最小程度。此外日军航母铺设的都是木地板，采用封闭式机库，一旦燃起大火容易很快蔓延，而且不能从外部救援。事实上中途岛海战中日军的4艘航母沉没都与这个因素有关。而美军在列克星敦级之后全部采用开放式机库，并且加强了内部结构的阻燃能力，这样能够避免或减轻次生灾害。</p><p>日军上空直掩体系分为高空、中空和低空三组飞机，然而此次当美军俯冲轰炸机从高空来袭时，日军并没有有效的拦截，所有的战斗机都在低空忙着猎杀美军的鱼雷机，高空和中空值勤的战斗机全部擅自离开了岗位，这应该属于直掩机队指挥官的失误。但是很有可能与飞行员们过于疲劳丧失判断力，并且低空直掩机可能早已耗尽了弹药却无法着舰补给有关。否则无法解释为何中空和高空的直掩机飞行员一个不剩的集体擅离职守。</p><p>反观美方，珊瑚海海战之前美国完全没有航空母舰的作战经验，因此非常注重总结并学习教训。例如从统计来看，舰载机的损失率非常高，一次出动就有1/3飞机回不来，于是美国就采用出征时装载更多的飞机来保证持续作战能力。其次美军在开展前非常重视战术侦察，而这正是日本海军的短板。</p><h3 id="1-10-后记"><a href="#1-10-后记" class="headerlink" title="1.10 后记"></a>1.10 后记</h3><p>个人觉得，翻拍《决战中途岛》并不是一个好主意。1976年版的虽然也有一堆问题（比如第一幕山本在杜立特空袭后10分钟收到报告，就知道是从航空母舰上起飞的消息明显是穿越），但是两个小时的片长聚焦在中途岛能够保证把故事说完整，拍摄时距离二战结束只有30多年，大家对于真正的战争是什么样还是有清晰的认识的。现在这个时间点拍摄一部由中方投资的反映二战美军英勇抗战的影片有点政治正确的意味，但是中途岛本身就是一个太庞大太重要的事件，背景复杂，研究和考据繁多，军迷又非常熟悉其中的细节和梗。翻拍的结果就是路人迷迷糊糊分不清谁是谁，军迷拿着放大镜捉虫可劲地找碴儿，两边都不得好。其实我觉得萨马岛海战和塔菲三号小队的故事更适合现在快节奏的娱乐环境，毕竟背景简单（主力舰队偶遇护航舰队）、场面足够火爆（战列舰过穿轻母+“像战列舰一样战斗的护航驱逐舰”塞缪尔·罗伯茨号骑脸筑摩）、人物对比鲜明（栗跑跑和向沉没的约翰斯顿号敬礼的雪风号舰长寺内道正）、结果也很煽情（太平洋上的狼牙山五壮士），一样可以从三艘驱逐舰这个中低层的角度反映战争的残酷和士兵的英勇，还能来个轰炸武藏和最后的苏里高宣告大舰巨炮的落幕，都不用怎么改编，也不用塞上什么爱情文戏，挺好。</p><p>PS：公元2019年12月17日，国产第一艘航母“山东号”正式入役，中国进入“双航母”时代，历史又翻开了新的一页。</p><p>To be continued…</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;中途岛海战引发的思考&quot;&gt;&lt;a href=&quot;#中途岛海战引发的思考&quot; class=&quot;headerlink&quot; title=&quot;中途岛海战引发的思考&quot;&gt;&lt;/a&gt;中途岛海战引发的思考&lt;/h1&gt;&lt;p&gt;A Thought On The Battle Of Midway&lt;/p&gt;
</summary>
      
    
    
    
    
    <category term="World War II" scheme="http://gloomymoon.github.io/tags/World-War-II/"/>
    
  </entry>
  
  <entry>
    <title>The Data Strikes Back</title>
    <link href="http://gloomymoon.github.io/2019/12/12/The-Data-Strikes-Back/"/>
    <id>http://gloomymoon.github.io/2019/12/12/The-Data-Strikes-Back/</id>
    <published>2019-12-12T10:46:59.000Z</published>
    <updated>2019-12-12T13:22:30.181Z</updated>
    
    <content type="html"><![CDATA[<h1 id="The-Data-Strikes-Back"><a href="#The-Data-Strikes-Back" class="headerlink" title="The Data Strikes Back"></a>The Data Strikes Back</h1><p>今天是双十二，我们来聊聊双十一。</p><h2 id="1-“骗局”？"><a href="#1-“骗局”？" class="headerlink" title="1 “骗局”？"></a>1 “骗局”？</h2><p>今年淘宝双十一之后阿里公布的销售额高达2684亿元，比去年增长25.7%。就在官方陶醉在历史新高、普罗大众沉浸在买买买的兴奋中时，有人挖出了早在当年4月份微博用户@尹立庆所发的《关于淘宝2009年-2018年历年双11销售额数据造假的消息》，文中利用简单的二次回归模型，成功预测了7个月后的销售数据，并质疑淘宝销售数据的真实性。</p><p>原博文已被删除，网页快照如下：</p><p><img src="http://5b0988e595225.cdn.sohucs.com/images/20191112/bc2486682470482d818b48fbfce0bc48.jpeg" alt=""></p><p><img src="http://5b0988e595225.cdn.sohucs.com/images/20191112/35343ec0e1a143759b8c42b7414fb4a6.jpeg" alt=""></p><p>一时间网上争论纷纷，有人怀疑在拼多多挤占了市场的情况下是否真能有如此高的增长，反方有摆出“阴谋论”的认为是各种反华势力借此来质疑中国经济的虚假增长，等等。</p><p>2016年，已经有人对这提出过类似的质疑。</p><p><img src="https://pic4.zhimg.com/80/v2-ad3b0a13f2753184a5cbefc442d728d0_hd.jpg" alt=""></p><h2 id="2-神预测还是过拟合"><a href="#2-神预测还是过拟合" class="headerlink" title="2 神预测还是过拟合"></a>2 神预测还是过拟合</h2><p>知乎上的问题<a href="https://www.zhihu.com/question/355439478" target="_blank" rel="noopener">《如何看待双十一销售额完美分布在三次回归曲线上且拟合高达 99.94%？是巧合还是造假？》</a>中，很多人的回答都跑偏了，包括部分数学、统计学、经济学的公知大V们。</p><ol><li>凡是拿冯·诺依曼的“四个参数画大象，五个参数甩鼻子”来解释的都是没有读懂题干，@尹立庆使用的是18年及以前的数据训练建模，来预测7个月后19年的销售额并且在验证集上达到了极高的准确度，说明这是一个非常优秀的模型。如果19年的实际数据与预测值差异非常大，那才是过拟合。</li></ol><ol start="2"><li>讨论R^2是三个9还是两个9，并引入其他数据如黑五和GDP来比较的，是偷换概念，作者质疑的是实际数据与预测数据差异非常小的小概率事件连续发生，而其他数据存在类似情况并不能反证这是正常的。事实上，用黑五的数据来做类似的预测，效果要差很多。<br><img src="https://pic2.zhimg.com/80/v2-1b306386c871adfc625b5a0acb46ad29_hd.jpg" alt=""></li></ol><ol start="3"><li>对于“造假”的理解，只有很少人提出看法。阿里不会愚蠢到直接修改一个最终结果，但是内部统计逻辑是不透明的，这就涉及到统计偏差。统计数据的偏差其实比我们想象的要普遍，比如国家统计局每年都会对GDP做核算和调整：<a href="https://www.guancha.cn/politics/2019_11_22_526030.shtml?s=zwyxgtjbt" target="_blank" rel="noopener">国家统计局：修订后的2018年GDP为919281亿元</a>。<br><img src="https://i.guancha.cn/news/mainland/2019/11/22/20191122101624689.jpg" alt=""><br>GDP是一个非常复杂的统计数字，但是阿里计算销售额肯定要相对简单得多，这当中存在的猫腻应该主要不是计算逻辑，而是每笔交易的真实性和交易金额的水分。</li></ol><ol start="4"><li>销售金额中的水分可能存在的地方有：交易时间、交易金额、退货和取消交易，这些就为了营销活动的执行提供了可操作的空间。</li></ol><h2 id="3-背后的故事"><a href="#3-背后的故事" class="headerlink" title="3 背后的故事"></a>3 背后的故事</h2><p>中科院应用数学的博士（<br><a href="https://www.cnbeta.com/articles/tech/909871.htm" target="_blank" rel="noopener">https://www.cnbeta.com/articles/tech/909871.htm</a> ） 指出了一个事实：如果计划就是这样制定的，那么执行团队会通过“各种手段”将KPI完成的八九不离十。</p><p>所以，故事可能是这样的：阿里负责制定KPI的团队制定了19年双十一的销售额指标，而且很可能就是使用二次或者三次回归模型（亦即@尹立庆的方法），然后运营部门层层分解，最终执行端想尽一切办法，压榨商户也好、提前预售也好、锁定购物车也好、延迟退货也好，最终确保完成了任务指标。</p><p>“原阿里集团安全研究实验室总监”的微博用户“安全_云舒”透露了部分细节：“阿里控住交易额很容易，通过数据分析找出最活跃的商品，然后通过增加或者减少这些商品投送，就能达到一个类似的预设目标，保持每年增长率，根本没必要伪造数据或者刷单。”</p><p><img src="http://cms-bucket.ws.126.net/2019/11/13/08ea544bc3944ca79be99c9875da178e.jpeg" alt=""></p><p>双十一后阿里股价平稳，并没有因为创历史新高而大幅提升，这个业绩并没有引起投资者的反应，或许阿里只是完成了自己的承诺，也可能大家都知道这并不能说明什么。</p><p><img src="/img/The-Data-Strikes-Back_02.png" alt=""></p><h2 id="4-一切都是套路"><a href="#4-一切都是套路" class="headerlink" title="4 一切都是套路"></a>4 一切都是套路</h2><p>分析并没有到此结束，如果上述的猜测都是真实的话，可能有更多容易忽略的信息值得思考：</p><ol><li>如果“云舒”所述属实，需要通过临时的增加、减少投放来控制交易额，阿里内部已经有一套非常完备的实时数据流处理体系，能够在最短的时间内展现出当前业务的状况；</li></ol><ol start="2"><li>在此基础上，运营团队有着高效的应对计划，能够针对业绩的缺口进行及时干预，一旦达成目标后立即停止，拥有可怕的实时操控大盘的能力；</li></ol><ol start="3"><li>对于业绩操控的营销手段应该是有过详细的分析和规划的，能够在投放时就掌握预期的反应率情况，即在哪个产品针对哪个客群，给予什么样的优惠政策，可以达到多少反应率、提升多少销售额；在如此庞大的商户和客户规模下，几乎拥有精细到个体的精准营销能力；</li></ol><p>具体怎么控制呢？</p><blockquote><p>打个比方说就是叭店里价格200的商品标价2000，限定2000份，在某一时间段发出，然后通过羊毛群群主，通知给普通消费者，让消费者买下，并在确认收货以后全额返还。</p><p>这就是免单</p><p>我认为大家额度知道叭？</p><p>我同学为双十一贡献快一万，其中9千是免单。</p><p>包括护肤品，上一季的衣服，茶叶，内衣，全部以福袋方式发放免单</p><p>我因为同学薅羊毛不亦乐乎，我就去看了额，一件束腰带800，两瓶精华2000一件我真心考不上的大衣（普通的黑白，袖子看着设计的都有点短）7000。</p></blockquote><p><img src="https://pic3.zhimg.com/80/v2-a9180c0139979f529c1bddd5a7a2bf0e_hd.jpg" alt=""><br><code>知乎：秋月白白</code></p><p><a href="https://www.zhihu.com/question/51821719" target="_blank" rel="noopener">《双十一的套路有哪些？》</a></p><p><a href="http://money.163.com/17/1105/11/D2FMB5E4002581PP.html" target="_blank" rel="noopener">《天猫双十一造假证据曝光 商家被逼”自费”刷单》</a></p><p>很多用户发现双十一的羊毛越来越难薅了，满额、叠加、膨胀，游戏门槛提升，游戏规则复杂，最后买单时发现也就便宜了几块钱，辛辛苦苦这是为了什么？</p><p>盖楼活动，又是拉新又是卖VIP，天天PK的新鲜感过去之后，才发现满满的都是套路，最后就是阿里的指标好看了，KPI完成了，员工的奖金才有了着落。</p><p>“让世界没有难做的生意”，可在双十一想凑个单，太难了，用户们感觉被耍了。</p><p>还有比被耍更令人厌恶的事情呢。</p><p>例如：特朗普的竞选团队雇佣Cambridge Analytica公司利用脸书的数据来制造有利于特朗普精选的材料，原理就是基于个人行为的心理学侧写（OCEAN）技术，用大家熟悉的话来说就是“用户画像”，CA分析了民众的政治倾向和参政意愿，对不同偏好的受众投放不同的广告邮件或展示不同的网页信息，曾在帮助特朗普前将另一位之后退出的候选人Ted Cruz的支持率从5%提升到35%。</p><p>详见<a href="https://www.zhihu.com/question/55178840" target="_blank" rel="noopener">《Cambridge Analytica 是一家怎样的公司？》</a></p><p>双十一的统计数据还是小问题，要警惕的是阿里这类互联网寡头掌握了海量用户的个人信息（其中不乏隐私和敏感信息），是不是会将其用于违反法律和道德的目的。我们没有明确的证据，但是面对这座金山，鲜有能够坐怀不乱的商业公司。</p><h2 id="5-数据的反噬"><a href="#5-数据的反噬" class="headerlink" title="5 数据的反噬"></a>5 数据的反噬</h2><p>“双十一”是一个人为制造的营销节目，目的是通过优惠返利提升平台的交易量。若由平台承担营销成本，则买家和商户都是受益方，平台获得了流量、口碑、信用和用户体验，是一个多方受益的结果。当平台做大后，当然希望能够压缩营销成本，于是要求商户提供优惠，以降低平台的补贴，于是全平台通用的优惠规则逐渐被商户专享的优惠取代。其好处不仅大大降低了平台的补贴费用，将营销的权利下放给商户，可以由商户根据自身的实力来决定优惠的力度，这对于有一定规模的商户肯定是更好的方案，但是却增加了商户间的竞争，促进了内卷。如果商户一致抵制的话，平台就无法完成双十一的销售额KPI，因此肯定会以各种软硬要求将指标摊派到每个商户，实际上促成和助长了刷单、虚假商品、先涨价再优惠的各种不良行为，甚至滋生了各种灰色、黑色产业链。</p><p>过分鼓吹双十一销售额与中国零售经济间的表征关系，无形中被强劲的GDP给绑架了，使其成为一个不得不完成的“政治”任务。</p><p>“必然的成功导致必然的造假。”</p><blockquote><p>全国政协委员、科技部部长万钢等就“科技创新”问题接受中外记者采访提问时表示，硬逼着每个科技项目都成功必然导致造假现象。</p><p>来源：<a href="http://news.sina.com.cn/c/2008-03-14/071915145999.shtml" target="_blank" rel="noopener">http://news.sina.com.cn/c/2008-03-14/071915145999.shtml</a></p></blockquote><p>销售额是用来反应业务开展情况的指标之一，不应当被当作任务终极目标来完成。虽然我们在制定计划和目标时，都会要求量化指标，但是不管是管理者还是执行者，都应当始终关注方式方法，防止执行过程中歪曲理解，恶意追求指标完成，而忽视了合规、合法、合理。目前的大数据和分析技术确实可以在某种程度上帮助我们发现业务上的问题、优化和改进我们的执行策略，也能够预警潜在的问题，但技术是无辜的，要慎重使用，避免被数据反噬。</p><p>双十一的成绩能够刚刚完成计划，而没有出现较大的超额完成，除了体现前面所述的强大的营销控制力，也反映出大家都不愿意超额完成任务，或许是因为成本过高，或许是因为会对次年的KPI任务造成更大的压力。事实上，双十一活动已经越来越表现出这样的结果：积压用户一个月的消费意愿，统一在一天内释放，很多营销优惠模式反而会造成一些冲动消费、过度消费和无效消费，这种非正常交易占比多少，我相信阿里内部会有统计分析，当达到一定比例时，整个业务数据就会变成美股那样的泡沫，就看怎么戳破了。金灿荣教授认为“质疑数据造假”是为了打击阿里赴港上市，这有点冷战思维了，只是从目前披露出来的种种负面新闻，逐渐显示淘宝的“双十一”造神运动已经忘记了“初心”，被数据绑架甚至反噬了。</p><p>数据无法自我循环，必须依附于某个产品、某个客户或某个流程。数据分析和数据化运营是互联网企业的力气，能够雪中送炭、锦上添花，但是其使用存在局限和天花板。例如：产品创新和模式创新无法通过数据获得，这些必须依赖于人的洞见与创意；借助于A/B测试的决策优化有可能无法反馈长期用户的偏好；以及博弈性场景也无法用数据来做决策。</p><p>理性希望，明年双十一的销售额不会再满足这个预测模型，而是主动压低预期并和经济发展解绑。更进一步，应当然后整顿虚假交易、假冒伪劣、灰黑产业链等平台的顽症，使竞价排名的算法公开公平透平，营销活动能够真正回馈消费者和商户，才是正道和“初心”。</p><blockquote><p>Don’t underestimate the power of the dark side.  –Lord Vader</p></blockquote><p><img src="/img/The-Data-Strikes-Back_01.jpg" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;The-Data-Strikes-Back&quot;&gt;&lt;a href=&quot;#The-Data-Strikes-Back&quot; class=&quot;headerlink&quot; title=&quot;The Data Strikes Back&quot;&gt;&lt;/a&gt;The Data Strikes Back&lt;/</summary>
      
    
    
    
    
    <category term="Data Analysis" scheme="http://gloomymoon.github.io/tags/Data-Analysis/"/>
    
  </entry>
  
  <entry>
    <title>The Queen of the Flattops: Epilogue</title>
    <link href="http://gloomymoon.github.io/2018/12/17/The-Queen-of-the-Flattops-Epilogue/"/>
    <id>http://gloomymoon.github.io/2018/12/17/The-Queen-of-the-Flattops-Epilogue/</id>
    <published>2018-12-17T00:50:56.000Z</published>
    <updated>2024-12-14T06:58:02.911Z</updated>
    
    <content type="html"><![CDATA[<h2 id="The-Queen-of-the-Flattops-Epilogue"><a href="#The-Queen-of-the-Flattops-Epilogue" class="headerlink" title="The Queen of the Flattops, Epilogue"></a>The Queen of the Flattops, Epilogue</h2><p>断断续续花了几个月的时间才把这艘Lexington做完，这是第一次完整上色的模型。选择这个题材也是为了纪念今年Lexington的残骸被探现，以及刚刚去世的发现者保罗·艾伦。</p><p>Lexington是一艘情怀舰，《列克星敦号与珊瑚海海战》一书也是记忆中的接触最早一本海军传记，印象深刻。作为间战期服役的早期实验性航空母舰，Lexington在太平洋战争早期堪称中流砥柱，不幸在珊瑚海一役中受损沉没，没有太多的战功和荣誉。但是作为一个颜值党，列克星敦级优美的流线型舰型、全封闭舰艏、巨大的吨位尺寸，视觉上的感受甩其他二战的美航一大截，亦不是“妖魔鬼怪”的IJN能比。从幸存到战后的Saratoga来看，列克星敦级的性能还是值得称道的。</p><p><img src="/img/Lexington/20181216_050146262_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_050324752_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_050417389_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_062749735_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_062956666_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_063413711_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_063452005_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_063545542_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_063652390_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_063736651_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_063753996_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_063824485_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_063838761_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_063941039_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_064026572_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_064104811_iOS.jpg" alt=""></p><p><img src="/img/Lexington/20181216_064149897_iOS.jpg" alt=""></p><p><img src="/img/48689690_p0.jpg" alt=""></p><div style="display:none"><br><a href="https://zh.moegirl.org/%E6%88%98%E8%88%B0%E5%B0%91%E5%A5%B3:%E5%88%97%E5%85%8B%E6%98%9F%E6%95%A6%28CV-2%29#" target="_blank" rel="noopener">太太我喜欢你啊！</a><br></div>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;The-Queen-of-the-Flattops-Epilogue&quot;&gt;&lt;a href=&quot;#The-Queen-of-the-Flattops-Epilogue&quot; class=&quot;headerlink&quot; title=&quot;The Queen of the Flattop</summary>
      
    
    
    
    
    <category term="Static Model" scheme="http://gloomymoon.github.io/tags/Static-Model/"/>
    
    <category term="Lexington" scheme="http://gloomymoon.github.io/tags/Lexington/"/>
    
    <category term="Aircraft Carrier" scheme="http://gloomymoon.github.io/tags/Aircraft-Carrier/"/>
    
  </entry>
  
  <entry>
    <title>The Queen of the Flattops, USS Lexington CV-2</title>
    <link href="http://gloomymoon.github.io/2018/12/14/The-Queen-of-the-Flattops/"/>
    <id>http://gloomymoon.github.io/2018/12/14/The-Queen-of-the-Flattops/</id>
    <published>2018-12-14T04:17:00.000Z</published>
    <updated>2018-12-14T13:02:50.069Z</updated>
    
    <content type="html"><![CDATA[<h1 id="The-Queen-of-the-Flattops-USS-Lexington-CV-2"><a href="#The-Queen-of-the-Flattops-USS-Lexington-CV-2" class="headerlink" title="The Queen of the Flattops, USS Lexington CV-2"></a>The Queen of the Flattops, USS Lexington CV-2</h1><h2 id="0-引言"><a href="#0-引言" class="headerlink" title="0 引言"></a>0 引言</h2><p>USS Lexington CV-2, “Lady Lex”, The Queen of the Flattops. </p><p>列克星敦级首舰列克星敦号（以下称Lexington），蓝星最强海军（第二强空军）的第一艘正规航空母舰<sup><span id="a1"><a href="#fn1">[1]</a></span></sup>，二战结束前都是世界上最大的航母之一，是少有的在缺乏经验时建（改）造而没有出现重大设计失误的大型舰（说的就是你赤城），拥有全通式飞行甲板、侧舷舰岛式独立上层建筑和烟囱、封闭式舰艏和机库、高航速、大载机量的特征都是现代航母的标准。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/94/USS_Lexington_%28CV-2%29_leaving_San_Diego_on_14_October_1941_%2880-G-416362%29.jpg/800px-USS_Lexington_%28CV-2%29_leaving_San_Diego_on_14_October_1941_%2880-G-416362%29.jpg"></p><p><strong><center>USS Lexington CV-2，摄于1941年10月14日</center></strong></p><p>Lexington于1921年1月8日在昆西市霍河造船厂铺设龙骨，1925年10月3日下水，1927年12月14日服役，编入太平洋舰队。1942年5月8日在珊瑚海海战中遭受日军攻击，因航空油气泄漏引发大爆炸而严重受损，为避免被日军俘获，最终由驱逐舰雷击处分沉没于南纬15.23，西经155.30，同年6月24日正式除籍。2018年3月4日，其残骸被保罗·艾伦的打捞团队发现。</p><h2 id="1-孕育：坎坷之路"><a href="#1-孕育：坎坷之路" class="headerlink" title="1 孕育：坎坷之路"></a>1 孕育：坎坷之路</h2><p>起初，列克星敦级被设计为装有8门16英寸（406毫米，和依阿华级同口径）主炮、排水量45,500吨、最高航速33节的一级大型战列巡洋舰<sup><span id="a2"><a href="#fn2">[2]</a></span></sup>。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Lexington_class_battlecruiser2.jpg/800px-Lexington_class_battlecruiser2.jpg"></p><p><img src="https://tse3.mm.bing.net/th?id=OIP.FkFU34C0fxbicduxVmSQSwHaDS&pid=Api"></p><p><strong><center>最终定型的1919年型战列巡洋舰列克星敦级</center></strong></p><p>战列巡洋舰作为20世纪初各国海军的新宠，最早代表是英国在1908年建成的“无敌”级（Invincible Class），拥有不逊于战列舰的火力和巡洋舰的航速，“作为高速战舰，既可以在海战中抢夺有利阵位，又可以在海战之后追歼撒退的敌军”（——温斯顿·丘吉尔）。在1916年日德兰海战中，皇家海军的战巡凭借高速压制对方战巡，使本方获得情报优势，最找将德军舰队引入T字阵位并击败之，但是该役中共有4艘战巡被击沉而战列舰无一战沉也暴露了其防护上的不足。</p><p>美国海军内部关于战巡在海战中的定位与英国人的认识大致相同，但是一直持有这种高速战舰是否会在未来海战中发挥重要作用的怀疑，因预算不足、技术限制以及各层人士的反对，美国一直没有开建高速战舰，只是不断巩固更新各级“铁乌龟”。直到1915年“战略问题1号”实战演习中发现，在恶劣的海况下小型的驱逐舰无法完成舰队侦察任务，己方主力舰即便拥有优势火力也无法将敌人引入决战。在大量演习经验和兵棋推演总结的基础上，美国人认可了战巡在战术和战略上具有的重要价值，面对大西洋上的德国战巡和太平洋上新兴的IJN，若以舰队决战为基础，都需要装备高速大型侦查舰和战舰。侦查能力也成为了争夺广阔大洋上制海权的关键。</p><p>日德兰海战的结果促使美国国会批准了《1916年海军法案》，允许海军新建造10艘战列舰和6艘战列巡洋舰，后者即是列克星敦级战列巡洋舰（CC-1到CC-6）<sup><span id="a3"><a href="#fn3">[3]</a></span></sup>。不久后美国参加第一次世界大战，直到1920年～1921年，6艘战巡才相继动工，比英国晚了整整12年。在此期间，为了满足海军对航速和防护的要求，设计方案屡次修改，最终方案是类似胡德号（HMS Hood）的一艘大型快速重炮战舰，即1919年型。</p><p>没想到2年后国际政治风云变幻，一纸条约宣告了美国战巡梦的彻底破灭<sup><span id="a4"><a href="#fn4">[4]</a></span></sup>。</p><h2 id="2-重生：殊途同归"><a href="#2-重生：殊途同归" class="headerlink" title="2 重生：殊途同归"></a>2 重生：殊途同归</h2><p>1922年2月6日，美、英、法、意、日五个海军强国（注意没有德国）在华盛顿签订《限制海军军备条约》（又称《华盛顿海军条约》，限制各国主力舰和航空母舰的总吨位数比例和火炮口径，除了条约允许的之外，不得再新建排水量超过10,000吨、火炮口径超过203毫米的主力舰。美国保留了两艘建造中的西弗杰尼亚级战列舰，列克星敦级战巡的建造计划不得不全部取消，为其提供掩护和辅助力量的新一批驱逐领舰的建造也受到波及没有实施。而之前时任助理海军部长，后来的美国总统富兰克林·罗斯福提议的将战列巡洋舰改造为航母的方案得到美国海军的支持，并在组建了海军航空局的莫菲特将军的影响下，挽救了这两艘战列巡洋舰。由于列克星敦级不在规定废弃名单中，在条约许可新建2艘不超过33,000吨航母的情况下（在条约失效前，美国一直都没有用足条约限定的航母总吨位），建造进度最快的Lexington（已完成33.8%<sup><span id="a5"><a href="#fn5">[5]</a></span></sup>）和Saratoga（已完成35.4%）被改造为航空母舰，其他姊妹舰Constellaion、Consitution、Ranger、United States被迫取消并在船厂解体。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/7/76/USS_Lexington_%28CV-2%29_on_building_ways%2C_1925.jpg"></p><p><strong><center>1925年，在船台上改建的Lexington航空母舰</center></strong></p><p>这是一个合理而且正确的决定，从计划开建CC-1到CC-6战巡的目的来看，改建成航母的Lexington和Saratoga（CV-3，”Sis Sara”）的定位并未改变，即与巡洋舰组成快速机动舰队，执行侦查和牵制敌军主力舰队的任务，（可能的话）利用舰载机实现先期打击，舰队决战仍然依赖于传统的战列舰。这两艘最初的航空母舰也为海军部的各类设想提供了实验的平台，随着航空技术的发展，航空母舰逐步具备赋予战巡的预想战术、战略执行能力，海军航空力量的战术价值不断被挖掘、提升，对战争的影响力远远超出预期。从事后诸葛亮的角度来看，尽管当时舰载航空兵存在各种限制和不足，但已经极大地改变了海战中侦查行动的进行方式，水上舰载机已经体现出高于传统侦查舰只的效率和效能，许多战列舰都配备了水上飞机观测炮弹落点协助校正。马上，舰载机更会展现出远超战列舰火力的强大杀伤力。</p><p>珍珠港事件后太平洋舰队的战列舰队元气大伤，幸存的几艘航空母舰在狂澜将至之时挺身而出与强大的IJN机动部队进行惨烈的对撞，支撑着美军渡过了战争初期的困难年代，并重夺西太平洋的制海权，不意间也改变了整个海战的模式。如果珍珠港事件后，面对IJN强大的一、二、五航战的是6艘战巡，其作用完全无法与2艘正规航母相比，更会因为在前期缺少航母战术的演习经验，无法以少胜多再现中途岛大捷，大大延长太平战争甚至整个二战的进程。美国在战巡上交了很少的学费，就马上踏入了正确的航母之道。</p><p><img src="http://i.ebayimg.com/images/i/351959917983-0-1/s-l1000.jpg" width="800px"></p><p><strong><center>正在舾装的Lexington</center></strong></p><blockquote><p>美国海军的战巡是不幸的，美国海军是幸运的。</p></blockquote><h2 id="3-设计：严谨优秀"><a href="#3-设计：严谨优秀" class="headerlink" title="3 设计：严谨优秀"></a>3 设计：严谨优秀</h2><p>USS Lexington在1921年作为战巡（CC-1）开建，次年《华盛顿海军条约》签订生效，Lexington于7月1日被下令改建为航空母舰（CV-2），原设计的4座双/三联装16英寸主炮、装甲、弹药库和533毫米鱼雷等被移除，为了符合条约要求排水量降低了8,500吨。Lexington防护装甲与巡洋舰相当，舰侧装甲被保留，而甲板装甲则被强化，其中主装甲带79～127毫米，机库甲板50毫米，机舱上部76～114毫米。龙骨的大体结构以及水下防护并未更改，保留了优美的流线型舰身，为了使战舰不易沉没，总计设有600多个单独水密隔舱。Lexington的飞行甲板长268米，宽26~27米，平均吃水7.3米，标准排水量36,000吨（条约允许增加3,000吨的防雷部，实际排水量49,000吨），满载排水量38,746吨（实际50,000吨）。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d1/USS_Lexington_%28CV-2%29_underway%2C_cicra_1928_%28NNAM.2001.205.067%29.jpg/800px-USS_Lexington_%28CV-2%29_underway%2C_cicra_1928_%28NNAM.2001.205.067%29.jpg"></p><p><strong><center>刚建成的Lexington，摄于1928年的</center></strong></p><p>为了在受限的吨位下达到海军部要求的航速，Lexington采用了油电混动，16台巴布科克威尔考克斯式重油专烧锅炉推动4台先进的电动涡轮发电机，每台发电机每小时发电33,200千瓦，发电机组联接8台电机用电力驱动4个螺旋桨转动，每个螺旋桨大轴能得到45,000马力，总体输出功率达到了令人咋舌的18万马力（辽宁号的动力是20万马力，但是满载排水量有6万吨），是同时代战列舰产生动力的6倍，这套GE制造的先进动力系统虽然比同等的齿轮推进装置更大、更重也更贵，但是其带来的澎湃动力使设计航速高达33.25节（约合61.58公里/小时，对比赤城是31节，加贺是29节，辽宁号是29节），轻微过载可以输出20万9千马力，供Lexington以34.5节的速度连续航行一小时，大大超出了设计任务书的要求。有意思的是在1929年12月17日至1930年1月16日，应当地政府要求，Lexington停靠华盛顿州塔科马市，为该市21万居民提供了一个月电力，超过450万千瓦时，缓解因干旱原因造成的水电匮乏危机，可见其动力输出的强劲。Saratoga也曾在一次紧急情况中提供了超过400万千瓦时的电量。</p><p><img src="http://www.researcheratlarge.com/Ships/CV2/Tacoma/CV-2_01.jpg" width="800px"></p><p><strong><center>停靠在塔科马期间为市民提供电力的Lexington</center></strong></p><p>列克星敦级最引人注目的特征就是其右舷巨大的岛式结构建筑，包括控制室、烟囱和炮塔。经过气流测试，利用高大的烟囱排放16个锅炉产生的废气，就不会影响飞机的起降，该设计被后续所有常规动力航母所采用。早期舰载机无法在夜间和恶劣天气情况下在航母上起降，因此在初期列克星敦级装备有4座双联装8英寸/55 Mk9主炮（203毫米，条约允许的最大口径，真正的载机巡洋舰，知道毛子和谁学的吧），岛式建筑的前方和后方各两座，呈背负式布置，主炮射程达2.8万码（25,592米），火力堪比重巡。这是早期航母在没有明确建造目标和战术理论支撑下必然的过度产物，IJN的赤城号也有同样的设计。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/65/USS_Lexington_%28CV-2%29_firing_203mm_guns_1928.jpg/800px-USS_Lexington_%28CV-2%29_firing_203mm_guns_1928.jpg"></p><p><strong><center>Lexington后部203毫米主炮开火</center></strong></p><p>Lexington还装备有12座单装5英寸高炮，和少数机枪。1942年3月，Lexington在改装中移除了这8门8英寸火炮，因为它们开火时产生的炮口风暴会严重影响起飞作业甚至损坏飞行甲板，移除的位置安装7座4联装1.1英寸高炮（包括之前改装的共计12座），另外又增加了22座厄利空22毫米机关炮。Lexington亦是美军首批装上CXAM-1型防空雷达的战舰。</p><p><img src="http://www.modelwarships.com/reviews/books-plans/warship-pictorial/wp-33/lexington-06.jpg" width="800px"></p><p><strong><center>战沉前的Lexington主要武备</center></strong></p><p>由于采用了封闭式舰艏和单层机库，Lexington设计载机量只有78，最初配备了83架飞机：36架战斗机共2个中队，32架攻击机共2个中队，加上3架备机（或多用途飞机）。1925年，海军的第一位航空将军约瑟夫·里弗斯少将<sup><span id="a6"><a href="#fn6">[6]</a></span></sup>对他所指挥的两艘列克星敦级航母的载机量非常不满意，提出了载机量至上论和航母分工论，到1929年，这两艘航母通过甲板系留的方式塞进去120架飞机。二战前美国设计建造的航母除了列克星敦级以外全部采用开放式舰艏就是为了增加机库的面积。在搭载飞机的数量和飞机起降周期的速度方面，美国航母都要优于其他各国，里弗斯将军的不懈努力为美国航母具备的非凡能力奠定了坚实的基础。1931年，里弗斯离开海军航空部队并在两年后晋升为海军上将，1936年又成为美国海军总司令。</p><p><img src="https://www.haborumuveszete.hu/file/news/52070/gallery/big/sdb-dauntless-zuhanobombazok-a-lexington-hangarjanak-mennyezete-ala-fuggesztve.jpg" width="800px"></p><p><strong><center>Lexington内部高大的机库上方悬挂SBD无畏俯冲轰炸机</center></strong></p><p>Lexington编制人员（包括飞行员）为：平时2,122人，战时2,951人。美国航空母舰一般配备一个标准舰载航空队，Lexington的航空队包括4个飞行中队，中队编号与舰号保持一致，分别为VF-2、VB-2、VT-2和VS-2。VF-2是战斗机中队，早期使用过双翼的格鲁曼F2F和布鲁斯特F2A水牛，1941年后全部换装为格鲁曼F4F野猫战斗机，中队一般配机18～22架。VB-2是轰炸机中队，VS-2是侦查轰炸机中队，各配备道格拉斯SBD-2/3无畏式俯冲轰炸机18架，由于轰炸机载重量大航程远，因此可以兼做侦查机用，必要时也可以挂弹执行攻击任务。VT-3是鱼雷机中队，配有道格拉斯TBD-1蹂躏者鱼雷机12架。舰载机和飞行中队的配置在实际中经常变化，尤其是作为早期海航战术探索先锋的Lexington和Saratoga。<sup><span id="a7"><a href="#fn7">[7]</a></span></sup></p><p><img src="http://warfarehistorynetwork.com/wp-content/uploads/WQ-Lexington-Fall-1611.jpg" width="800px"></p><p><strong><center>Lexington上的F4F野猫战斗机，从机身编号看应该是隶属于Saratoga的VF-3中队</center></strong></p><p>Lexington由于建造时间较早没有普及空调，但是备有现代化的面包房，和面机和制饼机都是电动的，每个部门有单独的咖啡供应（这些咖啡壶被戏称为第十七号锅炉）。舰艏水线位置设有现代化的医院，设备齐全，能够在十分钟内接受500名伤员。另外还设有图书馆、服务社（小卖部），满足士兵的日常需要。这座巨大的移动仓库还负责为舰队的其他小型护航船只提供补给，从油料到松香一应俱全。<sup><span id="a8"><a href="#fn8">[8]</a></span></sup></p><p>Lexington最大的不足在续航，续航力仅为10,000海里/10节，高速行驶下能够很快就耗完储备油料。由于右舷集中了烟囱舰桥等上层建筑，因此航空汽油舱、燃油舱和淡水舱都设计在左舷，用以抵消超重的右舷使军舰保持平衡，这也为之后左舷中雷后燃气泄漏埋下隐患。</p><p>相对早期的IJN和RN，总体上列克星敦级航空母舰的设计是优秀的，这缘于其基于战巡平台的巨大尺寸和防护能力，以及美国对航空母舰的认识更先进更到位，因此该级战舰在20年后太平洋战争一爆发，仅进行较少改装就能马上投入战斗成为舰队的中坚力量，传奇的“Sis Sara”更是打满太平洋全场（虽然大部分时候都在修理厂）。</p><h2 id="4-入役：海航先驱"><a href="#4-入役：海航先驱" class="headerlink" title="4 入役：海航先驱"></a>4 入役：海航先驱</h2><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/USS_Langley_%28CV-1%29%2C_USS_Lexington_%28CV-2%29_and_USS_Saratoga_%28CV-3%29_at_the_Puget_Sound_Naval_Shipyard%2C_in_1929_%28NNAM.1996.488.001.004%29.jpg/800px-USS_Langley_%28CV-1%29%2C_USS_Lexington_%28CV-2%29_and_USS_Saratoga_%28CV-3%29_at_the_Puget_Sound_Naval_Shipyard%2C_in_1929_%28NNAM.1996.488.001.004%29.jpg"></p><p><strong><center>1929年停泊在普吉特湾的Langley CV-1（下）、Lexington CV-2（上）和Saratoga CV-3（中）</center></strong></p><p>1928年4月7日，试航完成的Lexington在加州圣佩德罗被编入作战部队，并与姊妹舰Saratoga活跃在美国海军之中，参与的各项演习为美军提供了至关重要的航母使用经验，自列克星敦级服役后几乎历届“舰队问题”演习都有该级战舰的身影，例如著名的1929年第9次“舰队问题”演习。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/USS_Lexington_%28CV-2%29_steams_trough_smoke_screen%2C_February_1929.jpg/800px-USS_Lexington_%28CV-2%29_steams_trough_smoke_screen%2C_February_1929.jpg"></p><p><strong><center>摄于1929年的舰问九后不久的Lexington</center></strong></p><p>与1925年编入舰队的实验性航母Langley（CV-1）不同，Lexington和Saratoga的高航速使其完全具备了与主力舰队联合作战的能力。在第9次“舰队问题”演习中，扮演黑方的Saratoga与一条轻巡（USS Omaha）在里弗斯将军的带领下脱离主力从敌人意想不到的方向发动攻击，突袭编队在途中偶遇敌方轻巡（USS Detroit）并用8英寸火炮将其“击沉”，随后连夜向巴拿马运河挺进。次日Saratoga从距离运河大约140英里的位置一次性放出83架飞机，进攻的飞机未受任何阻挠，成功“摧毁”了连接太平洋的巴拿马运河的河道和机场，取得大胜。随后防守方的Lexington成功定位到放空飞机的Saratoga并对其发动进攻，Saratoga被判“击沉”。此次演习中由于防守方的岸基飞机误将Lexington当作Saratoga攻击，之后Saratoga的烟囱上刷上黑色条纹以示区别，这是区分两舰最简单的方式。</p><p>更多有航空母舰参加的演习接踵而至，其中包括1930年在加勒比海域进行的两次：在3月的第10次舰问演习中，Lexington的舰载飞机“摧毁”了对手Saratoga和Langley及其所有舰载机，并在短时间内“摧毁”了几艘战列舰；随后一个月的第11次舰问演习，Saratoga对姐姐施以同样的回报。这两次演习表明空中打击对海上力量的削弱速度是如此惊人，演习结束后，军方决定把大型航空母舰的侦察机数量增加到18架。</p><p>具有讽刺意味的是，在1932年2月7日的第4次联合大演习中，Lexington与Saratoga的舰载机群成功攻击并毁坏了被假定为目标的夏威夷珍珠港，而据说陆军的人员在被攻击之后向演习裁判组申诉，怀疑在星期天清晨发动攻击的合法性。随后的第13次舰问演习两舰再次被分开进行对抗，Lexington再次“重创”Saratoga，并“击沉”了两艘敌方的主力舰。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/USS_Saratoga_%28CV-3%29_and_USS_Lexington_%28CV-2%29_off_Diamond_Head_on_2_February_1933.jpg/800px-USS_Saratoga_%28CV-3%29_and_USS_Lexington_%28CV-2%29_off_Diamond_Head_on_2_February_1933.jpg"></p><p><strong><center>1933年2月2日，Lexington（后）和Saratoga</center></strong></p><p>1933年1月末，在第14次舰问演习前，海军和陆军联合模拟了一次航母攻击，Lexington和Saratoga再次成功“袭击”了珍珠港。值得一提的是1935年4到6月的第16次舰问演习，Lexington在经历了5天的高速航行后进行了海上补给，这在之后太平洋战争中被证明是非常重要的战术行动。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/USS_Ranger_%28CV-4%29%2C_USS_Lexington_%28CV-2%29_and_USS_Saratoga_%28CV-3%29_at_anchor_off_Honolulu_on_8_April_1938_%2880-G-410056%29.jpg/800px-USS_Ranger_%28CV-4%29%2C_USS_Lexington_%28CV-2%29_and_USS_Saratoga_%28CV-3%29_at_anchor_off_Honolulu_on_8_April_1938_%2880-G-410056%29.jpg"></p><p><strong><center>1938年火奴鲁鲁锚地的Lexington（中）、Saratoga（后）和Ranger CV-4（前）</center></strong></p><p>1937年的第18次舰问演习中，海军限制战列舰对Lexington的支援，结果显而易见，不受保护的航母无法独立面对水面舰只的火炮和鱼雷攻击。1938年的舰问再次测试了夏威夷港的防御，但是Lexington和她的妹妹不仅成功“袭击”了基地和路上设施，之后在未被发现的情况下“袭击”了三藩市。当时，美国海军舰队部署在加利福尼亚海岸，而珍珠港基地由美国陆军负责防御，海军领导几乎从未提及舰队在停泊时容易遭受攻击的弱点（也就是海军没有当回事）。1940年在第20次舰问演习中，虽然被Yorktown CV-5“破坏”了飞行甲板，Lexington仍成功“瘫痪”了前者。</p><p>经过这十多次的舰队问题演习，USN逐步确定了航母的战术使用原则：采用单航母加护卫舰的特混舰队模式，远离庞大的主力舰队独立执行攻击任务，多艘航母在战术层面上亦分开行动并保持距离，以免被敌人集中发现和摧毁。为了让单艘航母在一个攻击波中放出尽可能多的攻击机，全面采用甲板系留和全甲板攻击战术。这套模式在战争中被证明是行之有效的，但受通讯技术限制，在组织多航母协同攻击时只能做到同时，无法有效协调，面对集中使用航母的IJN的巨波攻击时显得无力。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/USSLexingtonCV2Launching.jpg/800px-USSLexingtonCV2Launching.jpg"></p><p><strong><center>“全甲板攻击！”</center></strong></p><p>Lady Lex和Sis Sara服役后参加的演习，不仅使USN逐渐发展并完善了一整套航空母舰的作战战术，充分展示了空中攻击部队的潜力，而且对之后所有海军舰只和战术的设计都有深远的影响，从这两艘战舰的飞行甲板上产生了自从军舰开始采用装甲和蒸汽依赖海战史上最大的飞跃。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Aerial_view_of_Ford_Island%2C_Pearl_Harbor%2C_on_10_November_1941_%2880-G-279385%29.jpg/760px-Aerial_view_of_Ford_Island%2C_Pearl_Harbor%2C_on_10_November_1941_%2880-G-279385%29.jpg"></p><p><strong><center>太平洋战争爆发前的珍珠港福特岛，北边是著名的战列舰大道，航母的锚地在岛的南边</center></strong></p><iframe src="//player.bilibili.com/player.html?aid=17202873&cid=28114922&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe><h2 id="5-二战：临危受命"><a href="#5-二战：临危受命" class="headerlink" title="5 二战：临危受命"></a>5 二战：临危受命</h2><p>第二次世界大战在太平洋正式爆发是1941年12月7日星期日凌晨，350余架飞机从IJN的6艘航空母舰上起飞，对停泊在珍珠港内的USN太平洋舰队以及瓦胡岛上的机场发动了突然袭击。美军太平洋舰队的战列舰4艘沉没，4艘被击伤，主力几乎全军覆没，能够供新上任的尼米兹司令调用的就剩下三艘航母（分别是Lexingtong、Saratoga、Enterprise CV-6）、二十几条潜艇和一众护卫舰，要面对的是拥有10艘航母、10艘战列舰、18艘重巡、100艘驱逐舰、64艘潜艇的新兴的强大IJN。因为战列舰不是在水下就是在修理厂，1941年12月31日，接任太平洋舰队司令的海军上将尼米兹在一艘排水量不足1500吨的潜艇“鳟鱼号”（USS Grayling SS-209）的甲板上举行就职仪式并升起了将旗，拉开了太平洋战场上美国的反击序幕。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/2/2c/Nimitz_on_Grayling%3B0820904.jpg" width="800px"></p><p><strong><center>1941年12月31日，尼米兹将军在鳟鱼号甲板上接任太平洋海军司令一职</center></strong></p><p>当12月7日珍珠港事件发生时，幸运的Lexington（及其它两艘航母）所在的第12特混舰队正在执行支援中途岛的任务（运载飞机），她随即派出侦察机搜索进攻的日军，未果，之后同USS Enterprise CV-6开赴瓦胡岛西南守备，直到12月13日才返回珍珠港。</p><p>次日美军计划派Lexington和Enterprise突袭加鲁伊特环礁，减轻威克岛的防守压力，但是23日威克岛宣告陷落，行至半途的两艘航母于27日无功而返。</p><p>1942年1月，Lexington在威尔逊·布朗中将的指挥下带着护卫的巡洋舰和驱逐舰从珍珠港出发再次进攻威克岛，不过1月23日凌晨舰队的加油船Neches（AO-5）被IJN潜艇（伊-72）击沉无法补充燃料，攻打威克岛的计划被迫取消。</p><h3 id="首战布干维尔"><a href="#首战布干维尔" class="headerlink" title="首战布干维尔"></a>首战布干维尔</h3><p>1942年2月20日，以Lexington为旗舰的第11特混舰队深入到离刚被日军占领的澳属新几内亚首府腊包尔400海里之内，准备前往布干维尔岛并在次日从那里发动突袭，攻击港口内的日军舰只。是日，虽然Lexington上的VF-3战斗机中队（VF-3原隶属于Saratoga，因母舰大修而搭载在CV-2上）指挥官约翰·萨奇，也就是发明萨奇剪战术的那位，成功击落了日军的侦察机九七式大艇，但是下午3点42分，Lexington最终被日军发现，收到情报的井上成美派遣第24航空队的18架一式陆攻在没有战斗机护航的情况下分两批起飞攻击美军舰队，在F4F-3野猫战斗机和防空火炮的拦截下损失了17架，Lexington仅受到一枚近失弹的影响。VF-3中队的爱德华·奥海尔中尉一次出击击落5架敌机，成为单次战斗王牌，封号“屠夫”，获得了国会荣誉勋章并连晋两级，美国海军航空兵的野猫崭露头角，自此一路再未缺席太平洋的航母作战。<sup><span id="a9"><a href="#fn9">[9]</a></span></sup></p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/80/Grumman_F4F-3_Wildcats_of_VF-3_in_flight_off_Oahu_on_10_April_1942_%2880-G-10613%29.jpg/800px-Grumman_F4F-3_Wildcats_of_VF-3_in_flight_off_Oahu_on_10_April_1942_%2880-G-10613%29.jpg"></p><p><strong><center>萨奇(F1)和奥海尔(F13)的座机格鲁曼F4F-3A野猫战斗机，1942年4月10日于瓦胡岛上空</center></strong></p><p>是役表明，对航空母舰或任何其他舰只来说，唯一真正的防空武器是飞机，而没有战斗机护航的攻击机群亦如同鱼腩，另外美国战斗机飞行员也发现了日本飞机（说的就是你零式）皮薄馅大的弱点。</p><p>因为攻击腊包尔的行动失去了突然性，第11特混舰队迅速撤离。</p><h3 id="空袭莱城和萨拉马瓦"><a href="#空袭莱城和萨拉马瓦" class="headerlink" title="空袭莱城和萨拉马瓦"></a>空袭莱城和萨拉马瓦</h3><p>Lexington在珊瑚海巡航至3月6日后，与USS Yorktown CV-5汇合并执行另一项攻击计划。两舰在3月10日进入巴布亚湾，放出所有舰载机分别向莱城和萨拉马瓦两个港口攻击，这次突袭出乎日军的意料，但是大部分日舰得以逃脱，美军仅击沉了1艘大型扫雷艇、1艘货船和1艘轻巡，自身几乎没有损失。战斗结束后Lexington与Yorktown分开独自返航，于3月26日抵达珍珠港时她已经破纪录地在海里连续待了54天。在珍珠港的海军工厂里，Lexington稍作修理，并移除了舰上的8英寸火炮，换装为大量4联装1.1英寸防空炮，并与4月15日再度出击，执行最后一次作战任务。</p><h3 id="珊瑚海海战"><a href="#珊瑚海海战" class="headerlink" title="珊瑚海海战"></a>珊瑚海海战</h3><p>早在1942年1月，日军就计划了名为MO的作战计划，主要目的是占领新几内亚的莫尔兹比港（Port Moresby），若日军占领该港口，就能够控制美国与澳大利亚之间的运输线，并且以此建立空军基地有效防御盟国的空袭。日军制定了详细的作战计划，组织了5支独立的特遣队，包括2艘大型航空母舰（五航战的翔鹤和瑞鹤），1艘轻型航空母舰（祥凤）、1艘水上飞机母舰以及6艘重巡、3艘轻巡、15艘驱逐舰，加上大量的运输舰、辅助舰只共70艘。</p><p>美军从4月初开始就破译了MO行动的常规代码，知道了日军的行动细节，尼米兹正确判断出日军的主攻目标，决定派出Lexington和Yorktown迎战。Saratoga因雷击受损正在大修，Enterprise CV-6和Hornet CV-8刚刚结束杜立特空袭在返回珍珠港的路上（为了装载B-25轰炸机，Hornet没有搭载其他战机，需要Enterprise提供护航），剩下的战舰都在旧金山且最高时速才21节，无法与航母一起作战，因此这是他唯二能派出的主力战舰。</p><p><img src="https://ob7zbqpa6.qnssl.com/255qqncy1gl9kjw04r76a6qdp4w67625.jpg" width="800px"></p><p><strong><center>珊瑚海海战地图，可以看出莫尔兹比港的战略重要性</center></strong></p><p>5月1日，从珍珠港赶来的Lexington与弗兰克·弗莱彻少将指挥的第17特混舰队在西珊瑚海汇合，整个舰队包括Yorktwon、6艘重巡和12艘驱逐舰，人类历史上首次航母间的对战在珊瑚海打响，大舰巨炮时代宣告落幕，蓝星的海军战争从此拉开了新的篇章。</p><p>5月4日，得知日军已经登录图拉吉的弗莱彻带领补给完毕的Yorktown及其护卫舰先行攻打图拉吉，港内大部分舰只已出发进攻莫尔兹比港，因此仅击沉了睦月级驱逐舰菊月号（其残骸现在仍然在那里，这可能也是目前依然存留在水面上并且没被解体的唯一的二战期间的IJN军舰），炸伤夕月号和补给舰，未影响日军的进攻计划。</p><p><img src="http://www.ibiblio.org/hyperwar/OnlineLibrary/photos/images/h76000/h76560.jpg" width="800px"></p><p><strong><center>1942年5月，珊瑚海海战期间的Lexington，8英寸火炮已被拆除</center></strong></p><p>5日早上，Lexington加满油后与Yorktown再次会合，当日晚上五航战的两艘航母进入珊瑚海，一直到6日两军相距仅70英里，但是都不知道对方的确切位置，也都没有派出侦察机，只依靠地面基地的空中侦察。6日晚上，燃油补给船尼奥肖号（USS Neosho AO-23）和驱逐舰西姆斯号（USS Sims DD-409）受命脱离舰队。</p><p>7日一大早，日军开始派出大量侦察机和水上飞机搜查盟国战舰，这次发现了脱离主舰队的尼奥肖号和西姆斯号。日军侦查员误判为航空母舰和巡洋舰，翔鹤和瑞鹤立即派出78架飞机袭击并击沉击西姆斯号，击伤尼奥肖号。Lexington前一天刚刚接受了尼奥肖号的补给，空空的油舱使尼奥肖号能够勉强浮在水面，直到4天后被前来救援的驱逐舰处分击沉。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/4/47/Shoho_g17026.jpg" width="800px"></p><p><strong><center>美军攻击祥风号轻型航空母舰</center></strong></p><p>几乎在同时Yorktown的远程侦察机报告在180海里外发现了一支IJN的航母编队，Lexington与Yorktown放出93架的攻击机队，虽然没有发现日军翔鹤、瑞鹤两艘航空母舰，却发现了掩护入侵部队的日军轻型航母祥凤，面对如此强大的攻击机群，祥凤号在几分钟内就被击沉。</p><p>日军于当日下午4点30分，再次派出12架俯冲轰炸机和15架雷击机搜寻，飞机在油料消耗过半时不得不扔弃炸弹鱼雷，归航中遇上了17特混舰队的战斗机，随即展开空战。混战中几架日机误将Yorktown当作母舰降落，直到领机被高炮攻击才仓皇转向，这批飞机最终损失了20架。整个夜间暴雨磅礴，护卫舰的炮手通宵执勤，飞行大队长们连夜制定作战计划，双方很清楚第二天早晨将面临严峻的时刻。</p><p>8日，在破晓的朝阳中，双方侦察机几乎同时发现了对方的航母编队，然后均倾其所有派出了全部舰载攻击机，两支机群浩浩荡荡擦肩而过，并未发现对方，美日两军的舰载机都在未被拦截的情况下扑向了对方。</p><p>Lexington的侦察机在8:30首先发现目标，10点57分美军开始进攻，由于瑞鹤号躲入热带暴风雨，翔鹤号成为众矢之的，被直接命中三枚炸弹，飞行甲板被严重破坏，无法起降飞机，实际上已经丧失作战机能。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/BattleCoralSea_Shokaku_g17031.jpg/800px-BattleCoralSea_Shokaku_g17031.jpg"></p><p><strong><center>被命中甲板和舰体的翔鹤，不得不缺席随后的中途岛海战</center></strong></p><p>几乎在美军攻击翔鹤的同时，Lexington的雷达发现了来袭的日军飞机。在近乎完美的能见度中，47架攻击机集中突入防守圈攻击两艘美国航母，Lexington吨位大目标明显，首先被2枚鱼雷、2枚炸弹直接命中，舰体左倾7度，3个锅炉房进水，甲板下起火，升降机运行受阻。不过在损管部门的努力下很快控制住火势，纠正了倾斜，并修复了动力系统，Lexington依然可以以25节航速航行，收纳了部分返航的战机，飞行员甚至都没注意到母舰已经受伤。日机的攻击迫使Yorktown驶离Lexington（这是该战中美军的一大失误），但是她运气稍好，躲过了所有的鱼雷攻击，仅被命中一颗250公斤炸弹和多枚近失弹，造成甲板和多处船体受损，但也没有影响飞机的起落。截至目前，弗莱彻比原忠一的处境要好得多。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/USS_Lexington_%28CV-2%29_under_air_attack_during_the_Battle_of_the_Coral_Sea%2C_8_May_1942_%28NH_95579%29.jpg/800px-USS_Lexington_%28CV-2%29_under_air_attack_during_the_Battle_of_the_Coral_Sea%2C_8_May_1942_%28NH_95579%29.jpg"></p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/24/Confirmed_hits_on_USS_Lexington_%28CV-2%29_during_the_Battle_of_the_Coral_Sea%2C_8_May_1942.png/800px-Confirmed_hits_on_USS_Lexington_%28CV-2%29_during_the_Battle_of_the_Coral_Sea%2C_8_May_1942.png"></p><p><strong><center>珊瑚海海战中，Lexington身中两枚鱼雷和两枚炸弹</center></strong></p><p>12点47分，Lexington连续发生的大爆炸扭转了这个优势，燃料管道在鱼雷袭击中受损泄漏，由于美军损管缺乏经验，没有及时抽走舰内的航空汽油，导致内部充满了易燃易爆气体，这些气体被发电机点燃，连续的爆炸损毁了电话线路，炸坏了总水管，火焰窜到了船的上层，浓烟从所有缝隙中涌出舰体，笼罩了整个Lexington。下午14点45分，另一串大爆炸瘫痪了发动机舱的通风系统，16时左右锅炉停止了供油，Lexington 4个巨大的青铜螺旋桨永远停止了转动。由于火势蔓延到了弹药库，炸弹和鱼雷随时可能发生殉爆，无奈之下，谢尔曼舰长于17时下令弃舰，2,735名官兵有序撤离，三艘驱逐舰受命靠近救援舰员。18:30，Lexington又发生了一连串可怕的爆炸，碎片、飞机、钢板、木板、大大小小的破片夹杂在白色的浓烟烈火中，冲上天空，飞行甲板完全被撕开，烈火足有一、二百米高，在茫茫夜色中这艘大舰地每一处轮廓和残骸都看得起一清二楚。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Crew_abandons_USS_Lexington_%28CV-2%29_on_8_May_1942_%28NNAM.2001.205.069%29.jpg/800px-Crew_abandons_USS_Lexington_%28CV-2%29_on_8_May_1942_%28NNAM.2001.205.069%29.jpg"></p><p><strong><center>船员从Lexington上撤离</center></strong></p><p>18时53分，弗莱彻下令放弃Lexington并撤出战区，菲尔普斯号（USS Phelps DD-360）对她发射了5发鱼雷，在最后一发命中后，当晚19时56分，Lexington带着阵亡的216位船员和36架战机逐渐消失在海面下，沉没在了珊瑚海的波涛之中。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/USS_Lexington_%28CV-2%29_burning_and_sinking_on_8_May_1942_%28NH_51382%29.jpg/750px-USS_Lexington_%28CV-2%29_burning_and_sinking_on_8_May_1942_%28NH_51382%29.jpg" width="800px"><br><strong><center>Lexington的最后时刻</center></strong></p><iframe src="//player.bilibili.com/player.html?aid=6717600&cid=10937774&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe><blockquote><p>她沉没的时候没有倒下</p><p>她是昂着头沉没的</p><p>她挺到了最后</p></blockquote><p>5月8日尼米兹下令弗莱彻撤退时，Yorktown上还有大概50架飞机可以作战。同日翔鹤号已经撤往特鲁克并准备返回日本检修，瑞鹤号受命在8日、9日午夜攻击剩余敌舰，但是没有再遇到Yorktown舰队，10日，高木接令也撤出战区。珊瑚海海战宣告落幕。</p><p>本次大战战术上IJN小胜，损失了11,200吨的祥凤，32,100吨的翔鹤受创，而USN损失了41,000吨的正规航母Lexington，25,000吨的Yorktown受创。但这是开战以来日军首次在太平洋战场上受挫，美军阻止了IJN从水路进攻莫尔兹比港的行动，保留下来了这一重要港口，守住了澳大利亚也缓解了瓜岛局势。并且此战中正规空母翔鹤受损需修理6个月、瑞鹤舰载机损失惨重飞行队伍需要重编，都无法参与一个月之后的中途岛海战，给日军造成了致命的打击。可以说没有珊瑚海海战对两艘IJN正规空母的牵制，仅靠3艘航母(CV-5/6/8)的USN面对6艘航母(两鹤/双龙/赤城加贺)的IJN，即使考虑到IJN所犯下的种种错误，这悬殊兵力下两军能在中途岛打出什么结果还是非常难说的。</p><p>提到二战时候的USN，首先会想到美国本身强大的工业实力，其次是近乎变态的损管能力，但USN也绝非先知，他们重视管损的原因就来自于在此次海战中沉没的Lexington(CV-2)。航母本质是移动机场，一旦飞行甲板/升降机被破坏，无法起降飞机，在本次作战中的战斗能力基本消失，另外，由于航母装载大量航空汽油，在泄漏后汽油容易挥发，极易殉爆，管道损坏这样的小伤很容易变成大伤，如果无法尽快修复损伤，飞机和飞行员除非被其他航母收容，不然处境会异常艰难。USN损失了一艘珍贵的Lexington换来需要重视损害控制、保护航空汽油以及重视侦查这三个道理，在后续的舰船设计上注重对燃油的防护、加强损管设施、内部结构采用耐火材料，通过增加侦察机和大力发展对控雷达提升侦查能力，降低了美国航母的战损率，牢牢控制着战场的主动权。日本海军的大凤和信浓这两艘优秀的航母的沉没和低下的管损能力密切相关。</p><p>另外，据战后分析，在珊瑚海海战中IJN损失飞机77架，1,047人伤亡，美军损失飞机66架（包括随Lexington沉没的36架），543人伤亡。在得到了如何使用鱼雷轰炸机和俯冲轰炸机经验的同时，美军也认识到舰载机损耗较高，“载机量至上论”突显出其正确性和重要性，此后，USN坚持采用机库悬吊加甲板系留的方式装上更多的飞机，使航母能够在更长的作战周期内维持相当的战力。对于被击落的机组成员美军都会派遣潜艇或驱逐舰全力施救，同时加紧本土飞行员的训练，在中途岛海战中萨奇剪战术成功应用并大面积推广，使得机动性能相对落后（但是防御和火力并不落后）的F4F在编队实战中能有效对抗零式战机，在性能更好的F6F等服役前已经掌握了太平洋上的制空权。反观IJN，发动技术始终落后，战机的设计不考虑对飞行员和关键部位的装甲防护，加上不成功便成仁的武士道精神，使得海航精锐丧失殆尽得不到补充，此消彼长之下，到大风信浓下水之时，竟再也找不到足够的战机和飞行员形成有效战力了，“马里亚纳火鸡”名副其实。</p><p>珊瑚海海战在战史上仅是中途岛海战的一次前哨战，但其意义远比这要大得多，这是军事史上首次航母之间的对战，也是首次视距外完全由舰载机完成战斗的海战，颠覆了很多海战常识，奠定了以航母为核心、以空制海的现代海战模式。</p><h2 id="6-影响：精神永存"><a href="#6-影响：精神永存" class="headerlink" title="6 影响：精神永存"></a>6 影响：精神永存</h2><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Aft_view_of_USS_Lexington_%28CV-2%29_c1939.jpg/800px-Aft_view_of_USS_Lexington_%28CV-2%29_c1939.jpg"></p><p><strong><center>后方视角的Lexington，摄于1939年</center></strong></p><p>从服役到沉没，Lexington一共航行了34,500海里，相当于绕地球航行14圈，她的飞行甲板上共进行了57,700次起落。Lexington一共有9任舰长，每位都至少晋升到少将衔，其中包括官至第五舰队司令的最后一任舰长弗雷德里克·C·谢尔曼中将和升至美国海军司令的第三任舰长欧内斯特·金海军上将。</p><p>Lexington在战斗中共获得两次“战斗之星”。</p><p>USS Lexington CV-2是历史上第4艘命名为列克星敦的美舰，这个名字对美国人来说具有特殊的情感。Lexington CV-2沉没后的同年6月16日，21年前建造她的伯利恒造船公司霍河造船厂主动联系军方，要求将厂内一艘被命名为卡伯特号的埃塞克斯级航空母舰改名为列克星敦号，用以纪念珊瑚海海战沉没的CV-2，获得同意。Lexington转生为CV-16后，因屡次被IJN宣称击沉获得了“Blue Ghost”外号，在莱特湾海战中亲手击沉瑞鹤成功完成复仇。CV-16战后进行现代化改造添加了斜角甲板，一直战到1991年成为最后一艘退役的该级航母。退役后的CV-16改建为博物馆静静地躺在美国科珀斯克里斯蒂的港口里，为前来瞻仰的她的人诉说当年的传奇。据说某人在延安窑洞的办公室墙上也挂着列克星敦的海报，又传建国后中美蜜月期甚至有可能引进饺子级列克星敦CV-16，不然中国第一艘航母舷号是16并且命名是L开头也太巧合了。</p><p><img src="https://nebula.wsimg.com/439004a898cf0d3cb8114da1a80e6b4d?AccessKeyId=EBDE26851E0DB40AC219&disposition=0&alloworigin=1" width="800px"></p><div style="display:none"><br><img src="https://www.museumships.us/images/aircraft-carriers/Lexington/lexington.jpg" alt=""></div><p><strong><center>位于德州科珀斯克里斯蒂市的人气景点列克星敦博物馆</center></strong></p><iframe src="//player.bilibili.com/player.html?aid=12336077&cid=20320232&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe><p>2018年3月5日，微软联合创始人保罗.艾伦宣布，他的“海燕”（Petrel）团队前一日在距澳大利亚昆士兰州东海岸约800公里、海平面以下3,000米的珊瑚海海底，发现Lexington航母及其舰载机的残骸。艾伦团队发布的照片显示，保存完好的舰载机停在海床上，机翼和机身上美军的五角星标志依旧清晰。海燕号是当前唯一私人拥有的能够完成海下6,000米探险的科考船，2017年以来她陆续发现了武藏号、运送过核弹的印第安纳波利斯号重巡（CL-52）、朱诺号轻巡（就是那艘载有《拯救大兵雷恩》原型之一沙利文五兄弟的CL-52）、海伦娜（CL-50），以及在“最后的T字”苏里高海战中被击沉的大量日舰。在此之前的2015年保罗.艾伦的科研团队就与皇家海军合作成功打捞胡德号战巡（被蛐蛐猫一发入魂的皇家荣耀）的舰钟。</p><p><img src="https://www.paulallen.com/wp-content/uploads/Lexington-Plate.png" width="800px"></p><p><strong><center>沉没的Lexington的铭牌</center></strong></p><iframe src="//player.bilibili.com/player.html?aid=20430009&cid=33396887&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe><p>PS：影响太平洋战争最重要的三样武器分别是原子弹、雷达和VT引信弹，这三样正好对应攻击、侦查和防御三个方面，其中后两者都与海军航空兵有关，雷达帮助美军准确预测来袭的日机以逸待劳，后期更是帮助美舰打破IJN夜战之王的神话，而VT引信弹则葬送了大量优秀的IJN机师。</p><p>PPS：1931年间，科幻小说《星河战队》的作者罗伯特·海因莱因曾在USS Lexington CV-2上服役，这段海上生活很大程度上影响了他的写作。</p><h2 id="附：注解和参考资料"><a href="#附：注解和参考资料" class="headerlink" title="附：注解和参考资料"></a>附：注解和参考资料</h2><p><span id="fn1"><a href="#a1">[1]</a></span>: 兰利号（USS Langley CV-1）是由煤船改装的实验舰，只能算轻型航母，后面更是被改造为水上飞机母舰（AV-3）。</p><p><span id="fn2"><a href="#a2">[2]</a></span>: <a href="https://zhuanlan.zhihu.com/p/32505296" target="_blank" rel="noopener">《美利坚的战巡梦——“列克星敦”级战列巡洋舰设计史》</a></p><p><span id="fn3"><a href="#a3">[3]</a></span>: CC = Cruiser, Capital，表明其地位是主力舰。 </p><p><span id="fn4"><a href="#a4">[4]</a></span>: 美国是唯一一个没有战巡服役的海军强国。1940年代建造的阿拉斯加级归类是巡洋领舰（CB-1~CB-6），作战目的是猎杀超标严重的IJN重巡，和列克星敦级战巡的定位不一样，更接近德意志级袖珍战列舰。</p><p><span id="fn5"><a href="#a5">[5]</a></span>: 《航空母舰：1908～1945》（美）诺曼·波尔马</p><p><span id="fn6"><a href="#a6">[6]</a></span>: <a href="https://en.wikipedia.org/wiki/Joseph_M._Reeves" target="_blank" rel="noopener">Joseph.M.Reeves</a></p><p><span id="fn7"><a href="#a7">[7]</a></span>: <a href="http://www.wings-aviation.ch/22-USNavy-Carrier/Fleet-Carrier/CV-02-USS-Lexington.htm" target="_blank" rel="noopener">http://www.wings-aviation.ch/22-USNavy-Carrier/Fleet-Carrier/CV-02-USS-Lexington.htm</a></p><p><span id="fn8"><a href="#a8">[8]</a></span>: 《列克星敦号与珊瑚海海战》（美）斯坦利·约翰斯顿，该书作者是列克星敦号的随军记者，参与了珊瑚海海战</p><p><img src="https://img3.doubanio.com/view/subject/l/public/s4612281.jpg" alt="《列克星敦号与珊瑚海海战》"></p><p><span id="fn9"><a href="#a9">[9]</a></span>: <a href="https://zhuanlan.zhihu.com/p/27497637" target="_blank" rel="noopener">格鲁曼的小老虎们——野猫舰载战斗机简史</a></p><p><span id="fn10"><a href="#a10">[10]</a></span>: <a href="https://www.paulallen.com/uss-lexington-wreck-located-rv-petrel/" target="_blank" rel="noopener">Wreck of Aircraft Carrier USS Lexington Located in Coral Sea After 76 Years</a></p><p>维基百科：<a href="https://en.wikipedia.org/wiki/USS_Lexington_(CV-2" target="_blank" rel="noopener">USS Lexington CV-2 on wikipedia.org</a>)</p><p>更多照片：<a href="http://www.navsource.org/archives/02/02.htm" target="_blank" rel="noopener">USS Lexington CV-2 on navsource.org</a></p><p>参考书籍：</p><ul><li>《列克星敦号与珊瑚海海战》（美）斯坦利·约翰斯顿</li><li>《浩瀚大洋是赌场：细说日本海军史》俞天任</li><li>《1914-1945年的海上战争》（英）伯纳德·爱尔兰</li><li>《大海战》（美）切斯特·W·尼米兹</li><li>《Conway’s All the World’s Fighting Ships, 1922-1946》</li><li>《航空母舰：1908～1945》（美）诺曼·波尔马</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;The-Queen-of-the-Flattops-USS-Lexington-CV-2&quot;&gt;&lt;a href=&quot;#The-Queen-of-the-Flattops-USS-Lexington-CV-2&quot; class=&quot;headerlink&quot; title=&quot;The </summary>
      
    
    
    
    
    <category term="World War II" scheme="http://gloomymoon.github.io/tags/World-War-II/"/>
    
    <category term="Lexington" scheme="http://gloomymoon.github.io/tags/Lexington/"/>
    
    <category term="Aircraft Carrier" scheme="http://gloomymoon.github.io/tags/Aircraft-Carrier/"/>
    
    <category term="CV-2" scheme="http://gloomymoon.github.io/tags/CV-2/"/>
    
  </entry>
  
  <entry>
    <title>Build Your Own CodeCombat Server</title>
    <link href="http://gloomymoon.github.io/2018/12/05/Build-Your-Own-CodeCombat-Server/"/>
    <id>http://gloomymoon.github.io/2018/12/05/Build-Your-Own-CodeCombat-Server/</id>
    <published>2018-12-05T00:44:07.000Z</published>
    <updated>2018-12-05T01:40:05.144Z</updated>
    
    <content type="html"><![CDATA[<h1 id="搭建私人CodeCombat服务器"><a href="#搭建私人CodeCombat服务器" class="headerlink" title="搭建私人CodeCombat服务器"></a>搭建私人CodeCombat服务器</h1><p>著名的CodeCombat网站已经被网易收购，其GitHub上的代码已经变为非完全开源，虽然网易版本的大部分内容仍然可以免费使用，但是I’dont like it。</p><h2 id="获取docker"><a href="#获取docker" class="headerlink" title="获取docker"></a>获取docker</h2><p>利用好心人提供的docker镜像能够快速实现搭建自己的私服，这里推荐两个：</p><ul><li><a href="https://hub.docker.com/r/operepo/ope-codecombat/" target="_blank" rel="noopener">operepo/ope-codecombat</a></li></ul><p>直接在Docker Quickstart Terminal中执行：<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>docker pull operepo/ope-codecombat</span><br></pre></td></tr></table></figure></p><ul><li>链接：<a href="https://pan.baidu.com/s/1jJOBP7w" target="_blank" rel="noopener">https://pan.baidu.com/s/1jJOBP7w</a>  密码：<code>pwxu</code></li></ul><blockquote><p>来源：<a href="https://blog.csdn.net/qq775121173/article/details/79088018" target="_blank" rel="noopener">codecombat 搭建私服过程(基于docker)</a></p></blockquote><p>下载下来之后是一个<code>codecombat_v2.iso</code>文件，可以通过如下命令导入：<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>docker <span class="keyword">import</span> codecombat_v2.iso codecombat2</span><br></pre></td></tr></table></figure></p><p>后续命令是基于该docker的操作。</p><h2 id="创建容器"><a href="#创建容器" class="headerlink" title="创建容器"></a>创建容器</h2><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -itd --name codecombatTest -p <span class="number">0.0.0.0</span>:<span class="number">3000:3000</span> -p <span class="number">0.0.0.0</span>:<span class="number">35729:35729</span> codecombat2</span><br></pre></td></tr></table></figure><h2 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h2><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="literal">start</span> codecombatTest</span><br></pre></td></tr></table></figure><h2 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> docker <span class="built_in">exec</span> -it codecombatTest /bin/bash</span></span><br></pre></td></tr></table></figure><h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$<span class="built_in"> service </span>mongodb start</span><br><span class="line">$ su kunmanxuan</span><br><span class="line">$ cd /home/kunmanxuan/codecombat/codecombatSetupPackage/codecombat</span><br><span class="line">$ npm start</span><br></pre></td></tr></table></figure><p>当出现下述画面时服务启动成功：<br><img src="https://img-blog.csdnimg.cn/20181031174642329.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxNzc1MTIxMTcz,size_16,color_FFFFFF,t_70" alt=""></p><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><p>如果需要编译请执行：<br><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm <span class="keyword">run</span><span class="bash"> dev</span></span><br></pre></td></tr></table></figure></p><h2 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h2><p><code>http://localhost:3000</code></p><p>Let’s start to play!</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;搭建私人CodeCombat服务器&quot;&gt;&lt;a href=&quot;#搭建私人CodeCombat服务器&quot; class=&quot;headerlink&quot; title=&quot;搭建私人CodeCombat服务器&quot;&gt;&lt;/a&gt;搭建私人CodeCombat服务器&lt;/h1&gt;&lt;p&gt;著名的CodeCom</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="CodeCombat" scheme="http://gloomymoon.github.io/tags/CodeCombat/"/>
    
  </entry>
  
  <entry>
    <title>ECMAScript-6-Primer-IV</title>
    <link href="http://gloomymoon.github.io/2018/04/01/ECMAScript-6-Primer-IV/"/>
    <id>http://gloomymoon.github.io/2018/04/01/ECMAScript-6-Primer-IV/</id>
    <published>2018-04-01T04:15:35.000Z</published>
    <updated>2018-04-01T04:16:14.274Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ECMAScript-6-Primer-IV"><a href="#ECMAScript-6-Primer-IV" class="headerlink" title="ECMAScript 6 Primer IV"></a>ECMAScript 6 Primer IV</h1><h2 id="8-数组的扩展"><a href="#8-数组的扩展" class="headerlink" title="8 数组的扩展"></a>8 数组的扩展</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ECMAScript-6-Primer-IV&quot;&gt;&lt;a href=&quot;#ECMAScript-6-Primer-IV&quot; class=&quot;headerlink&quot; title=&quot;ECMAScript 6 Primer IV&quot;&gt;&lt;/a&gt;ECMAScript 6 Primer </summary>
      
    
    
    
    
    <category term="JavaScript" scheme="http://gloomymoon.github.io/tags/JavaScript/"/>
    
    <category term="ECMAScript" scheme="http://gloomymoon.github.io/tags/ECMAScript/"/>
    
  </entry>
  
  <entry>
    <title>ECMAScript-6-Primer-III</title>
    <link href="http://gloomymoon.github.io/2018/03/30/ECMAScript-6-Primer-III/"/>
    <id>http://gloomymoon.github.io/2018/03/30/ECMAScript-6-Primer-III/</id>
    <published>2018-03-30T05:43:21.000Z</published>
    <updated>2018-04-01T04:06:13.382Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ECMAScript-6-Primer-III"><a href="#ECMAScript-6-Primer-III" class="headerlink" title="ECMAScript 6 Primer III"></a>ECMAScript 6 Primer III</h1><h2 id="7-函数的扩展"><a href="#7-函数的扩展" class="headerlink" title="7 函数的扩展"></a>7 函数的扩展</h2><h3 id="7-1-函数参数的默认值"><a href="#7-1-函数参数的默认值" class="headerlink" title="7.1 函数参数的默认值"></a>7.1 函数参数的默认值</h3><p>ES6允许为函数的参数设置默认值，直接写在参数定义的后面，而不用采用变通的方式。<br><figure class="highlight scilab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">log</span><span class="params">(x, y = 'World')</span>&#123;</span></span><br><span class="line">  console.<span class="built_in">log</span>(x, y);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">log</span>(<span class="string">'Hello'</span>) <span class="comment">// Hello World</span></span><br><span class="line"><span class="built_in">log</span>(<span class="string">'Hello'</span>, <span class="string">'China'</span>) <span class="comment">// Hello China</span></span><br><span class="line"><span class="built_in">log</span>(<span class="string">'Hello'</span>, <span class="string">''</span>) <span class="comment">// Hello</span></span><br></pre></td></tr></table></figure></p><p>这是非常简洁自然的写法。由于参数变量是默认生命的，所以不能用<code>let</code>或<code>const</code>再次声明。使用参数默认值时，函数不能有同名参数。<br><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 不报错</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">foo</span><span class="params">(x, x, y)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 报错</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">foo</span><span class="params">(x, x, y = 1)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// SyntaxError: Duplicate parameter name not allowed in this context</span></span><br></pre></td></tr></table></figure></p><p><strong>与解构赋值默认值结合使用</strong><br>参数默认值可以与解构赋值的默认值结合起来使用。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">foo</span>(<span class="params">&#123;x, y = <span class="number">5</span>&#125; = &#123;&#125;</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(x, y);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">foo() <span class="comment">// undefined 5</span></span><br></pre></td></tr></table></figure></p><p><strong>参数默认值的位置</strong><br>通常情况下，定义了默认值的参数应该是函数的尾参数，如果非尾部的参数设置默认值，这个参数是没法省略的。<br><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 例一</span></span><br><span class="line"><span class="selector-tag">function</span> <span class="selector-tag">f</span>(x = <span class="number">1</span>, y) &#123;</span><br><span class="line">  <span class="selector-tag">return</span> <span class="selector-attr">[x, y]</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">f</span>() <span class="comment">// [1, undefined]</span></span><br><span class="line"><span class="selector-tag">f</span>(<span class="number">2</span>) <span class="comment">// [2, undefined])</span></span><br><span class="line"><span class="selector-tag">f</span>(, <span class="number">1</span>) <span class="comment">// 报错</span></span><br><span class="line"><span class="selector-tag">f</span>(undefined, <span class="number">1</span>) <span class="comment">// [1, 1]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 例二</span></span><br><span class="line"><span class="selector-tag">function</span> <span class="selector-tag">f</span>(x, y = <span class="number">5</span>, z) &#123;</span><br><span class="line">  <span class="selector-tag">return</span> <span class="selector-attr">[x, y, z]</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">f</span>() <span class="comment">// [undefined, 5, undefined]</span></span><br><span class="line"><span class="selector-tag">f</span>(<span class="number">1</span>) <span class="comment">// [1, 5, undefined]</span></span><br><span class="line"><span class="selector-tag">f</span>(<span class="number">1</span>, ,<span class="number">2</span>) <span class="comment">// 报错</span></span><br><span class="line"><span class="selector-tag">f</span>(<span class="number">1</span>, undefined, <span class="number">2</span>) <span class="comment">// [1, 5, 2]</span></span><br></pre></td></tr></table></figure></p><p>如果传入<code>undefined</code>，将触发该参数等于默认值，<code>null</code>则没有这个效果。</p><p><strong>函数的length属性</strong><br>制定了默认值后，函数的<code>length</code>属性，将失真，仅返回没有指定默认值的参数个数。</p><p>同理，后文的rest参数也不会计入<code>length</code>属性。如果设置了默认值的参数不是尾参数，那么<code>length</code>也不会计入后面的参数。<br><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(<span class="function"><span class="keyword">function</span> <span class="params">(a)</span> </span>&#123;&#125;).length <span class="comment">// 1</span></span><br><span class="line">(<span class="function"><span class="keyword">function</span> <span class="params">(a = 5)</span> </span>&#123;&#125;).length <span class="comment">// 0</span></span><br><span class="line">(<span class="function"><span class="keyword">function</span> <span class="params">(a, b, c = 5)</span> </span>&#123;&#125;).length <span class="comment">// 2</span></span><br><span class="line"></span><br><span class="line">(<span class="function"><span class="keyword">function</span><span class="params">(<span class="rest_arg">...args</span>)</span> </span>&#123;&#125;).length <span class="comment">// 0</span></span><br><span class="line"></span><br><span class="line">(<span class="function"><span class="keyword">function</span> <span class="params">(a = 0, b, c)</span> </span>&#123;&#125;).length <span class="comment">// 0</span></span><br><span class="line">(<span class="function"><span class="keyword">function</span> <span class="params">(a, b = 1, c)</span> </span>&#123;&#125;).length <span class="comment">// 1</span></span><br></pre></td></tr></table></figure></p><p><strong>作用域</strong><br>一旦设置了参数的默认值，函数进行声明初始化时，参数会形成一个单独的作用域，初始化结束后这个作用域会消失。这种语法行为，在不设置参数默认值时是不会出现的。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> x = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">x, y = x</span>) </span>&#123;  <span class="comment">//默认值变量x指向第一个参数x</span></span><br><span class="line">  <span class="built_in">console</span>.log(y);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">f(<span class="number">2</span>) <span class="comment">// 2 </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">y = x</span>) </span>&#123; <span class="comment">//变量x本身没有定义，所以指向外层的全局变量x</span></span><br><span class="line">  <span class="keyword">let</span> x = <span class="number">2</span>;</span><br><span class="line">  <span class="built_in">console</span>.log(y);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">f() <span class="comment">// 1</span></span><br></pre></td></tr></table></figure></p><p>如果参数的默认值是一个函数，该函数的作用域也遵守这个规则。</p><p><strong>应用</strong><br>利用参数默认值，可以指定某一个参数不能省略，否则抛出一个错误。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">throwIfMissing</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> <span class="built_in">Error</span>(<span class="string">'Missing parameter'</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">foo</span>(<span class="params">mustBeProvided = throwIfMissing(</span>)) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> mustBeProvided;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">foo()</span><br><span class="line"><span class="comment">// Error: Missing parameter</span></span><br></pre></td></tr></table></figure></p><h3 id="7-2-rest参数"><a href="#7-2-rest参数" class="headerlink" title="7.2 rest参数"></a>7.2 rest参数</h3><p>ES6引入了rest参数，用于获取函数的多余参数，rest参数搭配的变量是一个数组，该变量将多余的参数放入数组中。<br><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">add</span><span class="params">(<span class="rest_arg">...values</span>)</span> </span>&#123;</span><br><span class="line">  let sum = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">var</span> val of values) &#123;</span><br><span class="line">    sum += val;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">add(<span class="number">2</span>, <span class="number">5</span>, <span class="number">3</span>) <span class="comment">// 10</span></span><br></pre></td></tr></table></figure></p><p>注意rest参数后不能再有其他参数。函数的<code>length</code>属性，不包括rest参数。</p><h3 id="7-3-严格模式"><a href="#7-3-严格模式" class="headerlink" title="7.3 严格模式"></a>7.3 严格模式</h3><p>从ES5开始，函数内部可以设定为严格模式。</p><p>ES2016做了一点修改，只要函数参数使用了默认值、解构赋值或者扩展运算符，那么函数内部就不能显示设定为严格模式。</p><p>两种方法可以规避这种限制。第一种是设定全局的严格模式，第二种是把函数包在一个无参数的立即执行函数里，这个函数中设定严格模式。</p><h3 id="7-4-name属性"><a href="#7-4-name属性" class="headerlink" title="7.4 name属性"></a>7.4 name属性</h3><p>函数的<code>name</code>属性，返回函数的函数名。</p><h3 id="7-5-箭头函数"><a href="#7-5-箭头函数" class="headerlink" title="7.5 箭头函数"></a>7.5 箭头函数</h3><p>ES6允许使用箭头（<code>=&gt;</code>）定义函数。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> f = <span class="function"><span class="params">v</span> =&gt;</span> v;</span><br><span class="line"></span><br><span class="line"><span class="comment">//箭头函数等同于：</span></span><br><span class="line"><span class="keyword">var</span> f = <span class="function"><span class="keyword">function</span>(<span class="params">v</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> v;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>如果箭头函数的代码块部分多于一条语句，要使用大括号将他们括起来，并使用<code>return</code>语句返回。由于大括号被解释为代码块，所以如果箭头函数直接返回一个对象，必须在对象外面加上括号。</p><p><strong>使用注意</strong></p><ul><li>函数体内的<code>this</code>对象，就是定义时所在的对象，而不是使用时所在的对象。</li><li>不可以当作构造函数。</li><li>不可以使用<code>arguments</code>对象，该对象在函数体内不存在。应该使用<code>rest</code>参数代替。</li><li>不可以使用<code>yield</code>命令，因此箭头函数不能用作<code>Generator</code>函数。</li></ul><p>由于箭头函数没有自己的<code>this</code>，所以也不能使用<code>call()</code>、<code>apply()</code>、<code>bind()</code>这些方法来改变<code>this</code>的指向。</p><p><strong>嵌套的箭头函数</strong><br>箭头函数内部还可以再使用箭头函数。</p><h3 id="7-6-双冒号运算符"><a href="#7-6-双冒号运算符" class="headerlink" title="7.6 双冒号运算符"></a>7.6 双冒号运算符</h3><p>由于箭头函数并不适用于所有场合，所以现在有一个提案，提出了函数绑定运算符，用来取代<code>call</code>、<code>apply</code>、<code>bind</code>调用。</p><p>函数绑定运算符是并排的两个冒号（<code>::</code>），左边是一个对象，右边是一个函数，该运算符将左边的对象，作为上下文环境（即<code>this</code>对象），绑定到右边的函数上面。<br><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">foo::bar;</span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line">bar.bind(foo);</span><br><span class="line"></span><br><span class="line">foo::bar(...arguments);</span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line">bar.apply(foo, arguments);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> hasOwnProperty = Object.prototype.hasOwnProperty;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">hasOwn</span><span class="params">(obj, key)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> obj::hasOwnProperty(key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果双冒号左边为空，右边是一个对象的方法，则等于将该方法绑定在该对象上面。<br><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> <span class="function"><span class="keyword">method</span> = <span class="title">obj</span>:</span>:obj.foo;</span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line"><span class="keyword">var</span> <span class="function"><span class="keyword">method</span> = :</span>:obj.foo;</span><br><span class="line"></span><br><span class="line">let log = ::console.log;</span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line"><span class="keyword">var</span> log = console.log.bind(console);</span><br></pre></td></tr></table></figure></p><h3 id="7-7-尾调用优化"><a href="#7-7-尾调用优化" class="headerlink" title="7.7 尾调用优化"></a>7.7 尾调用优化</h3><p><strong>什么是尾调用？</strong><br>尾调用（Tail Call）就是指某一个函数的最后一步是调用另一个函数。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">x</span>)</span>&#123;</span><br><span class="line">  <span class="keyword">return</span> g(x);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//下面三种都不是尾调用</span></span><br><span class="line"><span class="comment">// 情况一</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">x</span>)</span>&#123;</span><br><span class="line">  <span class="keyword">let</span> y = g(x);</span><br><span class="line">  <span class="keyword">return</span> y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 情况二</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">x</span>)</span>&#123;</span><br><span class="line">  <span class="keyword">return</span> g(x) + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 情况三</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params">x</span>)</span>&#123;</span><br><span class="line">  g(x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>尾调用优化</strong><br>尾调用由于是函数的最后一步操作，所以不需要保留外层函数的调用帧，只保留内部函数的调用帧，将大大节省内存。。</p><p><strong>尾递归</strong><br>函数调用自身，称为递归。如果尾调用自身，就称为尾递归。</p><p>递归非常耗费内存，但对于尾递归来说，由于只存在一个调用帧，所以永远不会发生“栈溢出”（stack overflow）错误。</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//非尾递归的Fabonacci数列实现：</span></span><br><span class="line">function Fibonacci (n) &#123;</span><br><span class="line">  if ( n &lt;= <span class="number">1</span> ) &#123;return <span class="number">1</span>&#125;;</span><br><span class="line"></span><br><span class="line">  return Fibonacci(n - <span class="number">1</span>) + Fibonacci(n - <span class="number">2</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Fibonacci(<span class="number">10</span>) <span class="comment">// 89</span></span><br><span class="line">Fibonacci(<span class="number">100</span>) <span class="comment">// 堆栈溢出</span></span><br><span class="line">Fibonacci(<span class="number">500</span>) <span class="comment">// 堆栈溢出</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//尾递归优化过的Fibonacci数列实现：</span></span><br><span class="line">function Fibonacci2 (n , ac1 = <span class="number">1</span> , ac2 = <span class="number">1</span>) &#123;</span><br><span class="line">  if( n &lt;= <span class="number">1</span> ) &#123;return ac2&#125;;</span><br><span class="line"></span><br><span class="line">  return Fibonacci2 (n - <span class="number">1</span>, ac2, ac1 + ac2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Fibonacci2(<span class="number">100</span>) <span class="comment">// 573147844013817200000</span></span><br><span class="line">Fibonacci2(<span class="number">1000</span>) <span class="comment">// 7.0330367711422765e+208</span></span><br><span class="line">Fibonacci2(<span class="number">10000</span>) <span class="comment">// Infinity</span></span><br></pre></td></tr></table></figure><p><strong>递归函数的改写</strong><br>尾递归的实现，往往需要改写递归函数，确保最后一步只调用自身。</p><p>一般的方法是把所有用到的内部变量改写成函数的参数。但这样做的缺点就是不太直观，一种方法是可以在尾递归函数外在提供一个正常行驶的函数。</p><p>函数式编程有一个概念，叫做柯里化（currying），指将多参数的函数转换成单参数的形式。因此柯里化也可以帮助递归函数的改写。</p><p>第二种方法是采用ED6的函数默认值。<br><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">factorial</span><span class="params">(n, total = 1)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (n === <span class="number">1</span>) <span class="keyword">return</span> total;</span><br><span class="line">  <span class="keyword">return</span> factorial(n - <span class="number">1</span>, n * total);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">factorial(<span class="number">5</span>) <span class="comment">// 120</span></span><br></pre></td></tr></table></figure></p><p><strong>严格模式</strong><br>ES6的尾调用优化只在严格模式下开启，在正常模式是无效的。</p><p><strong>尾递归优化的实现</strong><br>那么在正常模式下或不支持严格模式的环境中，如何优化递归呢，答案是采用“循环”换掉“递归”，自己实现优化。</p><h3 id="7-8-函数参数的尾逗号"><a href="#7-8-函数参数的尾逗号" class="headerlink" title="7.8 函数参数的尾逗号"></a>7.8 函数参数的尾逗号</h3><p>ES2017允许函数的最后一个参数有尾逗号。使函数参数与数组和对象的尾逗号规则保持一致。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ECMAScript-6-Primer-III&quot;&gt;&lt;a href=&quot;#ECMAScript-6-Primer-III&quot; class=&quot;headerlink&quot; title=&quot;ECMAScript 6 Primer III&quot;&gt;&lt;/a&gt;ECMAScript 6 Prim</summary>
      
    
    
    
    
    <category term="JavaScript" scheme="http://gloomymoon.github.io/tags/JavaScript/"/>
    
    <category term="ECMAScript" scheme="http://gloomymoon.github.io/tags/ECMAScript/"/>
    
  </entry>
  
  <entry>
    <title>ECMAScript-6-Primer-II</title>
    <link href="http://gloomymoon.github.io/2018/02/10/ECMAScript-6-Primer-II/"/>
    <id>http://gloomymoon.github.io/2018/02/10/ECMAScript-6-Primer-II/</id>
    <published>2018-02-10T01:31:47.000Z</published>
    <updated>2018-03-30T05:44:40.310Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ECMAScript-6-Primer-II"><a href="#ECMAScript-6-Primer-II" class="headerlink" title="ECMAScript 6 Primer II"></a>ECMAScript 6 Primer II</h1><h2 id="4-字符串的扩展"><a href="#4-字符串的扩展" class="headerlink" title="4 字符串的扩展"></a>4 字符串的扩展</h2><h3 id="4-1-字符的Unicode表示法"><a href="#4-1-字符的Unicode表示法" class="headerlink" title="4.1 字符的Unicode表示法"></a>4.1 字符的Unicode表示法</h3><p>JavaScript允许采用<code>\uxxxx</code>形式表示一个字符，其中<code>xxxx</code>表示字符的Unicode码点。</p><p>但是这种表示法只限于码点在<code>\u0000</code>～<code>\uFFFF</code>之间的字符，超出范围的字符必须要用连个双字节的形式表示。</p><p>ES6允许将码点放入大括号中，就能够正确解读超过<code>\uFFFF</code>的字符。<br><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">"<span class="tag">\<span class="name">uD</span></span>842<span class="tag">\<span class="name">uDFB</span></span>7"</span><br><span class="line">// "𠮷"</span><br><span class="line"></span><br><span class="line">"<span class="tag">\<span class="name">u</span></span>20BB7"</span><br><span class="line">// " 7" 无法正确解读，会理解<span class="tag">\<span class="name">u</span></span>20BB+7，而<span class="tag">\<span class="name">u</span></span>20BB是一个不可打印字符</span><br><span class="line"></span><br><span class="line">"<span class="tag">\<span class="name">u</span><span class="string">&#123;20BB7&#125;</span></span>"</span><br><span class="line">// "𠮷"</span><br><span class="line"></span><br><span class="line">"<span class="tag">\<span class="name">u</span><span class="string">&#123;41&#125;</span></span><span class="tag">\<span class="name">u</span><span class="string">&#123;42&#125;</span></span><span class="tag">\<span class="name">u</span><span class="string">&#123;43&#125;</span></span>"</span><br><span class="line">// "ABC"</span><br><span class="line"></span><br><span class="line">let hello = 123;</span><br><span class="line">hell<span class="tag">\<span class="name">u</span><span class="string">&#123;6F&#125;</span></span> // 123</span><br><span class="line"></span><br><span class="line">'<span class="tag">\<span class="name">u</span><span class="string">&#123;1F680&#125;</span></span>' === '<span class="tag">\<span class="name">uD</span></span>83D<span class="tag">\<span class="name">uDE</span></span>80'</span><br><span class="line">// true</span><br></pre></td></tr></table></figure></p><h3 id="4-2-codePointAt"><a href="#4-2-codePointAt" class="headerlink" title="4.2 codePointAt()"></a>4.2 codePointAt()</h3><p>JavaScript内部字符以UTF-16格式存储，每个字符固定为2个字节，对于需要使用4个字节存储的字符（即码点大于<code>0xFFFF</code>），JavaScript会认为他们是两个字符。</p><p>ES6提供了<code>codePointAt</code>方法，能够正确处理4个字节存储的字符，返回一个字符的码点。</p><h3 id="4-3-String-fromCodePoint"><a href="#4-3-String-fromCodePoint" class="headerlink" title="4.3 String.fromCodePoint()"></a>4.3 String.fromCodePoint()</h3><p>ES6提供了<code>String.fromCodePoint</code>方法，可以识别大于<code>0xFFFF</code>的字符，弥补了<code>String.fromCharCode</code>方法的不足。</p><h3 id="4-4-字符串的遍历接口"><a href="#4-4-字符串的遍历接口" class="headerlink" title="4.4 字符串的遍历接口"></a>4.4 字符串的遍历接口</h3><p>ES6为字符串添加了遍历器接口，使得字符串可以被<code>for ... of</code>循环遍历。<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (let codePoint of <span class="string">'foo'</span>) &#123;</span><br><span class="line">  console.log(codePoint)</span><br><span class="line">&#125;</span><br><span class="line"><span class="regexp">//</span> <span class="string">"f"</span></span><br><span class="line"><span class="regexp">//</span> <span class="string">"o"</span></span><br><span class="line"><span class="regexp">//</span> <span class="string">"o"</span></span><br></pre></td></tr></table></figure></p><p>这个遍历器的最大优点是可以识别大于<code>0xFFFF</code>的码点。</p><h3 id="4-5-at"><a href="#4-5-at" class="headerlink" title="4.5 at()"></a>4.5 at()</h3><p>ES5对字符串对象提供<code>charAt</code>方法，返回字符串给定位置的字符，但是该方法不能识别码点大于<code>0xFFFF</code>的字符。</p><p>目前有一个提案，提出字符串实例的<code>at</code>方法，可以识别大于<code>0xFFFF</code>的字符。</p><h3 id="4-6-normalize"><a href="#4-6-normalize" class="headerlink" title="4.6 normalize()"></a>4.6 normalize()</h3><p>ES6提供字符串实例的<code>normalize</code>方法，用来将字符的不同表示方法统一为同样的形式，成为Unocode正规化。</p><p>主要用于在判断欧洲语言有语调符号和重音符号的字符在视觉和语义上的判断是等价的。</p><h3 id="4-7-includes-startsWith-endsWith"><a href="#4-7-includes-startsWith-endsWith" class="headerlink" title="4.7 includes(), startsWith(), endsWith()"></a>4.7 includes(), startsWith(), endsWith()</h3><p>除了传统的<code>indexOf</code>方法，ES6又提供了三种方法来确定一个字符串是否包含在另一个字符串中。</p><ul><li>includes(): 返回布尔值，表示是否找到了参数字符串</li><li>startsWith(): 返回布尔值，表示参数字符串是否在原字符串的头部</li><li>endsWith(): 返回布尔值，表示参数字符串是否在原字符串的尾部</li></ul><p>三个方法都支持第二个参数，前两个表示开始搜索的位置，最后一个表示针对前<code>n</code>个字符。</p><h3 id="4-8-repeat"><a href="#4-8-repeat" class="headerlink" title="4.8 repeat()"></a>4.8 repeat()</h3><p><code>repeat</code>方法返回一个新字符串，表示将原字符串重复<code>n</code>次。<br><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'x'</span>.<span class="keyword">repeat</span><span class="comment">(3)</span> <span class="comment">// "xxx"</span></span><br><span class="line"><span class="string">'na'</span>.<span class="keyword">repeat</span><span class="comment">(0)</span> <span class="comment">// ""</span></span><br></pre></td></tr></table></figure></p><h3 id="4-9-padStart-padEnd"><a href="#4-9-padStart-padEnd" class="headerlink" title="4.9 padStart(), padEnd()"></a>4.9 padStart(), padEnd()</h3><p>如果某个字符串不够指定长度，ES2017提供了在头部或尾部补全的方法。<code>padStart()</code>用于头部补全，<code>padEnd()</code>用于尾部补全。<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'x'</span>.padStart(<span class="number">5</span>, <span class="string">'ab'</span>) <span class="regexp">//</span> <span class="string">'ababx'</span></span><br><span class="line"><span class="string">'x'</span>.padStart(<span class="number">4</span>, <span class="string">'ab'</span>) <span class="regexp">//</span> <span class="string">'abax'</span></span><br><span class="line"></span><br><span class="line"><span class="string">'x'</span>.padEnd(<span class="number">5</span>, <span class="string">'ab'</span>) <span class="regexp">//</span> <span class="string">'xabab'</span></span><br><span class="line"><span class="string">'x'</span>.padEnd(<span class="number">4</span>, <span class="string">'ab'</span>) <span class="regexp">//</span> <span class="string">'xaba'</span></span><br></pre></td></tr></table></figure></p><h3 id="4-10-matchAll"><a href="#4-10-matchAll" class="headerlink" title="4.10 matchAll()"></a>4.10 matchAll()</h3><p><code>matchAll</code>方法返回一个正则表示式在当前字符串的所有匹配，详见《正则的扩展》一节。</p><h3 id="4-11-模板字符串"><a href="#4-11-模板字符串" class="headerlink" title="4.11 模板字符串"></a>4.11 模板字符串</h3><p>ES6引入了模板字符串，是增强版的字符串，用反引号标识，可以定义多行字符串，或者嵌入变量。<br><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 普通字符串</span></span><br><span class="line">`<span class="built_in">In</span> JavaScript <span class="string">'\n'</span> is a line-feed.`</span><br><span class="line"></span><br><span class="line"><span class="comment">// 多行字符串</span></span><br><span class="line">`<span class="built_in">In</span> JavaScript this is</span><br><span class="line"> <span class="built_in">not</span> legal.`</span><br><span class="line"></span><br><span class="line">console.<span class="built_in">log</span>(`string <span class="built_in">text</span> line <span class="number">1</span></span><br><span class="line">string <span class="built_in">text</span> line <span class="number">2</span>`);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 字符串中嵌入变量</span></span><br><span class="line">let <span class="built_in">name</span> = <span class="string">"Bob"</span>, <span class="built_in">time</span> = <span class="string">"today"</span>;</span><br><span class="line">`Hello $&#123;<span class="built_in">name</span>&#125;, how are you $&#123;<span class="built_in">time</span>&#125;?`</span><br></pre></td></tr></table></figure></p><p>实际上大括号内部可以放入任意的JavaScript表达式，可以进行运算，引用对象属性，调用函数等。</p><p>如果需要引用模板字符串本上，在需要时执行，可以像下面这样写。<br><figure class="highlight zephir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 写法一</span></span><br><span class="line"><span class="keyword">let</span> str = <span class="string">'return '</span> + <span class="string">'`Hello $&#123;name&#125;!`'</span>;</span><br><span class="line"><span class="keyword">let</span> func = <span class="keyword">new</span> <span class="function"><span class="keyword">Function</span><span class="params">(<span class="string">'name'</span>, str)</span></span>;</span><br><span class="line">func(<span class="string">'Jack'</span>) <span class="comment">// "Hello Jack!"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 写法二</span></span><br><span class="line"><span class="keyword">let</span> str = <span class="string">'(name) =&gt; `Hello $&#123;name&#125;!`'</span>;</span><br><span class="line"><span class="keyword">let</span> func = <span class="keyword">eval</span>.call(<span class="keyword">null</span>, str);</span><br><span class="line">func(<span class="string">'Jack'</span>) <span class="comment">// "Hello Jack!"</span></span><br></pre></td></tr></table></figure></p><h3 id="4-12-实例：模板编译"><a href="#4-12-实例：模板编译" class="headerlink" title="4.12 实例：模板编译"></a>4.12 实例：模板编译</h3><p>具体请参见<a href="http://es6.ruanyifeng.com/#docs/string" target="_blank" rel="noopener">这里</a>。</p><h3 id="4-13-标签模板"><a href="#4-13-标签模板" class="headerlink" title="4.13 标签模板"></a>4.13 标签模板</h3><p>模板字符串还可以紧跟在一个函数名后面，该函数将被调用来处理这个模板字符串。着被称为“标签模板”功能（tagged  template）。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alert`<span class="number">123</span>`</span><br><span class="line"><span class="comment">// 等同于</span></span><br><span class="line"><span class="function"><span class="title">alert</span><span class="params">(<span class="number">123</span>)</span></span></span><br></pre></td></tr></table></figure></p><h3 id="4-13-String-raw"><a href="#4-13-String-raw" class="headerlink" title="4.13 String.raw()"></a>4.13 String.raw()</h3><p>ES6还未原生的String对象提供了一个<code>raw</code>方法，用来充当模板字符床的处理函数，返回一个斜杠都被转义的字符串。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">String</span>.raw<span class="string">`Hi\n<span class="subst">$&#123;<span class="number">2</span>+<span class="number">3</span>&#125;</span>!`</span>;</span><br><span class="line"><span class="comment">// 返回 "Hi\\n5!"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">String</span>.raw<span class="string">`Hi\u000A!`</span>;</span><br><span class="line"><span class="comment">// 返回 "Hi\\u000A!"</span></span><br></pre></td></tr></table></figure></p><p>如果原字符串的斜杠已经转义，那么<code>String.raw</code>会进行再次转义。</p><h2 id="5-正则的扩展"><a href="#5-正则的扩展" class="headerlink" title="5 正则的扩展"></a>5 正则的扩展</h2><h3 id="5-1-RegExp构造函数"><a href="#5-1-RegExp构造函数" class="headerlink" title="5.1 RegExp构造函数"></a>5.1 RegExp构造函数</h3><p>ES6允许在使用<code>RegExp</code>构造函数时，当第一个参数是正则表达式时，可以使用第二个参数添加修饰符。</p><h3 id="5-2-字符串的正则方法"><a href="#5-2-字符串的正则方法" class="headerlink" title="5.2 字符串的正则方法"></a>5.2 字符串的正则方法</h3><p>ES6将字符串对象的4个正则表达式：<code>match()</code>、<code>replace()</code>、<code>search()</code>和<code>split()</code>，在语言内部全部调用<code>RegExp</code>的实例方法。</p><h3 id="5-3-u修饰符"><a href="#5-3-u修饰符" class="headerlink" title="5.3 u修饰符"></a>5.3 u修饰符</h3><p>ES6对正则表达式添加了<code>u</code>修饰符，含义为“Unicode模式”，用来正确处理四个字节的UTF-16编码。<br>详细参见<a href="http://es6.ruanyifeng.com/#docs/regex" target="_blank" rel="noopener">这里</a>。</p><h3 id="5-4-y修饰符"><a href="#5-4-y修饰符" class="headerlink" title="5.4 y修饰符"></a>5.4 y修饰符</h3><p><code>y</code>修饰符叫做“粘连”修饰符，表示确保匹配必须从剩余的第一个位置开始。</p><h3 id="5-5-sticky属性"><a href="#5-5-sticky属性" class="headerlink" title="5.5 sticky属性"></a>5.5 sticky属性</h3><p>与<code>y</code>修饰符相匹配，ES6的正则对象多了<code>sticky</code>属性，表示是否设置了<code>y</code>修饰符。</p><h3 id="5-6-flags属性"><a href="#5-6-flags属性" class="headerlink" title="5.6 flags属性"></a>5.6 flags属性</h3><p>ES6为正则表达式新增了<code>flags</code>属性，返回正则表达式的修饰符。</p><h3 id="5-7-s修饰符：dotAll模式"><a href="#5-7-s修饰符：dotAll模式" class="headerlink" title="5.7 s修饰符：dotAll模式"></a>5.7 s修饰符：dotAll模式</h3><p>正则表达式中，点（.）是一个特殊字符，代表任意的单个字符，但是有两个例外。一个是四个字节的 UTF-16 字符，这个可以用u修饰符解决；另一个是行终止符（line terminator character）。</p><p>ES2018 引入s修饰符，使得.可以匹配任意单个字符。</p><h3 id="5-8-后行断言"><a href="#5-8-后行断言" class="headerlink" title="5.8 后行断言"></a>5.8 后行断言</h3><p>ES2018引入了后行断言。</p><h3 id="5-9-Unicode属性类"><a href="#5-9-Unicode属性类" class="headerlink" title="5.9 Unicode属性类"></a>5.9 Unicode属性类</h3><p>ES2018引入了一种新的类的写法<code>\p{...}</code>和<code>\P{...}</code>，允许正则表达式匹配符合Unicode某种属性的所有字符。</p><h3 id="5-10-具名组匹配"><a href="#5-10-具名组匹配" class="headerlink" title="5.10 具名组匹配"></a>5.10 具名组匹配</h3><p>正则表达式时用圆括号进行组匹配。ES2018引入了具名组匹配（Named Capture Groups），允许为每一个组匹配指定一个名字，既便于阅读代码，又便于引用。</p><p>有了具名组匹配以后，可以使用解构赋值直接从匹配结果上位变量赋值。<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">let &#123;groups: &#123;<span class="keyword">one</span>, <span class="keyword">two</span>&#125;&#125; = /^(?&lt;<span class="keyword">one</span>&gt;.*):(?&lt;<span class="keyword">two</span>&gt;.*)$/<span class="keyword">u</span>.exec('foo:bar');</span><br><span class="line"><span class="keyword">one</span>  <span class="comment">// foo</span></span><br><span class="line"><span class="keyword">two</span>  <span class="comment">// bar</span></span><br></pre></td></tr></table></figure></p><p>字符串替换时，使用<code>$&lt;组名&gt;</code>引用具名组。<br><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml">let re = /(?<span class="tag">&lt;<span class="name">year</span>&gt;</span>\d</span><span class="template-variable">&#123;4&#125;</span><span class="xml">)-(?<span class="tag">&lt;<span class="name">month</span>&gt;</span>\d</span><span class="template-variable">&#123;2&#125;</span><span class="xml">)-(?<span class="tag">&lt;<span class="name">day</span>&gt;</span>\d</span><span class="template-variable">&#123;2&#125;</span><span class="xml">)/u;</span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">'2015-01-02'.replace(re, '$<span class="tag">&lt;<span class="name">day</span>&gt;</span>/$<span class="tag">&lt;<span class="name">month</span>&gt;</span>/$<span class="tag">&lt;<span class="name">year</span>&gt;</span>')</span></span><br><span class="line"><span class="xml">// '02/01/2015'</span></span><br></pre></td></tr></table></figure></p><p>如果要在正则表达式内部引用某个“具名组匹配”，可以使用\k&lt;组名&gt;的写法。<br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> RE_TWICE = /^(?&lt;<span class="keyword">word</span>&gt;[a-z]+)!\k&lt;<span class="keyword">word</span>&gt;$/;</span><br><span class="line">RE_TWICE.test(<span class="string">'abc!abc'</span>) <span class="comment">// true</span></span><br><span class="line">RE_TWICE.test(<span class="string">'abc!ab'</span>) <span class="comment">// false</span></span><br></pre></td></tr></table></figure></p><h3 id="5-11-String-prototype-matchAll"><a href="#5-11-String-prototype-matchAll" class="headerlink" title="5.11 String.prototype.matchAll"></a>5.11 String.prototype.matchAll</h3><p>目前有一个提案，增加了<code>String.prototype.matchAll</code>方法，可以一次性取出所有匹配。不过，它返回的是一个遍历器（Iterator），而不是数组。</p><h2 id="6-熟知的扩展"><a href="#6-熟知的扩展" class="headerlink" title="6 熟知的扩展"></a>6 熟知的扩展</h2><h3 id="6-1-二进制和八进制表示法"><a href="#6-1-二进制和八进制表示法" class="headerlink" title="6.1 二进制和八进制表示法"></a>6.1 二进制和八进制表示法</h3><p>ES6提供了二进制和八进制熟知的新的表示法，分别用前缀<code>0b</code>和<code>0o</code>表示。</p><h3 id="6-2-Number-isFinite-Number-isNaN"><a href="#6-2-Number-isFinite-Number-isNaN" class="headerlink" title="6.2 Number.isFinite(), Number.isNaN()"></a>6.2 Number.isFinite(), Number.isNaN()</h3><p>ES6在<code>Number</code>对象上，新提供了<code>Number.isFinite()</code>和<code>Number.isNaN()</code>两个方法。<br>前者用来检查一个数值是否为有限，既不是<code>Infinity</code>，后者用来检查一个值是否为<code>NaN</code>。</p><h3 id="6-3-Number-parseInt-Number-parseFloat"><a href="#6-3-Number-parseInt-Number-parseFloat" class="headerlink" title="6.3 Number.parseInt(), Number.parseFloat()"></a>6.3 Number.parseInt(), Number.parseFloat()</h3><p>ES6将全局方法<code>parseInt()</code>和<code>parseFloat()</code>，移植到<code>Number</code>对象上面，行为完全保持不变。</p><h3 id="6-4-Number-isInteger"><a href="#6-4-Number-isInteger" class="headerlink" title="6.4 Number.isInteger()"></a>6.4 Number.isInteger()</h3><p><code>Number.isInteger()</code>用来判断一个数值是否为整数。<br><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Number</span>.isInteger(<span class="number">25</span>) // <span class="literal">true</span></span><br><span class="line"><span class="built_in">Number</span>.isInteger(<span class="number">25.0</span>) // <span class="literal">true</span></span><br></pre></td></tr></table></figure></p><h3 id="6-5-Number-EPSILON"><a href="#6-5-Number-EPSILON" class="headerlink" title="6.5 Number.EPSILON"></a>6.5 Number.EPSILON</h3><p>ES6在<code>Number</code>对象上，新增了一个极小的常量<code>Number.EPSILON</code>，表示1月1的最小浮点数之间的差，实际上是JavaScript能够表示的最小精度。<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">function withinErrorMargin (left, right) &#123;</span><br><span class="line">  return Math.abs(left - right) &lt; Number.EPSILON * Math.pow(<span class="number">2</span>, <span class="number">2</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">0.1</span> + <span class="number">0.2</span> === <span class="number">0.3</span> <span class="comment">// false</span></span><br><span class="line">withinErrorMargin(<span class="number">0.1</span> + <span class="number">0.2</span>, <span class="number">0.3</span>) <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line"><span class="number">1.1</span> + <span class="number">1.3</span> === <span class="number">2.4</span> <span class="comment">// false</span></span><br><span class="line">withinErrorMargin(<span class="number">1.1</span> + <span class="number">1.3</span>, <span class="number">2.4</span>) <span class="comment">// true</span></span><br></pre></td></tr></table></figure></p><p>上面的代码为浮点数运算部署了一个误差检查函数。</p><h3 id="6-6-安全整数和Number-isSafeInteger"><a href="#6-6-安全整数和Number-isSafeInteger" class="headerlink" title="6.6 安全整数和Number.isSafeInteger()"></a>6.6 安全整数和Number.isSafeInteger()</h3><p>ES6引入了<code>Number.MAX_SAFE_INTEGER</code>和<code>Number.MIN_SAFE_INTEGER</code>两个常量用来表示整数的上下限。<code>Number.isSafeInteger</code>则用来判断一个整数是否落在这个范围内。</p><h3 id="6-7-Math对象的扩展"><a href="#6-7-Math对象的扩展" class="headerlink" title="6.7 Math对象的扩展"></a>6.7 Math对象的扩展</h3><p><strong>Math.trunc()</strong><br>用于去除一个数的小数部分，返回整数部分。</p><p><strong>Math.sign()</strong><br>用来判断一个数到底是整数、负数、还是零，对于非数值，会先将其转换为数值。它回返回五种植。</p><ul><li>参数为正数，返回+1；</li><li>参数为负数，返回-1；</li><li>参数为 0，返回0；</li><li>参数为-0，返回-0;</li><li>其他值，返回NaN。</li></ul><p><strong>Math.cbrt()</strong><br>用于计算一个数的立方根。</p><p><strong>Math.clz32()</strong><br>返回一个数的32为无符号整数形式有多少个前导0。</p><p><strong>Math.imul()</strong><br>返回两个数以32位带符号整数形式相乘的结果，返回的也是一个32为带符号整数。</p><p><strong>Math.fround()</strong><br>返回一个数的32位单精度浮点数形式。</p><p><strong>Math.hypot()</strong><br>返回所有参数的平方和的平方根。</p><p><strong>Mach.expm1()</strong><br>返回e<sup>x</sup>-1。</p><p><strong>Math.log1p()</strong><br>返回<code>1 + x</code>的自然对数。</p><p><strong>Math.log10()</strong><br>返回以10为底的<code>x</code>的对数。</p><p><strong>Math.log2()</strong><br>返回以2为底的<code>x</code>的对数。</p><p><strong>双曲函数</strong></p><ul><li>Math.sinh(x) 返回x的双曲正弦（hyperbolic sine）</li><li>Math.cosh(x) 返回x的双曲余弦（hyperbolic cosine）</li><li>Math.tanh(x) 返回x的双曲正切（hyperbolic tangent）</li><li>Math.asinh(x) 返回x的反双曲正弦（inverse hyperbolic sine）</li><li>Math.acosh(x) 返回x的反双曲余弦（inverse hyperbolic cosine）</li><li>Math.atanh(x) 返回x的反双曲正切（inverse hyperbolic tangent</li></ul><h3 id="6-8-指数运算符"><a href="#6-8-指数运算符" class="headerlink" title="6.8 指数运算符"></a>6.8 指数运算符</h3><p>ES2016新增了一个指数运算符（<code>**</code>）。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ECMAScript-6-Primer-II&quot;&gt;&lt;a href=&quot;#ECMAScript-6-Primer-II&quot; class=&quot;headerlink&quot; title=&quot;ECMAScript 6 Primer II&quot;&gt;&lt;/a&gt;ECMAScript 6 Primer </summary>
      
    
    
    
    
    <category term="JavaScript" scheme="http://gloomymoon.github.io/tags/JavaScript/"/>
    
    <category term="ECMAScript" scheme="http://gloomymoon.github.io/tags/ECMAScript/"/>
    
  </entry>
  
  <entry>
    <title>ECMAScript 6 Primer I</title>
    <link href="http://gloomymoon.github.io/2018/02/08/ECMAScript-6-Primer-I/"/>
    <id>http://gloomymoon.github.io/2018/02/08/ECMAScript-6-Primer-I/</id>
    <published>2018-02-08T01:51:40.000Z</published>
    <updated>2018-02-11T03:52:23.485Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ECMAScript-6-Primer-I"><a href="#ECMAScript-6-Primer-I" class="headerlink" title="ECMAScript 6 Primer I"></a>ECMAScript 6 Primer I</h1><p><a href="http://es6.ruanyifeng.com/" target="_blank" rel="noopener">《ES6标准入门》<br>——阮一峰</a></p><h2 id="1-ECMAScript-6-简介"><a href="#1-ECMAScript-6-简介" class="headerlink" title="1 ECMAScript 6 简介"></a>1 ECMAScript 6 简介</h2><p>ECMAScript 6.0是JavaScript语言的下一代标准，已经在2015年6月正式发布，每年都会发布一个标准升级版，根据计划2017年6月发布了ES2017标准，ES6涵盖了ES2015、ES2016、ES2017等。</p><h2 id="2-let-和-const-命令"><a href="#2-let-和-const-命令" class="headerlink" title="2 let 和 const 命令"></a>2 let 和 const 命令</h2><h3 id="2-1-let-命令"><a href="#2-1-let-命令" class="headerlink" title="2.1 let 命令"></a>2.1 let 命令</h3><p>ES6新增了<code>let</code>命令，类似<code>var</code>，但是所声明的变量只在<code>let</code>所在的代码块内有效。</p><p>用<code>let</code>声明的变量一定要在声明后才能使用，否则报错，而不像<code>var</code>声明的变量在声明前可以使用（值为<code>undefined</code>），即<strong>不存在变量提升</strong>。因此在代码块内，使用<code>let</code>声明变量前的代码区间称为“暂时性死区”（temporal dead zone，TDZ）。TDZ意味着<code>typeof</code>不再是一个安全的操作。</p><p><code>let</code>不允许在相同的作用域内重复声明一个变量。</p><h3 id="2-2-块级作用域"><a href="#2-2-块级作用域" class="headerlink" title="2.2 块级作用域"></a>2.2 块级作用域</h3><p><code>let</code>实际上为JavaScript带来了块级作用域。外层代码块不受内层代码块的影响。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">f1</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> n = <span class="number">5</span>;</span><br><span class="line">  <span class="keyword">if</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">let</span> n = <span class="number">10</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">console</span>.log(n); <span class="comment">// 5</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>ES6允许块级作用域的任意嵌套。块级作用域的出现，使得广泛应用的立即执行函数表达式（IIFE）不再必要了。<br><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// IIFE 写法</span></span><br><span class="line">(function () &#123;</span><br><span class="line">  <span class="built_in">var</span> tmp = <span class="params">...</span>;</span><br><span class="line">  <span class="params">...</span></span><br><span class="line">&#125;());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 块级作用域写法</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">let</span> tmp = <span class="params">...</span>;</span><br><span class="line">  <span class="params">...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>考虑到兼容ES5的旧代码，应该避免在块级作用域内生命函数，如果确实需要，应该写成函数表达式而不是函数声明语句。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 函数声明语句</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">let</span> a = <span class="string">'secret'</span>;</span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">f</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 函数表达式</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">let</span> a = <span class="string">'secret'</span>;</span><br><span class="line">  <span class="keyword">let</span> f = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="2-3-const-命令"><a href="#2-3-const-命令" class="headerlink" title="2.3 const 命令"></a>2.3 const 命令</h3><p><code>const</code>声明一个常量，其他特性与<code>let</code>声明的变量类似。</p><p><code>const</code>本质上保证的是变量指向的内存地址不得改动，因此对于简单结构（数值、字符串、布尔值）就是常量，而复合类型（对象和数组），变量指向的内存是一个指针，<code>const</code>只能保证指针固定，但是它指向的数据结构是可变的。</p><p>如果想要冻结对象，应该使用<code>Object.freeze</code>方法。<br><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> foo = <span class="built_in">Object</span>.freeze(&#123;&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 常规模式时，下面一行不起作用；</span></span><br><span class="line"><span class="comment">// 严格模式时，该行会报错</span></span><br><span class="line">foo.prop = <span class="number">123</span>;</span><br></pre></td></tr></table></figure></p><p>如果连对象的属性也要冻结，可以使用如下代码：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> constantize = <span class="function">(<span class="params">obj</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">Object</span>.freeze(obj);</span><br><span class="line">  <span class="built_in">Object</span>.keys(obj).forEach( <span class="function">(<span class="params">key, i</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> ( <span class="keyword">typeof</span> obj[key] === <span class="string">'object'</span> ) &#123;</span><br><span class="line">      constantize( obj[key] );</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="2-4-顶层对象属性"><a href="#2-4-顶层对象属性" class="headerlink" title="2.4 顶层对象属性"></a>2.4 顶层对象属性</h3><p>由于浏览器、Web Worder和Node里顶层对象不统一，很难找到一种方法可以在所有情况系都取到顶层对象。</p><p>具体可以参见<a href="http://es6.ruanyifeng.com/#docs/let#global-%E5%AF%B9%E8%B1%A1" target="_blank" rel="noopener">这里</a>。</p><h2 id="3-变量的解构赋值"><a href="#3-变量的解构赋值" class="headerlink" title="3 变量的解构赋值"></a>3 变量的解构赋值</h2><h3 id="3-1-数组的解构赋值"><a href="#3-1-数组的解构赋值" class="headerlink" title="3.1 数组的解构赋值"></a>3.1 数组的解构赋值</h3><p>ES6允许按照一定的<strong>模式</strong>，从数组和对象中提取值。<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">let [a, b, c] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>];</span><br></pre></td></tr></table></figure></p><p>本质上只要等号两边的模式相同，左边的变量就会被赋予对应的值，匹配可以是完全的也可以是不完全的，如果解构不成功，变量的值就等于<code>undefined</code>。</p><p>只要某种数据结构具有Iterator接口，都可以采用数组形式的解构赋值。<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">function* fibs() &#123;</span><br><span class="line">  <span class="built_in">let</span> a = <span class="number">0</span>;</span><br><span class="line">  <span class="built_in">let</span> b = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    yield a;</span><br><span class="line">    [a, b] = [b, a + b];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">let</span> [<span class="built_in">first</span>, <span class="built_in">second</span>, <span class="built_in">third</span>, <span class="built_in">fourth</span>, <span class="built_in">fifth</span>, <span class="built_in">sixth</span>] = fibs();</span><br><span class="line"><span class="built_in">sixth</span> // <span class="number">5</span></span><br></pre></td></tr></table></figure></p><p>解构赋值允许指定默认值，ES6使用严格相等运算符（<code>===</code>）判断一个位置是否有值，所有只有当一个数组成员严格等于<code>undefined</code>时，默认赋值才会生效。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> [x = <span class="number">1</span>] = [<span class="literal">undefined</span>];</span><br><span class="line">x <span class="comment">// 1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> [x = <span class="number">1</span>] = [<span class="literal">null</span>];</span><br><span class="line">x <span class="comment">// null</span></span><br></pre></td></tr></table></figure></p><h3 id="3-2-对象的解构赋值"><a href="#3-2-对象的解构赋值" class="headerlink" title="3.2 对象的解构赋值"></a>3.2 对象的解构赋值</h3><p>对象的解构赋值与数组的不同是，对象的属性没有次序，变量必须与属性同名才能渠道正确的值，如果变量名与属性名不同，必须使用如下方法：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">let &#123; <span class="string">foo:</span> baz &#125; = &#123; <span class="string">foo:</span> <span class="string">'aaa'</span>, <span class="string">bar:</span> <span class="string">'bbb'</span> &#125;;</span><br><span class="line">baz <span class="comment">// "aaa"</span></span><br><span class="line"></span><br><span class="line">let obj = &#123; <span class="string">first:</span> <span class="string">'hello'</span>, <span class="string">last:</span> <span class="string">'world'</span> &#125;;</span><br><span class="line">let &#123; <span class="string">first:</span> f, <span class="string">last:</span> l &#125; = obj;</span><br><span class="line">f <span class="comment">// 'hello'</span></span><br><span class="line">l <span class="comment">// 'world'</span></span><br></pre></td></tr></table></figure></p><p>如果将一个已经声明的变量用于解构赋值，必须非常小心。<br><figure class="highlight ceylon"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 错误的写法</span></span><br><span class="line"><span class="keyword">let</span> x;</span><br><span class="line">&#123;x&#125; = &#123;x: <span class="number">1</span>&#125;;</span><br><span class="line"><span class="comment">// SyntaxError: syntax error</span></span><br></pre></td></tr></table></figure></p><p>上面代码的报错是因为JavaScript引擎会将<code>{x}</code>理解成为一个代码块，正确的方法是放在一个圆括号内。<br><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 正确的写法</span><br><span class="line">let <span class="keyword">x</span><span class="comment">;</span></span><br><span class="line"><span class="comment">(&#123;x&#125; = &#123;x: 1&#125;);</span></span><br></pre></td></tr></table></figure></p><h3 id="3-3-字符串的解构赋值"><a href="#3-3-字符串的解构赋值" class="headerlink" title="3.3 字符串的解构赋值"></a>3.3 字符串的解构赋值</h3><p>字符串也可以解构赋值，因为它可以被转换成一个类似数组的对象。<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">const [a, b, c, d, e] = <span class="string">'hello'</span>;</span><br><span class="line">a <span class="regexp">//</span> <span class="string">"h"</span></span><br><span class="line">b <span class="regexp">//</span> <span class="string">"e"</span></span><br><span class="line">c <span class="regexp">//</span> <span class="string">"l"</span></span><br><span class="line">d <span class="regexp">//</span> <span class="string">"l"</span></span><br><span class="line">e <span class="regexp">//</span> <span class="string">"o"</span></span><br><span class="line"></span><br><span class="line">let &#123;length : len&#125; = <span class="string">'hello'</span>;</span><br><span class="line">len <span class="regexp">//</span> <span class="number">5</span></span><br></pre></td></tr></table></figure></p><h3 id="3-4-数值和布尔值的解构赋值"><a href="#3-4-数值和布尔值的解构赋值" class="headerlink" title="3.4 数值和布尔值的解构赋值"></a>3.4 数值和布尔值的解构赋值</h3><p>结构赋值时，如果等号右边不是对象或数组，都会先将其转为对象，无法转为对象的，解构赋值会报错。<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> &#123;<span class="built_in">toString</span>: s&#125; = <span class="number">123</span>;</span><br><span class="line"><span class="attr">s</span> === Number.prototype.<span class="built_in">toString</span> // <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> &#123;<span class="built_in">toString</span>: s&#125; = <span class="literal">true</span>;</span><br><span class="line"><span class="attr">s</span> === Boolean.prototype.<span class="built_in">toString</span> // <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> &#123; prop: x &#125; = undefined; // TypeError</span><br><span class="line"><span class="keyword">let</span> &#123; prop: y &#125; = <span class="literal">null</span>; // TypeError</span><br></pre></td></tr></table></figure></p><p>数值和布尔值都能转换成对象，<code>undefined</code>和<code>null</code>无法转为对象。</p><h3 id="3-5-函数参数的解构赋值"><a href="#3-5-函数参数的解构赋值" class="headerlink" title="3.5 函数参数的解构赋值"></a>3.5 函数参数的解构赋值</h3><p>函数的参数也可以使用解构赋值，解构时也可以使用默认值。<br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">function <span class="built_in">move</span>(&#123;x = <span class="number">0</span>, y = <span class="number">0</span>&#125; = &#123;&#125;) &#123;</span><br><span class="line">  <span class="built_in">return</span> [x, y];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">move</span>(&#123;x: <span class="number">3</span>, y: <span class="number">8</span>&#125;); <span class="comment">// [3, 8]</span></span><br><span class="line"><span class="built_in">move</span>(&#123;x: <span class="number">3</span>&#125;); <span class="comment">// [3, 0]</span></span><br><span class="line"><span class="built_in">move</span>(&#123;&#125;); <span class="comment">// [0, 0]</span></span><br><span class="line"><span class="built_in">move</span>(); <span class="comment">// [0, 0]</span></span><br></pre></td></tr></table></figure></p><p>注意使用默认值的写法，如果使用<code>{x, y} = { x: 0, y: 0 }</code>将不能正确地对<code>{}</code>参数赋默认值。</p><h3 id="3-6-圆括号问题"><a href="#3-6-圆括号问题" class="headerlink" title="3.6 圆括号问题"></a>3.6 圆括号问题</h3><p>解构赋值使用起来方便，但是对于编译器来说，一个式子到底是模式还是表达式，解析起来并不容易。ES6的规则是，只要有可能导致结构的歧义，就不得使用圆括号，因此建议只要有可能，就不要在模式中放置圆括号。</p><p>可以使用圆括号的情况只有一种：赋值语句的非模式部分。<br><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="comment">(b)</span>] = [<span class="number">3</span>]; <span class="comment">// 正确</span></span><br><span class="line"><span class="comment">(&#123; p: (d)</span> &#125; = &#123;&#125;); <span class="comment">// 正确</span></span><br><span class="line">[<span class="comment">(parseInt.prop)</span>] = [<span class="number">3</span>]; <span class="comment">// 正确</span></span><br></pre></td></tr></table></figure></p><h3 id="3-7-用途"><a href="#3-7-用途" class="headerlink" title="3.7 用途"></a>3.7 用途</h3><p>变量解构赋值的用途很多，理解之后使用起来感觉像Python的切片方法一样灵活。</p><ol><li><p>交换变量的值</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="attr">x</span> = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">let</span> <span class="attr">y</span> = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">[x, y] = [y, x];</span><br></pre></td></tr></table></figure></li><li><p>函数返回多个值</p></li><li><p>函数参数的定义</p></li><li><p>提取 JSON 数据</p><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">let jsonData = &#123;</span><br><span class="line">  id: <span class="number">42</span>,</span><br><span class="line">  <span class="keyword">status</span>: <span class="string">"OK"</span>,</span><br><span class="line">  <span class="keyword">data</span>: [<span class="number">867</span>, <span class="number">5309</span>]</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">let &#123; id, <span class="keyword">status</span>, <span class="keyword">data</span>: <span class="keyword">number</span> &#125; = jsonData;</span><br><span class="line"></span><br><span class="line">console.<span class="built_in">log</span>(id, <span class="keyword">status</span>, <span class="keyword">number</span>);</span><br><span class="line">// <span class="number">42</span>, <span class="string">"OK"</span>, [<span class="number">867</span>, <span class="number">5309</span>]</span><br></pre></td></tr></table></figure></li><li><p>函数参数的默认值</p></li><li><p>遍历 Map 结构</p><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="built_in">map</span> = <span class="keyword">new</span> Map();</span><br><span class="line"><span class="built_in">map</span>.<span class="built_in">set</span>(<span class="string">'first'</span>, <span class="string">'hello'</span>);</span><br><span class="line"><span class="built_in">map</span>.<span class="built_in">set</span>(<span class="string">'second'</span>, <span class="string">'world'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (let [<span class="built_in">key</span>, value] of <span class="built_in">map</span>) &#123;</span><br><span class="line">  console.<span class="built_in">log</span>(<span class="built_in">key</span> + <span class="string">" is "</span> + value);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// first is hello</span></span><br><span class="line"><span class="comment">// second is world</span></span><br></pre></td></tr></table></figure><p>像不像Python的用法？</p></li><li><p>输入模板的制定方法</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> &#123; SourceMapConsumer, SourceNode &#125; = <span class="built_in">require</span>(<span class="string">"source-map"</span>);</span><br></pre></td></tr></table></figure><p>终于知道这样写的原因了。</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ECMAScript-6-Primer-I&quot;&gt;&lt;a href=&quot;#ECMAScript-6-Primer-I&quot; class=&quot;headerlink&quot; title=&quot;ECMAScript 6 Primer I&quot;&gt;&lt;/a&gt;ECMAScript 6 Primer I&lt;/</summary>
      
    
    
    
    
    <category term="JavaScript" scheme="http://gloomymoon.github.io/tags/JavaScript/"/>
    
    <category term="ECMAScript" scheme="http://gloomymoon.github.io/tags/ECMAScript/"/>
    
  </entry>
  
  <entry>
    <title>DataTables.js: Some Useful Tips</title>
    <link href="http://gloomymoon.github.io/2017/12/17/DataTables-js-Some-Useful-Tips/"/>
    <id>http://gloomymoon.github.io/2017/12/17/DataTables-js-Some-Useful-Tips/</id>
    <published>2017-12-17T12:13:14.000Z</published>
    <updated>2017-12-16T13:32:15.679Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DataTables-js-Some-Useful-Tips"><a href="#DataTables-js-Some-Useful-Tips" class="headerlink" title="DataTables.js: Some Useful Tips"></a>DataTables.js: Some Useful Tips</h1><h2 id="0-Preface"><a href="#0-Preface" class="headerlink" title="0 Preface"></a>0 Preface</h2><p><a href="https://datatables.net" target="_blank" rel="noopener">DataTables</a>是一款非常强大的jQuery表格插件，能够为普通的HTML表格添加丰富的交互功能。</p><h2 id="1-Setting-defaults"><a href="#1-Setting-defaults" class="headerlink" title="1 Setting defaults"></a>1 Setting defaults</h2><p>为了简化每次初始化表单的参数，可以将一些参数值设置为首选的初始值。DataTables中通过使用为<code>defaults</code>填写扩展方法来实现。</p><figure class="highlight scilab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$.extend(true, $.fn.dataTable.defaults, &#123;</span><br><span class="line">    <span class="comment">//这里填写自定义的初始参数和值</span></span><br><span class="line">    <span class="string">"searching"</span>: false,   <span class="comment">//默认不支持搜索</span></span><br><span class="line">    <span class="string">"ordering"</span>: false,    <span class="comment">//默认不允许排序</span></span><br><span class="line">    <span class="string">"language"</span>: &#123;         <span class="comment">//默认的语言字符串</span></span><br><span class="line">        <span class="string">"lengthMenu"</span>: <span class="string">"每页显示 _MENU_ 条记录"</span>,</span><br><span class="line">        <span class="string">"emptyTable"</span>: <span class="string">"没有记录"</span>,</span><br><span class="line">        <span class="string">"zeroRecords"</span>: <span class="string">"抱歉， 没有找到"</span>,</span><br><span class="line">        <span class="string">"info"</span>: <span class="string">" 从 _START_ 到 _END_ / 共 _TOTAL_ 条数据 "</span>,</span><br><span class="line">        <span class="string">"infoEmpty"</span>: <span class="string">"没有数据"</span>,</span><br><span class="line">        <span class="string">"infoFiltered"</span>: <span class="string">"(从 _MAX_ 条数据中检索)"</span>,</span><br><span class="line">        <span class="string">"loadingRecords"</span>: <span class="string">"加载中..."</span>,</span><br><span class="line">        <span class="string">"processing"</span>:     <span class="string">"处理中..."</span>,</span><br><span class="line">        <span class="string">"search"</span>:         <span class="string">"搜索："</span>,</span><br><span class="line">        <span class="string">"paginate"</span>: &#123;</span><br><span class="line">            <span class="string">"first"</span>:      <span class="string">"|&lt;"</span>,</span><br><span class="line">            <span class="string">"last"</span>:       <span class="string">"&gt;|"</span>,</span><br><span class="line">            <span class="string">"next"</span>:       <span class="string">"&gt;"</span>,</span><br><span class="line">            <span class="string">"previous"</span>:   <span class="string">"&lt;"</span></span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="comment">//默认的dom格式，dom格式见下节</span></span><br><span class="line">    <span class="string">"dom"</span>: <span class="string">"&lt;'</span>row'&lt;<span class="string">'col-sm-6'</span>&gt;&lt;<span class="string">'col-sm-6'</span>f&gt;&gt;<span class="string">" +</span></span><br><span class="line"><span class="string">            "</span>&lt;<span class="string">'row'</span>&lt;<span class="string">'col-sm-12'</span>tr&gt;&gt;<span class="string">" +</span></span><br><span class="line"><span class="string">            "</span>&lt;<span class="string">'row'</span>&lt;<span class="string">'col-sm-5'</span>i&gt;&lt;<span class="string">'col-sm-7'</span>p&gt;&gt;<span class="string">"</span></span><br><span class="line"><span class="string">&#125;);</span></span><br></pre></td></tr></table></figure><h2 id="2-DOM"><a href="#2-DOM" class="headerlink" title="2 DOM"></a>2 DOM</h2><p>DataTables内置了几个用来控制表单或显示附加信息的元素组件，可以在初始化时通过定义<code>dom</code>参数来选择显示哪些，以及现实的位置和布局。</p><p>内置的表单控件如下：</p><ul><li><code>l</code>（<code>l</code>ength）：表示每页显示记录数的控件</li><li><code>f</code>（<code>f</code>ilter）：表示搜索（过滤）输入框控件</li><li><code>t</code>（<code>t</code>able）：表示表单table元素本身</li><li><code>i</code>（<code>i</code>nformation）：表示统计信息展示控件</li><li><code>p</code>（<code>p</code>agination）：表示分页控件</li><li><code>r</code>（p<code>r</code>ocessing）：表示“处理中”信息展示控件</li></ul><p>默认情况下<code>dom</code>的值为<code>lfrtip</code>。</p><p>为满足表单及控件元素的个性化布局，<code>dom</code>选项支持Markup语法，支持添加自定义的<code>div</code>元素，主要关键语法如下：</p><ul><li><code>&lt;</code>和<code>&gt;</code>：表示<code>div</code>元素的开始和结束</li><li><code>&lt;&quot;className&quot;</code>和<code>&gt;</code>：表示<code>class</code>属性为<code>className</code>的<code>div</code>元素</li><li><code>&lt;&quot;#id&quot;</code>和<code>&gt;</code>：表示<code>id</code>属性为<code>id</code>的<code>div</code>元素</li><li><code>&lt;&quot;#id.className&quot;</code>和<code>&gt;</code>：上述两者的组合</li></ul><p>因此如果使用<strong>Bootstrap</strong>样式，可以将<code>dom</code>属性设置为：<br><figure class="highlight scilab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"&lt;'</span>row'&lt;<span class="string">'col-sm-6'</span>l&gt;&lt;<span class="string">'col-sm-6'</span>f&gt;&gt;<span class="string">" +</span></span><br><span class="line"><span class="string">"</span>&lt;<span class="string">'row'</span>&lt;<span class="string">'col-sm-12'</span>tr&gt;&gt;<span class="string">" +</span></span><br><span class="line"><span class="string">"</span>&lt;<span class="string">'row'</span>&lt;<span class="string">'col-sm-5'</span>i&gt;&lt;<span class="string">'col-sm-7'</span>p&gt;&gt;<span class="string">"</span></span><br></pre></td></tr></table></figure></p><p>生成的HTML结果为：<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row"</span>&gt;</span><br><span class="line">  &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-sm-6"</span>&gt;</span><br><span class="line">    &#123; <span class="built_in">length</span> &#125;</span><br><span class="line">  &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">  &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-sm-6"</span>&gt;</span><br><span class="line">    &#123; filter &#125;</span><br><span class="line">  &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row"</span>&gt;</span><br><span class="line">  &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-sm-12"</span>&gt;</span><br><span class="line">    &#123; table &#125;</span><br><span class="line">    &#123; processing &#125;</span><br><span class="line">  &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"row"</span>&gt;</span><br><span class="line">  &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-sm-5"</span>&gt;</span><br><span class="line">    &#123; information &#125;</span><br><span class="line">  &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">  &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"col-sm-7"</span>&gt;</span><br><span class="line">    &#123; pagination &#125;</span><br><span class="line">  &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;/<span class="keyword">div</span>&gt;</span><br></pre></td></tr></table></figure></p><h2 id="3-Column-rendering"><a href="#3-Column-rendering" class="headerlink" title="3 Column rendering"></a>3 Column rendering</h2><p>在某些时候，通过ajax方式获得数据填充表单时，需要对某些字段Column或者单元格Cell的HTML元素或值进行变化和加工，这个时候可以使用<code>createdCell</code>事件添加自定义格式化函数：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> table = $(<span class="string">'#table'</span>).DataTable(&#123;</span><br><span class="line">  <span class="string">"columnDefs"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">          <span class="comment">//仅针对第5个列的单元格进行处理</span></span><br><span class="line">          <span class="string">"targets"</span>: [<span class="number">4</span>],</span><br><span class="line">          <span class="string">"createdCell"</span>: <span class="function"><span class="keyword">function</span> (<span class="params">td, cellData, rowData, row, col</span>) </span>&#123;</span><br><span class="line">              <span class="keyword">if</span> (cellData &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                  <span class="comment">//单元格的显示内容根据数据的值变化</span></span><br><span class="line">                  $(td).html(<span class="string">'运行'</span>);</span><br><span class="line">              &#125;</span><br><span class="line">              <span class="keyword">else</span> &#123;</span><br><span class="line">                  $(td).html(<span class="string">'停止'</span>);</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  ],</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p><h2 id="4-Row-created-callback"><a href="#4-Row-created-callback" class="headerlink" title="4 Row created callback"></a>4 Row created callback</h2><p>用样的在行创建时也可以调用自定义方法来执行格式化工作：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$(<span class="string">'#table'</span>).DataTable( &#123;</span><br><span class="line">    <span class="string">"createdRow"</span>: function ( row, data, index ) &#123;</span><br><span class="line">        <span class="keyword">if</span> ( data[<span class="number">5</span>] * <span class="number">1</span> &gt; <span class="number">1</span> ) &#123;</span><br><span class="line">            /<span class="regexp">/当第6个列的值&gt;1时，为行添加class</span></span><br><span class="line"><span class="regexp">            $('row).eq(5).addClass('danger');</span></span><br><span class="line"><span class="regexp">        &#125;</span></span><br><span class="line"><span class="regexp">    &#125;</span></span><br><span class="line"><span class="regexp">&#125;);</span></span><br></pre></td></tr></table></figure></p><p>在实际使用中，<code>createdCell</code>和<code>createdRow</code>都可以达到同样的效果。</p><h2 id="5-Individual-column-searching"><a href="#5-Individual-column-searching" class="headerlink" title="5 Individual column searching"></a>5 Individual column searching</h2><p>除了全局搜索框以外，DataTables还支持每个列的独立搜索框，搜索框有两种类型：input和select。</p><p>Input输入框：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//为每个列添加input元素</span></span><br><span class="line">$(<span class="string">'#table tfoot th'</span>).each( <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> title = $(<span class="keyword">this</span>).text();</span><br><span class="line">    $(<span class="keyword">this</span>).html( <span class="string">'&lt;input type="text" style="width:100%" /&gt;'</span> );</span><br><span class="line">&#125; );</span><br><span class="line"><span class="keyword">var</span> table = $(<span class="string">"table"</span>).DataTable();</span><br><span class="line"></span><br><span class="line">table.columns().every( <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> that = <span class="keyword">this</span>;</span><br><span class="line">    $( <span class="string">'input'</span>, <span class="keyword">this</span>.footer() ).on( <span class="string">'keyup change'</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( that.search() !== <span class="keyword">this</span>.value ) &#123;</span><br><span class="line">            that</span><br><span class="line">                .search( <span class="keyword">this</span>.value )</span><br><span class="line">                .draw();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; );</span><br><span class="line">&#125; );</span><br></pre></td></tr></table></figure></p><p>Select输入框：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$(<span class="string">"#table"</span>).DataTable( &#123;</span><br><span class="line">  initComplete: <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">      <span class="comment">//仅针对第4、5、6、7、8列添加搜索框</span></span><br><span class="line">      <span class="keyword">this</span>.api().columns([<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>]).every( <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">          <span class="keyword">var</span> column = <span class="keyword">this</span>;</span><br><span class="line">          <span class="keyword">var</span> select = $(<span class="string">'&lt;select&gt;&lt;option value=""&gt;&lt;/option&gt;&lt;/select&gt;'</span>)</span><br><span class="line">              .appendTo( $(column.footer()).empty() )</span><br><span class="line">              .on( <span class="string">'change'</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">                  <span class="keyword">var</span> val = $.fn.dataTable.util.escapeRegex(</span><br><span class="line">                      $(<span class="keyword">this</span>).val()</span><br><span class="line">                  );</span><br><span class="line">                  column</span><br><span class="line">                      .search( val ? <span class="string">'^'</span>+val+<span class="string">'$'</span> : <span class="string">''</span>, <span class="literal">true</span>, <span class="literal">false</span> )</span><br><span class="line">                      .draw();</span><br><span class="line">              &#125; );</span><br><span class="line">          <span class="built_in">console</span>.log(column.header());</span><br><span class="line">          column.data().unique().sort().each( <span class="function"><span class="keyword">function</span> (<span class="params"> d, j </span>) </span>&#123;</span><br><span class="line">              t = d;</span><br><span class="line">              <span class="comment">//第5列搜索框展现和值是不一样的</span></span><br><span class="line">              <span class="keyword">if</span>(column.index()==<span class="number">4</span>)&#123;</span><br><span class="line">                  t = d==<span class="string">'1'</span>?<span class="string">'运行'</span>:<span class="string">'停止'</span>;</span><br><span class="line">              &#125;</span><br><span class="line">              select.append( <span class="string">'&lt;option value="'</span>+d+<span class="string">'"&gt;'</span>+ t +<span class="string">'&lt;/option&gt;'</span> );</span><br><span class="line">          &#125; );</span><br><span class="line">      &#125; );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></p><h2 id="6-Row-selection"><a href="#6-Row-selection" class="headerlink" title="6 Row selection"></a>6 Row selection</h2><p>记录的多重选择实现起来比较简单，通过<code>tr</code>的点击事件添加特定的<code>class</code>，最后通过jQuery的选择<code>class</code>名来获取选中的数据信息：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> table = $(<span class="string">'#table'</span>).DataTable();</span><br><span class="line"></span><br><span class="line">$(<span class="string">'#example tbody'</span>).on( <span class="string">'click'</span>, <span class="string">'tr'</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    $(<span class="keyword">this</span>).toggleClass(<span class="string">'selected'</span>);</span><br><span class="line">&#125; );</span><br><span class="line"></span><br><span class="line">$(<span class="string">'#button'</span>).click( <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    alert( table.rows(<span class="string">'.selected'</span>).data().length +<span class="string">' row(s) selected'</span> );</span><br><span class="line">&#125; );</span><br></pre></td></tr></table></figure></p><h2 id="7-Access-data-thru-jQuery-selector"><a href="#7-Access-data-thru-jQuery-selector" class="headerlink" title="7 Access data thru jQuery selector"></a>7 Access data thru jQuery selector</h2><p>如果需要在DataTable对象外部方位内部的数据（而不是HTML的dom对象），例如像一部中多重选中记录后，需要选中记录的内容，可以使用如下方法：<br><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">data</span> = table.<span class="keyword">rows</span>( $(<span class="string">"#table tbody tr.selected"</span>) ).<span class="built_in">data</span>().toArray();</span><br></pre></td></tr></table></figure></p><p>注意最后<code>data()</code>方法之后需要用<code>toArray()</code>转化一下，就能够获取原始的dict类型的数据对象。</p><p>其中<code>rows()</code>方法可以替换成<code>columns()</code>，并且其参数可以用jQuery的选择器来过滤和筛选。</p><h2 id="8-Refresh-data"><a href="#8-Refresh-data" class="headerlink" title="8 Refresh data"></a>8 Refresh data</h2><p>在DataTable初始化后，需要动态更新内部数据而不用<code>destroy</code>后重新初始化，有如下两种方法：</p><p>A. 使用javascript的数组手动刷新数据：<br><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">//通过其他方式获取需要更新的数据</span><br><span class="line"><span class="class"><span class="keyword">data</span> = [...];</span></span><br><span class="line"><span class="title">table</span>.clear().rows.add(<span class="class"><span class="keyword">data</span>).draw();</span></span><br></pre></td></tr></table></figure></p><p>B. 使用ajax的<code>reload</code>方法自动刷新数据：<br><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">var <span class="keyword">table</span> = $('#<span class="keyword">table</span>').DataTable(&#123;</span><br><span class="line">    <span class="string">"ajax"</span>: &#123;</span><br><span class="line">        url: <span class="string">"/api/getData"</span></span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">setInterval( function () &#123;</span><br><span class="line">    <span class="keyword">table</span>.ajax.reload();</span><br><span class="line">&#125;, <span class="number">5000</span> );</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;DataTables-js-Some-Useful-Tips&quot;&gt;&lt;a href=&quot;#DataTables-js-Some-Useful-Tips&quot; class=&quot;headerlink&quot; title=&quot;DataTables.js: Some Useful Tips&quot;</summary>
      
    
    
    
    
    <category term="JavaScript" scheme="http://gloomymoon.github.io/tags/JavaScript/"/>
    
    <category term="DataTables" scheme="http://gloomymoon.github.io/tags/DataTables/"/>
    
  </entry>
  
  <entry>
    <title>CodeMirror sizer miscalculating</title>
    <link href="http://gloomymoon.github.io/2017/11/14/CodeMirror-sizer-miscalculating/"/>
    <id>http://gloomymoon.github.io/2017/11/14/CodeMirror-sizer-miscalculating/</id>
    <published>2017-11-14T08:28:31.000Z</published>
    <updated>2017-11-14T09:14:41.288Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CodeMirror-sizer-miscalculating"><a href="#CodeMirror-sizer-miscalculating" class="headerlink" title="CodeMirror sizer miscalculating"></a>CodeMirror sizer miscalculating</h1><p><a href="http://codemirror.net" target="_blank" rel="noopener">CodeMirror</a>是一个用JavaScript实现的Web端代码编辑器，支持多种编程语言，提供许多高级编辑功能插件。丰富的API接口和CSS主题样式能够很好地满足应用开发的需要。</p><p>主要功能：</p><ul><li>支持超过100种编程语言</li><li>强大的可组合的语言模式系统（composable language mode system）</li><li>自动补完（Autocompletion）</li><li>代码折叠</li><li>可编辑按键绑定</li><li>Vim、Emacs和Sublime绑定</li><li>搜索和替换接口</li><li>括号和标签配对</li><li>支持分窗试图</li><li>集成错误代码提示（Linter integration）<br>……</li></ul><h4 id="Q-如何使用Java语法高亮模式"><a href="#Q-如何使用Java语法高亮模式" class="headerlink" title="Q: 如何使用Java语法高亮模式"></a>Q: 如何使用Java语法高亮模式</h4><p>A: 首先需要在项目中引入<code>\mode\clike\</code>目录，加载<code>\mode\clike\clike.js</code>，并且在初始化时添加<code>mode: &quot;text/x-java&quot;</code>参数。<br><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> editor = CodeMirror.fromTextArea(<span class="built_in">document</span>.getElementById(<span class="string">"editor"</span>), &#123;</span><br><span class="line">        mode: <span class="string">"text/x-java"</span>,</span><br><span class="line">        lineNumbers: <span class="keyword">true</span></span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure></p><h4 id="Q-当代码行数小于10时，sizer没有正确起作用"><a href="#Q-当代码行数小于10时，sizer没有正确起作用" class="headerlink" title="Q: 当代码行数小于10时，sizer没有正确起作用"></a>Q: 当代码行数小于10时，sizer没有正确起作用</h4><p><img src="/img/CodeMirrorSizerMiscalculating_01.png" alt=""><br>超过10行时变为正常<br><img src="/img/CodeMirrorSizerMiscalculating_02.png" alt=""></p><p>A: 该问题在github上有对应的issue：<a href="https://github.com/codemirror/CodeMirror/issues/3527" target="_blank" rel="noopener">Code mirror sizer miscalculating gutter width if doc has less than 10 lines #3527</a></p><p>解决方案是加载自动更新组件，添加自动更新参数。首先在项目中引入并加载<code>\addon\display\autorefresh.js</code>，然后在初始化时添加<code>autoRefresh: true</code>参数：<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">var</span> <span class="string">editor</span> <span class="string">=</span> <span class="string">CodeMirror.fromTextArea(document.getElementById("editor"),</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">        mode:</span> <span class="string">"text/x-java"</span><span class="string">,</span></span><br><span class="line"><span class="attr">        lineNumbers:</span> <span class="literal">true</span><span class="string">,</span></span><br><span class="line"><span class="attr">        autoRefresh:</span> <span class="literal">true</span></span><br><span class="line">    <span class="string">&#125;);</span></span><br></pre></td></tr></table></figure></p><p>如果在页面多次隐藏CodeMirror编辑器后再次出现该问题时，可以在每次显示时手动<code>refresh</code>或<code>focus</code>一下。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;CodeMirror-sizer-miscalculating&quot;&gt;&lt;a href=&quot;#CodeMirror-sizer-miscalculating&quot; class=&quot;headerlink&quot; title=&quot;CodeMirror sizer miscalculatin</summary>
      
    
    
    
    
    <category term="JavaScript" scheme="http://gloomymoon.github.io/tags/JavaScript/"/>
    
    <category term="CodeMirror" scheme="http://gloomymoon.github.io/tags/CodeMirror/"/>
    
  </entry>
  
  <entry>
    <title>Shanghai Disney Resort: First Raid</title>
    <link href="http://gloomymoon.github.io/2017/04/04/Shanghai-Disney-Resort-First-Raid/"/>
    <id>http://gloomymoon.github.io/2017/04/04/Shanghai-Disney-Resort-First-Raid/</id>
    <published>2017-04-04T11:17:03.000Z</published>
    <updated>2017-04-18T00:36:35.634Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Shanghai-Disney-Resort-First-Raid"><a href="#Shanghai-Disney-Resort-First-Raid" class="headerlink" title="Shanghai Disney Resort: First Raid"></a>Shanghai Disney Resort: First Raid</h2><h3 id="0-首刷行程"><a href="#0-首刷行程" class="headerlink" title="0. 首刷行程"></a>0. 首刷行程</h3><p>LP买了春季季票，计划用来遛娃。借着清明小长假，一家人一起进行了首刷（之前小畏已经去过2次，但是大为有课还没有去过）。大致行程如下：<br>4月3日下午：花车巡游、泰山剧场、古迹探险营旁边的儿童乐园、海妖复仇号、戏水滩、爱丽丝迷宫、漫威英雄总部、烟火灯光秀，9点离园；<br>4月4日8点抵园：小飞侠×2、晶海奇航、蜂蜜罐、小矮人矿坑FP、加勒比海盗排队25分钟、风暴来领剧场、雪佛兰、急速光轮FP、古迹探险营排队30分钟、冰雪奇缘演唱会，最后在花车巡游前出园，刚刚好一个整天的时间。</p><p>利益相关：个人不是资深迪斯尼粉，虽然小时候是看着这些动画长大的，记忆中人物的形象很鲜明（包括李扬老师的配音）但是故事细节模糊不清，那个时候好看的进口动画片很多，不像现在的国产动画都很粗糙。但是迪斯尼收购的Pixer、漫威、加勒比、卢卡斯影业都是响当当IP，对这些会有更多的共鸣。</p><h3 id="1-景观"><a href="#1-景观" class="headerlink" title="1. 景观"></a>1. 景观</h3><p>大家注意到的大多是全球最大的迪斯尼城堡、占用巨大的面积、40亿美元的建资。而体现一个游乐园的能力和用心程度往往在于细节：无论是景观设施的细节还是人员服务的细节。</p><p><strong>栏杆</strong><br>印象最深刻的景观细节是所有走道两边的栏杆，不同区域、不同排队区都有符合各自风格特色的栏杆和临时门。<br>探险岛原始风格木栏杆：<br><img src="" alt="此处应有图"></p><p>明日世界略带气雾效果的玻璃栏杆：<br><img src="" alt="此处应有图"></p><p>宝藏湾破旧城墙效果的石栏：<br><img src="" alt="此处应有图"></p><p><strong>下水道盖</strong><br>迪斯尼主城堡最中间巨大玻璃吊灯厅下，四副琉璃壁画前面不同花纹的下水道盖<br><img src="" alt="此处应有图"></p><p>除此以外还有各种圆形、方形的铁盖<br><img src="" alt="此处应有图"></p><p><strong>排队区的布景</strong><br>加勒比海盗排队区布置的各种布景<br><img src="" alt="此处应有图"></p><p>古迹探险营排队区的各种探险屋布景，甚至还有照相机的暗房<br><img src="" alt="此处应有图"></p><p><strong>餐厅</strong><br>Barbossa烤肉店内部的装饰非常有代入感<br><img src="" alt="此处应有图"></p><p>餐厅外部的街景，小巷上空还挂着晾晒的衣服<br><img src="" alt="此处应有图"></p><p><strong>街景</strong><br>宝藏湾路灯上挂着关押着海盗的铁笼子，里面的骷髅拿着非常有意思的牌子<br><img src="" alt="此处应有图"></p><h3 id="2-服务"><a href="#2-服务" class="headerlink" title="2. 服务"></a>2. 服务</h3><p><strong>入口</strong><br>很多游客要抢FP，所以一入园就跑步前进，迪斯尼在入口大路两边安排了很多员工，手举警示标语，这笔简单的插块指示牌或者是放个录音喇叭给人的感觉要亲切很多。<br><img src="" alt="此处应有图"></p><p><strong>街摊</strong><br>迪斯尼园内有很多礼品和食物的小摊位，但是没有一个摊位有播放促销语音、或者员工招揽顾客的情况，他们只是微笑着等待你自投罗网。<br><img src="" alt="此处应有图"></p><p><strong>排队区</strong><br>人们项目的排队区会有员工在地上画迪斯尼动画人物肖像，略微降低排队的烦躁感。<br><img src="" alt="此处应有图"><br>主路上也会有人用树叶排除Micky的头像造型供大家拍照。<br><img src="" alt="此处应有图"></p><p><strong>游乐设施服务人员</strong><br>人员服务态度层次不一，但是基本上还是较为和善的。</p><h3 id="3-游乐项目"><a href="#3-游乐项目" class="headerlink" title="3. 游乐项目"></a>3. 游乐项目</h3><p>游乐项目总体来说更多考虑小朋友的偏好，除了极速光轮其他小畏大小的都能游玩，小矮人过山车、飞跃地平线、雷鸣山漂流确实非常值得排队游玩。但是印象最深的反而是加勒比海盗，内景布置和动画都非常精彩，细节菜单满满，值得二刷三刷。<br><img src="" alt="此处应有图"></p><p>维尼熊的密封罐不能自己转动，中间的方向盘成为摆设，有点遗憾。<br><img src="" alt="此处应有图"></p><p>巴斯光年小孩子喜欢，激光枪有红外瞄准，上下车有并行布道，对小朋友的考虑很周全<br><img src="" alt="此处应有图"></p><p>漫威英雄世界内容不少，但是没什么新意，钢铁侠装甲1-5代和反浩克装甲看上去玩具感十足，比较粗糙，资深粉肯定不满意。据说美队比较帅，但是去的那次比较晚已经下班了。<br><img src="" alt="此处应有图"></p><p>星战远征基地也一样只是一些布景和道具摆设，场馆里的人还没有Lego拼砌屋里的人多。千年隼驾驶舱布景粗糙。Lord Vader被关在小栏杆后面踱来踱去感觉好动物园里的百兽之王，难道不是应该随机在园区里带着501的暴风兵高冷地巡逻么。R2大神也毫无人气，可怜小朋友们都不认识，反倒是和小猴子凯洛伦拍照的人更多。<br><img src="" alt="此处应有图"></p><p>小飞侠、晶海奇航、古迹探险营、红皇后的花园迷宫都有不少亮点。<br><img src="" alt="此处应有图"></p><p>雪佛兰是个神马玩也儿。<br>[此处没有图]</p><h3 id="4-表演秀"><a href="#4-表演秀" class="headerlink" title="4. 表演秀"></a>4. 表演秀</h3><p><strong>花车巡游</strong><br>整个过程中演职人员都非常敬业，全程跳舞、互动、微笑，不管是扮演米妮还是为米妮推车的服务员表演都同样认真、到位。清楚地记得花木兰花车后面的女士兵后颈上黝黑的肤色，就能够知道她们经历了怎样的辛劳。<br><img src="" alt="此处应有图"></p><p><strong>泰山</strong><br>结合中古杂技、飞人，演员貌似没有带钢丝，非常专业。<br><img src="" alt="此处应有图"></p><p><strong>冰雪奇缘</strong><br>老外说中文还差点，而且全程中文歌词，有点跟不上。<br><img src="" alt="此处应有图"></p><p><strong>杰克船长大冒险</strong><br>开场白有点长，而且中国观众互动比较弱，但是后面剧场表演很出色，最后的特技表演很精彩。<br><img src="" alt="此处应有图"></p><p><strong>大白活力秀</strong><br>中国观众互动比较弱，效果不是很理想。<br><img src="" alt="此处应有图"></p><h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h3><p>迪斯尼乐园不是那种安排一天满满的形成、赶着排队拿FP就能体验的乐园，正如他的官方名字，是一个度假村。<br>比较理想的玩法是多去几次，每次看人数尽量选择排队少的项目，FP留给特别想玩的项目，多留意一些路边没人的小景观点，比如明石台就几乎没人。多了解迪斯尼的电影动画，能够发现一些细节的隐藏元素，也是非常有意思的。<br><img src="" alt="此处应有图"></p><p>毕竟迪斯尼主打的是梦幻乐园，到了这里就把自己当作一个孩子，发现美、相信美，度过快乐魔幻的一天才是。</p><h3 id="One-more-thing"><a href="#One-more-thing" class="headerlink" title="One more thing"></a>One more thing</h3><p>你在迪斯尼有看到过监控摄像头吗？反正我是没看到，细思恐极。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Shanghai-Disney-Resort-First-Raid&quot;&gt;&lt;a href=&quot;#Shanghai-Disney-Resort-First-Raid&quot; class=&quot;headerlink&quot; title=&quot;Shanghai Disney Resort: Fi</summary>
      
    
    
    
    
    <category term="Disneyland" scheme="http://gloomymoon.github.io/tags/Disneyland/"/>
    
  </entry>
  
  <entry>
    <title>Teach Your Kids to Code: Pre-Course I</title>
    <link href="http://gloomymoon.github.io/2017/03/30/Teach-Your-Kids-to-Code-Pre-Course-I/"/>
    <id>http://gloomymoon.github.io/2017/03/30/Teach-Your-Kids-to-Code-Pre-Course-I/</id>
    <published>2017-03-30T08:23:16.000Z</published>
    <updated>2017-03-30T08:23:16.606Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>Python Machine Learning VII</title>
    <link href="http://gloomymoon.github.io/2017/03/24/Python-Machine-Learning-VII/"/>
    <id>http://gloomymoon.github.io/2017/03/24/Python-Machine-Learning-VII/</id>
    <published>2017-03-24T07:05:52.000Z</published>
    <updated>2017-03-27T07:05:57.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Combining-Different-Models-for-Ensemble-Learning"><a href="#Combining-Different-Models-for-Ensemble-Learning" class="headerlink" title="Combining Different Models for Ensemble Learning"></a>Combining Different Models for Ensemble Learning</h2><p>本章将基于前几章学到的内容和技术，用多个的分类器构建成一个分类器，来获得比任何单一模型更好的效果。</p><ul><li>基于多数投票算法的预测</li><li>通过随机抽取组合训练数据集降低过拟合</li><li>通过学习弱模型（weak learners）的差错构建更强的模型</li></ul><h3 id="Learning-with-ensembles"><a href="#Learning-with-ensembles" class="headerlink" title="Learning with ensembles"></a>Learning with ensembles</h3><p>集成算法（ensemble methods）的目的是将多个不同类型的分类器组成一个分类器，获得优于任何一个单个分类器的泛化表现。集成算法有多种技术，本节我们将介绍最基本的方法并了解为何能够获得较好的泛化性能。</p><p>最流行的集成算法是多数投票算法，原理是每个样本的最终分类取决于50%以上的分类器预测。严格意义上，多数投票仅针对与二元分类。但也能够轻易地改造用于多元分类问题，称作相对多数投票（plurality voting）。</p><p>从训练数据，我们从训练m个不同的分类器（C1,…,Cm），例如决策树、支持向量机、逻辑回归等，当然可以使用同个分类器在不同的训练子集上学习。下图是一个使用多数投票的示意图：<br><img src="/img/PythonMachineLearningVII_01.png" alt=""></p><h3 id="Implementing-a-simple-majority-vote-classifier"><a href="#Implementing-a-simple-majority-vote-classifier" class="headerlink" title="Implementing a simple majority vote classifier"></a>Implementing a simple majority vote classifier</h3><p>让我们先实现一个简单的集成分类器算法作为热身。该算法支持基于各自的置信度权重来组合不同的分类器算法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator</span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> ClassifierMixin</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> six</span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> clone</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> _name_estimators</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MajorityVoteClassifier</span><span class="params">(BaseEstimator, ClassifierMixin)</span>:</span></span><br><span class="line">    <span class="string">""" A majority vote ensemble classifier</span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    classifiers : array-like, shape = [n_classifiers]</span></span><br><span class="line"><span class="string">      Different classifiers for the ensemble</span></span><br><span class="line"><span class="string">      </span></span><br><span class="line"><span class="string">    vote : str, &#123;'classlabel', 'probability'&#125;</span></span><br><span class="line"><span class="string">      Default: 'classlabel'</span></span><br><span class="line"><span class="string">      If 'classlabel' the prediction is based on the argmax of class labels.</span></span><br><span class="line"><span class="string">      Else if 'probability', the argmax of the sum of propabilities is used</span></span><br><span class="line"><span class="string">      to predict the class label (recommended for calibrated classifiers).</span></span><br><span class="line"><span class="string">      </span></span><br><span class="line"><span class="string">    weights : array-like, shape = [n_classifiers]</span></span><br><span class="line"><span class="string">      Optional, default: None</span></span><br><span class="line"><span class="string">      If a list of `int` or `float` values are provided, the classifiers are weighted by</span></span><br><span class="line"><span class="string">      importance; Uses uniform weights if `weights=None`.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, classifiers, vote=<span class="string">'classlabel'</span>, weights=None)</span>:</span></span><br><span class="line">        self.classifiers = classifiers</span><br><span class="line">        self.named_classifiers = &#123;key: value <span class="keyword">for</span> key, value <span class="keyword">in</span> </span><br><span class="line">                                  _name_estimators(classifiers)&#125;</span><br><span class="line">        self.vote = vote</span><br><span class="line">        self.weights = weights</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">        <span class="string">""" Fit classifiers.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like, spars matrix&#125;,</span></span><br><span class="line"><span class="string">            shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">            Matrix of training samples.</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        y : array-like, shape = [n_samples]</span></span><br><span class="line"><span class="string">            Vector of target class labels.</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        self : object</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># Use LabelEncoder to ensure class labels start</span></span><br><span class="line">        <span class="comment"># with 0, which is important for np.argmax</span></span><br><span class="line">        <span class="comment"># call in self.predict</span></span><br><span class="line">        self.lablenc_ = LabelEncoder()</span><br><span class="line">        self.lablenc_.fit(y)</span><br><span class="line">        self.classes_ = self.lablenc_.classes_</span><br><span class="line">        self.classifiers_ = []</span><br><span class="line">        <span class="keyword">for</span> clf <span class="keyword">in</span> self.classifiers:</span><br><span class="line">            fitted_clf = clone(clf).fit(X, self.lablenc_.transform(y))</span><br><span class="line">            self.classifiers_.append(fitted_clf)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">""" Predict class labels fro X.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like, sparse matrix&#125;,</span></span><br><span class="line"><span class="string">            Shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">            Matrix of traning samples.</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        maj_vote : array-like, shape = [n_samples]</span></span><br><span class="line"><span class="string">            Predicted class labels.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> self.vote == <span class="string">'probability'</span>:</span><br><span class="line">            may_vote = np.argmax(self.predict_proba(X), axis=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># 'classlabel' vote</span></span><br><span class="line">            <span class="comment"># Collect results from clf.predict calls</span></span><br><span class="line">            predictions = np.asarray([clf.predict(X) <span class="keyword">for</span> clf <span class="keyword">in</span></span><br><span class="line">                                      self.classifiers_]).T</span><br><span class="line">            maj_vote = np.apply_along_axis(<span class="keyword">lambda</span> x: np.argmax(np.bincount(x,</span><br><span class="line">                                                                           weights=self.weights)),</span><br><span class="line">                                           axis=<span class="number">1</span>,</span><br><span class="line">                                           arr=predictions)</span><br><span class="line">        maj_vote = self.lablenc_.inverse_transform(maj_vote)</span><br><span class="line">        <span class="keyword">return</span> maj_vote</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict_proba</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">""" Predict class probabilities for X.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like, sparse matrix&#125;,</span></span><br><span class="line"><span class="string">            shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">            Training vectors, where n_samples is the number of samples and</span></span><br><span class="line"><span class="string">            n_features is the number of features.</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        avg_proba : array-like,</span></span><br><span class="line"><span class="string">            shape = [n_samples, n_classes]</span></span><br><span class="line"><span class="string">            Weighted average probability for each class per sample.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        probas = np.asarray([clf.predict_proba(X) <span class="keyword">for</span> clf <span class="keyword">in</span> self.classifiers_])</span><br><span class="line">        avg_proba = np.average(probas,</span><br><span class="line">                               axis=<span class="number">0</span>,</span><br><span class="line">                               weights=self.weights)</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> avg_proba</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_params</span><span class="params">(self, deep=True)</span>:</span></span><br><span class="line">        <span class="string">""" Get classifier parameter names for GridSearch """</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> deep:</span><br><span class="line">            <span class="keyword">return</span> super(MajorityVoteClassifier, self).get_params(deep=<span class="keyword">False</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            out = self.named_classifiers.copy()</span><br><span class="line">            <span class="keyword">for</span> name, step <span class="keyword">in</span>\</span><br><span class="line">                six.iteritems(self.named_classifiers):</span><br><span class="line">                <span class="keyword">for</span> key, value <span class="keyword">in</span> six.iteritems(step.get_params(deep=<span class="keyword">True</span>)):</span><br><span class="line">                    out[<span class="string">'%s__%s'</span> % (name, key)] = value</span><br><span class="line">            <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure></p><p><strong>Combining different algorithms for classification with majority vote</strong><br>为了让分类工作更具挑战性，我们选取Iris数据中的两个特征<code>sepal width</code>和<code>petal lengeh</code>，并且仅仅区分两个分类<code>Iris-Versicolor</code>和<code>Iris-Virginica</code>，并计算ROC AUC。<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn <span class="built_in">import</span> datasets</span><br><span class="line">from sklearn.cross_validation <span class="built_in">import</span> train_test_split</span><br><span class="line">from sklearn.preprocessing <span class="built_in">import</span> StandardScaler, LabelEncoder</span><br><span class="line"><span class="attr">iris</span> = datasets.load_iris()</span><br><span class="line">X, <span class="attr">y</span> = iris.data[<span class="number">50</span>:, [<span class="number">1</span>, <span class="number">2</span>]], iris.target[<span class="number">50</span>:]</span><br><span class="line"><span class="attr">le</span> = LabelEncoder()</span><br><span class="line"><span class="attr">y</span> = le.fit_transform(y)</span><br><span class="line">X_train, X_test, y_train, <span class="attr">y_test</span> = train_test_split(X, y,</span><br><span class="line">                                                   <span class="attr">test_size=0.5,</span></span><br><span class="line">                                                  <span class="attr">random_state=1)</span></span><br></pre></td></tr></table></figure></p><p>现在我们来训练三个不同的分类器：逻辑回归、决策树和KNN，通过10-fold交叉检验来看下各自的表现。<br><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">clf1 = LogisticRegression(penalty=<span class="string">'l2'</span>, C=<span class="number">0.001</span>, random_state=<span class="number">0</span>)</span><br><span class="line">clf2 = DecisionTreeClassifier(max_depth=<span class="number">1</span>, criterion=<span class="string">'entropy'</span>, random_state=<span class="number">0</span>)</span><br><span class="line">clf3 = KNeighborsClassifier(n_neighbors=<span class="number">1</span>, p=<span class="number">2</span>, metric=<span class="string">'minkowski'</span>)</span><br><span class="line">pipe1 = Pipeline([[<span class="string">'sc'</span>, StandardScaler()], [<span class="string">'clf'</span>, clf1]])</span><br><span class="line">pipe3 = Pipeline([[<span class="string">'sc'</span>, StandardScaler()], [<span class="string">'clf'</span>, clf3]])</span><br><span class="line">clf_labels = [<span class="string">'Logistic Regression'</span>, <span class="string">'Decision Tree'</span>, <span class="string">'KNN'</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'10-fold cross validation:\n'</span>)</span><br><span class="line"><span class="keyword">for</span> clf, label <span class="keyword">in</span> zip([pipe1, clf2, pipe3], clf_labels):</span><br><span class="line">    scores = cross_val_score(estimator=clf,</span><br><span class="line">                             X=X_train,</span><br><span class="line">                             y=y_train,</span><br><span class="line">                             cv=<span class="number">10</span>,</span><br><span class="line">                             scoring=<span class="string">'roc_auc'</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"ROC SUC: %0.2f (+/- %0.2f) [%s]"</span> % (scores.mean(), scores.std(), label))</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">10-fold</span> <span class="selector-tag">cross</span> <span class="selector-tag">validation</span>:</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">ROC</span> <span class="selector-tag">SUC</span>: <span class="selector-tag">0</span><span class="selector-class">.92</span> (+/- <span class="number">0.20</span>) <span class="selector-attr">[Logistic Regression]</span></span><br><span class="line"><span class="selector-tag">ROC</span> <span class="selector-tag">SUC</span>: <span class="selector-tag">0</span><span class="selector-class">.92</span> (+/- <span class="number">0.15</span>) <span class="selector-attr">[Decision Tree]</span></span><br><span class="line"><span class="selector-tag">ROC</span> <span class="selector-tag">SUC</span>: <span class="selector-tag">0</span><span class="selector-class">.93</span> (+/- <span class="number">0.10</span>) <span class="selector-attr">[KNN]</span></span><br></pre></td></tr></table></figure></p><p>接下来用我们的<code>MajorityVoteClassifier</code>用多数投票算法来整合不同的分类器：<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mv_clf</span> = MajorityVoteClassifier(<span class="attr">classifiers=[pipe1,</span> clf2, pipe3])</span><br><span class="line">clf_labels += ['Majority Voting']</span><br><span class="line"><span class="attr">all_clf</span> = [pipe1, clf2, pipe3, mv_clf]</span><br><span class="line">for clf, label <span class="keyword">in</span> zip(all_clf, clf_labels):</span><br><span class="line">    <span class="attr">scores</span> = cross_val_score(<span class="attr">estimator=clf,</span></span><br><span class="line">                             <span class="attr">X=X_train,</span></span><br><span class="line">                             <span class="attr">y=y_train,</span></span><br><span class="line">                             <span class="attr">cv=10,</span></span><br><span class="line">                             <span class="attr">scoring='roc_auc')</span></span><br><span class="line">    print(<span class="string">"Accuracy: %0.2f (+/- %0.2f) [%s]"</span> % (scores.mean(), scores.std(), label))</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Accuracy</span>: <span class="number">0.92</span> (+/- <span class="number">0.20</span>) [Logistic Regression]</span><br><span class="line"><span class="keyword">Accuracy</span>: <span class="number">0.92</span> (+/- <span class="number">0.15</span>) [Decision Tree]</span><br><span class="line"><span class="keyword">Accuracy</span>: <span class="number">0.93</span> (+/- <span class="number">0.10</span>) [KNN]</span><br><span class="line"><span class="keyword">Accuracy</span>: <span class="number">0.97</span> (+/- <span class="number">0.10</span>) [<span class="keyword">Majority</span> Voting]</span><br></pre></td></tr></table></figure></p><h3 id="Evaluating-and-tuning-the-ensemble-classifier"><a href="#Evaluating-and-tuning-the-ensemble-classifier" class="headerlink" title="Evaluating and tuning the ensemble classifier"></a>Evaluating and tuning the ensemble classifier</h3><p>通过ROC曲线看下多数投票算法在未知数据上的表现如何：<br><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">from sklearn.metrics import roc_curve, auc</span><br><span class="line">colors = [<span class="string">'black'</span>, <span class="string">'orange'</span>, <span class="string">'blue'</span>, <span class="string">'green'</span>]</span><br><span class="line">linestyles = [<span class="string">':'</span>, <span class="string">'--'</span>, <span class="string">'-.'</span>, <span class="string">'-'</span>]</span><br><span class="line"><span class="keyword">for</span> clf, <span class="keyword">label</span>, clr, ls <span class="keyword">in</span> zip(all_clf, clf_labels, colors, linestyles):</span><br><span class="line">    # assuming the <span class="keyword">label</span> <span class="keyword">of</span> the positive <span class="keyword">class</span> <span class="keyword">is</span> <span class="number">1</span></span><br><span class="line">    y_pred = clf.fit(X_train, y_train).predict_proba(X_test)[:, <span class="number">1</span>]</span><br><span class="line">    fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_pred)</span><br><span class="line">    roc_auc = auc(x=fpr, y=tpr)</span><br><span class="line">    plt.plot(fpr, tpr, color=clr, linestyle=ls,</span><br><span class="line">             <span class="keyword">label</span>=<span class="string">'%s (auc = %0.2f)'</span> % (<span class="keyword">label</span>, roc_auc))</span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">         linestyle=<span class="string">'--'</span>,</span><br><span class="line">         color=<span class="string">'gray'</span>,</span><br><span class="line">         linewidth=<span class="number">2</span>)</span><br><span class="line">plt.xlim([-<span class="number">0.1</span>, <span class="number">1.1</span>])</span><br><span class="line">plt.ylim([-<span class="number">0.1</span>, <span class="number">1.1</span>])</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel(<span class="string">'False Positive Rate'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'True Positive Rate'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningVII_02.png" alt=""><br>集成算法在测试机上表现不错（ROC AUC=0.95）。<br>因为我们选取了仅仅两个特征，可以看下集成算法的分类界面如何，因为模型中已经带有标准化管道，这里的标准化是为了显示。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">sc = StandardScaler()</span><br><span class="line">X_train_std = sc.fit_transform(X_train)</span><br><span class="line"><span class="keyword">from</span> itertools import product</span><br><span class="line">x_min = X_train_std[:, 0].min() - 1</span><br><span class="line">x_max = X_train_std[:, 0].max() + 1</span><br><span class="line">y_min = X_train_std[:, 1].min() - 1</span><br><span class="line">y_max = X_train_std[:, 1].max() + 1</span><br><span class="line"></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),</span><br><span class="line">                     np.arange(y_min, y_max, 0.1))</span><br><span class="line">f, axarr = plt.subplots(<span class="attribute">nrows</span>=2, <span class="attribute">ncols</span>=2, <span class="attribute">sharex</span>=<span class="string">'col'</span>, <span class="attribute">sharey</span>=<span class="string">'row'</span>,</span><br><span class="line">                        figsize=(7, 5))</span><br><span class="line"><span class="keyword">for</span> idx, clf, tt <span class="keyword">in</span> zip(product([0, 1], [0, 1]), all_clf, clf_labels):</span><br><span class="line">    clf.fit(X_train_std, y_train)</span><br><span class="line">    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line">    axarr[idx[0], idx[1]].contourf(xx, yy, Z, <span class="attribute">alpha</span>=0.3)</span><br><span class="line">    axarr[idx[0], idx[1]].scatter(X_train_std[<span class="attribute">y_train</span>==0, 0],</span><br><span class="line">                                  X_train_std[<span class="attribute">y_train</span>==0, 1],</span><br><span class="line">                                  <span class="attribute">c</span>=<span class="string">'blue'</span>,</span><br><span class="line">                                  <span class="attribute">marker</span>=<span class="string">'^'</span>,</span><br><span class="line">                                  <span class="attribute">s</span>=50)</span><br><span class="line">    axarr[idx[0], idx[1]].scatter(X_train_std[<span class="attribute">y_train</span>==1, 0],</span><br><span class="line">                                  X_train_std[<span class="attribute">y_train</span>==1, 1],</span><br><span class="line">                                  <span class="attribute">c</span>=<span class="string">'red'</span>,</span><br><span class="line">                                  <span class="attribute">marker</span>=<span class="string">'o'</span>,</span><br><span class="line">                                  <span class="attribute">s</span>=50)</span><br><span class="line">    axarr[idx[0], idx[1]].set_title(tt)</span><br><span class="line">plt.text(-3.5, -4.5, <span class="attribute">s</span>=<span class="string">'Sepal width [standardized]'</span>,</span><br><span class="line">         <span class="attribute">ha</span>=<span class="string">'center'</span>, <span class="attribute">va</span>=<span class="string">'center'</span>, <span class="attribute">fontsize</span>=12)</span><br><span class="line">plt.text(-10.5, 4.5, <span class="attribute">s</span>=<span class="string">'Petal length [standardized]'</span>,</span><br><span class="line">         <span class="attribute">ha</span>=<span class="string">'center'</span>, <span class="attribute">va</span>=<span class="string">'center'</span>, <span class="attribute">fontsize</span>=12, <span class="attribute">rotation</span>=90)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningVII_03.png" alt=""></p><p>在我们尝试调试集成算法中每个分类器参数时。可以调用<code>get_params</code>方法查看<code>GridSearch</code>对象内部参数的使用方法：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">mv_clf</span><span class="selector-class">.get_params</span>()</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">'decisiontreeclassifier'</span>: DecisionTreeClassifier(class_weight=<span class="keyword">None</span>, criterion=<span class="string">'entropy'</span>, max_depth=<span class="number">1</span>,</span><br><span class="line">             max_features=<span class="keyword">None</span>, max_leaf_nodes=<span class="keyword">None</span>,</span><br><span class="line">             min_impurity_split=<span class="number">1e-07</span>, min_samples_leaf=<span class="number">1</span>,</span><br><span class="line">             min_samples_split=<span class="number">2</span>, min_weight_fraction_leaf=<span class="number">0.0</span>,</span><br><span class="line">             presort=<span class="keyword">False</span>, random_state=<span class="number">0</span>, splitter=<span class="string">'best'</span>),</span><br><span class="line"> <span class="string">'decisiontreeclassifier__class_weight'</span>: <span class="keyword">None</span>,</span><br><span class="line"> <span class="string">'decisiontreeclassifier__criterion'</span>: <span class="string">'entropy'</span>,</span><br><span class="line"> <span class="string">'decisiontreeclassifier__max_depth'</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">'decisiontreeclassifier__max_features'</span>: <span class="keyword">None</span>,</span><br><span class="line"> <span class="string">'decisiontreeclassifier__max_leaf_nodes'</span>: <span class="keyword">None</span>,</span><br><span class="line"> <span class="string">'decisiontreeclassifier__min_impurity_split'</span>: <span class="number">1e-07</span>,</span><br><span class="line"> <span class="string">'decisiontreeclassifier__min_samples_leaf'</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">'decisiontreeclassifier__min_samples_split'</span>: <span class="number">2</span>,</span><br><span class="line"> <span class="string">'decisiontreeclassifier__min_weight_fraction_leaf'</span>: <span class="number">0.0</span>,</span><br><span class="line"> <span class="string">'decisiontreeclassifier__presort'</span>: <span class="keyword">False</span>,</span><br><span class="line"> <span class="string">'decisiontreeclassifier__random_state'</span>: <span class="number">0</span>,</span><br><span class="line"> <span class="string">'decisiontreeclassifier__splitter'</span>: <span class="string">'best'</span>,</span><br><span class="line"> <span class="string">'pipeline-1'</span>: Pipeline(steps=[[<span class="string">'sc'</span>, StandardScaler(copy=<span class="keyword">True</span>, with_mean=<span class="keyword">True</span>, with_std=<span class="keyword">True</span>)], [<span class="string">'clf'</span>, LogisticRegression(C=<span class="number">0.001</span>, class_weight=<span class="keyword">None</span>, dual=<span class="keyword">False</span>, fit_intercept=<span class="keyword">True</span>,</span><br><span class="line">           intercept_scaling=<span class="number">1</span>, max_iter=<span class="number">100</span>, multi_class=<span class="string">'ovr'</span>, n_jobs=<span class="number">1</span>,</span><br><span class="line">           penalty=<span class="string">'l2'</span>, random_state=<span class="number">0</span>, solver=<span class="string">'liblinear'</span>, tol=<span class="number">0.0001</span>,</span><br><span class="line">           verbose=<span class="number">0</span>, warm_start=<span class="keyword">False</span>)]]),</span><br><span class="line"> <span class="string">'pipeline-1__clf'</span>: LogisticRegression(C=<span class="number">0.001</span>, class_weight=<span class="keyword">None</span>, dual=<span class="keyword">False</span>, fit_intercept=<span class="keyword">True</span>,</span><br><span class="line">           intercept_scaling=<span class="number">1</span>, max_iter=<span class="number">100</span>, multi_class=<span class="string">'ovr'</span>, n_jobs=<span class="number">1</span>,</span><br><span class="line">           penalty=<span class="string">'l2'</span>, random_state=<span class="number">0</span>, solver=<span class="string">'liblinear'</span>, tol=<span class="number">0.0001</span>,</span><br><span class="line">           verbose=<span class="number">0</span>, warm_start=<span class="keyword">False</span>),</span><br><span class="line"> <span class="string">'pipeline-1__clf__C'</span>: <span class="number">0.001</span>,</span><br><span class="line"> <span class="string">'pipeline-1__clf__class_weight'</span>: <span class="keyword">None</span>,</span><br><span class="line"> <span class="string">'pipeline-1__clf__dual'</span>: <span class="keyword">False</span>,</span><br><span class="line"> <span class="string">'pipeline-1__clf__fit_intercept'</span>: <span class="keyword">True</span>,</span><br><span class="line"> <span class="string">'pipeline-1__clf__intercept_scaling'</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">'pipeline-1__clf__max_iter'</span>: <span class="number">100</span>,</span><br><span class="line"> <span class="string">'pipeline-1__clf__multi_class'</span>: <span class="string">'ovr'</span>,</span><br><span class="line"> <span class="string">'pipeline-1__clf__n_jobs'</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">'pipeline-1__clf__penalty'</span>: <span class="string">'l2'</span>,</span><br><span class="line"> <span class="string">'pipeline-1__clf__random_state'</span>: <span class="number">0</span>,</span><br><span class="line"> <span class="string">'pipeline-1__clf__solver'</span>: <span class="string">'liblinear'</span>,</span><br><span class="line"> <span class="string">'pipeline-1__clf__tol'</span>: <span class="number">0.0001</span>,</span><br><span class="line"> <span class="string">'pipeline-1__clf__verbose'</span>: <span class="number">0</span>,</span><br><span class="line"> <span class="string">'pipeline-1__clf__warm_start'</span>: <span class="keyword">False</span>,</span><br><span class="line"> <span class="string">'pipeline-1__sc'</span>: StandardScaler(copy=<span class="keyword">True</span>, with_mean=<span class="keyword">True</span>, with_std=<span class="keyword">True</span>),</span><br><span class="line"> <span class="string">'pipeline-1__sc__copy'</span>: <span class="keyword">True</span>,</span><br><span class="line"> <span class="string">'pipeline-1__sc__with_mean'</span>: <span class="keyword">True</span>,</span><br><span class="line"> <span class="string">'pipeline-1__sc__with_std'</span>: <span class="keyword">True</span>,</span><br><span class="line"> <span class="string">'pipeline-1__steps'</span>: [[<span class="string">'sc'</span>,</span><br><span class="line">   StandardScaler(copy=<span class="keyword">True</span>, with_mean=<span class="keyword">True</span>, with_std=<span class="keyword">True</span>)],</span><br><span class="line">  [<span class="string">'clf'</span>,</span><br><span class="line">   LogisticRegression(C=<span class="number">0.001</span>, class_weight=<span class="keyword">None</span>, dual=<span class="keyword">False</span>, fit_intercept=<span class="keyword">True</span>,</span><br><span class="line">             intercept_scaling=<span class="number">1</span>, max_iter=<span class="number">100</span>, multi_class=<span class="string">'ovr'</span>, n_jobs=<span class="number">1</span>,</span><br><span class="line">             penalty=<span class="string">'l2'</span>, random_state=<span class="number">0</span>, solver=<span class="string">'liblinear'</span>, tol=<span class="number">0.0001</span>,</span><br><span class="line">             verbose=<span class="number">0</span>, warm_start=<span class="keyword">False</span>)]],</span><br><span class="line"> <span class="string">'pipeline-2'</span>: Pipeline(steps=[[<span class="string">'sc'</span>, StandardScaler(copy=<span class="keyword">True</span>, with_mean=<span class="keyword">True</span>, with_std=<span class="keyword">True</span>)], [<span class="string">'clf'</span>, KNeighborsClassifier(algorithm=<span class="string">'auto'</span>, leaf_size=<span class="number">30</span>, metric=<span class="string">'minkowski'</span>,</span><br><span class="line">            metric_params=<span class="keyword">None</span>, n_jobs=<span class="number">1</span>, n_neighbors=<span class="number">1</span>, p=<span class="number">2</span>,</span><br><span class="line">            weights=<span class="string">'uniform'</span>)]]),</span><br><span class="line"> <span class="string">'pipeline-2__clf'</span>: KNeighborsClassifier(algorithm=<span class="string">'auto'</span>, leaf_size=<span class="number">30</span>, metric=<span class="string">'minkowski'</span>,</span><br><span class="line">            metric_params=<span class="keyword">None</span>, n_jobs=<span class="number">1</span>, n_neighbors=<span class="number">1</span>, p=<span class="number">2</span>,</span><br><span class="line">            weights=<span class="string">'uniform'</span>),</span><br><span class="line"> <span class="string">'pipeline-2__clf__algorithm'</span>: <span class="string">'auto'</span>,</span><br><span class="line"> <span class="string">'pipeline-2__clf__leaf_size'</span>: <span class="number">30</span>,</span><br><span class="line"> <span class="string">'pipeline-2__clf__metric'</span>: <span class="string">'minkowski'</span>,</span><br><span class="line"> <span class="string">'pipeline-2__clf__metric_params'</span>: <span class="keyword">None</span>,</span><br><span class="line"> <span class="string">'pipeline-2__clf__n_jobs'</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">'pipeline-2__clf__n_neighbors'</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">'pipeline-2__clf__p'</span>: <span class="number">2</span>,</span><br><span class="line"> <span class="string">'pipeline-2__clf__weights'</span>: <span class="string">'uniform'</span>,</span><br><span class="line"> <span class="string">'pipeline-2__sc'</span>: StandardScaler(copy=<span class="keyword">True</span>, with_mean=<span class="keyword">True</span>, with_std=<span class="keyword">True</span>),</span><br><span class="line"> <span class="string">'pipeline-2__sc__copy'</span>: <span class="keyword">True</span>,</span><br><span class="line"> <span class="string">'pipeline-2__sc__with_mean'</span>: <span class="keyword">True</span>,</span><br><span class="line"> <span class="string">'pipeline-2__sc__with_std'</span>: <span class="keyword">True</span>,</span><br><span class="line"> <span class="string">'pipeline-2__steps'</span>: [[<span class="string">'sc'</span>,</span><br><span class="line">   StandardScaler(copy=<span class="keyword">True</span>, with_mean=<span class="keyword">True</span>, with_std=<span class="keyword">True</span>)],</span><br><span class="line">  [<span class="string">'clf'</span>,</span><br><span class="line">   KNeighborsClassifier(algorithm=<span class="string">'auto'</span>, leaf_size=<span class="number">30</span>, metric=<span class="string">'minkowski'</span>,</span><br><span class="line">              metric_params=<span class="keyword">None</span>, n_jobs=<span class="number">1</span>, n_neighbors=<span class="number">1</span>, p=<span class="number">2</span>,</span><br><span class="line">              weights=<span class="string">'uniform'</span>)]]&#125;</span><br></pre></td></tr></table></figure></p><p>我们通过之前学习的网格搜索来调试下逻辑回归的参数C和决策树的深度。<br><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.grid_search import GridSearchCV</span><br><span class="line"><span class="keyword">params</span> = &#123;<span class="string">'decisiontreeclassifier__max_depth'</span>: [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">          <span class="string">'pipeline-1__clf__C'</span>: [<span class="number">0.001</span>, <span class="number">0.1</span>, <span class="number">100.0</span>]&#125;</span><br><span class="line">grid = GridSearchCV(estimator=mv_clf,</span><br><span class="line">                    param_grid=<span class="keyword">params</span>,</span><br><span class="line">                    cv=<span class="number">10</span>,</span><br><span class="line">                    scoring=<span class="string">'roc_auc'</span>)</span><br><span class="line">grid.fit(X_train, y_train)</span><br><span class="line"><span class="keyword">for</span> <span class="keyword">params</span>, mean_score, scores <span class="keyword">in</span> grid.grid_scores_:</span><br><span class="line">    print(<span class="string">"%0.3f +/- %0.2f %r"</span> % (mean_score, scores.std() / <span class="number">2</span>, <span class="keyword">params</span>))</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.967</span> +/- <span class="number">0.05</span> &#123;<span class="symbol">'decisiontreeclassifier__max_depth'</span>: <span class="number">1</span>, <span class="symbol">'pipeline</span>-<span class="number">1__</span>clf__C': <span class="number">0.001</span>&#125;</span><br><span class="line"><span class="number">0.967</span> +/- <span class="number">0.05</span> &#123;<span class="symbol">'decisiontreeclassifier__max_depth'</span>: <span class="number">1</span>, <span class="symbol">'pipeline</span>-<span class="number">1__</span>clf__C': <span class="number">0.1</span>&#125;</span><br><span class="line"><span class="number">1.000</span> +/- <span class="number">0.00</span> &#123;<span class="symbol">'decisiontreeclassifier__max_depth'</span>: <span class="number">1</span>, <span class="symbol">'pipeline</span>-<span class="number">1__</span>clf__C': <span class="number">100.0</span>&#125;</span><br><span class="line"><span class="number">0.967</span> +/- <span class="number">0.05</span> &#123;<span class="symbol">'decisiontreeclassifier__max_depth'</span>: <span class="number">2</span>, <span class="symbol">'pipeline</span>-<span class="number">1__</span>clf__C': <span class="number">0.001</span>&#125;</span><br><span class="line"><span class="number">0.967</span> +/- <span class="number">0.05</span> &#123;<span class="symbol">'decisiontreeclassifier__max_depth'</span>: <span class="number">2</span>, <span class="symbol">'pipeline</span>-<span class="number">1__</span>clf__C': <span class="number">0.1</span>&#125;</span><br><span class="line"><span class="number">1.000</span> +/- <span class="number">0.00</span> &#123;<span class="symbol">'decisiontreeclassifier__max_depth'</span>: <span class="number">2</span>, <span class="symbol">'pipeline</span>-<span class="number">1__</span>clf__C': <span class="number">100.0</span>&#125;</span><br></pre></td></tr></table></figure></p><p>当逻辑回归算法正则化参数降低时，决策树的深度已经不影响性能。由于多次使用测试数据来评估模型不是最佳实践，我们将使用另外一种集成学习方法：分袋（bagging）。</p><h3 id="Bagging-building-an-ensemble-of-classifiers-from-bootstrap-samples"><a href="#Bagging-building-an-ensemble-of-classifiers-from-bootstrap-samples" class="headerlink" title="Bagging - building an ensemble of classifiers from bootstrap samples"></a>Bagging - building an ensemble of classifiers from bootstrap samples</h3><p>分袋算法是与多数投票相关的一种集成学习算法，其示意图如下：<br><img src="/img/PythonMachineLearningVII_04.png" alt=""></p><p>分袋算法中，不使用同一个训练集来训练集成模型中的单个分类器，而是使用有放回的随机抽样样本，又称为引导聚集（bootstrap aggregating）。我们将使用Wine数据来创建一个较复杂的分类算法，这里我们仅仅考虑分类2和3，并且只适用两个特征Alcohol和Hue。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">df_wine = pd.read_csv(<span class="string">'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'</span>,</span><br><span class="line">                      header=None)</span><br><span class="line">df_wine<span class="selector-class">.columns</span> = [<span class="string">'Class label'</span>, <span class="string">'Alcohol'</span>,</span><br><span class="line">                   <span class="string">'Malic acid'</span>, <span class="string">'Ash'</span>,</span><br><span class="line">                   <span class="string">'Alcalinity of ash'</span>, </span><br><span class="line">                   <span class="string">'Magnesium'</span>, <span class="string">'Total phenols'</span>,</span><br><span class="line">                   <span class="string">'Flavanoids'</span>, <span class="string">'Nonflavanoid phenols'</span>,</span><br><span class="line">                   <span class="string">'Proanthocyanins'</span>,</span><br><span class="line">                   <span class="string">'Color intensity'</span>, <span class="string">'Hue'</span>,</span><br><span class="line">                   <span class="string">'OD280/OD315 of diluted wines'</span>,</span><br><span class="line">                   <span class="string">'Proline'</span>]</span><br><span class="line">df_wine = df_wine[df_wine[<span class="string">'Class label'</span>] != <span class="number">1</span>]</span><br><span class="line">y = df_wine[<span class="string">'Class label'</span>].values</span><br><span class="line">X = df_wine[[<span class="string">'Alcohol'</span>, <span class="string">'Hue'</span>]].values</span><br><span class="line"></span><br><span class="line">from sklearn<span class="selector-class">.preprocessing</span> import LabelEncoder</span><br><span class="line">from sklearn<span class="selector-class">.cross_validation</span> import train_test_split</span><br><span class="line">le = LabelEncoder()</span><br><span class="line">y = le.fit_transform(y)</span><br><span class="line">X_train, X_test, y_train, y_test =\</span><br><span class="line">            train_test_split(X, y, test_size=<span class="number">0.40</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p><p>我们将数据按照60：40比例分成训练和测试集后，使用scikit-learn实现的<code>BaggingClassifier</code>算法来集成500棵未剪枝的决策树，先看下单独的未剪枝决策树在训练集和测试集上的准确度。<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble <span class="built_in">import</span> BaggingClassifier</span><br><span class="line"><span class="attr">tree</span> = DecisionTreeClassifier(<span class="attr">criterion='entropy',</span> <span class="attr">max_depth=None)</span></span><br><span class="line"><span class="attr">bag</span> = BaggingClassifier(<span class="attr">base_estimator=tree,</span></span><br><span class="line">                        <span class="attr">n_estimators=500,</span></span><br><span class="line">                        <span class="attr">max_samples=1.0,</span></span><br><span class="line">                        <span class="attr">max_features=1.0,</span></span><br><span class="line">                        <span class="attr">bootstrap=True,</span></span><br><span class="line">                        <span class="attr">bootstrap_features=False,</span></span><br><span class="line">                        <span class="attr">n_jobs=1,</span></span><br><span class="line">                        <span class="attr">random_state=1)</span></span><br><span class="line"></span><br><span class="line">from sklearn.metrics <span class="built_in">import</span> accuracy_score</span><br><span class="line"><span class="attr">tree</span> = tree.fit(X_train, y_train)</span><br><span class="line"><span class="attr">y_train_pred</span> = tree.predict(X_train)</span><br><span class="line"><span class="attr">y_test_pred</span> = tree.predict(X_test)</span><br><span class="line"><span class="attr">tree_train</span> = accuracy_score(y_train, y_train_pred)</span><br><span class="line"><span class="attr">tree_test</span> = accuracy_score(y_test, y_test_pred)</span><br><span class="line">print('Decision tree train/test accuracies %.<span class="number">3</span>f/%.<span class="number">3</span>f' % </span><br><span class="line">      (tree_train, tree_test))</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Decision tree train/test accuracies <span class="number">1.000</span>/<span class="number">0.854</span></span><br></pre></td></tr></table></figure></p><p>决策树在训练集上分类全部正确，但是在测试机上精准度较低，显示出过拟合。<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bag = bag.fit(X_train, y_train)</span><br><span class="line">y_train_pred = bag.predict(X_train)</span><br><span class="line">y_test_pred = bag.predict(X_test)</span><br><span class="line">bag_train = accuracy_score(y_train, y_train_pred)</span><br><span class="line">bag_test = accuracy_score(y_test, y_test_pred)</span><br><span class="line">print('Bagging train/test accuracies %.3f/%.3f' % </span><br><span class="line">      (bag_train, bag_test))</span><br></pre></td></tr></table></figure></p><p>分袋集成算法在测试机上有更好的表现，下面我们来比较下两个算法的分类界面：<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">x_min = <span class="symbol">X_train</span>[:, <span class="number">0</span>].min() - <span class="number">1</span></span><br><span class="line">x_max = <span class="symbol">X_train</span>[:, <span class="number">0</span>].max() + <span class="number">1</span></span><br><span class="line">y_min = <span class="symbol">X_train</span>[:, <span class="number">1</span>].min() - <span class="number">1</span></span><br><span class="line">y_max = <span class="symbol">X_train</span>[:, <span class="number">1</span>].max() + <span class="number">1</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class="number">0.1</span>),</span><br><span class="line">                     np.arange(y_min, y_max, <span class="number">0.1</span>))</span><br><span class="line">f, axarr = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">2</span>,</span><br><span class="line">                        sharex=<span class="string">'col'</span>,</span><br><span class="line">                        sharey=<span class="string">'row'</span>,</span><br><span class="line">                        figsize=(<span class="number">8</span>, <span class="number">3</span>))</span><br><span class="line">for idx, clf, tt in zip([<span class="number">0</span>, <span class="number">1</span>], [tree, bag], [<span class="string">'Decision Tree'</span>, <span class="string">'Bagging'</span>]):</span><br><span class="line">    clf.fit(<span class="symbol">X_train</span>, y_train)</span><br><span class="line">    <span class="symbol">Z</span> = clf.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    <span class="symbol">Z</span> = <span class="symbol">Z</span>.reshape(xx.shape)</span><br><span class="line">    axarr[idx].contourf(xx, yy, <span class="symbol">Z</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line">    axarr[idx].scatter(<span class="symbol">X_train</span>[y_train==<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                       <span class="symbol">X_train</span>[y_train==<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                       c=<span class="string">'blue'</span>, marker=<span class="string">'^'</span>)</span><br><span class="line">    axarr[idx].scatter(<span class="symbol">X_train</span>[y_train==<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                       <span class="symbol">X_train</span>[y_train==<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       c=<span class="string">'red'</span>, marker=<span class="string">'o'</span>)</span><br><span class="line">    axarr[idx].set_title(tt)</span><br><span class="line">axarr[<span class="number">0</span>].set_ylabel(<span class="string">'Alcohol'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.text(<span class="number">10.2</span>, <span class="number">-1.2</span>, s=<span class="string">'Hue'</span>, ha=<span class="string">'center'</span>, va=<span class="string">'center'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningVII_05.png" alt=""><br>分袋算法有效降低模型的方差，但是对于降低模型的偏差没有助益。</p><h3 id="Leveraging-weak-learners-via-adaptive-boosting"><a href="#Leveraging-weak-learners-via-adaptive-boosting" class="headerlink" title="Leveraging weak learners via adaptive boosting"></a>Leveraging weak learners via adaptive boosting</h3><p>本节将讨论boosting增强算法中最普遍使用的自适应boosting（AdaBoost，Adaptive Boosting）。其增强算法的基本流程如下：</p><ol><li>从训练数据D中不放回随机抽样训练子集d1，并在其上训练一个弱模型C1</li><li>从D中不放回随机抽取第二份训练子集并加入第一次错分类的50%样本作为d2，在其上训练一个弱模型C2</li><li>在D中选取C1和C2分类不一致的样本d3，并训练第三个弱模型C3</li><li>通过多数投票算法组合三个弱模型</li></ol><p>相比分袋算法，增强算法不仅能降低偏差也能够降低方差。而AdaBoost使用整个训练集来训练弱模型，实时每次迭代将调整样本的权重，提升分类错误的样本的比例来逐步训练一个强模型。下图是一个AdaBoost分类算法的训练过程示意图：<br><img src="/img/PythonMachineLearningVII_06.png" alt=""></p><p>我们仍然使用Wine数据来训练一个AdaBoost集成分类器，通过<code>base_estimator</code>属性，我们将训练500棵决策树：<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import AdaBoostClassifier</span><br><span class="line">tree = DecisionTreeClassifier(criterion='entropy', max_depth=1)</span><br><span class="line">ada = AdaBoostClassifier(base_estimator=tree,</span><br><span class="line">                         n_estimators=500,</span><br><span class="line">                         learning_rate=0.1,</span><br><span class="line">                         random_state=0)</span><br><span class="line">tree = tree.fit(X_train, y_train)</span><br><span class="line">y_train_pred = tree.predict(X_train)</span><br><span class="line">y_test_pred = tree.predict(X_test)</span><br><span class="line">tree_train = accuracy_score(y_train, y_train_pred)</span><br><span class="line">tree_test = accuracy_score(y_test, y_test_pred)</span><br><span class="line">print('AdaBoost train/test accuracies %.3f/%.3f' %</span><br><span class="line">      (tree_train, tree_test))</span><br></pre></td></tr></table></figure></p><p>决策树在训练集上过拟合。<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ada = ada.fit(X_train, y_train)</span><br><span class="line">y_train_pred = ada.predict(X_train)</span><br><span class="line">y_test_pred = ada.predict(X_test)</span><br><span class="line">ada_train = accuracy_score(y_train, y_train_pred)</span><br><span class="line">ada_test = accuracy_score(y_test, y_test_pred)</span><br><span class="line">print('AdaBoost train/test accuracies %.3f/%.3f' %</span><br><span class="line">      (ada_train, ada_test))</span><br></pre></td></tr></table></figure></p><p>AdaBoost模型预测全部正确，但是在降低模型偏差的情况下，方差有所增加。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Combining-Different-Models-for-Ensemble-Learning&quot;&gt;&lt;a href=&quot;#Combining-Different-Models-for-Ensemble-Learning&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Machine Learning" scheme="http://gloomymoon.github.io/tags/Machine-Learning/"/>
    
    <category term="scikit-learn" scheme="http://gloomymoon.github.io/tags/scikit-learn/"/>
    
  </entry>
  
  <entry>
    <title>Python Machine Learning VI</title>
    <link href="http://gloomymoon.github.io/2017/03/22/Python-Machine-Learning-VI/"/>
    <id>http://gloomymoon.github.io/2017/03/22/Python-Machine-Learning-VI/</id>
    <published>2017-03-22T01:30:00.000Z</published>
    <updated>2017-03-24T06:53:04.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Learning-Best-Practices-for-Model-Evaluation-and-Hyperparameter-Tuning"><a href="#Learning-Best-Practices-for-Model-Evaluation-and-Hyperparameter-Tuning" class="headerlink" title="Learning Best Practices for Model Evaluation and Hyperparameter Tuning"></a>Learning Best Practices for Model Evaluation and Hyperparameter Tuning</h2><p>前面的课程我们学习了几种基本的机器学习分类算法，以及如何对数据进行预处理。本章将介绍通过调优获得更好的建模效果，以及如何评估模型的表现：</p><ul><li>获取模型表现的无偏估计量</li><li>分析诊断机器学习算法中碰到的普遍问题</li><li>模型调优</li><li>通过各种指标评估预测效果</li></ul><h3 id="Streamlining-workflows-with-pipelines"><a href="#Streamlining-workflows-with-pipelines" class="headerlink" title="Streamlining workflows with pipelines"></a>Streamlining workflows with pipelines</h3><p>之前我们接触到的预处理技术，例如标准化、主成分分析，都会将训练获得参数服用到新的数据上，比如测试数据集。本节将介绍一个超级好用的工具，scikit-learn中的Pipeline类，支持训练模型中任意多次转换并在新数据集上进行预测。</p><p><strong>Loading the Breast Cancer Wisconsin dataset</strong><br>本章节我们将使用威斯康辛乳癌数据，包含569个样本。数据前两列包含记录的唯一识别号和对应的肿瘤类型（M=恶性，B=良性），3-32列包含了30个从细胞影响计算得出的实数型变量，我们将用着30个变量来建立一个预测良性恶性肿瘤的模型。首先从UCI网站上读取数据及，并拆分成训练和测试集：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">df = pd.read_csv(<span class="string">'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'</span>, eader=None)</span><br><span class="line"></span><br><span class="line">from sklearn<span class="selector-class">.preprocessing</span> import LabelEncoder</span><br><span class="line">X = df<span class="selector-class">.loc</span>[:, <span class="number">2</span>:].values</span><br><span class="line">y = df<span class="selector-class">.loc</span>[:, <span class="number">1</span>].values</span><br><span class="line">le = LabelEncoder()</span><br><span class="line">y = le.fit_transform(y)</span><br><span class="line"></span><br><span class="line">from sklearn<span class="selector-class">.cross_validation</span> import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.20</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">le.<span class="attribute">transform</span>([<span class="string">'M'</span>, <span class="string">'B'</span>])</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">array</span><span class="params">([<span class="number">1</span>, <span class="number">0</span>], dtype=int64)</span></span></span><br></pre></td></tr></table></figure></p><p>简单的通过<code>LabelEncoder</code>类将目标分类从字符串转换为整型，1表示恶性，0表示良性。然后数据按照80:20的比例随机分为训练集和测试集。</p><p><strong>Combining transformers and estimators in a pipeline</strong><br>首先我们需要将数据标准化到同一尺度上，然后使用PCA将30维数据压缩到更低的二维子空间上。这次我们将<code>StandardScaler</code>、<code>PCA</code>、<code>LogisticRegression</code>对象全部串联到管道（pipeline）上处理：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn<span class="selector-class">.preprocessing</span> import StandardScaler</span><br><span class="line">from sklearn<span class="selector-class">.decomposition</span> import PCA</span><br><span class="line">from sklearn<span class="selector-class">.linear_model</span> import LogisticRegression</span><br><span class="line">from sklearn<span class="selector-class">.pipeline</span> import Pipeline</span><br><span class="line">pipe_lr = Pipeline([(<span class="string">'scl'</span>, StandardScaler()),</span><br><span class="line">                    (<span class="string">'pca'</span>, PCA(n_components=<span class="number">2</span>)),</span><br><span class="line">                    (<span class="string">'clf'</span>, LogisticRegression(random_state=<span class="number">1</span>))])</span><br><span class="line">pipe_lr.fit(X_train, y_train)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Test Accuracy: %.3f'</span> % pipe_lr.score(X_test, y_test)</span></span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Test </span>Accuracy: 0.947</span><br></pre></td></tr></table></figure></p><p><code>Pipeline</code>对象初始化时接受一个包含多个元祖的列表，元祖的第一个元素表示管道中每个对象的标识符，第二个元素是scikit-learn的转换器或算子。<br>管道对象的中间步骤作为转换器，最后一个步骤是算子。上述示例代码中创建了一个包含2个中间步骤和1个逻辑回归分类器的管道。当我们对管道对象<code>pipe_lr</code>实行<code>fit</code>操作室，中间步骤会执行<code>fit</code>和<code>transform</code>，并将结果数据传递给下一个步骤使用。管道工作的示意图如下：<br><img src="/img/PythonMachineLearningVI_01.png" alt=""></p><h3 id="Using-k-fold-cross-validation-to-assess-model-performance"><a href="#Using-k-fold-cross-validation-to-assess-model-performance" class="headerlink" title="Using k-fold cross-validation to assess model performance"></a>Using k-fold cross-validation to assess model performance</h3><p>构建预测模型关键步骤之一就是评估模型在未知数据上的表现情况。如果我们在同一个数据集上开发和验证效果，会造成模型的欠拟合和过拟合问题。为了平衡偏置-方差（bias-variance），需要谨慎评估模型效果。这节将介绍的holdout交叉检验和k-fold交叉检验能够使我们获得可信的模型泛化误差，从而得知模型在未知数据上的表现好坏。</p><p><strong>The holdout method</strong><br>常规的建模方法是将原始数据分为训练集和测试集，前者用来训练模型，后者用来检验效果。通常为了提升模型的泛化能力我们会不断调整参数找到最优的模型，如果这是我们一直使用测试集来验证效果，那么测试数据会成为训练数据的一部分使模型产生过拟合。<br>更好的方法是将原始数据分为三份：训练集、验证集、测试集。使用验证集而不是测试集来做模型优化。下图是使用这种交叉检验方法的流程示意图，我们可以在验证集上不断验证和优化模型参数，优化完成后再在测试集上评估模型的泛化误差：<br><img src="/img/PythonMachineLearningVI_02.png" alt=""></p><p>这样做的一个问题是评估会严重受到如何区分数据的影响，因此又产生了更加健壮的交叉检验方法：k-fold。</p><p><strong>K-fold cross-validation</strong><br>k-fold交叉检验的方法是，我们将训练数据随机分成k份（无放回抽样），k-1份用来建模，1份用来测试。这个过程重复k次，获得k个模型和对应的表现评估结果。其过程如下图：<br><img src="/img/PythonMachineLearningVI_03.png" alt=""><br>这里k=10，E表示模型的效果（例如分类准确度）。对于一般情况下，10是一个合理的数量，如果训练数据很小，可以适当提升这个数量。当我们提升k时，每次迭代都会用到更多的训练数据，结果是降低偏置（bias）。但是k过大也会增加计算时间，并且增加方差（variance），因为每次迭代的训练集都会非常相似。</p><blockquote><p>当数据量非常小的情况下推荐使用特殊的交叉检验方法leave-one-out（LOO），在LOO中，k等于样本数n，这意味着每次迭代都只有一条记录用于测试。</p></blockquote><p>在标准k-fold交叉检验基础上的一个小改进是分层（stratified）技术。在数据分fold的时候要保持分类标签的占比与原始数据中的占比一致。<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import numpy <span class="keyword">as</span> np</span><br><span class="line">from sklearn.cross_validation import StratifiedKFold</span><br><span class="line">kfold = StratifiedKFold(y=y_train, n_folds=10, random_state=1)</span><br><span class="line">scores = []</span><br><span class="line"><span class="keyword">for</span> k, (train, <span class="keyword">test</span>) <span class="keyword">in</span> enumerate(kfold):</span><br><span class="line">    pipe_lr.<span class="keyword">fit</span>(X_train[train], y_train[train])</span><br><span class="line">    <span class="keyword">score</span> = pipe_lr.<span class="keyword">score</span>(X_train[<span class="keyword">test</span>], y_train[<span class="keyword">test</span>])</span><br><span class="line">    scores.<span class="keyword">append</span>(<span class="keyword">score</span>)</span><br><span class="line">    <span class="keyword">print</span>('Fold: %s, <span class="keyword">Class</span> dist.: %s, Acc: %.3f' % (k+1, np.bincount(y_train[train]), <span class="keyword">score</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span>('CV accuracy: %.3f +/- %.3f' % (np.<span class="keyword">mean</span>(scores), np.std(scores)))</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">Fold:</span> <span class="number">1</span>, Class dist.: [<span class="number">256</span> <span class="number">153</span>], <span class="string">Acc:</span> <span class="number">0.891</span></span><br><span class="line"><span class="string">Fold:</span> <span class="number">2</span>, Class dist.: [<span class="number">256</span> <span class="number">153</span>], <span class="string">Acc:</span> <span class="number">0.978</span></span><br><span class="line"><span class="string">Fold:</span> <span class="number">3</span>, Class dist.: [<span class="number">256</span> <span class="number">153</span>], <span class="string">Acc:</span> <span class="number">0.978</span></span><br><span class="line"><span class="string">Fold:</span> <span class="number">4</span>, Class dist.: [<span class="number">256</span> <span class="number">153</span>], <span class="string">Acc:</span> <span class="number">0.913</span></span><br><span class="line"><span class="string">Fold:</span> <span class="number">5</span>, Class dist.: [<span class="number">256</span> <span class="number">153</span>], <span class="string">Acc:</span> <span class="number">0.935</span></span><br><span class="line"><span class="string">Fold:</span> <span class="number">6</span>, Class dist.: [<span class="number">257</span> <span class="number">153</span>], <span class="string">Acc:</span> <span class="number">0.978</span></span><br><span class="line"><span class="string">Fold:</span> <span class="number">7</span>, Class dist.: [<span class="number">257</span> <span class="number">153</span>], <span class="string">Acc:</span> <span class="number">0.933</span></span><br><span class="line"><span class="string">Fold:</span> <span class="number">8</span>, Class dist.: [<span class="number">257</span> <span class="number">153</span>], <span class="string">Acc:</span> <span class="number">0.956</span></span><br><span class="line"><span class="string">Fold:</span> <span class="number">9</span>, Class dist.: [<span class="number">257</span> <span class="number">153</span>], <span class="string">Acc:</span> <span class="number">0.978</span></span><br><span class="line"><span class="string">Fold:</span> <span class="number">10</span>, Class dist.: [<span class="number">257</span> <span class="number">153</span>], <span class="string">Acc:</span> <span class="number">0.956</span></span><br><span class="line"></span><br><span class="line">CV <span class="string">accuracy:</span> <span class="number">0.950</span> +/- <span class="number">0.029</span></span><br></pre></td></tr></table></figure></p><p>首先我们按照y_train数据为分类标签初始化一个<code>StratifiedKFold</code>迭代器，然后进行k次迭代，每次使用train下标数组筛选出训练集，并提供到之前我们定义的<code>pile_lr</code>管道中，并使用test下标数组筛选出的测试集计算准确度，并收集到<code>scores</code>列表中，最后计算平均准确度和标准差。<br>scikit-learn提供了更加方便的评分类，能够直接使用分层k-fold交叉检验得到模型的效果：<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.cross_validation <span class="built_in">import</span> cross_val_score</span><br><span class="line"><span class="attr">scores</span> = cross_val_score(<span class="attr">estimator=pipe_lr,</span></span><br><span class="line">                         <span class="attr">X=X_train,</span></span><br><span class="line">                         <span class="attr">y=y_train,</span></span><br><span class="line">                         <span class="attr">cv=10,</span></span><br><span class="line">                         <span class="attr">n_jobs=1)</span></span><br><span class="line">print('CV accuracy: %.<span class="number">3</span>f +/- %.<span class="number">3</span>f' % (np.mean(scores), np.std(scores)))</span><br></pre></td></tr></table></figure></p><p>Output一样。<br><code>cross_val_score</code>另一个有用的特性是可以利用多个CPU分布执行，如果将<code>n_jobs</code>参数设置为2，就可以使用2个CPU执行10次迭代，如果设置为-1，则可以使用所有的可用CPU。</p><h3 id="Debugging-algorithms-with-learning-and-validation-curves"><a href="#Debugging-algorithms-with-learning-and-validation-curves" class="headerlink" title="Debugging algorithms with learning and validation curves"></a>Debugging algorithms with learning and validation curves</h3><p>本节将介绍两个简单但是强大的分析工具能够帮助我们提升预测模型的性能：学习曲线（learning curves）和验证曲线（validation curves）。</p><p><strong>Diagnosing bias and variance problems with learning curves</strong><br>如果预测模型构建的过于复杂，会在训练数据上过拟合，从而失去对未知数据的泛化能力。通常收集更多的训练样本有助于降低过拟合，但是在实际中者往往困难重重。通过绘制不同大小训练集下模型的训练和验证的准确度曲线，可以非常容易地检测出模型是否存在偏差或方差，以及更多的数据是否有助于解决问题。在绘制学习曲线和验证曲线前，我们先来看下偏差和方差问题的例子。<br><img src="/img/PythonMachineLearningVI_04.png" alt=""><br>左上图的模型表现为高偏差（high bias），训练准确度和交叉验证准确度都较低，意味着模型欠拟合。常用的解决方案是增加模型的参数数量，或降低正则化力度。<br>有上图的模型表现为高方差（high variance），表现为训练准确度和交叉验证准确度之间巨大的差异，意味着模型在训练数据集上过拟合。常用的解决方案是增加训练数据，降低模型复杂程度，对于非正则化模型也可以利用特征选择和特征压缩的技术降低特征数量。</p><p>首先我们使用scikit-learn中的学习曲线功能评估模型：<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">import</span> matplotlib.pyplot as plt</span><br><span class="line">from sklearn.learning_curve <span class="built_in">import</span> learning_curve</span><br><span class="line"><span class="attr">pipe_lr</span> = Pipeline([</span><br><span class="line">                    ('scl', StandardScaler()),</span><br><span class="line">                    ('clf', LogisticRegression(<span class="attr">penalty='l2',</span> <span class="attr">random_state=0))])</span></span><br><span class="line">train_sizes, train_scores, <span class="attr">test_scores</span> = \</span><br><span class="line">    learning_curve(<span class="attr">estimator=pipe_lr,</span></span><br><span class="line">                   <span class="attr">X=X_train,</span></span><br><span class="line">                   <span class="attr">y=y_train,</span></span><br><span class="line">                   <span class="attr">train_sizes=np.linspace(0.1,</span> <span class="number">1.0</span>, <span class="number">10</span>),</span><br><span class="line">                   <span class="attr">cv=10,</span></span><br><span class="line">                   <span class="attr">n_jobs=1)</span></span><br><span class="line"><span class="attr">train_mean</span> = np.mean(train_scores, <span class="attr">axis=1)</span></span><br><span class="line"><span class="attr">train_std</span> = np.std(train_scores, <span class="attr">axis=1)</span></span><br><span class="line"><span class="attr">test_mean</span> = np.mean(test_scores, <span class="attr">axis=1)</span></span><br><span class="line"><span class="attr">test_std</span> = np.std(test_scores, <span class="attr">axis=1)</span></span><br><span class="line">plt.plot(train_sizes, train_mean, <span class="attr">color='blue',</span> </span><br><span class="line">         <span class="attr">marker='o',</span> <span class="attr">markersize=5,</span> <span class="attr">label='training</span> accuracy')</span><br><span class="line">plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, </span><br><span class="line">                 <span class="attr">alpha=0.15,</span> <span class="attr">color='blue')</span></span><br><span class="line">plt.plot(train_sizes, test_mean, <span class="attr">color='green',</span> <span class="attr">linestyle='--',</span></span><br><span class="line">         <span class="attr">marker='s',</span> <span class="attr">markersize=5,</span></span><br><span class="line">         <span class="attr">label='validation</span> accuracy')</span><br><span class="line">plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, </span><br><span class="line">                 <span class="attr">alpha=0.15,</span> <span class="attr">color='green')</span></span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel('Number of training samples')</span><br><span class="line">plt.ylabel('Accuracy')</span><br><span class="line">plt.legend(<span class="attr">loc='lower</span> right')</span><br><span class="line">plt.ylim([<span class="number">0.8</span>, <span class="number">1.0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>Output:<br><img src="/img/PythonMachineLearningVI_05.png" alt=""><br>通过设置<code>learning_curve</code>方法的<code>train_sizes</code>参数，可以控制用来生成学习曲线的样本数据的相对数量或绝对数量，这里我们使用<code>np.linspace(0.1, 1.0, 10)</code>生成10分等差数来设置训练集的大小。默认情况下<code>learning_curve</code>方法是用分层k-fold交叉检验，通过<code>cv</code>参数设置k为10。最后我们简单计算交叉检验后的平均训练和测试精准度，并用<code>plot</code>方法展现，并用<code>fill_between</code>方法绘制平均精准度的标准差。</p><p>从图中可以看出，模型在测试集上的表现还不错，但是有轻微的过拟合，训练和验证精准度之间存在一定的差距。</p><p><strong>Addressing overfitting and underfitting with validation curves</strong><br>验证曲线可以定位过拟合或欠拟合问题从而有效帮助提升模型性能。和学习曲线不同，验证曲线描绘的是基于不同模型参数 情况下训练和验证精准度情况，本示例中逻辑回归的参数是C。<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.learning_curve <span class="built_in">import</span> validation_curve</span><br><span class="line"><span class="attr">param_range</span> = [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10.0</span>, <span class="number">100.0</span>]</span><br><span class="line">train_scores, <span class="attr">test_scores</span> = validation_curve(</span><br><span class="line">                <span class="attr">estimator=pipe_lr,</span></span><br><span class="line">                <span class="attr">X=X_train,</span></span><br><span class="line">                <span class="attr">y=y_train,</span></span><br><span class="line">                <span class="attr">param_name='clf__C',</span></span><br><span class="line">                <span class="attr">param_range=param_range,</span></span><br><span class="line">                <span class="attr">cv=10)</span></span><br><span class="line"><span class="attr">train_mean</span> = np.mean(train_scores, <span class="attr">axis=1)</span></span><br><span class="line"><span class="attr">train_std</span> = np.std(train_scores, <span class="attr">axis=1)</span></span><br><span class="line"><span class="attr">test_mean</span> = np.mean(test_scores, <span class="attr">axis=1)</span></span><br><span class="line"><span class="attr">test_std</span> = np.std(test_scores, <span class="attr">axis=1)</span></span><br><span class="line">plt.plot(param_range, train_mean, <span class="attr">color='blue',</span> </span><br><span class="line">         <span class="attr">marker='o',</span> <span class="attr">markersize=5,</span> <span class="attr">label='training</span> accuracy')</span><br><span class="line">plt.fill_between(param_range, train_mean + train_std, train_mean - train_std, </span><br><span class="line">                 <span class="attr">alpha=0.15,</span> <span class="attr">color='blue')</span></span><br><span class="line">plt.plot(param_range, test_mean, <span class="attr">color='green',</span> <span class="attr">linestyle='--',</span></span><br><span class="line">         <span class="attr">marker='s',</span> <span class="attr">markersize=5,</span></span><br><span class="line">         <span class="attr">label='validation</span> accuracy')</span><br><span class="line">plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, </span><br><span class="line">                 <span class="attr">alpha=0.15,</span> <span class="attr">color='green')</span></span><br><span class="line">plt.grid()</span><br><span class="line">plt.xscale('log')</span><br><span class="line">plt.xlabel('Parameter C')</span><br><span class="line">plt.ylabel('Accuracy')</span><br><span class="line">plt.legend(<span class="attr">loc='lower</span> right')</span><br><span class="line">plt.ylim([<span class="number">0.8</span>, <span class="number">1.0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>Output:<br><img src="/img/PythonMachineLearningVI_06.png" alt=""><br>类似学习曲线方法，<code>validation_curve</code>方法默认使用分层k-fold交叉检验，通过<code>param_name</code>参数设置我们希望评估的模型参数，本例子中，通过<code>&#39;clf__C&#39;</code>来访问管道中<code>LogisticRegression</code>分类器对象的参数<code>C</code>，<code>param_range</code>用于指定参数的取值范围。最后绘制平均准确度和标准差图像。</p><p>从结果可以发现，当C变小（加强正则化）时，模型出现轻微欠拟合，而C增大时模型又出现过拟合，参数C的甜区大约在0.1左右。</p><h3 id="Fine-tuning-machine-learning-models-via-grid-search"><a href="#Fine-tuning-machine-learning-models-via-grid-search" class="headerlink" title="Fine-tuning machine learning models via grid search"></a>Fine-tuning machine learning models via grid search</h3><p>在机器学习算法中，有两类参数：通过训练数据学习道德参数，例如逻辑回归中的权重，和算法优化的参数。后者是可调参数，也成为超参数（hyperparameters），例如逻辑回归中的正则化参数、决策树中的深度。</p><p>上节我们通过验证曲线调优一个超参数，本节将介绍一个更强大的超参数优化方法：网格搜索法（grid search），它能找到多个超参数的最优组合。</p><p><strong>Tuning hyperparameters via grid search</strong><br>网格搜索原理很简单，通过贪心算法评估我们给出的所有超参数组合来找到最优解：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from sklearn<span class="selector-class">.grid_search</span> import GridSearchCV</span><br><span class="line">from sklearn<span class="selector-class">.svm</span> import SVC</span><br><span class="line">pipe_svc = Pipeline([(<span class="string">'scl'</span>, StandardScaler()),</span><br><span class="line">                    (<span class="string">'clf'</span>, SVC(random_state=<span class="number">1</span>))])</span><br><span class="line">param_range = [<span class="number">0.0001</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10.0</span>, <span class="number">100.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">param_grid = [&#123;<span class="string">'clf__C'</span>: param_range,</span><br><span class="line">               <span class="string">'clf__kernel'</span>: [<span class="string">'linear'</span>]&#125;,</span><br><span class="line">              &#123;<span class="string">'clf__C'</span>: param_range,</span><br><span class="line">               <span class="string">'clf__gamma'</span>: param_range,</span><br><span class="line">               <span class="string">'clf__kernel'</span>: [<span class="string">'rbf'</span>]&#125;]</span><br><span class="line">gs = GridSearchCV(estimator=pipe_svc,</span><br><span class="line">                  param_grid=param_grid,</span><br><span class="line">                  scoring=<span class="string">'accuracy'</span>,</span><br><span class="line">                  cv=<span class="number">10</span>,</span><br><span class="line">                  n_jobs=-<span class="number">1</span>)</span><br><span class="line">gs = gs.fit(X_train, y_train)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(gs.best_score_, gs.best_params_)</span></span></span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>.<span class="number">978021978021978</span> &#123;<span class="string">'clf__C'</span>: <span class="number">0</span>.<span class="number">1</span>, <span class="string">'clf__kernel'</span>: <span class="string">'linear'</span>&#125;</span><br></pre></td></tr></table></figure></p><p>上述代码中，我们创建一个<code>GridSearchCV</code>对象用来训练和调优一个支持向量机管道。<code>param_grid</code>参数定义一个包含多个字典的列表，存放了我们希望尝试的参数。对于线性SVM，只需要调试参数<code>C</code>，而对RBF核支持向量机，我们尝试参数<code>C</code>和<code>gamma</code>两个参数组合（<code>gamma</code>参数仅针对核支持向量机有效）。网络搜索完成后，可以从<code>best_score_</code>变量获取到最好模型的分数，<code>best_params_</code>变量获取对应的参数组合。本例中C=0.01时的线性SVM模型准确度最高，为97.8。</p><p>最后我们可以使用独立的测试数据集来评估最优模型的性能，可以通过<code>best_estimator_</code>属性获得。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">clf = gs.best_estimator_</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Test accuracy: %.3f'</span> % clf.score(X_test, y_test)</span></span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Test </span>accuracy: 0.965</span><br></pre></td></tr></table></figure></p><p><strong>Algorithm selection with nested cross-validation</strong><br>如果需要在不同的模型算法间调试比较，另一个推荐的方法是嵌套交叉检验（nested cross-validation）。其原理如下图，首先在外层是一个k-fold的交叉检验循环，将数据分为训练集和测试集，内层是另一个k-fold交叉检验用来做模型选择。图示中是一个外五内二的模型，这种典型的配置也成为5x2交叉检验。<br><img src="/img/PythonMachineLearningVI_07.png" alt=""></p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">gs = GridSearchCV(<span class="name">estimator=pipe_svc</span>,</span><br><span class="line">                  param_grid=param_grid,</span><br><span class="line">                  scoring='accuracy',</span><br><span class="line">                  cv=10,</span><br><span class="line">                  n_jobs=-1)</span><br><span class="line">scores = cross_val_score(<span class="name">gs</span>, X, y, scoring='accuracy', cv=5)</span><br><span class="line">print('CV accuracy: %.<span class="number">3</span>f +/- %.<span class="number">3</span>f' % (<span class="name">np</span>.mean(<span class="name">scores</span>), np.std(<span class="name">scores</span>)))</span><br></pre></td></tr></table></figure><p>Output:<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CV <span class="string">accuracy:</span> <span class="number">0.972</span> +/- <span class="number">0.012</span></span><br></pre></td></tr></table></figure></p><p>同样我们可以用嵌套交叉检验比较决策树分类器，为了简化起见，这里仅仅调试深度参数：<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.tree <span class="built_in">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="attr">gs</span> = GridSearchCV(<span class="attr">estimator=DecisionTreeClassifier(random_state=0),</span></span><br><span class="line">                  <span class="attr">param_grid=[&#123;'max_depth':</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, None]&#125;],</span><br><span class="line">                  <span class="attr">scoring='accuracy',</span></span><br><span class="line">                  <span class="attr">cv=5)</span></span><br><span class="line"><span class="attr">scores</span> = cross_val_score(gs,</span><br><span class="line">                         X_train,</span><br><span class="line">                         y_train,</span><br><span class="line">                         <span class="attr">scoring='accuracy',</span></span><br><span class="line">                         <span class="attr">cv=5)</span></span><br><span class="line">print('CV accuracy: %.<span class="number">3</span>f +/- %.<span class="number">3</span>f' % (np.mean(scores), np.std(scores)))</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CV <span class="string">accuracy:</span> <span class="number">0.908</span> +/- <span class="number">0.045</span></span><br></pre></td></tr></table></figure></p><p>在这个例子上，SVM模型的表现显著优于决策树。</p><h3 id="Looking-at-different-performance-evaluation-metrics"><a href="#Looking-at-different-performance-evaluation-metrics" class="headerlink" title="Looking at different performance evaluation metrics"></a>Looking at different performance evaluation metrics</h3><p>前面的章节和段落，我们都是使用预测准确度来评估模型的效果，通常这是一个有用的指标。此外，还有不少指标也能够用于评估模型的效果，例如精确率（precision）、召回率（recall）和F1评分（F1-score）。</p><p><strong>Reading a confusion matrix</strong><br>首先需要介绍下混淆矩阵（confusion matrix），一个简单的展示真正（true positive）、真负（true negative）、假正（false postive）和假负（false negtive）数量的方阵，如下图所示：<br><img src="/img/PythonMachineLearningVI_08.png" alt=""></p><p>这些指标可以简单的根据预测结果计算出，scikit-learn也同时提供方便的<code>confusion_matrix</code>函数供我们直接使用：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics import confusion_matrix</span><br><span class="line">pipe_svc.fit(X_train, y_train)</span><br><span class="line">y_pred = pipe_svc.predict(X_test)</span><br><span class="line">confmat = confusion_matrix(<span class="attribute">y_true</span>=y_test, <span class="attribute">y_pred</span>=y_pred)</span><br><span class="line"><span class="builtin-name">print</span>(confmat)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">71</span>  <span class="number">1</span>]</span><br><span class="line"> [ <span class="number">2</span> <span class="number">40</span>]]</span><br></pre></td></tr></table></figure></p><p>我们使用matplotlib的<code>matshow</code>函数来画一张类似上面的二维图表：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">2.5</span>, <span class="number">2.5</span>))</span><br><span class="line">ax.matshow(confmat, cmap=plt<span class="selector-class">.cm</span><span class="selector-class">.Blues</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span> <span class="keyword">in</span> range(confmat<span class="selector-class">.shape</span>[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(confmat<span class="selector-class">.shape</span>[<span class="number">1</span>]):</span><br><span class="line">        ax.text(x=j, y=<span class="selector-tag">i</span>, s=confmat[<span class="selector-tag">i</span>, j], va=<span class="string">'center'</span>, ha=<span class="string">'center'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'predicted label'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'true label'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>Output:<br><img src="/img/PythonMachineLearningVI_09.png" alt=""></p><p><strong>Optimizing the precision and recall of a classification model</strong><br>预测错误（ERR）和准确（ACC）是衡量样本误分类的指标，ERR是所有错误分类数量除以预测总数，ACC是所有预测正确的数量除以预测总数。ACC=1-ERR。</p><p>真正率（TPR）和假正率（FPR）是衡量错无分类情况的指标，FPR=FP/(FP+TN)，TPR=TP/(FN+TP)。<br>在实际业务中，真正率和假正率可能是我们需要特别关注的，例如癌症检测中，对于恶性肿瘤的正确识别非常重要。</p><p>精准率（PRE）和召回（REC）是衡量真正和真负的指标，实际上召回率等同于真正率：PRE=TP/(TP+FP)，REC=TP/(FN+TP)。</p><p>实际中，会使用F1评分，它是精准率和召回率的组合形式：F1=2<em>(PRE</em>REC)/(PRE+REC)。</p><p>上述这些评分指标都在<code>sklearn.metrics</code>模块中实现。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn<span class="selector-class">.metrics</span> import precision_score</span><br><span class="line">from sklearn<span class="selector-class">.metrics</span> import recall_score, f1_score</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Precision: %.3f'</span> % precision_score(y_true=y_test, y_pred=y_pred)</span></span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Recall: %.3f'</span> % recall_score(y_true=y_test, y_pred=y_pred)</span></span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'F1: %.3f'</span> % f1_score(y_true=y_test, y_pred=y_pred)</span></span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">Precision</span>: 0.976</span><br><span class="line"></span><br><span class="line"><span class="attribute">Recall</span>: 0.952</span><br><span class="line"></span><br><span class="line"><span class="attribute">F1</span>: 0.964</span><br></pre></td></tr></table></figure></p><p>通过<code>GridSearch</code>还有很多其他评价指标，访问<a href="http://scikit-learn.org/stable/modules/model_evaluation.html" target="_blank" rel="noopener"></a>详细列表。</p><p>注：scikit-learn中对于标记为1的分类视为正（positive）。</p><p><strong>Plotting a receiver operating characteristic</strong><br>受试者工作特征曲线（receiver operating characteristic，ROC），又称为感受性曲线，通过设置分类器不同的决策临界值，计算出一系列以假负率和真正率为坐标的性能曲线。基于ROC曲线，可以计算曲线下面积（area under then curve，AUC）来表示分类模型的性能。</p><p>下面我们将使用之前定义的逻辑回归管道，基于2个特征构建的分类器绘制ROC曲线，为了让图像更加直观，我们将<code>StratifiedKFold</code>的验证次数降低到三次。<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics <span class="built_in">import</span> roc_curve, auc</span><br><span class="line">from scipy <span class="built_in">import</span> interp</span><br><span class="line"><span class="attr">X_train2</span> = X_train[:, [<span class="number">4</span>, <span class="number">14</span>]]</span><br><span class="line"><span class="attr">cv</span> = StratifiedKFold(y_train, <span class="attr">n_folds=3,</span> <span class="attr">random_state=1)</span></span><br><span class="line"><span class="attr">fig</span> = plt.figure(<span class="attr">figsize=(7,</span> <span class="number">5</span>))</span><br><span class="line"><span class="attr">mean_tpr</span> = <span class="number">0.0</span></span><br><span class="line"><span class="attr">mean_fpr</span> = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"><span class="attr">all_tpr</span> = []</span><br><span class="line"></span><br><span class="line">for i, (train, test) <span class="keyword">in</span> enumerate(cv):</span><br><span class="line">    <span class="attr">probas</span> = pipe_lr.fit(X_train2[train],y_train[train]).predict_proba(X_train2[test])</span><br><span class="line">    fpr, tpr, <span class="attr">thresholds</span> = roc_curve(y_train[test], probas[:, <span class="number">1</span>], <span class="attr">pos_label=1)</span></span><br><span class="line">    mean_tpr += interp(mean_fpr, fpr, tpr)</span><br><span class="line">    mean_tpr[<span class="number">0</span>] = <span class="number">0.0</span></span><br><span class="line">    <span class="attr">roc_auc</span> = auc(fpr, tpr)</span><br><span class="line">    plt.plot(fpr, tpr, <span class="attr">lw=1,</span> <span class="attr">label='ROC</span> fold %d (<span class="attr">area</span> = %<span class="number">0.2</span>f)' % (i+<span class="number">1</span>, roc_auc))</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="attr">linestyle='--',</span> <span class="attr">color=(0.6,</span> <span class="number">0.6</span>, <span class="number">0.6</span>),</span><br><span class="line">         <span class="attr">label='random</span> guessing')</span><br><span class="line">mean_tpr /= len(cv)</span><br><span class="line">mean_tpr[-<span class="number">1</span>] = <span class="number">1.0</span></span><br><span class="line"><span class="attr">mean_auc</span> = auc(mean_fpr, mean_tpr)</span><br><span class="line">plt.plot(mean_fpr, mean_tpr, 'k--', <span class="attr">label='mean</span> ROC (<span class="attr">area</span> = %<span class="number">0.2</span>f)' % mean_auc, <span class="attr">lw=2)</span></span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>], <span class="attr">lw=2,</span> <span class="attr">linestyle=':',</span> <span class="attr">color='black',</span> </span><br><span class="line">         <span class="attr">label='perfect</span> performance')</span><br><span class="line">plt.xlim([-<span class="number">0.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.ylim([-<span class="number">0.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.xlabel('<span class="literal">false</span> positive rate')</span><br><span class="line">plt.ylabel('<span class="literal">true</span> positive rate')</span><br><span class="line">plt.title('Receiver Operator Characteristic')</span><br><span class="line">plt.legend(<span class="attr">loc='lower</span> right')</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>Output:<br><img src="/img/PythonMachineLearningVI_10.png" alt=""><br>上述结果可以看出三次fold间存在一定的方差，平均ROC AUC为0.75。<br>如果我们仅仅关系ROC AUC分数，可以直接使用<code>sklearn.metrics</code>子模块的<code>roc_auc_score</code>方法。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pipe_svc = pipe_svc.fit(X_train2, y_train)</span><br><span class="line">y_pred2 = pipe_svc.predict(X_test[:, [<span class="number">4</span>, <span class="number">14</span>]])</span><br><span class="line">from sklearn<span class="selector-class">.metrics</span> import roc_auc_score, accuracy_score</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'ROC AUC: %.3f'</span> % roc_auc_score(y_true=y_test, y_score=y_pred2)</span></span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Accuracy: %.3f'</span> % accuracy_score(y_true=y_test, y_pred=y_pred2)</span></span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">ROC</span> <span class="selector-tag">AUC</span>: 0<span class="selector-class">.671</span></span><br><span class="line"></span><br><span class="line"><span class="selector-tag">Accuracy</span>: 0<span class="selector-class">.728</span></span><br></pre></td></tr></table></figure></p><p>通过ROC AUC描述分类器的表现能够洞察模型在不平衡样本上的性能。</p><p><strong>The scoring metrics for multiclass classification</strong><br>暂略</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Learning-Best-Practices-for-Model-Evaluation-and-Hyperparameter-Tuning&quot;&gt;&lt;a href=&quot;#Learning-Best-Practices-for-Model-Evaluation-and-H</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Machine Learning" scheme="http://gloomymoon.github.io/tags/Machine-Learning/"/>
    
    <category term="scikit-learn" scheme="http://gloomymoon.github.io/tags/scikit-learn/"/>
    
  </entry>
  
  <entry>
    <title>Python Machine Learning V</title>
    <link href="http://gloomymoon.github.io/2017/03/19/Python-Machine-Learning-V/"/>
    <id>http://gloomymoon.github.io/2017/03/19/Python-Machine-Learning-V/</id>
    <published>2017-03-19T06:49:45.000Z</published>
    <updated>2017-03-21T10:17:56.674Z</updated>
    
    <content type="html"><![CDATA[<h2 id="5-Compressing-Data-via-Dimensionality-Reduction"><a href="#5-Compressing-Data-via-Dimensionality-Reduction" class="headerlink" title="5 Compressing Data via Dimensionality Reduction"></a>5 Compressing Data via Dimensionality Reduction</h2><p>本章将介绍三类基础方法，将训练数据映射到低维特征子空间。数据压缩是机器学习中一个重要的课题，它帮助我们存储和分析现代科技收集的增长惊人的数据。本章将涵盖如下主要内容：</p><ul><li>主成分分析（Principal component analysis，PCA），用于无监督数据压缩</li><li>线性判别分析（Linear Discriminant Analysis，LDA），作为一种有监督的降维技术最大化区分性</li><li>利用核主成分分析法进行非线性降维</li></ul><h3 id="Unsupervised-dimensionality-reduction-via-principal-component-analysis"><a href="#Unsupervised-dimensionality-reduction-via-principal-component-analysis" class="headerlink" title="Unsupervised dimensionality reduction via principal component analysis"></a>Unsupervised dimensionality reduction via principal component analysis</h3><p>主成分分析（PCA）是一种无监督线性转换技术了，除了维度压缩以外也应用于很多其他领域，例如数据的探索分析、股票交易的信号降噪和生物信息学中的基因组数据分析及基因显性水平。PCA协助我们基于特征间的相关性识别数据中隐含的模式。简言之，PCA旨在找到高维数据中最大方差（variance）的方向并投射到一个有同等或更低维度的子空间上。新子空间中两两正交的轴（也就是主成份principal components)既可以视为方差最大的方向。如下图所示，x1和x2是原始的特征坐标，PC1和PC2即是主成份。子空间的维度是全新构造出来的的正交特征，也称为主元，而不是简单的从原始特征维中去除。PCA的算法原理这里不做介绍了。<br><img src="/img/PythonMachineLearningV_01.png" alt=""><br>PCA算法主要步骤如下：</p><ol><li>标准化d维的原始数据集</li><li>构建协方差矩阵</li><li>求解协方差矩阵的特征值（eigenvalues）和特征向量（eigenvactors）</li><li>取最大的k个特征值对应的特征向量</li><li>将选取的特征向量作为列向量组成投影矩阵w</li><li>使用w将样本数据投影到选取的k个特征向量上<blockquote><p>可参见<a href="http://www.cnblogs.com/jerrylead/archive/2011/04/18/2020209.html" target="_blank" rel="noopener"></a></p></blockquote></li></ol><p><strong>Total and explained variance</strong><br>本节我们先对付PCA算法的前四布：标准化数据、构建协方差矩阵、计算特征值和特征向量、排序特征向量。<br>我们仍使用上一张用到的Wine数据集来举例，并按照70:30的比例分为训练和测试集，然后进行方差为1的标准化。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">df_wine = pd.read_csv(<span class="string">'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'</span>, header=None)</span><br><span class="line">from sklearn<span class="selector-class">.cross_validation</span> import train_test_split</span><br><span class="line">from sklearn<span class="selector-class">.preprocessing</span> import StandardScaler</span><br><span class="line">X, y = df_wine<span class="selector-class">.iloc</span>[:, <span class="number">1</span>:]<span class="selector-class">.values</span>, df_wine<span class="selector-class">.iloc</span>[:, <span class="number">0</span>].values</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)</span><br><span class="line">sc = StandardScaler()</span><br><span class="line">X_train_std = sc.fit_transform(X_train)</span><br><span class="line">Xtest_std = sc.fit_transform(X_test)</span><br></pre></td></tr></table></figure></p><p>第二步是构建一个dxd维的协方差矩阵，d等于数据集中变量的个数，存放两两特征间的协方差，协方差值为正时表示两个变量同时增加后减少，负值表示变量变化趋势相反。我们可以直接使用NumPy中的<code>linalg.eig</code>函数直接计算Wine数据的协方差矩阵：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">cov_mat = np.cov(X_train_std.T)</span><br><span class="line">eigen_vals, eigen_vecs = np<span class="selector-class">.linalg</span><span class="selector-class">.eig</span>(cov_mat)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'\nEigenvalues \n%s'</span> % eigen_vals)</span></span></span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Eigenvalues </span><br><span class="line">[ <span class="number">4.8923083</span>   <span class="number">2.46635032</span>  <span class="number">1.42809973</span>  <span class="number">1.01233462</span>  <span class="number">0.84906459</span>  <span class="number">0.60181514</span></span><br><span class="line">  <span class="number">0.52251546</span>  <span class="number">0.08414846</span>  <span class="number">0.33051429</span>  <span class="number">0.29595018</span>  <span class="number">0.16831254</span>  <span class="number">0.21432212</span></span><br><span class="line">  <span class="number">0.2399553</span> ]</span><br></pre></td></tr></table></figure></p><p><code>numpy.cov</code>方法用于计算标准化后训练数据集的协方差矩阵，<code>linalg.eig</code>方法对协方差矩阵进行特征分解，返回一个含有13个特征值的响亮（eigen_vals）和对应的特征向量（存储为13x13维度的矩阵eigen_vecs）。因为我们希望通过引射到一个新的子空间上达到降低数据维度的目的，因此需要选择包含有最大信息的特征向量（也就是主成份），而特征值就定义了特征向量的重要程度，因此只要将特征值降序排列，提取我们感兴趣的前k个特征向量即可。在这之前我们先来看下每个特征值都赢得方差百分比（variance explained ratios）。每个特征值对应的方差百分比是其自身与所有特征值总和的比值。<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tot = <span class="built_in">sum</span>(eigen_vals)</span><br><span class="line"><span class="built_in">var_exp</span> = [(i / tot) <span class="keyword">for</span> i <span class="keyword">in</span> sorted(eigen_vals, <span class="built_in">reverse</span>=True)]</span><br><span class="line">cum_var_exp = <span class="built_in">np</span>.cumsum(<span class="built_in">var_exp</span>)</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">14</span>), <span class="built_in">var_exp</span>, alpha=<span class="number">0.5</span>, align='<span class="built_in">center</span>', <span class="built_in">label</span>='individual explained variance')</span><br><span class="line">plt.<span class="keyword">step</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">14</span>), cum_var_exp, where='mid', <span class="built_in">label</span>='cumulative explained variance')</span><br><span class="line">plt.<span class="built_in">ylabel</span>('Explained variance ratio')</span><br><span class="line">plt.<span class="built_in">xlabel</span>('Principal <span class="built_in">components</span>')</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningV_02.png" alt=""><br>从结果上看，第一个主成份贡献了近40%的方差，前两个贡献了近60%的方差。<br>虽然方差解释图和上章中通过随机森林的特征选择类似，但是主成分分析是一种无监督的方法，其分析并不基于分类标签，而是衡量在特征轴上数据值的离散情况。</p><p><strong>Feature transformation</strong><br>完成协方差矩阵分写后就可以将Wine数据集转换到新的主成份特征向量上。首先是按照特征值降序对特征对排序：<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">eigen_pairs = [(<span class="built_in">np</span>.<span class="built_in">abs</span>(eigen_vals[i]), eigen_vecs[:, i])</span><br><span class="line">               <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len(eigen_vals))]</span><br><span class="line">eigen_pairs.<span class="built_in">sort</span>(<span class="built_in">reverse</span>=True)</span><br></pre></td></tr></table></figure></p><p>然后我们选取值最大的两个特征向量创建映射矩阵。因为为了展示方便，仅选取两个特征变量以便能够在二维散点图上展现，实际工作中主成份的数量需要衡量，综合考虑计算效率和分类器的效果。<br><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">w = np.hstack((eigen_pairs[<span class="string">0</span>][<span class="symbol">1</span>][<span class="string">:, np.newaxis</span>],</span><br><span class="line"><span class="code">                eigen_pairs[1][1][:, np.newaxis]))</span></span><br><span class="line">print('Matrix W:\n', w)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Matrix W:</span><br><span class="line"> [[ <span class="number">0.14669811</span>  <span class="number">0.50417079</span>]</span><br><span class="line"> [-<span class="number">0.24224554</span>  <span class="number">0.24216889</span>]</span><br><span class="line"> [-<span class="number">0.02993442</span>  <span class="number">0.28698484</span>]</span><br><span class="line"> [-<span class="number">0.25519002</span> -<span class="number">0.06468718</span>]</span><br><span class="line"> [ <span class="number">0.12079772</span>  <span class="number">0.22995385</span>]</span><br><span class="line"> [ <span class="number">0.38934455</span>  <span class="number">0.09363991</span>]</span><br><span class="line"> [ <span class="number">0.42326486</span>  <span class="number">0.01088622</span>]</span><br><span class="line"> [-<span class="number">0.30634956</span>  <span class="number">0.01870216</span>]</span><br><span class="line"> [ <span class="number">0.30572219</span>  <span class="number">0.03040352</span>]</span><br><span class="line"> [-<span class="number">0.09869191</span>  <span class="number">0.54527081</span>]</span><br><span class="line"> [ <span class="number">0.30032535</span> -<span class="number">0.27924322</span>]</span><br><span class="line"> [ <span class="number">0.36821154</span> -<span class="number">0.174365</span>  ]</span><br><span class="line"> [ <span class="number">0.29259713</span>  <span class="number">0.36315461</span>]]</span><br></pre></td></tr></table></figure></p><p>在原始数据上对每一条记录进行转换（点积）就能够转换成2个新的特征，同样对所有数据应用映射也可以直接通过点积操作。最后我们通过二维散点图看下转换今后的数据分布情况。<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">X_train_pca = X_train_std.<span class="built_in">dot</span>(w)</span><br><span class="line">colors = [<span class="string">'r'</span>, <span class="string">'b'</span>, <span class="string">'g'</span>]</span><br><span class="line">markers = [<span class="string">'s'</span>, <span class="string">'x'</span>, <span class="string">'o'</span>]</span><br><span class="line"><span class="keyword">for</span> l, c, m in zip(np.unique(y_train), colors, markers):</span><br><span class="line">    plt.<span class="built_in">scatter</span>(X_train_pca[y_train==l, <span class="number">0</span>],</span><br><span class="line">                X_train_pca[y_train==l, <span class="number">1</span>],</span><br><span class="line">                c=c, label=l, marker=m)</span><br><span class="line">plt.xlabel(<span class="string">'PC 1'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'PC 2'</span>)</span><br><span class="line">plt.<span class="built_in">legend</span>(loc=<span class="string">'lower left'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningV_03.png" alt=""><br>转换后的数据在X轴（第一个主成份）上的分布比Y轴（第二个主成份）上区分度更好，通过一个简单的线性分类器就能够很好地定义数据分布界限。</p><p><strong>Principal component analysis in scikit-learn</strong><br>scikit-learn中已经实现的PCA类是一个数据变化模块，和之前的类似，优先使用<code>fit</code>方法在训练数据上学习，然后转换训练数据和测试数据。下面我们结合PCA的转换、逻辑回归分类建模，并将模型结果用第二章中的方法展现出来：<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from plot_decision_regions <span class="built_in">import</span> *</span><br><span class="line">from sklearn.linear_model <span class="built_in">import</span> LogisticRegression</span><br><span class="line">from sklearn.decomposition <span class="built_in">import</span> PCA</span><br><span class="line"><span class="attr">pca</span> = PCA(<span class="attr">n_components=2)</span></span><br><span class="line"><span class="attr">lr</span> = LogisticRegression()</span><br><span class="line"><span class="attr">X_train_pca</span> = pca.fit_transform(X_train_std)</span><br><span class="line"><span class="attr">X_test_pca</span> = pca.transform(X_test_std)</span><br><span class="line">lr.fit(X_train_pca, y_train)</span><br><span class="line">plot_decision_regions(X_train_pca, y_train, <span class="attr">classifier=lr)</span></span><br><span class="line">plt.xlabel('PC <span class="number">1</span>')</span><br><span class="line">plt.ylabel('PC <span class="number">2</span>')</span><br><span class="line">plt.legend(<span class="attr">loc='lower</span> left')</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningV_04.png" alt=""><br>注意到这个散点图和我们自己实现的PCA不同，是X轴的镜像，这不是算法的错误，而是因为特征向量可正可负，我们可以简单的对数据乘以-1，使得结果一样。最后我们将逻辑归回模型应用在转换后的测试集上看下分类效果：<br><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">plot_decision_regions</span>(X_test_pca, y_test, classifier=lr)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.xlabel</span>(<span class="string">'PC 1'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.ylabel</span>(<span class="string">'PC 2'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.legend</span>(loc=<span class="string">'lower left'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.show</span>()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningV_05.png" alt=""><br>简单的逻辑回归在这个2维的特征子空间上表现不错，仅有1个样本被错误分类。</p><p>如果我们需要了解不同主成份的方差比例，可以在初始化PCA类的时候将参数<code>n_components</code>设置为<code>None</code>，这样所有的主成份都会保留，方差比例可以通过<code>explained_variance_ratio_</code>属性访问。<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components=None)</span><br><span class="line">X_train_pca = pca.fit_transform(X_train_std)</span><br><span class="line">pca.explained_variance_ratio_</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([ <span class="number">0.37329648</span>,  <span class="number">0.18818926</span>,  <span class="number">0.10896791</span>,  <span class="number">0.07724389</span>,  <span class="number">0.06478595</span>,</span><br><span class="line">        <span class="number">0.04592014</span>,  <span class="number">0.03986936</span>,  <span class="number">0.02521914</span>,  <span class="number">0.02258181</span>,  <span class="number">0.01830924</span>,</span><br><span class="line">        <span class="number">0.01635336</span>,  <span class="number">0.01284271</span>,  <span class="number">0.00642076</span>])</span><br></pre></td></tr></table></figure></p><h3 id="Supervised-data-compression-via-linear-discriminant-analysis"><a href="#Supervised-data-compression-via-linear-discriminant-analysis" class="headerlink" title="Supervised data compression via linear discriminant analysis"></a>Supervised data compression via linear discriminant analysis</h3><p>线性判别分析（Linear Discriminant Analysis，LDA）是一种特征压缩技术，可以提升模型计算效率降低过拟合。和PCA背后的原理类似，LDA的目标是搜索一个分类分布更优的特征子空间。PCA和LDA都是通过线性转换技术降低数据的维度，前者是无监督算法，而后者是有监督的。直觉上有监督学习效果优于无监督学习，但是实际上在某些领域例如特定图像识别问题上，PCA反而有更加出色的表现。</p><p>LDA的主要步骤如下：</p><ol><li>标准化d维数据（d表示特征的数量）</li><li>为每个分类计算d维的均值向量（mean vector）</li><li>构建类间散布矩阵Sb（between-class scatter matrix）和类内散布矩阵Sw（within-class scatter matrix）</li><li>计算(Sw^-1)(Sb)的特征向量和特征值</li><li>选择k个最大特征值对应的特征向量，组成d×k维的转换矩阵W，特征向量是矩阵的列</li><li>将样本通过W投射到新的特征子空间上</li></ol><p><strong>Computing the scatter matrices</strong><br>因为在之前PCA步骤中我们已经标准化了Wine数据集，这里不再重复。我们首先为每个分类计算均值向量：<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">np</span>.set_printoptions(precision=<span class="number">4</span>)</span><br><span class="line">mean_vecs = []</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">label</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">4</span>):</span><br><span class="line">    mean_vecs.<span class="built_in">append</span>(<span class="built_in">np</span>.<span class="built_in">mean</span>(</span><br><span class="line">                     X_train_std[y_train==<span class="built_in">label</span>], axis=<span class="number">0</span>))</span><br><span class="line">    <span class="built_in">print</span>('MV <span class="built_in">%s</span>: <span class="built_in">%s</span>\n' <span class="symbol">%</span>(<span class="built_in">label</span>, mean_vecs[<span class="built_in">label</span>-<span class="number">1</span>]))</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">MV 1: [ 0.9259 <span class="string">-0</span>.3091  0.2592 <span class="string">-0</span>.7989  0.3039  0.9608  1.0515 <span class="string">-0</span>.6306  0.5354</span><br><span class="line">  0.2209  0.4855  0.798   1.2017]</span><br><span class="line"></span><br><span class="line">MV 2: [<span class="string">-0</span>.8727 <span class="string">-0</span>.3854 <span class="string">-0</span>.4437  0.2481 <span class="string">-0</span>.2409 <span class="string">-0</span>.1059  0.0187 <span class="string">-0</span>.0164  0.1095</span><br><span class="line"> <span class="string">-0</span>.8796  0.4392  0.2776 <span class="string">-0</span>.7016]</span><br><span class="line"></span><br><span class="line">MV 3: [ 0.1637  0.8929  0.3249  0.5658 <span class="string">-0</span>.01   <span class="string">-0</span>.9499 <span class="string">-1</span>.228   0.7436 <span class="string">-0</span>.7652</span><br><span class="line">  0.979  <span class="string">-1</span>.1698 <span class="string">-1</span>.3007 <span class="string">-0</span>.3912]</span><br></pre></td></tr></table></figure></p><p>有了均值向量后我们可以用来计算类内散步矩阵Sw：<br><img src="/img/PythonMachineLearningV_06.png" alt=""><br>其中i代表分类，m是分类的均值向量，x是特征。<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">d = <span class="number">13</span> # number of <span class="built_in">features</span></span><br><span class="line">S_W = <span class="built_in">np</span>.zeros((d, d))</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">label</span>, mv <span class="keyword">in</span> zip(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">4</span>), mean_vecs):</span><br><span class="line">    class_scatter = <span class="built_in">np</span>.zeros((d, d))</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">row</span> <span class="keyword">in</span> X[y == <span class="built_in">label</span>]:</span><br><span class="line">        <span class="built_in">row</span>, mv = <span class="built_in">row</span>.reshape(d, <span class="number">1</span>), mv.reshape(d, <span class="number">1</span>)</span><br><span class="line">        class_scatter += (<span class="built_in">row</span>-mv).dot((<span class="built_in">row</span>-mv).T)</span><br><span class="line">    S_W += class_scatter</span><br><span class="line"><span class="built_in">print</span>('Within-class scatter <span class="built_in">matrix</span>: %sx%s' <span class="symbol">%</span> (S_W.shape[<span class="number">0</span>], S_W.shape[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Within-<span class="class"><span class="keyword">class</span> <span class="title">scatter</span> <span class="title">matrix</span>: <span class="type">13x13</span></span></span><br></pre></td></tr></table></figure></p><p>由于我们在构建散步矩阵前假设训练集中的每个分类数量是均匀分布的，但是实际情况中，不可能这样完美：<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print('Class label distribution: %s' % np.bincount(<span class="name">y_train</span>)[<span class="number">1</span>:])</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Class</span> <span class="keyword">label</span> distribution: [<span class="number">40</span> <span class="number">49</span> <span class="number">35</span>]</span><br></pre></td></tr></table></figure></p><p>因此我们在汇总所有Si前需要做归一化处理，对每个Si都要除以分类i中样本的个数，这样有点类似于我们之前的协方差矩阵：<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">d = <span class="number">13</span> # number of <span class="built_in">features</span></span><br><span class="line">S_W = <span class="built_in">np</span>.zeros((d, d))</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">label</span>, mv <span class="keyword">in</span> zip(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">4</span>), mean_vecs):</span><br><span class="line">    class_scatter = <span class="built_in">np</span>.<span class="built_in">cov</span>(X_train_std[y_train==<span class="built_in">label</span>].T)</span><br><span class="line">    S_W += class_scatter</span><br><span class="line"><span class="built_in">print</span>('Within-class scatter <span class="built_in">matrix</span>: %sx%s' <span class="symbol">%</span> (S_W.shape[<span class="number">0</span>], S_W.shape[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure></p><p>然后可以构建类间散布矩阵Sb：<br><img src="/img/PythonMachineLearningV_07.png" alt=""><br>其中m是总体的均值向量。<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mean_overall</span> = np.mean(X_train_std, <span class="attr">axis=0)</span></span><br><span class="line"><span class="attr">d</span> = <span class="number">13</span> <span class="comment"># number of features</span></span><br><span class="line"><span class="attr">S_B</span> = np.zeros((d, d))</span><br><span class="line">for i, mean_vec <span class="keyword">in</span> enumerate(mean_vecs):</span><br><span class="line">    <span class="attr">n</span> = X[<span class="attr">y==i+1,</span> :].shape[<span class="number">0</span>]</span><br><span class="line">    <span class="attr">mean_vec</span> = mean_vec.reshape(d, <span class="number">1</span>)</span><br><span class="line">    <span class="attr">mean_overall</span> = mean_overall.reshape(d, <span class="number">1</span>)</span><br><span class="line">    S_B += n * (mean_vec - mean_overall).dot((mean_vec - mean_overall).T)</span><br><span class="line">print('Between-class scatter matrix: %sx%s' % (S_B.shape[<span class="number">0</span>], S_B.shape[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure></p><p><strong>Selecting linear discrimnants for the new feature subspace</strong><br>接下来的工作与PCA类似：<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">eigen_vals, eigen_vecs = <span class="built_in">np</span>.linalg.eig(<span class="built_in">np</span>.linalg.inv(S_W).dot(S_B))</span><br><span class="line">eigen_pairs = [(<span class="built_in">np</span>.<span class="built_in">abs</span>(eigen_vals[i]), eigen_vecs[:, i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len(eigen_vals))]</span><br><span class="line">eigen_pairs = sorted(eigen_pairs, <span class="built_in">key</span>=<span class="built_in">lambda</span> k: k[<span class="number">0</span>], <span class="built_in">reverse</span>=True)</span><br><span class="line"><span class="built_in">print</span>('EigenValues <span class="keyword">in</span> <span class="built_in">decreasing</span> order:\n')</span><br><span class="line"><span class="keyword">for</span> eigen_val <span class="keyword">in</span> eigen_pairs:</span><br><span class="line">    <span class="built_in">print</span>(eigen_val[<span class="number">0</span>])</span><br><span class="line">`</span><br></pre></td></tr></table></figure></p><p>降序排列的特征值如下：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">EigenValues</span> <span class="selector-tag">in</span> <span class="selector-tag">decreasing</span> <span class="selector-tag">order</span>:</span><br><span class="line"></span><br><span class="line">643<span class="selector-class">.015384346</span></span><br><span class="line">225<span class="selector-class">.086981854</span></span><br><span class="line">8<span class="selector-class">.00267518379e-14</span></span><br><span class="line">5<span class="selector-class">.75753461418e-14</span></span><br><span class="line">3<span class="selector-class">.51050796047e-14</span></span><br><span class="line">3<span class="selector-class">.46389583683e-14</span></span><br><span class="line">2<span class="selector-class">.58781151001e-14</span></span><br><span class="line">2<span class="selector-class">.58781151001e-14</span></span><br><span class="line">2<span class="selector-class">.44498173106e-14</span></span><br><span class="line">1<span class="selector-class">.65321991297e-14</span></span><br><span class="line">8<span class="selector-class">.33122517135e-15</span></span><br><span class="line">2<span class="selector-class">.3238388797e-15</span></span><br><span class="line">6<span class="selector-class">.52243007612e-16</span></span><br></pre></td></tr></table></figure></p><p>熟悉线性代数的同学或许还记得一个d×d维的协方差矩阵的秩的数量不会超过d-1个，这里可以看到仅有两个非零的特征值。<br>我们同样用类似PCA中方差百分比的贡献度，将片别分析中每个分类判别的信息都通过图表来展现：<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tot = <span class="built_in">sum</span>(eigen_vals.<span class="built_in">real</span>)</span><br><span class="line">discr = [(i / tot) <span class="keyword">for</span> i <span class="keyword">in</span> sorted(eigen_vals.<span class="built_in">real</span>, <span class="built_in">reverse</span>=True)]</span><br><span class="line">cum_discr = <span class="built_in">np</span>.cumsum(discr)</span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">14</span>), discr, alpha=<span class="number">0.5</span>, align='<span class="built_in">center</span>', <span class="built_in">label</span>='individual <span class="string">"discriminability"</span>')</span><br><span class="line">plt.<span class="keyword">step</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">14</span>), cum_discr, where='mid', <span class="built_in">label</span>='cumulative <span class="string">"discriminability"</span>')</span><br><span class="line">plt.<span class="built_in">ylabel</span>('<span class="string">"discriminability"</span> ratio')</span><br><span class="line">plt.<span class="built_in">xlabel</span>('Linear Discriminants')</span><br><span class="line">plt.ylim([-<span class="number">0.1</span>, <span class="number">1.1</span>])</span><br><span class="line">plt.<span class="built_in">legend</span>(loc='best')</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningV_08.png" alt=""><br>前两个线性判别式捕获了将近100%的有用分类信息。然后我们可以用这两个特征变量来组建转换矩阵W：<br><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">w = np.hstack((eigen_pairs[<span class="string">0</span>][<span class="symbol">1</span>][<span class="string">:, np.newaxis</span>].real,</span><br><span class="line"><span class="code">               eigen_pairs[1][1][:, np.newaxis].real))</span></span><br><span class="line">print('Matrix W:\n', w)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Matrix W:</span><br><span class="line"> [[<span class="string">-0</span>.0707  0.3778]</span><br><span class="line"> [ 0.0359  0.2223]</span><br><span class="line"> [<span class="string">-0</span>.0263  0.3813]</span><br><span class="line"> [ 0.1875 <span class="string">-0</span>.2955]</span><br><span class="line"> [<span class="string">-0</span>.0033 <span class="string">-0</span>.0143]</span><br><span class="line"> [ 0.2328 <span class="string">-0</span>.0151]</span><br><span class="line"> [<span class="string">-0</span>.7719 <span class="string">-0</span>.2149]</span><br><span class="line"> [<span class="string">-0</span>.0803 <span class="string">-0</span>.0726]</span><br><span class="line"> [ 0.0896 <span class="string">-0</span>.1767]</span><br><span class="line"> [ 0.1815  0.2909]</span><br><span class="line"> [<span class="string">-0</span>.0631 <span class="string">-0</span>.2376]</span><br><span class="line"> [<span class="string">-0</span>.3794 <span class="string">-0</span>.0867]</span><br><span class="line"> [<span class="string">-0</span>.3355  0.586 ]]</span><br></pre></td></tr></table></figure></p><p><strong>Projecting samples onto the new feature space</strong><br>类似的，利用转换矩阵将训练数据投影到新的特征子空间上：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">X_train_lda = X_train_std.<span class="built_in">dot</span>(w)</span><br><span class="line">colors = [<span class="string">'r'</span>, <span class="string">'b'</span>, <span class="string">'g'</span>]</span><br><span class="line">markers = [<span class="string">'s'</span>, <span class="string">'x'</span>, <span class="string">'o'</span>]</span><br><span class="line"><span class="keyword">for</span> l, c, m in zip(np.unique(y_train), colors, markers):</span><br><span class="line">    plt.<span class="built_in">scatter</span>(X_train_lda[y_train==l, <span class="number">0</span>],</span><br><span class="line">                X_train_lda[y_train==l, <span class="number">1</span>],</span><br><span class="line">                c=c, label=l, marker=m)</span><br><span class="line">plt.xlabel(<span class="string">'LD 1'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'LD 2'</span>)</span><br><span class="line">plt.<span class="built_in">legend</span>(loc=<span class="string">'upper right'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningV_09.png" alt=""></p><p><strong>LDA via scikit-learn</strong><br>逐步实现能够帮助我们理解LDA和PCA的内部实现差异，下面我们来看看scikit-learn自带的LDA类对数据降维，然后用逻辑回归来建模的效果；<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">X_train_lda = X_train_std.<span class="built_in">dot</span>(w)</span><br><span class="line">colors = [<span class="string">'r'</span>, <span class="string">'b'</span>, <span class="string">'g'</span>]</span><br><span class="line">markers = [<span class="string">'s'</span>, <span class="string">'x'</span>, <span class="string">'o'</span>]</span><br><span class="line"><span class="keyword">for</span> l, c, m in zip(np.unique(y_train), colors, markers):</span><br><span class="line">    plt.<span class="built_in">scatter</span>(X_train_lda[y_train==l, <span class="number">0</span>],</span><br><span class="line">                X_train_lda[y_train==l, <span class="number">1</span>],</span><br><span class="line">                c=c, label=l, marker=m)</span><br><span class="line">plt.xlabel(<span class="string">'LD 1'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'LD 2'</span>)</span><br><span class="line">plt.<span class="built_in">legend</span>(loc=<span class="string">'upper right'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningV_10.png" alt=""><br>可以看到逻辑回归只有在一个样本上分类错误。但是通过降低正则化强度，我们能够适当调整分类面使得模型能够对所有数据正确分类。不过，我们先来看下模型在测试数据集上的表现情况：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X_test_lda = lda.<span class="attribute">transform</span>(X_test_std)</span><br><span class="line"><span class="function"><span class="title">plot_decision_regions</span><span class="params">(X_test_lda, y_test, classifier=lr)</span></span></span><br><span class="line">plt.xlabel(<span class="string">'LD 1'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'LD 2'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'lower left'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningV_11.png" alt=""><br>Bingo! 模型在测试集上100%正确，仅仅使用了2个特征向量而不是原始13个特征。</p><h3 id="Using-Kernel-principal-component-analysis-for-nonlinear-mappings"><a href="#Using-Kernel-principal-component-analysis-for-nonlinear-mappings" class="headerlink" title="Using Kernel principal component analysis for nonlinear mappings"></a>Using Kernel principal component analysis for nonlinear mappings</h3><p>我们之前学习到的大部分机器学习算法都假设输入数据是线性分离的，而现实中我们可能遇到的更多的是非线性分类问题，此时类似PCA和LDA等线性转换技术来降维就不是一个好的选择。本节我们来看下核主成分分析（kernel PCA），将非线性分割问题转换到一个可以线性分类的低维子空间上。<br><img src="/img/PythonMachineLearningV_12.png" alt=""></p><p><strong>Kernel functions and the kernel trick</strong><br>还记得我们在第三章介绍的核支持向量机，可以将非线性问题投射到更高维的线性空间上使其转化为线性可分。为了将样本数据转换到更高维的k维子空间上，我们定义了一个非线性映射函数Φ：<br><img src="/img/PythonMachineLearningV_13.png" alt=""><br>例如，如果x是一个二维向量，那么下面就是一种将它投射到三位空间上的一个方法：<br><img src="/img/PythonMachineLearningV_14.png" alt=""><br>结合PCA，我们可以先把一个非线性可分的数据集投射到高维空间上，然后再通过PCA降维到另一个可线性分割的子空间上。这里的难点是，计算非常大，因此我们引入了核机制（kernel trick）。使用核机制可以在原有特征空间上计算两个高位特征向量间的相似度（similarity）。</p><p>主要是用到的和函数如下：</p><ul><li>多项式核函数（the polynomial kernel）</li><li>双曲正切函数（the hyperbolic tangent）</li><li>高斯和函数或称为径向基函数（Gaussian kernel or Radial Basis Fucntion , RBF）</li></ul><p><strong>Implementing a kernel principal component analysis in Python</strong><br>略</p><p><strong>Projecting new data points</strong><br>略</p><p><strong>Kernelprincipal components analysis in scikit-learn</strong><br>scikit-learn在<code>sklearn.decomposion</code>模块中实现了一个核PCA类，使用方法类似标准PCA类，我们可以通过参数<code>kernel</code>自定义和函数：<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets <span class="built_in">import</span> make_moons</span><br><span class="line">from sklearn.decomposition <span class="built_in">import</span> KernelPCA</span><br><span class="line">X, <span class="attr">y</span> = make_moons(<span class="attr">n_samples=100,</span> <span class="attr">random_state=123)</span></span><br><span class="line"><span class="attr">scikit_kpca</span> = KernelPCA(<span class="attr">n_components=2,</span> <span class="attr">kernel='rbf',</span> <span class="attr">gamma=15)</span></span><br><span class="line"><span class="attr">X_skernpca</span> = scikit_kpca.fit_transform(X)</span><br><span class="line"></span><br><span class="line">plt.scatter(X_skernpca[<span class="attr">y==0,</span> <span class="number">0</span>], X_skernpca[<span class="attr">y==0,</span> <span class="number">1</span>], <span class="attr">color='red',</span> <span class="attr">marker='^',</span> <span class="attr">alpha=0.5)</span></span><br><span class="line">plt.scatter(X_skernpca[<span class="attr">y==1,</span> <span class="number">0</span>], X_skernpca[<span class="attr">y==1,</span> <span class="number">1</span>], <span class="attr">color='blue',</span> <span class="attr">marker='o',</span> <span class="attr">alpha=0.5)</span></span><br><span class="line">plt.xlabel('PC <span class="number">1</span>')</span><br><span class="line">plt.ylabel('PC <span class="number">2</span>')</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningV_15.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;5-Compressing-Data-via-Dimensionality-Reduction&quot;&gt;&lt;a href=&quot;#5-Compressing-Data-via-Dimensionality-Reduction&quot; class=&quot;headerlink&quot; title</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Machine Learning" scheme="http://gloomymoon.github.io/tags/Machine-Learning/"/>
    
    <category term="scikit-learn" scheme="http://gloomymoon.github.io/tags/scikit-learn/"/>
    
  </entry>
  
  <entry>
    <title>Bit City</title>
    <link href="http://gloomymoon.github.io/2017/03/15/Bit-City/"/>
    <id>http://gloomymoon.github.io/2017/03/15/Bit-City/</id>
    <published>2017-03-15T02:27:19.000Z</published>
    <updated>2017-03-16T14:10:41.069Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Bit-City：一个值得轻度肝的小游戏"><a href="#Bit-City：一个值得轻度肝的小游戏" class="headerlink" title="Bit City：一个值得轻度肝的小游戏"></a>Bit City：一个值得轻度肝的小游戏</h1><p>3月13日<a href="http://nimblebit.com/" target="_blank" rel="noopener">NimbleBit</a> LLC发布了最新的游戏Bit City，立即上了App Store的首页推荐，目前（3月16日）已经收获近600评分，平均评分4星。</p><p><img src="/img/BitCity/20170316_060640000_iOS.jpg" alt=""></p><p><img src="/img/BitCity/20170315_014552000_iOS.jpg" alt=""></p><p>NimbleBit是由两个双胞胎兄弟Ian Marsh和Dave Marsh在2009年联合创办的一个独立游戏开发公司，成员目前只有4人，哥哥Ian负责码代码，弟弟David负责描像素，除两位创始人以外，还有一位开发工程师Tim Rudolph和一位客服Dani Rudolph。NimbleBit最成功的游戏是获得苹果2011年年度游戏荣誉的Tiny Tower，又衍生出Star Wars: Tiny Death Star、Tiny Tower Vegas，其独特的像素风和”non-annoying” F2P游戏理念为人所称道，被用来作为抗议频繁骚扰用户进行IAP的氪金游戏的正面案例。除Tiny Tower之外，NimbleBit的其他游戏一样特色鲜明、轻度可肝，例如Pocket Frogs、Pocket Trains、Pocket Planes、Disco Zoo、Nimble Quest、GOLFINITY等。</p><p>Bit City用户评分只有4星，比其他主打游戏4.5分要低，主要原因是很多用户拿它与经典的SimCity系列进行比较，也难怪，因为游戏的主界面太容易让人联想到SimCity系列了（这里对比的SimCity都是指SimCity4及之前的版本）。</p><p><img src="/img/BitCity/20170315_013046000_iOS.jpg" alt=""></p><p>斜45度上帝视角、绿色的草地、灰色的街道、淡褐色空地、各式各样耸立的建筑、四处漫游的小车，充满了浓浓的SimCity风。</p><p><img src="/img/BitCity/20170315_013049000_iOS.jpg" alt=""></p><p>和开放式的SimCity不同，Bit City中建筑只能建在灰褐色的空地中，每关的空地总数也是有限的。空地分为1x1和2x2两种大小，每个空地都可以建造三类建筑中的一种：住宅、商业和公共设施，连颜色和需求也和SimCity中的RBI对应。每个建筑都有各自的每秒金币收入，建造过多的类型（也是需求低的）收入会受到惩罚（例如-10%），建造过少的类型收入则增加（+10%），三类建筑的数量需要平衡。每个建筑都可以单独升级，升级会略微提升收入并随机一个新的外观，可以在建筑物界面里勾选Historical选项保持当前外观，点击主界面正下方的黄色Build按钮会随机（应该是按照顺序）升级一栋建筑，升级需要一定时间并且会随着建筑等级越来越久，可同时升级的数量会随着关卡数逐步增加。</p><p><img src="/img/BitCity/20170315_013059000_iOS.jpg" alt=""></p><p>游戏开始时（Level 1）城市的面积很小，当所有的空地都造满建筑时，达到了人口上限（每个1x1空地提升的人口是固定的1000人，人口总数显示在主界面左上角）后，即可进入下一关，城市面积增加并解锁更多游戏内容。</p><p>Bit City与SimCity相似的游戏体验仅此而已，剩下的更加类似无脑戳戳类游戏，这也是App Store上很多地评分玩家抱怨的主原因。</p><p>每个城市都有三个固定的初始建筑：市政厅、银行和停车场。</p><p><img src="/img/BitCity/20170315_013111000_iOS.jpg" alt=""></p><p>市政厅中是可以购买的各类升级内容，分为City和Game两类，City类升级花费游戏内金币，升级仅针对本关有效，进入下一关后全部清除，并且可升级的内容会随着关数逐步解锁；Game类升级花费游戏内绿钞，永久有效。绿钞的获取是NimbleBit游戏的特色之一，可以通过IAP购买，也可以比较轻易的在游戏内逐步积累。</p><p><img src="/img/BitCity/20170315_013127000_iOS.jpg" alt=""></p><p>银行的功能是程序离线时可以保存一部分（10%）的金币收入，可以升级的唯一一项内容是可以保存的离线时长。随着关数的增加，分行会越来越多，离线收入的基数也会越来越大。</p><p><img src="/img/BitCity/20170315_013122000_iOS.jpg" alt=""></p><p>停车场中可以解锁汽车类型，每解锁一类新车，汽车带来的收入就会增加，同时地图上漫游的车辆也会变多。cubic风格的小汽车头上会不时冒出金币或绿钞，戳戳之后可以获得相应的回报。所有的小车获得金币或绿钞都是一样的，除了偶尔出现的大金币或大绿钞。</p><p><img src="/img/BitCity/20170315_051752000_iOS.jpg" alt=""></p><p>后续的关卡还会出现机场和码头，可以解锁飞机和船舶，但是基本的玩法和汽车一样。</p><p><img src="/img/BitCity/20170315_013206000_iOS.jpg" alt=""></p><p>完成特定的任务可以获得可观的绿钞回报。</p><p><img src="/img/BitCity/20170315_013209000_iOS.jpg" alt=""></p><p>NimbleBit的游戏中绿钞是重要的资源，比金币的作用大的多，比如可以快进游戏速度（一定时间）。</p><p><img src="/img/BitCity/20170315_013216000_iOS.jpg" alt=""></p><p>可以购买Game升级，永久提升某些游戏参数。</p><p><img src="/img/BitCity/20170315_013309000_iOS.jpg" alt=""></p><p>当然最肝的是可以解锁各种特殊建筑外观，比如埃菲尔铁塔。</p><p><img src="/img/BitCity/20170315_013329000_iOS.jpg" alt=""></p><p>Bit City可以氪的内容不多，2.99刀的一个补贴绿钞的小猪实惠可口。</p><p><img src="/img/BitCity/20170315_021813000_iOS.jpg" alt=""></p><p>如果足够细心可以发现作者设计的很多彩蛋，比如上图中叫做Tiny Tower的住宅。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Bit-City：一个值得轻度肝的小游戏&quot;&gt;&lt;a href=&quot;#Bit-City：一个值得轻度肝的小游戏&quot; class=&quot;headerlink&quot; title=&quot;Bit City：一个值得轻度肝的小游戏&quot;&gt;&lt;/a&gt;Bit City：一个值得轻度肝的小游戏&lt;/h1&gt;&lt;</summary>
      
    
    
    
    
    <category term="Games" scheme="http://gloomymoon.github.io/tags/Games/"/>
    
  </entry>
  
  <entry>
    <title>Python Machine Learning IV</title>
    <link href="http://gloomymoon.github.io/2017/01/25/Python-Machine-Learning-IV/"/>
    <id>http://gloomymoon.github.io/2017/01/25/Python-Machine-Learning-IV/</id>
    <published>2017-01-25T13:21:56.000Z</published>
    <updated>2017-03-17T04:00:25.378Z</updated>
    
    <content type="html"><![CDATA[<h2 id="4-Building-Good-Training-Sets-–-Data-Preprocessing"><a href="#4-Building-Good-Training-Sets-–-Data-Preprocessing" class="headerlink" title="4 Building Good Training Sets – Data Preprocessing"></a>4 Building Good Training Sets – Data Preprocessing</h2><p>数据的质量和有效信息含量直接决定了机器学习算法能够学得多好。因此在建模前绝对应当对数据进行细查和预处理。本章节将介绍构建模型前必须要具备的数据预处理技术。</p><ul><li>清除或插补缺失值</li><li>将分类数据塑形成模型可用的形式</li><li>为模型构建选择相关的特征变量</li></ul><h3 id="Dealing-with-missing-data"><a href="#Dealing-with-missing-data" class="headerlink" title="Dealing with missing data"></a>Dealing with missing data</h3><p>我们通常将缺失值视为空格或者<code>NaN</code>。不幸的是，很多计算工具无法处理这类缺失值或者会产生无法预测的结果，因此在进一步分析前需要预先处理这类缺失值。讨论这些方法前我们先来创建一个简单的样例数据，这是一个CSV（comma-separated values）文件。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> StringIO</span><br><span class="line">csv_data = <span class="string">'''A,B,C,D</span></span><br><span class="line"><span class="string">    1.0,2.0,3.,4.0</span></span><br><span class="line"><span class="string">    5.0,6.0,,8.0</span></span><br><span class="line"><span class="string">    0.0,11.0,12.0,'''</span></span><br><span class="line">csv_data = unicode(csv_data)</span><br><span class="line">df = pd.read_csv(StringIO(csv_data))</span><br><span class="line">df</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ABCD</span><br><span class="line"><span class="number">0</span><span class="number">1</span><span class="number">2</span><span class="number">3</span><span class="number">4</span></span><br><span class="line"><span class="number">1</span><span class="number">5</span><span class="number">6</span>NaN<span class="number">8</span></span><br><span class="line"><span class="number">2</span><span class="number">0</span><span class="number">11</span><span class="number">12</span>NaN</span><br></pre></td></tr></table></figure></p><p>从输出结果看到我们从CSV格式的数据读入到DataFrame对象后，缺失值被替换为<code>NaN</code>。如果使用Python3，则无需使用unicode函数。对于更大的DataFrame，可以使用<code>insnull</code>方法查看每个单元是否含有数值类型的值，然后用<code>sum</code>方法统计缺失的数量。<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">df</span><span class="selector-class">.isnull</span>()<span class="selector-class">.sum</span>()</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">A    <span class="number">0</span></span><br><span class="line">B    <span class="number">0</span></span><br><span class="line"><span class="keyword">C</span>    <span class="number">1</span></span><br><span class="line"><span class="keyword">D</span>    <span class="number">1</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p><blockquote><p>scikit-learn是基于NumPy开发的，有时候用DataFrame处理数据更加便利，因此我们可以通过DataFrame的<code>values</code>方法获取NumPy数组类型的的数据，并将它喂给scikit-learn的算法。</p></blockquote><p><strong>Eliminating samples or features with missing values</strong><br>最简单的缺失处理方法是扔掉对应的特征（列）或样本（行）。列和行可以方便地通过<code>dropna</code>方法剔除掉。<br><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">df</span><span class="selector-class">.dropna</span>()</span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.dropna</span>(axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ABCD</span><br><span class="line"><span class="number">0</span><span class="number">1</span><span class="number">2</span><span class="number">3</span><span class="number">4</span></span><br><span class="line"></span><br><span class="line">AB</span><br><span class="line"><span class="number">0</span><span class="number">1</span><span class="number">2</span></span><br><span class="line"><span class="number">1</span><span class="number">5</span><span class="number">6</span></span><br><span class="line"><span class="number">2</span><span class="number">0</span><span class="number">11</span></span><br></pre></td></tr></table></figure></p><p><code>dropna</code>方法还有一些额外的参数可以实现更加灵活的剔除逻辑。<br><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 仅剔除所有特征都为NaN的记录</span></span><br><span class="line">df.dropna(how=<span class="string">'all'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta"># 仅剔除至少有4个特征为NaN的记录</span></span><br><span class="line">df.dropna(thresh=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta"># 仅剔除特定列（这里是C）是NaN的记录</span></span><br><span class="line">df.dropna(subset=[<span class="string">'C'</span>])</span><br></pre></td></tr></table></figure></p><p>剔除缺失数据简单，但是可能会丢失过多的样本或者太多特征变量，损失对分类算法来说有用的信息。</p><p><strong>Imputing missing values</strong><br>通过其他样本的数据来对缺失值应用各种插补技术，是另外一种处理方式。一个最常用的方式是使用均值插补，scikit-learn的<code>Imputer</code>类可以方便地实现这类工作。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing import Imputer</span><br><span class="line">imr = Imputer(<span class="attribute">missing_values</span>=<span class="string">'NaN'</span>, <span class="attribute">strategy</span>=<span class="string">'mean'</span>, <span class="attribute">axis</span>=0)</span><br><span class="line">imr = imr.fit(df)</span><br><span class="line">imputed_data = imr.transform(df.values)</span><br><span class="line">imputed_data</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[  <span class="number">1.</span> ,   <span class="number">2.</span> ,   <span class="number">3.</span> ,   <span class="number">4.</span> ],</span><br><span class="line">       [  <span class="number">5.</span> ,   <span class="number">6.</span> ,   <span class="number">7.5</span>,   <span class="number">8.</span> ],</span><br><span class="line">       [  <span class="number">0.</span> ,  <span class="number">11.</span> ,  <span class="number">12.</span> ,   <span class="number">6.</span> ]])</span><br></pre></td></tr></table></figure></p><p>该例子中将缺失值<code>NaN</code>替换为每列的平均值，如果将参数<code>axis=0</code>改为<code>axis=1</code>，将替换为行的平均值。<code>strategy</code>参数其他选项还有<code>median</code>和<code>most_frequent</code>，表示中值和最常出现的值。</p><p><strong>Understanding the scikit-learn estimator API</strong><br><code>Imputer</code>类在scikit-learn中属于transformer类，主要用来对数据进行各种变形，通常包含两个重要的方法<code>fit</code>和<code>transform</code>。<code>fit</code>方法用来在训练集上学习参数，然后通过<code>transform</code>方法和参数对训练数据集进行转换。被转换的数据集必须与学习的数据集具有相同的特征变量数，下图展现了学习参数并应用于新数据集的转化过程。<br><img src="/img/PythonMachineLearningIV_01.png" alt=""></p><h3 id="Handling-categorical-data"><a href="#Handling-categorical-data" class="headerlink" title="Handling categorical data"></a>Handling categorical data</h3><p>至此，我们处理的都是数值类型特征，但在真实数据世界中存在各种分类（categorical）特征数据。分类数据可以分为有序的（ordinal）和无序的（nominal），有序的特征例如T恤衫的尺寸，因为根据定义XL大于L大于M。无序的特征比如T恤衫的颜色，颜色之间的大小排序没有现实意义。<br>同样我们先来创建一个样例数据集。<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">df = pd.<span class="symbol">DataFrame</span>([</span><br><span class="line">        [<span class="string">'green'</span>, <span class="string">'M'</span>, <span class="number">10.1</span>, <span class="string">'class1'</span>],</span><br><span class="line">        [<span class="string">'red'</span>, <span class="string">'L'</span>, <span class="number">13.5</span>, <span class="string">'class2'</span>],</span><br><span class="line">        [<span class="string">'blue'</span>, <span class="string">'XL'</span>, <span class="number">15.3</span>, <span class="string">'class1'</span>]</span><br><span class="line">    ])</span><br><span class="line">df.columns=[<span class="string">'color'</span>, <span class="string">'size'</span>, <span class="string">'price'</span>, <span class="string">'classlabel'</span>]</span><br><span class="line">df</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">colorsizepriceclasslabel</span><br><span class="line"><span class="number">0</span>greenM<span class="number">10.1</span>class1</span><br><span class="line"><span class="number">1</span>redL<span class="number">13.5</span>class2</span><br><span class="line"><span class="number">2</span>blueXL<span class="number">15.3</span>class1</span><br></pre></td></tr></table></figure></p><p>该数据中包含一个无序分类特征（颜色），一个有序分类特征（尺寸），一个数值特征（价格），和一个分类标识。本书中讨论的分类算法都无视分类标识中的大小和优先关系。</p><p><strong>Mapping ordinal features</strong><br>我们必须手工定义有序分类特征到整形的映射逻辑关系，假设我们知道特征之间的区别关系，如：XL=L+1=M+2<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">size_mapping = &#123;<span class="string">'XL'</span>: <span class="number">3</span>,</span><br><span class="line">                <span class="string">'L'</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">'M'</span>: <span class="number">1</span>&#125;</span><br><span class="line">df[<span class="string">'size'</span>] = df[<span class="string">'size'</span>].map(size_mapping)</span><br><span class="line">df</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">colorsizepriceclasslabel</span><br><span class="line"><span class="number">0</span>green<span class="number">1</span><span class="number">10.1</span>class1</span><br><span class="line"><span class="number">1</span>red<span class="number">2</span><span class="number">13.5</span>class2</span><br><span class="line"><span class="number">2</span>blue<span class="number">3</span><span class="number">15.3</span>class1</span><br></pre></td></tr></table></figure></p><p>如果需要将整型转会原始的字符串，可以定义逆映射<code>inv_size_mapping = {v:k for k, v in size_mapping.items()}</code>，然后同样适用<code>map</code>方法做一次转换。</p><p><strong>Encoding class labels</strong><br>许多机器学习库都要求分类标识必须使用整型数值，我们可以使用类似于对有序分类特征映射的方法对分类标签进行转换，由于分类标识之间没有优先关系，所以具体数值大小无关紧要，我们可以简单从0开始枚举。<br><figure class="highlight ceylon"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy as np</span><br><span class="line"><span class="keyword">class</span><span class="number">_m</span>apping = &#123;label:idx <span class="keyword">for</span> idx, label <span class="keyword">in</span> enumerate(np.unique(df[<span class="string">'classlabel'</span>]))&#125;</span><br><span class="line"><span class="keyword">class</span><span class="number">_m</span>apping</span><br><span class="line">df[<span class="string">'classlabel'</span>] = df[<span class="string">'classlabel'</span>].map(<span class="keyword">class</span><span class="number">_m</span>apping)</span><br><span class="line">df</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">'class1'</span>: <span class="number">0</span>, <span class="string">'class2'</span>: <span class="number">1</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">color</span><span class="built_in">size</span>priceclasslabel</span><br><span class="line"><span class="number">0</span><span class="built_in">green</span><span class="number">1</span><span class="number">10.1</span><span class="number">0</span></span><br><span class="line"><span class="number">1</span><span class="built_in">red</span><span class="number">2</span><span class="number">13.5</span><span class="number">1</span></span><br><span class="line"><span class="number">2</span><span class="built_in">blue</span><span class="number">3</span><span class="number">15.3</span><span class="number">0</span></span><br></pre></td></tr></table></figure></p><p>scikit-learn直接实现了一个更方便的LabelEncoder类可以直接实现上述功能。<br><figure class="highlight ceylon"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">inv<span class="number">_</span><span class="keyword">class</span><span class="number">_m</span>apping = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="keyword">class</span><span class="number">_m</span>apping.items()&#125;</span><br><span class="line">df[<span class="string">'classlabel'</span>] = df[<span class="string">'classlabel'</span>].map(inv<span class="number">_</span><span class="keyword">class</span><span class="number">_m</span>apping)</span><br><span class="line">from sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">class</span><span class="number">_</span>le = LabelEncoder()</span><br><span class="line">y = <span class="keyword">class</span><span class="number">_</span>le.fit<span class="number">_</span>transform(df[<span class="string">'classlabel'</span>].values)</span><br><span class="line">y</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br></pre></td></tr></table></figure></p><p><code>fit_transform</code>是调用<code>fit</code>和<code>transform</code>的快捷方式，另外还可以直接使用<code>inverse_transform</code>进行逆向转换。<br><figure class="highlight ceylon"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span><span class="number">_</span>le.inverse<span class="number">_</span>transform(y)</span><br></pre></td></tr></table></figure></p><p><strong>Performing ont-hot encoding on nominal features</strong><br>可以使用同样的技术对无序分类特征转换成整型，例如：blue -&gt; 0, green -&gt; 1, red -&gt; 2，机器学习算法会假设绿色大于蓝色，红色大于绿色，尽管这个假设并不正确，但是仍然可以得出一些有用的结果（当然不是最优的）。<br>一个常用的解决是独热编码（one-hot encoding），通过给变量的每一个可能取值都创建一个独立的哑变量（dummy feature）。本例中，可以将颜色特征转换成三个新的变量：blue, green, red，每个变量都通过二元标识来表示对应的颜色取值情况，比如蓝色样本的变量取值为：blue=1, green=0, red=0。scikit-learn.preprocessing模块中的OneHotEncoder实现了该类转换功能.<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">X</span> = df[[<span class="string">'color'</span>, <span class="string">'size'</span>, <span class="string">'price'</span>]].values</span><br><span class="line">color_le = <span class="symbol">LabelEncoder</span>()</span><br><span class="line"><span class="symbol">X</span>[:, <span class="number">0</span>] = color_le.fit_transform(<span class="symbol">X</span>[:, <span class="number">0</span>])</span><br><span class="line">from sklearn.preprocessing import <span class="symbol">OneHotEncoder</span></span><br><span class="line">ohe = <span class="symbol">OneHotEncoder</span>(categorical_features=[<span class="number">0</span>])</span><br><span class="line">ohe.fit_transform(<span class="symbol">X</span>).toarray()</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[  <span class="number">0.</span> ,   <span class="number">1.</span> ,   <span class="number">0.</span> ,   <span class="number">1.</span> ,  <span class="number">10.1</span>],</span><br><span class="line">       [  <span class="number">0.</span> ,   <span class="number">0.</span> ,   <span class="number">1.</span> ,   <span class="number">2.</span> ,  <span class="number">13.5</span>],</span><br><span class="line">       [  <span class="number">1.</span> ,   <span class="number">0.</span> ,   <span class="number">0.</span> ,   <span class="number">3.</span> ,  <span class="number">15.3</span>]])</span><br></pre></td></tr></table></figure></p><p>DataFrame甚至有一个更加简单的<code>get_dummies</code>方法可以直接将字符类型变量转换成哑变量。<br><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.get_dummies(df<span class="string">[['price', 'color', 'size']]</span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pricesizecolor_bluecolor_greencolor_red</span><br><span class="line"><span class="number">0</span><span class="number">10.1</span><span class="number">1</span><span class="number">0.0</span><span class="number">1.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">1</span><span class="number">13.5</span><span class="number">2</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">1.0</span></span><br><span class="line"><span class="number">2</span><span class="number">15.3</span><span class="number">3</span><span class="number">1.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br></pre></td></tr></table></figure></p><h3 id="Partioning-a-dataset-in-training-and-test-sets"><a href="#Partioning-a-dataset-in-training-and-test-sets" class="headerlink" title="Partioning a dataset in training and test sets"></a>Partioning a dataset in training and test sets</h3><p>第一章和第三章都介绍过将建模数据切分为训练集和测试集的概念，本节我们将引入一个新的数据集，通过数据预处理学习几种特征选择的降维技术。</p><p>新数据是由<a href="https://archive.ics.uci.edu/ml/datasets/Wine" target="_blank" rel="noopener">UCI</a>提供的葡萄酒数据，其包含了178个酒品样本和13个描述化学属性的特征变量，通过pandas我们可以直接从互联网都如该数据。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df_wine = pd.read_csv(<span class="string">'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'</span>, header=None)</span><br><span class="line">df_wine<span class="selector-class">.columns</span> = [<span class="string">'Class label'</span>, <span class="string">'Alcohol'</span>, <span class="string">'Malic acid'</span>, <span class="string">'Ash'</span>,</span><br><span class="line">                   <span class="string">'Alcalinity of ash'</span>, <span class="string">'Magnesium'</span>, <span class="string">'Total phenols'</span>, <span class="string">'Flavanoids'</span>,</span><br><span class="line">                   <span class="string">'Nonflavanoid phenols'</span>, <span class="string">'Proanthocyanins'</span>, <span class="string">'Color intensity'</span>, <span class="string">'Hue'</span>,</span><br><span class="line">                   <span class="string">'OD280/OD315 of diluted wines'</span>, <span class="string">'Proline'</span>]</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Class labels'</span>, np.unique(df_wine[<span class="string">'Class label'</span>])</span></span>)</span><br><span class="line">df_wine.head()</span><br></pre></td></tr></table></figure></p><p>Output:</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="symbol">'Class</span> labels', array([<span class="name">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=int64))</span><br></pre></td></tr></table></figure><p>样本包含3个分类，1、2和3，对应意大利不同区域种植的三种不同的葡萄。<br>通过cross_validation模块的<code>train_test_split</code>方法可以将数据随机分到测试集和训练集。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn<span class="selector-class">.cross_validation</span> import train_test_split</span><br><span class="line">X, y = df_wine<span class="selector-class">.iloc</span>[:, <span class="number">1</span>:]<span class="selector-class">.values</span>, df_wine<span class="selector-class">.iloc</span>[:, <span class="number">0</span>].values</span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="Bringing-features-onto-the-same-scale"><a href="#Bringing-features-onto-the-same-scale" class="headerlink" title="Bringing features onto the same scale"></a>Bringing features onto the same scale</h3><p>特征归一化（feature scaling）是预处理前容易被忽略的重要步骤，除了决策树和随机森林等少数几类算法，将特征变量映射到统一尺度下有助于大多数机器学习算法和调优，通常来说主要有两种方法：归一化（normalization）和标准化（standardization）。归一化指将特征重新映射到[0, 1]的范围，这是一种最大最小归一化的特殊情况（min-max scaling）。每个样本的特征值xi可以按照下述公式得到新值：x’ = (x - min(x))/(max(x)-min(x))。scikit-learn中可以直接使用MinMaxScaler实现。</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">mms = MinMaxScaler()</span><br><span class="line">X_train_norm = mms.fit_transform(X_train)</span><br><span class="line">X_test_norm = mms.transform(X_test)</span><br></pre></td></tr></table></figure><p>实际中标准化比归一化更加常用，因为许多线性模型（如逻辑回归和SBM）的权重初始值会设置为0或者接近0的小随机数，变量经过标准化后形成正态分布，均值为0，标准差为1，标准化还能够保留离群值（outliers）信息，但又不会影响算法。标准化常用的方法如下：<br><img src="/img/PythonMachineLearningIV_02.png" alt=""></p><p>其中µ 是样本均值，σ 是标准差。</p><p>下表展示了同一个变量经过归一化和标准化之后的结果：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">input</span> <span class="selector-tag">standardized</span> <span class="selector-tag">normalized</span></span><br><span class="line">0<span class="selector-class">.0</span> <span class="selector-tag">-1</span><span class="selector-class">.336306</span> 0<span class="selector-class">.0</span></span><br><span class="line">1<span class="selector-class">.0</span> <span class="selector-tag">-0</span><span class="selector-class">.801784</span> 0<span class="selector-class">.2</span></span><br><span class="line">2<span class="selector-class">.0</span> <span class="selector-tag">-0</span><span class="selector-class">.267261</span> 0<span class="selector-class">.4</span></span><br><span class="line">3<span class="selector-class">.0</span> 0<span class="selector-class">.267261</span> 0<span class="selector-class">.6</span></span><br><span class="line">4<span class="selector-class">.0</span> 0<span class="selector-class">.801784</span> 0<span class="selector-class">.8</span></span><br><span class="line">5<span class="selector-class">.0</span> 1<span class="selector-class">.336306</span> 1<span class="selector-class">.0</span></span><br></pre></td></tr></table></figure><p>scikit-learn同样实现了标准化的类：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">stdsc = StandardScaler()</span><br><span class="line">X_train_std = stdsc.fit_transform(X_train)</span><br><span class="line">X_test_std = stdsc.transform(X_test)</span><br><span class="line">X_test_std</span><br></pre></td></tr></table></figure><p>注意StandardScaler只训练一次，然后用来后续的所有测试和验证数据集。</p><blockquote><p>更加细节内容可以参照：<a href="http://www.zhaokv.com/2016/01/normalization-and-standardization.html" target="_blank" rel="noopener">http://www.zhaokv.com/2016/01/normalization-and-standardization.html</a></p></blockquote><h3 id="Selecting-meaningful-features"><a href="#Selecting-meaningful-features" class="headerlink" title="Selecting meaningful features"></a>Selecting meaningful features</h3><p>如果一个模型在训练集上的表现明显优于测试集，则意味着过拟合，也称为高方差（variance），通常是模型过于复杂造成。解决方案如下：</p><ul><li><p>收集更多训练数据</p></li><li><p>进入针对复杂程度的惩罚系数，例如之前介绍的正则化方法</p></li><li><p>选择一个参数更少的简单模型</p></li><li><p>对建模数据进行降维</p><p>​</p></li></ul><p>收集更多数据通常受到实际限制，本节将介绍正则化和变量选择降维技术来降低过拟合。</p><p><strong>Sparse solutions with L1 regularization</strong></p><p>第三章中介绍L2 regularization是一种降低模型复杂程度的方法，L1 regularization则是另一种。对于scikit-learn中支持L1 regularization的模型，可以简单的添加<code>penalty</code>参数并设置为`’l1’。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn<span class="selector-class">.linear_model</span> import LogisticRegression</span><br><span class="line">lr = LogisticRegression(penalty=<span class="string">'l1'</span>, C=<span class="number">0.1</span>)</span><br><span class="line">lr.fit(X_train_std, y_train)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Training accuracy:'</span>, lr.score(X_train_std, y_train)</span></span>)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Test accuracy:'</span>, lr.score(X_test_std, y_test)</span></span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Training accuracy: 0.983870967742</span><br><span class="line"><span class="keyword">Test </span>accuracy: 0.981481481481</span><br></pre></td></tr></table></figure><p>结果显示模型在训练集上和测试机上都没有出现过拟合。当我们查看<code>lr.intercept_</code>属性，可以看到返回一个有三个值的数组：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([-<span class="number">0.38381622</span>, -<span class="number">0.15806481</span>, -<span class="number">0.70048192</span>])</span><br></pre></td></tr></table></figure><p>由于我们用LogisticRegression在一个多分类数据上建模，算法默认会使用One-vs-Rest方法，第一个参数对应的是分类1对分类2和分类3，第二个参数是分类2对分类1和分类3，第三个参数是分类3对分类1和分类2。<code>lr.coef_</code>获取的权重数组有三条记录，每条对应一个分类的参数权重。这里每条记录都有13个权重参数对应了13个特征变量。</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">array([[ <span class="number">0.28007103</span>,  <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-0.02793263</span>,  <span class="number">0.</span>        ,</span><br><span class="line">           <span class="number">0.</span>        ,  <span class="number">0.70994966</span>,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,</span><br><span class="line">           <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.23675898</span>],</span><br><span class="line">         [<span class="number">-0.64388996</span>, <span class="number">-0.06884945</span>, <span class="number">-0.05719169</span>,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,</span><br><span class="line">           <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-0.92692532</span>,</span><br><span class="line">           <span class="number">0.06003993</span>,  <span class="number">0.</span>        , <span class="number">-0.37105</span>   ],</span><br><span class="line">         [ <span class="number">0.</span>        ,  <span class="number">0.06148265</span>,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,</span><br><span class="line">           <span class="number">0.</span>        , <span class="number">-0.63570527</span>,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.49779924</span>,</span><br><span class="line">          <span class="number">-0.3583329</span> , <span class="number">-0.57169567</span>,  <span class="number">0.</span>        ]])</span><br></pre></td></tr></table></figure><p>可以看到参数矩阵是稀疏的，意味经过L1正则化完成了特征筛选，使得训练的模型可以不受数据中不相关特征的影响。最后，通过调整正则化力度，观察不同变量的权重系数变化情况。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line">colors = [<span class="string">'blue'</span>, <span class="string">'green'</span>, <span class="string">'red'</span>, <span class="string">'cyan'</span>, <span class="string">'magenta'</span>, <span class="string">'yellow'</span>, <span class="string">'black'</span>,</span><br><span class="line">          <span class="string">'pink'</span>, <span class="string">'lightgreen'</span>, <span class="string">'lightblue'</span>, <span class="string">'gray'</span>, <span class="string">'indigo'</span>, <span class="string">'orange'</span>]</span><br><span class="line">weights, params = [], []</span><br><span class="line"><span class="keyword">for</span> <span class="keyword">c</span> in np.arange(-<span class="number">4</span>, <span class="number">6</span>):</span><br><span class="line">    <span class="keyword">lr</span> = LogisticRegression(penalty=<span class="string">'l1'</span>, C=<span class="number">10</span>**<span class="keyword">c</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">lr</span>.fit(X_train_std, y_train)</span><br><span class="line">    weights.<span class="keyword">append</span>(<span class="keyword">lr</span>.coef_[<span class="number">1</span>])</span><br><span class="line">    params.<span class="keyword">append</span>(<span class="number">10</span>**<span class="keyword">c</span>)import matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line">colors = [<span class="string">'blue'</span>, <span class="string">'green'</span>, <span class="string">'red'</span>, <span class="string">'cyan'</span>, <span class="string">'magenta'</span>, <span class="string">'yellow'</span>, <span class="string">'black'</span>,</span><br><span class="line">          <span class="string">'pink'</span>, <span class="string">'lightgreen'</span>, <span class="string">'lightblue'</span>, <span class="string">'gray'</span>, <span class="string">'indigo'</span>, <span class="string">'orange'</span>]</span><br><span class="line">weights, params = [], []</span><br><span class="line"><span class="keyword">for</span> <span class="keyword">c</span> in np.arange(-<span class="number">4</span>, <span class="number">6</span>):</span><br><span class="line">    <span class="keyword">lr</span> = LogisticRegression(penalty=<span class="string">'l1'</span>, C=<span class="number">10</span>**<span class="keyword">c</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">lr</span>.fit(X_train_std, y_train)</span><br><span class="line">    weights.<span class="keyword">append</span>(<span class="keyword">lr</span>.coef_[<span class="number">1</span>])</span><br><span class="line">    params.<span class="keyword">append</span>(<span class="number">10</span>**<span class="keyword">c</span>)</span><br><span class="line">weights = np.array(weights)</span><br><span class="line"><span class="keyword">for</span> column, color in zip(<span class="built_in">range</span>(weights.shape[<span class="number">1</span>]), colors):</span><br><span class="line">    plt.plot(params, weights[:, column], label=df_wine.columns[column+<span class="number">1</span>], color=color)</span><br><span class="line">plt.axhline(<span class="number">0</span>, color=<span class="string">'black'</span>, linestyle=<span class="string">'--'</span>, linewidth=<span class="number">3</span>)</span><br><span class="line">plt.xlim([<span class="number">10</span>**(-<span class="number">5</span>), <span class="number">10</span>**<span class="number">5</span>])</span><br><span class="line">plt.ylabel(<span class="string">'weight coefficient'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'C'</span>)</span><br><span class="line">plt.xscale(<span class="string">'log'</span>)</span><br><span class="line">plt.legend(<span class="keyword">loc</span>=<span class="string">'upper left'</span>)</span><br><span class="line">ax.legend(<span class="keyword">loc</span>=<span class="string">'upper center'</span>, bbox_to_anchor=(<span class="number">1.38</span>, <span class="number">1.03</span>), ncol=<span class="number">1</span>, fancybox=True)</span><br><span class="line">plt.show()</span><br><span class="line">weights = np.array(weights)</span><br><span class="line"><span class="keyword">for</span> column, color in zip(<span class="built_in">range</span>(weights.shape[<span class="number">1</span>]), colors):</span><br><span class="line">    plt.plot(params, weights[:, column], label=df_wine.columns[column+<span class="number">1</span>], color=color)</span><br><span class="line">plt.axhline(<span class="number">0</span>, color=<span class="string">'black'</span>, linestyle=<span class="string">'--'</span>, linewidth=<span class="number">3</span>)</span><br><span class="line">plt.xlim([<span class="number">10</span>**(-<span class="number">5</span>), <span class="number">10</span>**<span class="number">5</span>])</span><br><span class="line">plt.ylabel(<span class="string">'weight coefficient'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'C'</span>)</span><br><span class="line">plt.xscale(<span class="string">'log'</span>)</span><br><span class="line">plt.legend(<span class="keyword">loc</span>=<span class="string">'upper left'</span>)</span><br><span class="line">ax.legend(<span class="keyword">loc</span>=<span class="string">'upper center'</span>, bbox_to_anchor=(<span class="number">1.38</span>, <span class="number">1.03</span>), ncol=<span class="number">1</span>, fancybox=True)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/img/PythonMachineLearningIV_03.png" alt=""></p><p>上图展示了L1正则化对所有参数的作用，当正则化参数很强（C&lt;0.1）时，所有特征的权重都会趋于0。</p><p><strong>Sequential feature selection algorithms</strong></p><p>另一个降低模型复杂度避免过拟合的方法是通过特征筛选进行降维（dimensionality reduction），这对于非正则化（unregularized）模型尤为有用。降维主要有两类技术：特征选择（feature selection）和特征抽取（feature extraction）。前者是从原始变量中选择部分特征，而后者是基于原变量构建一个特征子空间。本章我们将探索特征筛选算法，下章节将介绍特征抽取技术。</p><p>序列特征选择（Sequential feature selection）是一类贪婪搜索算法，用于将初始d维特征子集压缩到k维特征子集上。算法的原理是自动选择一个特征子集，通过删除不相关的特征或者噪音数据使得模型能够提升计算效率或降低泛化误差（generalization error）。一个经典的序列特征选择算法是序列后向选择（Sequential Backward Selection，SBS）。SBS从特征全集开始，每次从中剔除一个特征，直到特征数量达到希望值。为了判断每次剔除哪个变量，需要定义一个评价函数J，J可以简单定义为剔除特定变量前后之间的性能差异，这样只要保证每次剔除的变量的评价函数J最小即可。SBS算法没有在scikit-learn中实现，但是因为非常简单，我们可以自行完成：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.base import clone</span><br><span class="line">from itertools import combinations</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.cross_validation import train_test_split</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SBS</span>():</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, estimator, k_features,</span></span></span><br><span class="line"><span class="function"><span class="params">    scoring=accuracy_score,</span></span></span><br><span class="line"><span class="function"><span class="params">    test_size=<span class="number">0</span>.<span class="number">25</span>, random_state=<span class="number">1</span>)</span></span><span class="symbol">:</span></span><br><span class="line"><span class="keyword">self</span>.scoring = scoring</span><br><span class="line"><span class="keyword">self</span>.estimator = clone(estimator)</span><br><span class="line"><span class="keyword">self</span>.k_features = k_features</span><br><span class="line"><span class="keyword">self</span>.test_size = test_size</span><br><span class="line"><span class="keyword">self</span>.random_state = random_state</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(<span class="keyword">self</span>, X, y)</span></span><span class="symbol">:</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="keyword">self</span>.test_size, random_state=<span class="keyword">self</span>.random_state)</span><br><span class="line">dim = X_train.shape[<span class="number">1</span>]</span><br><span class="line"><span class="keyword">self</span>.indices<span class="number">_</span> = tuple(range(dim))</span><br><span class="line"><span class="keyword">self</span>.subsets<span class="number">_</span> = [<span class="keyword">self</span>.indices<span class="number">_</span>]</span><br><span class="line">score = <span class="keyword">self</span>._calc_score(X_train, y_train, X_test, y_test, <span class="keyword">self</span>.indices<span class="number">_</span>)</span><br><span class="line"><span class="keyword">self</span>.scores<span class="number">_</span> = [score]</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> dim &gt; <span class="keyword">self</span>.<span class="symbol">k_features:</span></span><br><span class="line">scores = []</span><br><span class="line">subsets = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> combinations(<span class="keyword">self</span>.indices<span class="number">_</span>, r=dim-<span class="number">1</span>)<span class="symbol">:</span></span><br><span class="line">score = <span class="keyword">self</span>._calc_score(X_train, y_train, X_test, y_test, p)</span><br><span class="line">scores.append(score)</span><br><span class="line">subsets.append(p)</span><br><span class="line"></span><br><span class="line">best = np.argmax(scores)</span><br><span class="line"><span class="keyword">self</span>.indices<span class="number">_</span> = subsets[best]</span><br><span class="line"><span class="keyword">self</span>.subsets<span class="number">_</span>.append(<span class="keyword">self</span>.indices<span class="number">_</span>)</span><br><span class="line">dim -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">self</span>.scores<span class="number">_</span>.append(scores[best])</span><br><span class="line"><span class="keyword">self</span>.k_score<span class="number">_</span> = <span class="keyword">self</span>.scores<span class="number">_</span>[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">self</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(<span class="keyword">self</span>, X)</span></span><span class="symbol">:</span></span><br><span class="line"><span class="keyword">return</span> X[<span class="symbol">:</span>, <span class="keyword">self</span>.indices<span class="number">_</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calc_score</span><span class="params">(<span class="keyword">self</span>, X_train, y_train, X_test, y_test, indices)</span></span><span class="symbol">:</span></span><br><span class="line"><span class="keyword">self</span>.estimator.fit(X_train[<span class="symbol">:</span>, indices], y_train)</span><br><span class="line">y_pred = <span class="keyword">self</span>.estimator.predict(X_test[<span class="symbol">:</span>, indices])</span><br><span class="line">score = <span class="keyword">self</span>.scoring(y_test, y_pred)</span><br><span class="line"><span class="keyword">return</span> score</span><br></pre></td></tr></table></figure><p>我们实现的方法中，<code>k_features</code>参数定义了需要的特征数量，<code>scoreing</code>参数默认使用scikit-learn的<code>accuracy_score</code>来评估特征子集上的模型分类效果。在<code>while</code>循环中的<code>fit</code>方法，<code>itertools.combination</code>方法不断精简生成新的特征子集并评价模型表现，知道特征数量满足我们的制定要求。每一次循环中表现最好的特征子集的准确度存放于<code>self.scores_</code>列表中，最终特征变量的下标会存储在<code>self.indices_</code>中，可以方便的用<code>transform</code>方法生成选中特征的数据集。注意在<code>fit</code>方法中，我们简单的将不在最佳表现特征子集中的列去除，而没有显示计算各特征组合的差异。</p><p>现在我们可以将SBS算法应用于KNN分类算法中实践一下：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.neighbors <span class="built_in">import</span> KNeighborsClassifier</span><br><span class="line"><span class="built_in">import</span> matplotlib.pyplot as plt</span><br><span class="line"><span class="attr">knn</span> = KNeighborsClassifier(<span class="attr">n_neighbors=2)</span></span><br><span class="line"><span class="attr">sbs</span> = SBS(knn, <span class="attr">k_features=1)</span></span><br><span class="line">sbs.fit(X_train_std, y_train)</span><br></pre></td></tr></table></figure><p>我们在SBS实现中已经在<code>fit</code>方法中将输入数据集拆分为训练和测试集，所以可以直接输入<code>X_train</code>训练集。这个步骤必不可少，可以避免我们原始的测试数据成为训练数据的一部分。</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">k_feat = [len(k) <span class="keyword">for</span> k <span class="keyword">in</span> sbs.subsets_]</span><br><span class="line">plt.plot(k_feat, sbs.scores_, marker='o')</span><br><span class="line">plt.ylim([<span class="number">0.7</span>, <span class="number">1.1</span>])</span><br><span class="line">plt.<span class="built_in">ylabel</span>('Accuracy')</span><br><span class="line">plt.<span class="built_in">xlabel</span>('Number of <span class="built_in">features</span>')</span><br><span class="line">plt.<span class="built_in">grid</span>()</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br></pre></td></tr></table></figure><p><img src="/img/PythonMachineLearningIV_04.png" alt=""></p><p>从上图结果可以看到，当特征数量下降时，KNN分类器的准确度获得提升。为了满足我们的好奇心，可以查看准确度达到100%时的5个特征是什么，通过获取<code>sbs.subsets_</code>的第9个（也就是特征数为5时）的特征变量名：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">k5 = list(sbs.subsets_[8])</span><br><span class="line">print(df_wine.columns[<span class="string">1:</span>][<span class="symbol">k5</span>])</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Index</span>([<span class="symbol">'Alcohol'</span>, <span class="symbol">'Malic</span> acid', <span class="symbol">'Alcalinity</span> <span class="keyword">of</span> ash', <span class="symbol">'Hue'</span>, <span class="symbol">'Proline'</span>], dtype=<span class="symbol">'object'</span>)</span><br></pre></td></tr></table></figure><p>下一步，验证一下KNN分类器在原始测试集上的表现性能：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">knn.fit(X_train_std, y_train)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Training accuracy: '</span>, knn.score(X_train_std, y_train)</span></span>)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">"Test accuracy: "</span>, knn.score(X_test_std, y_test)</span></span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Training accuracy:  0.983870967742</span><br><span class="line"></span><br><span class="line"><span class="keyword">Test </span>accuracy:  0.944444444444</span><br></pre></td></tr></table></figure><p>首先我们使用完整特征集训练的模型，在训练集上精准度约为98.4%，在测试集上准确度誉为94.4%，显示模型有一定程度的过拟合。现在我们使用选择的5个特征来重新训练：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">knn.fit(X_train_std[:, k5], y_train)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Training accuracy: '</span>, knn.score(X_train_std[:, k5], y_train)</span></span>)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Test accuracy: '</span>, knn.score(X_test_std[:, k5], y_test)</span></span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Training accuracy:  0.959677419355</span><br><span class="line"></span><br><span class="line"><span class="keyword">Test </span>accuracy:  0.962962962963</span><br></pre></td></tr></table></figure><p>使用比原来少一半的特征，KNN模型在测试数据集上的精准度提升了2个百分点，并且与训练集上的精准度差异明显小，显著降低模型的过拟合度。</p><blockquote><p>Feature selection algorithms in scikit-learn</p><p>scikit-learn中有很多特征选择算法，可以参见<a href="http://scikitlearn.org/stable/modules/feature_selection.html" target="_blank" rel="noopener"></a>，也可以参见<a href="http://www.cnblogs.com/heaad/archive/2011/01/02/1924088.html" target="_blank" rel="noopener"></a></p></blockquote><h3 id="Assessing-feature-importance-with-random-forests"><a href="#Assessing-feature-importance-with-random-forests" class="headerlink" title="Assessing feature importance with random forests"></a>Assessing feature importance with random forests</h3><p>除了用SBS算法和逻辑回归，还可以利用随机森林来选择相关特征。通过随机森林，在无需关注数据是否线性可分的情况下，直接通过所有决策树计算出的平均杂质度减少情况来评估特征的重要程度。scikit-learn中的随机森林算法已经手机了特征重要度，我们可以在训练后方便地通过<code>feature_importances_</code>属性来访问。下面的代码中，我们现在Wine数据上训练10000棵树的随机森林，并对13个特征的重要性排名。基于树的模型无需标准化和规范化。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble import RandomForestClassifier</span><br><span class="line">feat_labels = df_wine.columns[1:]</span><br><span class="line">forest = RandomForestClassifier(<span class="attribute">n_estimators</span>=10000, <span class="attribute">random_state</span>=0, <span class="attribute">n_jobs</span>=-1)</span><br><span class="line">forest.fit(X_train, y_train)</span><br><span class="line">importances = forest.feature_importances_</span><br><span class="line">indices = np.argsort(importances)[::-1]</span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> range(X_train.shape[1]):</span><br><span class="line">    <span class="builtin-name">print</span>(<span class="string">"%2d) %-*s %f"</span> % (f + 1, 30, feat_labels[f], importances[indices[f]]))</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> <span class="number">1</span>) Alcohol                        <span class="number">0.182483</span></span><br><span class="line"> <span class="number">2</span>) Malic acid                     <span class="number">0.158610</span></span><br><span class="line"> <span class="number">3</span>) Ash                            <span class="number">0.150948</span></span><br><span class="line"> <span class="number">4</span>) Alcalinity of ash              <span class="number">0.131987</span></span><br><span class="line"> <span class="number">5</span>) Magnesium                      <span class="number">0.106589</span></span><br><span class="line"> <span class="number">6</span>) Total phenols                  <span class="number">0.078243</span></span><br><span class="line"> <span class="number">7</span>) Flavanoids                     <span class="number">0.060718</span></span><br><span class="line"> <span class="number">8</span>) Nonflavanoid phenols           <span class="number">0.032033</span></span><br><span class="line"> <span class="number">9</span>) Proanthocyanins                <span class="number">0.025400</span></span><br><span class="line"><span class="number">10</span>) Color intensity                <span class="number">0.022351</span></span><br><span class="line"><span class="number">11</span>) Hue                            <span class="number">0.022078</span></span><br><span class="line"><span class="number">12</span>) OD280/OD315 of diluted wines   <span class="number">0.014645</span></span><br><span class="line"><span class="number">13</span>) Proline                        <span class="number">0.013916</span></span><br></pre></td></tr></table></figure><p>所有特征的重要度已经经过规范化，它们的总和等于1.0。通过10000棵决策树训练的结论是alcohol是区分酒对重要的特征变量，且排名靠前的3个特征也在之前SBS算法选择的5个特征中。不过就可解释性而言，随机森林有个问题需要注意，如果两个和多个特征高度相关，一个特征会获得很高的排名而其它相关的特征会被忽视。如果我们仅仅关心模型的预测能力而不用解释变量的重要性则不必过分关注这个问题。</p><p>最后，scikit-learn中的随机森林分类器同样实现了<code>transform</code>方法，可以基于用户指定的阈值选择特征变量，例如我们可以设定阈值为0.15，将Wine数据集的变量限定在最重要的三个。</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_selected = forest.transform(X_train, threshold=0.15)</span><br><span class="line">X_selected.shape</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">124</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;4-Building-Good-Training-Sets-–-Data-Preprocessing&quot;&gt;&lt;a href=&quot;#4-Building-Good-Training-Sets-–-Data-Preprocessing&quot; class=&quot;headerlink&quot;</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Machine Learning" scheme="http://gloomymoon.github.io/tags/Machine-Learning/"/>
    
    <category term="scikit-learn" scheme="http://gloomymoon.github.io/tags/scikit-learn/"/>
    
  </entry>
  
  <entry>
    <title>Python Machine Learning III</title>
    <link href="http://gloomymoon.github.io/2017/01/21/Python-Machine-Learning-III/"/>
    <id>http://gloomymoon.github.io/2017/01/21/Python-Machine-Learning-III/</id>
    <published>2017-01-21T07:23:52.000Z</published>
    <updated>2017-01-26T07:04:48.420Z</updated>
    
    <content type="html"><![CDATA[<h2 id="3-A-Tour-of-Machine-Learning-Classifiers-Using-Scikit-learn"><a href="#3-A-Tour-of-Machine-Learning-Classifiers-Using-Scikit-learn" class="headerlink" title="3 A Tour of Machine Learning Classifiers Using Scikit-learn"></a>3 A Tour of Machine Learning Classifiers Using Scikit-learn</h2><p>本章将浏览一系列流行而且强大的机器学习算法，学习区别的时候也会了解各个分类算法的强项和弱点。</p><ul><li>流行分类算法的概要介绍</li><li>使用scikit-learn</li><li>选择一个机器学习算法前需要回答的问题</li></ul><h3 id="Choosing-a-classification-algorithm"><a href="#Choosing-a-classification-algorithm" class="headerlink" title="Choosing a classification algorithm"></a>Choosing a classification algorithm</h3><p>为特定任务选择合适的分类算法需要实践，每个算法都有各自的特性和前提假设，没有一个算法适用于所有场景。实践中，应当比较多个不同算法的效果来找到最合适的分类算法。请记住分类器的性能和预测能力主要依赖于（分析人员）对训练数据的理解。</p><p>训练算法的主要过程如下：</p><ol><li>选择特征变量</li><li>选择性能评价指标</li><li>选择一个分类算法并优化（optimization）</li><li>评估模型的效果</li><li>算法调优（tuning）</li></ol><h3 id="First-steps-with-scikit-learn"><a href="#First-steps-with-scikit-learn" class="headerlink" title="First steps with scikit-learn"></a>First steps with scikit-learn</h3><p><strong>Training a perceptron via scikit-learn</strong><br>我们先使用scikit-learn来训练一个感知器模型，训练数据仍使用Iris。<br><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="title">iris</span> = datasets.load_iris()</span><br><span class="line"><span class="type">X</span> = iris.<span class="class"><span class="keyword">data</span>[:, [2,3]]</span></span><br><span class="line"><span class="title">y</span> = iris.target</span><br></pre></td></tr></table></figure></p><p>因为使用频繁，iris已经被直接纳入scikit-learn包中，实际应用中也会用该数据来进行模型调试。和原始数据不同，这里的iris数据中的target已经转换成整型（0, 1, 2）,这也是算法调优推荐的做法。为了评估模型在未知数据上的性能，后续章节（第5章）会介绍如何将数据分为多个独立的部分，这里先了解主要用法。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_validation import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, <span class="attribute">test_size</span>=0.3, <span class="attribute">random_state</span>=0)</span><br></pre></td></tr></table></figure></p><p>使用<code>train_test_split</code>方法将X和y分成测试集（30%）和训练集（70%）。</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">sc = StandardScaler()</span><br><span class="line">sc.fit(X_train)</span><br><span class="line">X_train_std = sc.transform(X_train)</span><br><span class="line">X_test_std = sc.transform(X_test)</span><br></pre></td></tr></table></figure><p>StandardScaler对象的<code>fit</code>参数计算训练样本中每个特征维度的均值和标准差，<code>transform</code>方法则会根据均值和标准差对数据集进行标准化，注意这里对测试集和训练集使用的是同一个尺度（scaling）。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model import Perceptron</span><br><span class="line">ppn = Perceptron(<span class="attribute">n_iter</span>=40, <span class="attribute">eta0</span>=0.1, <span class="attribute">random_state</span>=0)</span><br><span class="line">ppn.fit(X_train_std, y_train)</span><br></pre></td></tr></table></figure></p><p>Scikit-learn中的感知器用法和我们第二章中实现的类似，eta0等同于我们的eta，注意这里我们直接用三个分类的数据训练模型，之后就可以通过<code>predict</code>方法在测试集上进行预测。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = ppn.predict(X_test_std)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Misclassfified samples: %d'</span> % (y_test != y_pred)</span></span>.sum())</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Misclassfified <span class="string">samples:</span> <span class="number">4</span></span><br></pre></td></tr></table></figure></p><p>预测错误4个，错误率约等于8.9%（4/45）<br>Scikit-learn的<code>metrics</code>包中提供了各种不同的性能指标，例如准确率：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn<span class="selector-class">.metrics</span> import accuracy_score</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Accuracy: %.2f'</span> % accuracy_score(y_test, y_pred)</span></span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">Accuracy:</span> <span class="number">0.91</span></span><br></pre></td></tr></table></figure></p><p>最后我们可以使用第2章中编写的<code>plot_decision_regions</code>方法来展示模型分类效果，做的修改是为了高亮显示样本集数据。<br>Plot_decision_regions.py<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">from matplotlib.colors import ListedColormap</span><br><span class="line">import matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">import numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">def plot_decision_regions(<span class="keyword">X</span>, <span class="keyword">y</span>, classifier, test_idx=None, resolution=<span class="number">0.02</span>):</span><br><span class="line">    # setup marker generator <span class="built_in">and</span> color <span class="keyword">map</span></span><br><span class="line">    markers = (<span class="string">'s'</span>, <span class="string">'x'</span>, <span class="string">'o'</span>, <span class="string">'^'</span>, <span class="string">'v'</span>)</span><br><span class="line">    colors = (<span class="string">'red'</span>, <span class="string">'blue'</span>, <span class="string">'lightgreen'</span>, <span class="string">'gray'</span>, <span class="string">'cyan'</span>)</span><br><span class="line">    <span class="keyword">cmap</span> = ListedColormap(colors[:<span class="built_in">len</span>(np.unique(<span class="keyword">y</span>))])</span><br><span class="line"></span><br><span class="line">    # plot the decision surface</span><br><span class="line">    x1_min, x1_max = <span class="keyword">X</span>[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, <span class="keyword">X</span>[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">    x2_min, x2_max = <span class="keyword">X</span>[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, <span class="keyword">X</span>[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), </span><br><span class="line">       np.arange(x2_min, x2_max, resolution))</span><br><span class="line">    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)</span><br><span class="line">    Z = Z.reshape(xx1.shape)</span><br><span class="line">    plt.contourf(xx1, xx2, Z, alpha=<span class="number">0.4</span>, <span class="keyword">cmap</span>=<span class="keyword">cmap</span>)</span><br><span class="line">    plt.xlim(xx1.<span class="built_in">min</span>(), xx1.<span class="built_in">max</span>())</span><br><span class="line">    plt.ylim(xx2.<span class="built_in">min</span>(), xx2.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line">    # plot <span class="keyword">all</span> samples</span><br><span class="line">    X_test, y_test = <span class="keyword">X</span>[test_idx, :], <span class="keyword">y</span>[test_idx]</span><br><span class="line">    <span class="keyword">for</span> idx, <span class="keyword">cl</span> in enumerate(np.unique(<span class="keyword">y</span>)):</span><br><span class="line">    plt.scatter(<span class="keyword">x</span>=<span class="keyword">X</span>[<span class="keyword">y</span> == <span class="keyword">cl</span>, <span class="number">0</span>], <span class="keyword">y</span>=<span class="keyword">X</span>[<span class="keyword">y</span> == <span class="keyword">cl</span>, <span class="number">1</span>],</span><br><span class="line">    alpha=<span class="number">0.8</span>, <span class="keyword">c</span>=<span class="keyword">cmap</span>(idx),</span><br><span class="line">    marker=markers[idx], label=<span class="keyword">cl</span>)</span><br><span class="line"></span><br><span class="line">    # <span class="keyword">highlight</span> test samples</span><br><span class="line">    <span class="keyword">if</span> test_idx:</span><br><span class="line">    X_test, y_test = <span class="keyword">X</span>[test_idx, :], <span class="keyword">y</span>[test_idx]</span><br><span class="line">    plt.scatter(X_test[:, <span class="number">0</span>], X_test[:, <span class="number">1</span>], <span class="keyword">c</span>=<span class="string">''</span>,</span><br><span class="line">    alpha=<span class="number">1.0</span>, linewidth=<span class="number">1</span>, marker=<span class="string">'o'</span>,</span><br><span class="line">    s=<span class="number">55</span>, label=<span class="string">'test set'</span>)</span><br></pre></td></tr></table></figure></p><p>展示感知器分类结果：<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from plot_decision_regions import *</span><br><span class="line">X_combined_std = <span class="built_in">np</span>.vstack((X_train_std, X_test_std))</span><br><span class="line">y_combined = <span class="built_in">np</span>.hstack((y_train, y_test))</span><br><span class="line">plot_decision_regions(X=X_combined_std, y=y_combined, classifier=ppn, test_idx=<span class="built_in">range</span>(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.<span class="built_in">xlabel</span>('petal <span class="built_in">length</span> [standardized]')</span><br><span class="line">plt.<span class="built_in">ylabel</span>('petal <span class="built_in">width</span> [standardized]')</span><br><span class="line">plt.<span class="built_in">legend</span>(loc='upper left')</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningIII_01.png" alt=""></p><p>结果如图所示，对于无法线性区分的数据，感知器永远不会收敛。</p><h3 id="Modeling-class-probabilities-via-logistic-regression"><a href="#Modeling-class-probabilities-via-logistic-regression" class="headerlink" title="Modeling class probabilities via logistic regression"></a>Modeling class probabilities via logistic regression</h3><p>感知器方法简单易懂，是很好的入门算法，但是因为存在上述缺陷无法有效应付类似的业务场景。我们来尝试另一个同样简单但是强大的分类器算法：逻辑回归，请注意其本质是一个线性/二元分类模型，而不是回归。<br><strong>Logistic regression intuition and conditional probabilities</strong><br>逻辑回归实现简单但是性能优秀，有广泛的应用。介绍逻辑回归这一概率模型前，先要引入比值比（odds radio，OR），其定义如下： p/(1-p)，其中p代表某个需要预测的事件出现的概率。在此基础上定义logit函数：<br><img src="/img/PythonMachineLearningIII_02.png" alt=""></p><p>该函数输入洁玉0～1之间，输出是整个实数范围。因为我们更关心的是概率p的预测，所以需要需要对logit函数取反，就是logstic函数：<br><img src="/img/PythonMachineLearningIII_03.png" alt=""></p><p>其中z是输入网络，是所有特征和权重的线性组合。因为该函数形如S，所以也成为sigmoid函数。下图是sigmoid在[-7, 7]范围上的曲线图：<br><img src="/img/PythonMachineLearningIII_04.png" alt=""></p><p>将之前我们实现的Adaline算法中的激活函数替换成sigmoid函数就成为了逻辑回归。<br><img src="/img/PythonMachineLearningIII_05.png" alt=""></p><p>此时sigmoid函数的输出解释为样本数据属于分类1的概率。通过单步阶梯函数能够方便的转化为二元分类器，但是有的时候概率能够应用于更多的场景，例如降水概率、患病概率。</p><p><strong>Learning the weights of the logistic cost function</strong><br>（理论公式，略过）<br><strong>Training a logistic regression model with scikit-learn</strong><br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn<span class="selector-class">.linear_model</span> import LogisticRegression</span><br><span class="line">lr = LogisticRegression(C=<span class="number">1000.0</span>, random_state=<span class="number">0</span>)</span><br><span class="line">lr.fit(X_train_std, y_train)</span><br><span class="line"><span class="function"><span class="title">plot_decision_regions</span><span class="params">(X_combined_std, y_combined, classifier=lr, test_idx=range(<span class="number">105</span>, <span class="number">150</span>)</span></span>)</span><br><span class="line">plt.xlabel(<span class="string">'petal length [standardized]'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'petal width [standardized]'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper left'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>Scikit-learn实现了高效的逻辑回归算法，使用方法类似，训练后展示的分类效果如下图：<br><img src="/img/PythonMachineLearningIII_06.png" alt=""></p><p>更进一步，我们能够预测单个样本划分到每类结果的概率：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">lr</span><span class="selector-class">.predict_proba</span>(<span class="selector-tag">X_test_std</span><span class="selector-attr">[0, :]</span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array(<span class="string">[[  2.05743774e-11,   6.31620264e-02,   9.36837974e-01]]</span>)</span><br></pre></td></tr></table></figure></p><p><strong>Tackling overfitting via reqularization</strong><br>在解释参数C以前，我们先了解下过拟合（overfitting）和正则化（regularization）。过拟合是指模型在训练集上表现良好但是在测试集上效果不佳（称作高方差，variance），可能是变量太多函数泰国复杂或者训练数据不够；也可能出现欠拟合（underfitting，也称作高偏差，bias）），模型没有很好的找到数据中的模式和规律，训练不足。下图虽然使用非线性分类边界描绘，但是能够直观地解释过拟合和欠拟合的情况和原因：<br><img src="/img/PythonMachineLearningIII_07.png" alt=""></p><p>寻找合适的模型偏差-方差的一个方法是通过正则化调整模型的复杂程度。正则化能够有效应对变量同线性问题，过滤噪点数据，避免过拟合，其原理是对过度的权重参数进入额外的惩罚。最常用的正则化形式是L2正则化：<br><img src="/img/PythonMachineLearningIII_08.png" alt=""></p><p>将这个结果加入到成本函数中，其中λ是正则化参数，λ越大正则化效应越大。</p><blockquote><p>正则化也是将特征变量标准化的原因之一。</p></blockquote><p>在scikit-learn实现中，参数C定义为λ的倒数，借用SVM的约定。降低C就是增加λ。<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">weights, params = [], []</span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">np</span>.arange(-<span class="number">5</span>, <span class="number">5</span>):</span><br><span class="line">    lr = LogisticRegression(C=<span class="number">10</span>**c, random_state=<span class="number">0</span>)</span><br><span class="line">    lr.fit(X_train_std, y_train)</span><br><span class="line">    weights.<span class="built_in">append</span>(lr.coef_[<span class="number">1</span>])</span><br><span class="line">    params.<span class="built_in">append</span>(<span class="number">10</span>**c)</span><br><span class="line">weights = <span class="built_in">np</span>.<span class="built_in">array</span>(weights)</span><br><span class="line">plt.plot(params, weights[:, <span class="number">0</span>], <span class="built_in">label</span>='petal <span class="built_in">length</span>')</span><br><span class="line">plt.plot(params, weights[:, <span class="number">1</span>], linestyle='--', <span class="built_in">label</span>='petal <span class="built_in">width</span>')</span><br><span class="line">plt.<span class="built_in">ylabel</span>('weight coefficient')</span><br><span class="line">plt.<span class="built_in">xlabel</span>('C')</span><br><span class="line">plt.<span class="built_in">legend</span>(loc='upper left')</span><br><span class="line">plt.xscale('<span class="built_in">log</span>')</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br></pre></td></tr></table></figure></p><p>从图上可以看出，当C变小时，特征变量的系统系数逐渐收缩到0，达到了正则化效应增强的结果。<br><img src="/img/PythonMachineLearningIII_09.png" alt=""></p><h3 id="Maximum-margin-classification-with-support-vector-machines"><a href="#Maximum-margin-classification-with-support-vector-machines" class="headerlink" title="Maximum margin classification with support vector machines"></a>Maximum margin classification with support vector machines</h3><p>另一个广泛使用的强大分类算法是支持向量机（support vector machine，SVM），其可以视为是感知器的延伸。在感知器算法中我们需要最小化错分类偏差，在支持向量机中优化目标是最大化类间间隔。类间间隔的定义是两个超平面之间的距离，训练集中最接近超平面的样本成为支持向量。<br><img src="/img/PythonMachineLearningIII_10.png" alt=""></p><p><strong>Maximum margin intuition</strong><br>（计算公式推导，略过）</p><p><strong>Dealing with the nonlinearly separable case using slack variables</strong><br> 这里不过分深入公式的推导，简单介绍下参数C的作用，如下图所示，通过参数C可以控制对错误分类结果的惩罚力度。C越大对错误分类的惩罚越大（即分类更加准确），C越小对错误分类的限制要求更宽松。因此C参数与正则化相关，通过增加C的大小，就会增加模型的偏度，降低模型的方差，这个影响关系和逻辑回归中的参数C的效用一致。<br><img src="/img/PythonMachineLearningIII_11.png" alt=""></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn<span class="selector-class">.svm</span> import SVC</span><br><span class="line">svm = SVC(kernel=<span class="string">'linear'</span>, C=<span class="number">1.0</span>, random_state=<span class="number">0</span>)</span><br><span class="line">svm.fit(X_train_std, y_train)</span><br><span class="line"><span class="function"><span class="title">plot_decision_regions</span><span class="params">(X_combined_std, y_combined, classifier=svm, test_idx=range(<span class="number">105</span>, <span class="number">150</span>)</span></span>)</span><br><span class="line">plt.xlabel(<span class="string">'petal length [standardized]'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'petal width [standardized]'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper left'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/img/PythonMachineLearningIII_12.png" alt=""></p><blockquote><p>逻辑回归和支持向量机的比较<br>在实际分类问题中，线性逻辑回归和线性支持向量机的效果非常接近。两者的区别是，逻辑回归会尽可能利用所有数据，相较支持向量机会夸大异常点数据；而支持向量机更关注距离分类面最近的数据点（支持向量）。但是另一方面，逻辑回归的优势是实现相对简单，并且可以基于流数据在线更新。</p></blockquote><p><strong>Alternative implementations in scikit-learn</strong><br>我们之前使用的模型底层调用的是优化后的C/C++库，另外，scikit-learn提供了另一种算法实现用于当训练数据太大无法装入内存的场景，原理类似于我们之前学习的Adaline的SGD实现方式，通过<code>partial_fit</code>方法来增量训练模型，调用方式如下：<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.linear_model <span class="built_in">import</span> SGDClassifier</span><br><span class="line"><span class="attr">ppn</span> = SGDClassifier(<span class="attr">loss=’perceptron’)</span></span><br><span class="line"><span class="attr">lr</span> = SGDClassifier(<span class="attr">loss=’log’)</span></span><br><span class="line"><span class="attr">svm</span> = SGDClassifier(<span class="attr">loss=’hinge’)</span></span><br></pre></td></tr></table></figure></p><h3 id="Solving-nonlinear-problems-using-a-kernel-SVM"><a href="#Solving-nonlinear-problems-using-a-kernel-SVM" class="headerlink" title="Solving nonlinear problems using a kernel SVM"></a>Solving nonlinear problems using a kernel SVM</h3><p>支持向量机广泛流行的另一个原因是能够容易地核化（kernelized）解决非线性分类问题。再讨论核函数支持向量机（kernel SVM）前，先来定义一个非线性分类的数据。<br>下面的代码使用<code>logical_xor</code>函数创建一个异或门形式的数据，其中100标记为1，100标记为-1。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(0)</span><br><span class="line">X_xor = np.random.randn(200, 2)</span><br><span class="line">y_xor = np.logical_xor(X_xor[:, 0] &gt; 0, X_xor[:, 1] &gt;0)</span><br><span class="line">y_xor = np.where(y_xor, 1, -1)</span><br><span class="line"></span><br><span class="line">plt.scatter(X_xor[<span class="attribute">y_xor</span>==1, 0], X_xor[<span class="attribute">y_xor</span>==1, 1], <span class="attribute">c</span>=<span class="string">'b'</span>, <span class="attribute">marker</span>=<span class="string">'x'</span>, <span class="attribute">label</span>=<span class="string">'1'</span>)</span><br><span class="line">plt.scatter(X_xor[<span class="attribute">y_xor</span>==-1, 0], X_xor[<span class="attribute">y_xor</span>==-1, 1], <span class="attribute">c</span>=<span class="string">'r'</span>, <span class="attribute">marker</span>=<span class="string">'s'</span>, <span class="attribute">label</span>=<span class="string">'-1'</span>)</span><br><span class="line">plt.ylim(-3.0)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningIII_13.png" alt=""></p><p>显然无法通过逻辑回归或线性SVM线性分割样本数据中的1和-1。这就需要用到核函数的基本思想：创建一个原始特征的非线性组合，将样本映射到高维空间，使他们成为线性可分割的。这里我们引入一个新的维度（即特征组合）：z3=x1^2+x2^2：<br><img src="/img/PythonMachineLearningIII_14.png" alt=""></p><p><strong>Using the kernel trick to find separating hyperplanes in higher dimensional space</strong><br>使用最广泛的一个核函数是径向基函数（Radial Basis Function，RBF）或称作高斯核函数（Gaussian kernel），简化形式如下：<br><img src="/img/PythonMachineLearningIII_15.png" alt=""></p><p>粗略地说，术语“核”可以简单理解为一对样本数据间的相似性函数（similarity function）。方程中的负号导致结果是越相似的样本返回越接近1，越不相似越接近0。现在我们就可以用之前的SVC类来训练非线性分类模型，简单的将参数<code>kernel</code>的值替换为<code>’rbf’</code>：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm import SVC</span><br><span class="line">svm = SVC(<span class="attribute">kernel</span>=<span class="string">'rbf'</span>, <span class="attribute">C</span>=10.0, <span class="attribute">gamma</span>=0.10, <span class="attribute">random_state</span>=0)</span><br><span class="line">svm.fit(X_xor, y_xor)</span><br><span class="line">plot_decision_regions(X_xor, y_xor, <span class="attribute">classifier</span>=svm)</span><br><span class="line">plt.legend(<span class="attribute">loc</span>=<span class="string">'upper left'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningIII_16.png" alt=""></p><p>参数γ（程序中的gamma=0.1），可以理解为是高斯球面的切分点（cut-off）。如果增大参数γ，就会强化训练集数据的作用，结果就是导致更加拟合的分界面。为了直观理解，我们用iris数据训练RBF核函数支持向量机。<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">svm = SVC(kernel='rbf', random_state=<span class="number">0</span>, <span class="built_in">gamma</span>=<span class="number">0.2</span>, C=<span class="number">1.0</span>)</span><br><span class="line">svm.fit(X_train_std, y_train)</span><br><span class="line">plot_decision_regions(X_combined_std, y_combined, classifier=svm, test_idx=<span class="built_in">range</span>(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.<span class="built_in">xlabel</span>('petal <span class="built_in">length</span> [standardized]')</span><br><span class="line">plt.<span class="built_in">ylabel</span>('petal <span class="built_in">width</span> [standardized]')</span><br><span class="line">plt.<span class="built_in">legend</span>(loc='upper left')</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningIII_17.png" alt=""></p><p>增加γ的取值后对比如下，注意观测分类边界：<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">svm = SVC(kernel='rbf', random_state=<span class="number">0</span>, <span class="built_in">gamma</span>=<span class="number">100.0</span>, C=<span class="number">1.0</span>)</span><br><span class="line">svm.fit(X_train_std, y_train)</span><br><span class="line">plot_decision_regions(X_combined_std, y_combined, classifier=svm, test_idx=<span class="built_in">range</span>(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.<span class="built_in">xlabel</span>('petal <span class="built_in">length</span> [standardized]')</span><br><span class="line">plt.<span class="built_in">ylabel</span>('petal <span class="built_in">width</span> [standardized]')</span><br><span class="line">plt.<span class="built_in">legend</span>(loc='upper left')</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningIII_18.png" alt=""></p><p>这次可以看出分类0和1的边紧贴样本数据，但是显然在未来新数据上会出现较高的正则化错误，可见参数γ在过拟合中具有显著影响。</p><h3 id="Decision-tree-learning"><a href="#Decision-tree-learning" class="headerlink" title="Decision tree learning"></a>Decision tree learning</h3><p>决策树（decision tree）分类模型具有很好的可解释性，正如同其命名，决策树通过一系列问题并作出决策达到划分测试数据的目的。<br>决策树算法从根节点开始将数据按照特征基于信息增量（information gain）原则进行划分，然后对每个划分后的子集递归使用该方法，知道最终每个叶子数集只含有一个分类。实际中，严格按照这个原则会产生一个含有大量节点的深层次的过拟合决策树，所以，我们需要通过设置最大深度来对树进行剪枝。</p><p><strong>Maximizing information gain – getting the most bang for the buck</strong><br>首先定义决策树算法中需要优化的目标函数，这里目标函数的目标是最大化每次划分的信息增量值：<br><img src="/img/PythonMachineLearningIII_19.png" alt=""></p><p>其中f是特征变量，Dp和Dj是划分前的父节点数据集和划分后的第j个子集，Np和Nj是父集和第j个子集的样本数，I是杂质度度量函数。简单来说信息增量就是划分后自己的杂质度总和-划分前的杂质度，划分后子集越纯信息增量越大。基于简单和复杂度因素考虑，很多库提供的都是二元决策树算法。<br>比较常用的三个杂质度量函数是基尼系数（Gini index）、信息熵（entropy）和分类错误（classification error）。<br>信息熵的定义如下：<br><img src="/img/PythonMachineLearningIII_20.png" alt=""></p><p>其中p标识样本中属于分类c的数量占比，当所有节点中的数据都属于同一类中时，信息熵为0。<br>基尼系数可以视为最小化误分类概率的判别准则：<br><img src="/img/PythonMachineLearningIII_21.png" alt=""></p><p>实践中基尼系数和信息熵的效果非常接近，无需刻意选择算法，不如测试不同的剪枝阈值。</p><p>另一个杂质度度量函数是分类错误：<br><img src="/img/PythonMachineLearningIII_22.png" alt=""></p><p>这是一个对剪枝较有用的衡量方法（而不是生成决策树）。下图展示的是不同杂质度和p分布情况下不同算法的差异：<br><img src="/img/PythonMachineLearningIII_23.png" alt=""></p><p><strong>Building a decision tree</strong><br>决策树会将特征空间切分为复杂的矩形，但是必须小心决策树的深度，因为更深的决策分支会形成更加复杂的切分矩形，也更容易产生过拟合。对决策树算法本身来说，特征变量归一不是必需的。<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.tree <span class="built_in">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="attr">tree</span> = DecisionTreeClassifier(<span class="attr">criterion='entropy',</span> <span class="attr">max_depth=3,</span> <span class="attr">random_state=0)</span></span><br><span class="line">tree.fit(X_train, y_train)</span><br><span class="line"><span class="attr">X_combined</span> = np.vstack((X_train, X_test))</span><br><span class="line"><span class="attr">y_combined</span> = np.hstack((y_train, y_test))</span><br><span class="line">plot_decision_regions(X_combined, y_combined, <span class="attr">classifier=tree,</span> <span class="attr">test_idx=range(105,</span> <span class="number">150</span>))</span><br><span class="line">plt.xlabel('petal length [cm]')</span><br><span class="line">plt.ylabel('petal width [cm]')</span><br><span class="line">plt.legend(<span class="attr">loc='upper</span> left')</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningIII_24.png" alt=""></p><p>scikit-learn可以将生成的决策树导出为<code>.dot</code>文件，然后通过GraphViz程序做可视化展现。GraphViz程序可以在(<a href="http://www.graphviz.org)[http://www.graphviz.org]免费下载，提供Linux、Window和Mac" target="_blank" rel="noopener">www.graphviz.org)[http://www.graphviz.org]免费下载，提供Linux、Window和Mac</a> OSX版本。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn<span class="selector-class">.tree</span> import export_graphviz</span><br><span class="line"><span class="function"><span class="title">export_graphviz</span><span class="params">(tree, out_file=’tree.dot’, feature_names=[‘petal length’, ‘petal width’])</span></span></span><br></pre></td></tr></table></figure></p><p>安装完GraphViz后可以通过命令行将<code>.dot</code>文件输出为PNG图片：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">dot</span> –<span class="selector-tag">Tpng</span> <span class="selector-tag">tree</span><span class="selector-class">.dot</span> –<span class="selector-tag">o</span> <span class="selector-tag">tree</span><span class="selector-class">.png</span></span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningIII_25.png" alt=""></p><p><strong>Combining weak to strong learners via random forests</strong><br>随机森林（random forests）在近十年机器学习应用中广受欢迎，源于其优秀的性能、可扩展性和易使用性。随机森林可以直观地理解为是许多决策树的集合（ensemble），通过将许多弱分类器构建一个更加健壮的强分类器，可以有效降低正则化错误和过拟合。随机森林算法可以概括为以下四个步骤：</p><ol><li>随机抽取数量为n的引导样本数据（从训练集中有放回的随机选择n个样本）；</li><li>基于引导样本生成一颗决策树。生成时遵循如下规则：无放回地随机选取d个特征变量，根据选定的d个特征变量选择最佳的切分方案，最佳的衡量可以采用例如信息增量最大的目标函数；</li><li>重复步骤1、2共k次；</li><li>根据预测结果按照多数投票算法（majority vote）整和所有的决策树。多数投票算法后续会详细介绍。</li></ol><p>尽管随机森林无法提供像决策树这样清晰的可解释性，但是其巨大的优势在于：无需调优超变量、无需考虑剪枝问题、无需担心噪点数据的影响。我们只需要关注一个参数：树的棵数k。通常来说树越多，模型效果越好同时需要计算的时间也越多。<br>尽管如此，随机森林仍有超参数可以调优：引导样本的数量n和随机特征变量的数量d。样本数量n用于调节随机森林的偏度和方差，增大n数会降低样本的随机性，可能会增加过拟合情况。大多数算法（包括scikit-learn的RandomForestClassifier）实现中，默认引导样本数等于训练集中的样本数，一般这是一个较好的偏度-方差平衡点。随机特征数d一般都小于训练集中的总特征数，一个合理的默认值是总特征数m的平方根。<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble <span class="built_in">import</span> RandomForestClassifier</span><br><span class="line"><span class="attr">forest</span> = RandomForestClassifier(<span class="attr">criterion='entropy',</span> <span class="attr">n_estimators=10,</span> <span class="attr">random_state=1,</span> <span class="attr">n_jobs=2)</span></span><br><span class="line">forest.fit(X_train, y_train)</span><br><span class="line">plot_decision_regions(X_combined, y_combined, <span class="attr">classifier=forest,</span> <span class="attr">test_idx=range(105,</span> <span class="number">150</span>))</span><br><span class="line">plt.xlabel('petal length')</span><br><span class="line">plt.ylabel('petal width')</span><br><span class="line">plt.legend(<span class="attr">loc='upper</span> left')</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>上述代码训练了一个有10棵数的森林，<code>n_estimators</code>定义了数的棵数，使用信息熵来衡量杂质度。<code>n_jobs</code>参数表示利用多核技术并行训练我们的模型，这里我们使用2个内核。<br><img src="/img/PythonMachineLearningIII_26.png" alt=""></p><h3 id="K-nearest-neighbors-–-a-lazy-learning-algorithm"><a href="#K-nearest-neighbors-–-a-lazy-learning-algorithm" class="headerlink" title="K-nearest neighbors – a lazy learning algorithm"></a>K-nearest neighbors – a lazy learning algorithm</h3><p>最后本章讨论的是K近邻分类器（k-nearest neighbor，KNN），与之前介绍的算法不同，KNN是一种惰性学习（lazy learner），它不是在训练及上学习一个辨识函数，而是记忆训练集。</p><blockquote><p>参数和非参数模型（Parametric versus nonparametric models）<br>机器学习算法可以简单分为参数和非参数模型。通过参数模型可以在训练及上学习一个含有参数的函数，可以用来对新数据分类。典型的如感知器、逻辑回归、线性SVM。而非参数模型无法特征化一系列参数，并且参数的个数会随着训练集变化。决策树和核函数SVM就是这类典型。<br>KNN属于非参数模型的一个子类，称为基于实例的学习（instance-based learning）。惰性学习是其中一种特殊情况，其学习过程没有任何成本（no cost）</p></blockquote><p>KNN算法本身非常直观，可以概括为下述几步：</p><ol><li>选取参数k和距离指标</li><li>选择距离待分类样本最近的k个邻居</li><li>根据多数投票算法对样本进行分类</li></ol><p>下图展示了新数据（？点）是如何根据最近的5个邻居按照多数投票算法被分为三角形一类的过程。<br><img src="/img/PythonMachineLearningIII_27.png" alt=""></p><p>该类基于记忆的分类器一大优势是能够快速适应新的训练数据集，但是不利是最坏场景下算法复杂程度会随着样本数据增加线性增长，而且模型需要保存大量的样本数据，工作在大数据集上对存储空间也是一个挑战。<br>下面是使用欧几里德距离公式实现的KNN模型的代码：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn<span class="selector-class">.neighbors</span> import KNeighborsClassifier</span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">5</span>, p=<span class="number">2</span>, metric=<span class="string">'minkowski'</span>)</span><br><span class="line">knn.fit(X_train_std, y_train)</span><br><span class="line"><span class="function"><span class="title">plot_decision_regions</span><span class="params">(X_combined_std, y_combined, classifier=knn, test_idx=range(<span class="number">105</span>, <span class="number">150</span>)</span></span>)</span><br><span class="line">plt.xlabel(<span class="string">'petal length [standardized]'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'petal width [standardized]'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper left'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningIII_28.png" alt=""></p><p>参数k的选择对于过拟合和欠拟合有着决定性的影响，同时还要注意距离计算公式能够适应数据的特性。欧式距离简单，并且通常适合于实数类型的特征值，如果使用欧式距离归一化也是必不可少的，这样可以保证所有的特征对距离的贡献平等。代码中的<code>’minkowski’</code>表示使用泛化（generalization）后的欧式距离或曼哈顿距离，参数<code>p=2</code>表示欧式距离，<code>p=1</code>表示曼哈顿距离。其他距离参数可以参考scikit-learn官网说明文档(sklearn.neighbors.DistanceMetric.html)[ <a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html]。" target="_blank" rel="noopener">http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html]。</a></p><blockquote><p>维数灾难（The curse of dimensionality）<br>KNN很容易受到维数灾难影响产生过拟合。该影响可以简述为当特征维数很高但是样本数量不足造成所有的近邻距离都非常遥远。之前介绍的正则化无法应用于决策树和KNN，所以我们需要使用特征选择和降维技术来避免维数灾难。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;3-A-Tour-of-Machine-Learning-Classifiers-Using-Scikit-learn&quot;&gt;&lt;a href=&quot;#3-A-Tour-of-Machine-Learning-Classifiers-Using-Scikit-learn&quot; </summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Machine Learning" scheme="http://gloomymoon.github.io/tags/Machine-Learning/"/>
    
    <category term="scikit-learn" scheme="http://gloomymoon.github.io/tags/scikit-learn/"/>
    
  </entry>
  
  <entry>
    <title>Python Machine Learning II</title>
    <link href="http://gloomymoon.github.io/2017/01/18/Python-Machine-Learning-II/"/>
    <id>http://gloomymoon.github.io/2017/01/18/Python-Machine-Learning-II/</id>
    <published>2017-01-18T14:00:10.000Z</published>
    <updated>2017-01-21T07:21:39.375Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2-Training-Machine-Learning-Algorithms-for-Classification"><a href="#2-Training-Machine-Learning-Algorithms-for-Classification" class="headerlink" title="2 Training Machine Learning Algorithms for Classification"></a>2 Training Machine Learning Algorithms for Classification</h2><ul><li>建立机器学习算法的基础知识</li><li>利用pandas、NumPy和matplotlib来读入、处理和展示数据</li><li>用Python实现线性分类算法</li></ul><h3 id="Artificial-neurons-–-a-brief-glimpse-into-the-early-history-of-machine-learning"><a href="#Artificial-neurons-–-a-brief-glimpse-into-the-early-history-of-machine-learning" class="headerlink" title="Artificial neurons – a brief glimpse into the early history of machine learning"></a>Artificial neurons – a brief glimpse into the early history of machine learning</h3><p>早期大脑神经元结构对人工智能研究的影响：<br><img src="/img/PythonMachineLearningII_01.png" alt=""></p><p>每个神经元就是一个二元分类器，定义一个激活函数Φ(z)来实现分类，其中z是一系列输入变量x的线性组合z = w1x1+w2x2+…+wmxm，其中w表示每个变量的权重：<br><img src="/img/PythonMachineLearningII_02.png" alt=""></p><p>下图描绘了输入是如何转换成二元输出的示意图：<br><img src="/img/PythonMachineLearningII_03.png" alt=""></p><p>整个感知器的训练过程如下：</p><ol><li>所有w初始化为0或者一个很小的随机数</li><li>对于每个训练样本x，计算输出y，并基于结果与否更新w，更新的变化值如下：<br><img src="/img/PythonMachineLearningII_04.png" alt=""></li></ol><p>只有当分类结果是线性且学习率充分小时，感知器才能够保证收敛。<br><img src="/img/PythonMachineLearningII_05.png" alt=""></p><p>感知器概念图，在学习阶段，激活函数的输出用来更新每个输入变量的权重参数。</p><h3 id="Implementing-a-perceptron-learning-algorithm-in-Python"><a href="#Implementing-a-perceptron-learning-algorithm-in-Python" class="headerlink" title="Implementing a perceptron learning algorithm in Python"></a>Implementing a perceptron learning algorithm in Python</h3><p>Perceptron.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Perceptron</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""Perceptron classifier.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    eta : float</span></span><br><span class="line"><span class="string">        Learning rate (between 0.0 and 1.0)</span></span><br><span class="line"><span class="string">    n_iter : int</span></span><br><span class="line"><span class="string">        Passes over the traning dataset.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Attributes</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    w_ : 1d-array</span></span><br><span class="line"><span class="string">        Weights after fitting.</span></span><br><span class="line"><span class="string">    errors_ : list</span></span><br><span class="line"><span class="string">        Number of misclassifications in every epoch.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, eta=<span class="number">0.01</span>, n_iter=<span class="number">10</span>)</span>:</span></span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">        <span class="string">"""Fit training data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like&#125;, shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">            Training vectors, where n_samples is the number of samples </span></span><br><span class="line"><span class="string">            and n_features is the number of features.</span></span><br><span class="line"><span class="string">        y : array-like, shape = [n_samples]</span></span><br><span class="line"><span class="string">            Target values.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        self : object</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.w_ = np.zeros(<span class="number">1</span> + X.shape[<span class="number">1</span>])</span><br><span class="line">        self.errors_ = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(self.n_iter):</span><br><span class="line">            errors = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> xi, target <span class="keyword">in</span> zip(X, y):</span><br><span class="line">                update = self.eta * (target - self.predict(xi))</span><br><span class="line">                self.w_[<span class="number">1</span>:] += update * xi</span><br><span class="line">                self.w_[<span class="number">0</span>] += update</span><br><span class="line">                errors += int(update != <span class="number">0.0</span>)</span><br><span class="line">            self.errors_.append(errors)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">net_input</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""Calculate net input"""</span></span><br><span class="line">        <span class="keyword">return</span> np.dot(X, self.w_[<span class="number">1</span>:]) + self.w_[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""Return class label after unit step"""</span></span><br><span class="line">        <span class="keyword">return</span> np.where(self.net_input(X) &gt;= <span class="number">0.0</span>, <span class="number">1</span>, <span class="number">-1</span>)</span><br></pre></td></tr></table></figure></p><p><strong>Training a perceptron model on the Iris dataset</strong><br>为测试感知器，我们使用Iris中的Setosa和Versicolor两类数据，便于展示这里仅使用sepal length和petal length两个变量。<br><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">from</span> perceptron <span class="keyword">import</span> Perceptron</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="title">df</span> = pd.read_csv('iris.<span class="class"><span class="keyword">data</span>', header=<span class="type">None</span>)</span></span><br><span class="line"><span class="title">df</span>.head()</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">     <span class="number">0</span>      <span class="number">1</span>      <span class="number">2</span>      <span class="number">3</span>      <span class="number">4</span></span><br><span class="line"><span class="number">0</span>    <span class="number">5.1</span>    <span class="number">3.5</span>    <span class="number">1.4</span>    <span class="number">0.2</span>    Iris-setosa</span><br><span class="line"><span class="number">1</span>    <span class="number">4.9</span>    <span class="number">3.0</span>    <span class="number">1.4</span>    <span class="number">0.2</span>    Iris-setosa</span><br><span class="line"><span class="number">2</span>    <span class="number">4.7</span>    <span class="number">3.2</span>    <span class="number">1.3</span>    <span class="number">0.2</span>    Iris-setosa</span><br><span class="line"><span class="number">3</span>    <span class="number">4.6</span>    <span class="number">3.1</span>    <span class="number">1.5</span>    <span class="number">0.2</span>    Iris-setosa</span><br><span class="line"><span class="number">4</span>    <span class="number">5.0</span>    <span class="number">3.6</span>    <span class="number">1.4</span>    <span class="number">0.2</span>    Iris-setosa</span><br></pre></td></tr></table></figure></p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">%pylab inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">y = df.iloc[<span class="number">0</span>:<span class="number">100</span>, <span class="number">4</span>].values</span><br><span class="line">y = np.<span class="keyword">where</span>(y == <span class="string">'Iris-setosa'</span>, -<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">X = df.iloc[<span class="number">0</span>:<span class="number">100</span>, [<span class="number">0</span>, <span class="number">2</span>]].values</span><br><span class="line">plt.scatter(X[:<span class="number">50</span>, <span class="number">0</span>], X[:<span class="number">50</span>, <span class="number">1</span>], <span class="built_in">color</span>=<span class="string">'red'</span>, marker=<span class="string">'o'</span>, label=<span class="string">'setosa'</span>)</span><br><span class="line">plt.scatter(X[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>], X[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>], <span class="built_in">color</span>=<span class="string">'blue'</span>, marker=<span class="string">'x'</span>, label=<span class="string">'versicolor'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'petal length'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'sepal length'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper left'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/img/PythonMachineLearningII_06.png" alt=""></p><p>现在可以用我们的感知器来训练Iris数据<br><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ppn = Perceptron(eta=<span class="number">0.1</span>, n_iter=<span class="number">10</span>)</span><br><span class="line">ppn.fit(X, y)</span><br><span class="line">plt.plot(<span class="keyword">range</span>(<span class="number">1</span>, len(ppn.errors_) + <span class="number">1</span>), ppn.errors_, marker=<span class="string">'o'</span>)</span><br><span class="line">plt.xlabel(<span class="symbol">'Epochs</span>')</span><br><span class="line">plt.ylabel(<span class="symbol">'Number</span> <span class="keyword">of</span> misclassifications')</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningII_07.png" alt=""></p><p>六次迭代后感知器已经收敛。<br>为了便于展现编写了一个2维数据可视化函数plot_decision_regions。<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">from matplotlib.colors import ListedColormap</span><br><span class="line"></span><br><span class="line">def plot_decision_regions(<span class="keyword">X</span>, <span class="keyword">y</span>, classifier, resolution=<span class="number">0.02</span>):</span><br><span class="line">    # setup marker generator <span class="built_in">and</span> color <span class="keyword">map</span></span><br><span class="line">    markers = (<span class="string">'s'</span>, <span class="string">'x'</span>, <span class="string">'o'</span>, <span class="string">'^'</span>, <span class="string">'v'</span>)</span><br><span class="line">    colors = (<span class="string">'red'</span>, <span class="string">'blue'</span>, <span class="string">'lightgreen'</span>, <span class="string">'gray'</span>, <span class="string">'cyan'</span>)</span><br><span class="line">    <span class="keyword">cmap</span> = ListedColormap(colors[:<span class="built_in">len</span>(np.unique(<span class="keyword">y</span>))])</span><br><span class="line"></span><br><span class="line">    # plot the decision surface</span><br><span class="line">    x1_min, x1_max = <span class="keyword">X</span>[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, <span class="keyword">X</span>[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">    x2_min, x2_max = <span class="keyword">X</span>[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, <span class="keyword">X</span>[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))</span><br><span class="line">    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)</span><br><span class="line">    Z = Z.reshape(xx1.shape)</span><br><span class="line">    plt.contourf(xx1, xx2, Z, alpha=<span class="number">0.4</span>, <span class="keyword">cmap</span>=<span class="keyword">cmap</span>)</span><br><span class="line">    plt.xlim(xx1.<span class="built_in">min</span>(), xx1.<span class="built_in">max</span>())</span><br><span class="line">    plt.ylim(xx2.<span class="built_in">min</span>(), xx2.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line">    # plot class samples</span><br><span class="line">    <span class="keyword">for</span> idx, <span class="keyword">cl</span> in enumerate(np.unique(<span class="keyword">y</span>)):</span><br><span class="line">        plt.scatter(<span class="keyword">x</span>=<span class="keyword">X</span>[<span class="keyword">y</span> == <span class="keyword">cl</span>, <span class="number">0</span>], <span class="keyword">y</span>=<span class="keyword">X</span>[<span class="keyword">y</span> == <span class="keyword">cl</span>, <span class="number">1</span>], </span><br><span class="line">                    alpha=<span class="number">0.8</span>, <span class="keyword">c</span>=<span class="keyword">cmap</span>(idx), </span><br><span class="line">                    marker=markers[idx], label=<span class="keyword">cl</span>)</span><br></pre></td></tr></table></figure></p><p>然后就可以展现感知器的分类线，能够完美区分样本中的Iris类型。<br><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">plot_decision_regions</span>(X, y, classifier=ppn)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.xlabel</span>(<span class="string">'sepal length [cm]'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.ylabel</span>(<span class="string">'petal length [cm]'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.legend</span>(loc=<span class="string">'upper left'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.show</span>()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningII_08.png" alt=""></p><h3 id="Adaptive-linear-neurons-and-the-convergence-of-learning"><a href="#Adaptive-linear-neurons-and-the-convergence-of-learning" class="headerlink" title="Adaptive linear neurons and the convergence of learning"></a>Adaptive linear neurons and the convergence of learning</h3><p>ADAptive Linear Neuron(Adaline)是对感知器算法的一个改进，其关键理念是定义并最小化成本函数，基于线性激活函数替代单步阶梯函数。<br><img src="/img/PythonMachineLearningII_09.png" alt=""></p><p><strong>Minimizing cost functions with gradient descent</strong><br>有监督学习算法的关键因素之一就是定义一个目标函数（objective function）。目标函数通常可以是最小化的陈本函数，在Adaline方法中，成本函数J定义为输出和目标的误差平方和（Sum of Squared Errors, SSE），相比单步阶梯函数该线性激活函数是可微的：<br><img src="/img/PythonMachineLearningII_10.png" alt=""></p><p>另一个优势是这是个凸函数（convex），因此可以使用一个简单强大的优化算法，梯度下降（gradient descent），找到成本函数最小的权重值。梯度下降算法示意图如下：<br><img src="/img/PythonMachineLearningII_11.png" alt=""></p><p><strong>Implementing an Adaptive Linear Neuron in Python</strong><br>Adaline和感知器很类似，所以可以直接在原有的代码上修改<code>fit</code>方法重写成本函数最小化算法。<br>AdalineGD.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdalineGD</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""ADAptive LInear NEuron classifier.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    eta : float</span></span><br><span class="line"><span class="string">        Learning rate (between 0.0 and 1.0)</span></span><br><span class="line"><span class="string">    n_iter : int</span></span><br><span class="line"><span class="string">        Passes over the traning dataset.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Attributes</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    w_ : 1d-array</span></span><br><span class="line"><span class="string">        Weights after fitting.</span></span><br><span class="line"><span class="string">    errors_ : list</span></span><br><span class="line"><span class="string">        Number of misclassifications in every epoch.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, eta=<span class="number">0.01</span>, n_iter=<span class="number">10</span>)</span>:</span></span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">        <span class="string">"""Fit training data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like&#125;, shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">            Training vectors, where n_samples is the number of samples </span></span><br><span class="line"><span class="string">            and n_features is the number of features.</span></span><br><span class="line"><span class="string">        y : array-like, shape = [n_samples]</span></span><br><span class="line"><span class="string">            Target values.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        self : object</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.w_ = np.zeros(<span class="number">1</span> + X.shape[<span class="number">1</span>])</span><br><span class="line">        self.cost_ = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n_iter):</span><br><span class="line">            output = self.net_input(X)</span><br><span class="line">            errors = (y - output)</span><br><span class="line">            self.w_[<span class="number">1</span>:] += self.eta * X.T.dot(errors)</span><br><span class="line">            self.w_[<span class="number">0</span>] += self.eta * errors.sum()</span><br><span class="line">            cost = (errors**<span class="number">2</span>).sum() / <span class="number">2.0</span></span><br><span class="line">            self.cost_.append(cost)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">net_input</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""Calculate net input"""</span></span><br><span class="line">        <span class="keyword">return</span> np.dot(X, self.w_[<span class="number">1</span>:]) + self.w_[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">activation</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""Compute linear activation"""</span></span><br><span class="line">        <span class="keyword">return</span> self.net_input(X)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""Return class label after unit step"""</span></span><br><span class="line">        <span class="keyword">return</span> np.where(self.activation(X) &gt;= <span class="number">0.0</span>, <span class="number">1</span>, <span class="number">-1</span>)</span><br></pre></td></tr></table></figure></p><p>实践中，经常需要尝试不同的学习率使结果收敛。这里我们尝试0.1和0.0001两个参数进行比较。<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from AdalineGD import AdalineGD</span><br><span class="line">fig, ax = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">2</span>, figsize=(<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line">ada1 = AdalineGD(n_iter=<span class="number">10</span>, eta=<span class="number">0.01</span>).fit(X, y)</span><br><span class="line">ax[<span class="number">0</span>].plot(range(<span class="number">1</span>, len(ada1.cost_) + <span class="number">1</span>), np.log10(ada1.cost_), marker='o')</span><br><span class="line">ax[<span class="number">0</span>].set_xlabel('Epochs')</span><br><span class="line">ax[<span class="number">0</span>].set_ylabel('log(Sum-squared-error)')</span><br><span class="line">ax[<span class="number">0</span>].set_title('Adaline - Learning rate <span class="number">0.01</span>')</span><br><span class="line">ada2 = AdalineGD(n_iter=<span class="number">10</span>, eta=<span class="number">0.0001</span>).fit(X, y)</span><br><span class="line">ax[<span class="number">1</span>].plot(range(<span class="number">1</span>, len(ada2.cost_) + <span class="number">1</span>), ada2.cost_, marker='o')</span><br><span class="line">ax[<span class="number">1</span>].set_xlabel('Epochs')</span><br><span class="line">ax[<span class="number">1</span>].set_ylabel('Sum-squared-error')</span><br><span class="line">ax[<span class="number">1</span>].set_title('Adaline - Learning rate <span class="number">0.0001</span>')</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningII_12.png" alt=""></p><p>这两次实践分别遇到了两类典型的问题，第一次（左图）选用的学习率太大，算法在迭代中直接越过最小值最后发散，第二次（右图）选取的学习率太低，多次迭代后还没有达到收敛。</p><p>许多机器学习算法的调优都需要先进行特征归一化，梯度下降是其中之一。这里我们使用标准化（standardization）方法进行特征归一化，使数据分布正态化，即每个特征的以0为中心方差为1的正态分布。然后再使用0.01的学习率来训练Adaline算法。<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">X_std = <span class="built_in">np</span>.<span class="built_in">copy</span>(X)</span><br><span class="line">X_std[:, <span class="number">0</span>] = (X[:, <span class="number">0</span>] - X[:, <span class="number">0</span>].<span class="built_in">mean</span>()) / X[:, <span class="number">0</span>].<span class="built_in">std</span>()</span><br><span class="line">X_std[:, <span class="number">1</span>] = (X[:, <span class="number">1</span>] - X[:, <span class="number">1</span>].<span class="built_in">mean</span>()) / X[:, <span class="number">1</span>].<span class="built_in">std</span>()</span><br><span class="line"></span><br><span class="line">ada = AdalineGD(n_iter=<span class="number">15</span>, eta=<span class="number">0.01</span>)</span><br><span class="line">ada.fit(X_std, y)</span><br><span class="line">plot_decision_regions(X_std, y, classifier=ada)</span><br><span class="line">plt.<span class="built_in">title</span>('Adaline - Gradient Descent')</span><br><span class="line">plt.<span class="built_in">xlabel</span>('sepal <span class="built_in">length</span> [standardized]')</span><br><span class="line">plt.<span class="built_in">ylabel</span>('petal <span class="built_in">length</span> [standardized]')</span><br><span class="line">plt.<span class="built_in">legend</span>(loc='upper left')</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>, len(ada.cost_) + <span class="number">1</span>), ada.cost_, marker='o')</span><br><span class="line">plt.<span class="built_in">xlabel</span>('Epochs')</span><br><span class="line">plt.<span class="built_in">ylabel</span>('Sum-squared-<span class="built_in">error</span>')</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonMachineLearningII_13.png" alt=""></p><p>Adaline收敛，但是注意尽管所有样本都正确分类，SSE仍然不是0。</p><p><strong>Large scale machine learning and stochastic gradient descent</strong><br>现实中用梯度下降算法在百万条数据的训练非常耗时，因为每次迭代都要对全量数据进行评估并更新权重参数来达到全局最小值。一个常用的替代方案是随机梯度下降（stochastic gradient descent），权重的更新不是基于所有样本的偏差累计，而是基于每个样本的偏差，使得算法能够更频繁的更新权重参数从而快速达到收敛。为了达到准确结果，使用随机梯度下降算法每次迭代前都需要对数据进行随机排序（shuffle）。<br>随机梯度下降的另一个优势是可以在线学习（online learning），随着系统运行，新的训练数据不断产生，在线学习可以快速适应变化，而且若无必要保存，训练数据使用后可以直接丢弃。<br>我们在AdalineGD上修改<code>fit</code>方法的权重更新方式，新增<code>partial_fit</code>方法用于在线学习（不重新初始化权重），新增<code>shuffle</code>参数和<code>random_state</code>参数用于。<br>AdalineSGD.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> seed</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdalineSGD</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""ADAptive LInear NEuron classifier.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    eta : float</span></span><br><span class="line"><span class="string">        Learning rate (between 0.0 and 1.0)</span></span><br><span class="line"><span class="string">    n_iter : int</span></span><br><span class="line"><span class="string">        Passes over the traning dataset.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Attributes</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    w_ : 1d-array</span></span><br><span class="line"><span class="string">        Weights after fitting.</span></span><br><span class="line"><span class="string">    errors_ : list</span></span><br><span class="line"><span class="string">        Number of misclassifications in every epoch.</span></span><br><span class="line"><span class="string">    shuffle : bool (default: True)</span></span><br><span class="line"><span class="string">        Shuffles traning data every epoch if True to prevent cycles.</span></span><br><span class="line"><span class="string">    random_state : int (default: None)</span></span><br><span class="line"><span class="string">        Set random state for shuffling and initializing the weights. </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, eta=<span class="number">0.01</span>, n_iter=<span class="number">10</span>, shuffle=True, random_state=None)</span>:</span></span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line">        self.w_initialized = <span class="keyword">False</span></span><br><span class="line">        self.shuffle = shuffle</span><br><span class="line">        <span class="keyword">if</span> random_state:</span><br><span class="line">            seed(random_state)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">        <span class="string">"""Fit training data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like&#125;, shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">            Training vectors, where n_samples is the number of samples </span></span><br><span class="line"><span class="string">            and n_features is the number of features.</span></span><br><span class="line"><span class="string">        y : array-like, shape = [n_samples]</span></span><br><span class="line"><span class="string">            Target values.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        self : object</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self._initialize_weights(X.shape[<span class="number">1</span>])</span><br><span class="line">        self.cost_ = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n_iter):</span><br><span class="line">            <span class="keyword">if</span> self.shuffle:</span><br><span class="line">                X, y = self._shuffle(X, y)</span><br><span class="line">            cost = []</span><br><span class="line">            <span class="keyword">for</span> xi, target <span class="keyword">in</span> zip(X, y):</span><br><span class="line">                cost.append(self._update_weights(xi, target))</span><br><span class="line">            avg_cost = sum(cost)/len(y)</span><br><span class="line">            self.cost_.append(avg_cost)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partial_fit</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">        <span class="string">"""Fit training data without reinitializing the weights"""</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.w_initialized:</span><br><span class="line">            self._initialize_weights(X.shape[<span class="number">1</span>]) <span class="comment"># ndarray.shap 返回一个维度列表, 列表长度等于维数(ndarray.ndim)</span></span><br><span class="line">        <span class="keyword">if</span> y.ravel().shape[<span class="number">0</span>] &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">for</span> xi, target <span class="keyword">in</span> zip(X, y):</span><br><span class="line">                self._update_weights(xi, target)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">                self._update_weights(X, y)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_shuffle</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">        <span class="string">"""Shuffle training data"""</span></span><br><span class="line">        r = np.random.permutation(len(y)) <span class="comment"># permutation若传入一个整数，返回一个洗牌后的arange</span></span><br><span class="line">        <span class="keyword">return</span> X[r], y[r]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize_weights</span><span class="params">(self, m)</span>:</span></span><br><span class="line">        <span class="string">"""Initialize weights to zeros"""</span></span><br><span class="line">        self.w_ = np.zeros(<span class="number">1</span> + m)</span><br><span class="line">        self.w_initialized = <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_update_weights</span><span class="params">(self, xi, target)</span>:</span></span><br><span class="line">        <span class="string">"""Apply Adaline learning rule to update the weights"""</span></span><br><span class="line">        output = self.net_input(xi)</span><br><span class="line">        error = (target - output)</span><br><span class="line">        self.w_[<span class="number">1</span>:] += self.eta * xi.dot(error)</span><br><span class="line">        self.w_[<span class="number">0</span>] += self.eta * error</span><br><span class="line">        cost = <span class="number">0.5</span> * error**<span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> cost</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">net_input</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""Calculate net input"""</span></span><br><span class="line">        <span class="keyword">return</span> np.dot(X, self.w_[<span class="number">1</span>:]) + self.w_[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">activation</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""Compute linear activation"""</span></span><br><span class="line">        <span class="keyword">return</span> self.net_input(X)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""Return class label after unit step"""</span></span><br><span class="line">        <span class="keyword">return</span> np.where(self.activation(X) &gt;= <span class="number">0.0</span>, <span class="number">1</span>, <span class="number">-1</span>)</span><br></pre></td></tr></table></figure></p><p>使用AdalineSGD：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from AdalineSGD import AdalineSGD</span><br><span class="line"></span><br><span class="line">ada = AdalineSGD(n_iter=<span class="number">15</span>, eta=<span class="number">0.01</span>, random_state=<span class="number">1</span>)</span><br><span class="line">ada.fit(X_std, y)</span><br><span class="line"><span class="function"><span class="title">plot_decision_regions</span><span class="params">(X_std, y, classifier=ada)</span></span></span><br><span class="line">plt.title(<span class="string">'Adaline - Stochastic Gradient Descent'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'sepal length [standardized]'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'petal length [standardized]'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper left'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.plot(range(<span class="number">1</span>, len(ada.cost_) + <span class="number">1</span>), ada<span class="selector-class">.cost_</span>, marker=<span class="string">'o'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Average Cost'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>从结果可以看到平均成本下降非常迅速，15次迭代后效果和梯度下降差不多。<br><img src="/img/PythonMachineLearningII_14.png" alt=""></p><p>如果需要在在线环境下基于流数据进行可以调用<code>partial_fit</code>方法针对每条记录进行训练。用法如下：<code>ada.partial_fit(X_std[0, :], y[0])</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;2-Training-Machine-Learning-Algorithms-for-Classification&quot;&gt;&lt;a href=&quot;#2-Training-Machine-Learning-Algorithms-for-Classification&quot; clas</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Machine Learning" scheme="http://gloomymoon.github.io/tags/Machine-Learning/"/>
    
    <category term="scikit-learn" scheme="http://gloomymoon.github.io/tags/scikit-learn/"/>
    
  </entry>
  
  <entry>
    <title>Python Machine Learning I</title>
    <link href="http://gloomymoon.github.io/2017/01/17/Python-Machine-Learning-I/"/>
    <id>http://gloomymoon.github.io/2017/01/17/Python-Machine-Learning-I/</id>
    <published>2017-01-17T13:47:23.000Z</published>
    <updated>2017-01-24T02:46:29.519Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Python-Machine-Learning"><a href="#Python-Machine-Learning" class="headerlink" title="Python Machine Learning"></a>Python Machine Learning</h1><p><a href="">Sebastian Raschka</a></p><blockquote><p>Sebastian Raschka是密歇根州立大学的博士生，擅长Python和机器学习，是GitHub广受欢迎的数据科学家之一。</p></blockquote><h2 id="1-Giving-Computers-the-Ability-to-learn-from-Data"><a href="#1-Giving-Computers-the-Ability-to-learn-from-Data" class="headerlink" title="1 Giving Computers the Ability to learn from Data"></a>1 Giving Computers the Ability to learn from Data</h2><h3 id="Building-intelligent-machines-to-transform-data-into-knowledge"><a href="#Building-intelligent-machines-to-transform-data-into-knowledge" class="headerlink" title="Building intelligent machines to transform data into knowledge"></a>Building intelligent machines to transform data into knowledge</h3><h3 id="The-three-defirent-types-of-machine-learning"><a href="#The-three-defirent-types-of-machine-learning" class="headerlink" title="The three defirent types of machine learning"></a>The three defirent types of machine learning</h3><p>机器学习的三种类型：无监督学习、有监督学习、增强学习</p><p><strong>Making predictions about the future with supervised learning</strong><br><img src="/img/PythonMachineLearningI_01.png" alt=""><br>Classification for predicting class labels<br>分类是有监督学习的一类，包括二元分类（如是别垃圾邮件）、多元分类（如手写识别）</p><p>Regression for predicting continuous outcomes<br>回归是分析一组预测因子和连续性结论之间的关系，用来预测连续性结果，例如使用学习时间和SAT成绩关系</p><p><strong>Solving interactive problems with reinforcement learning</strong><br><img src="/img/PythonMachineLearningI_02.png" alt=""><br>增强学习的目的是构建一个通过与环境交互不断提升表现的系统。因为基于reward signal，可以认为与有监督学习类似。但reward signal并不是表示真假或数值，而是有reward函数对交互行为产生的效益的评价，典型的增强学习是下棋引擎，交互行为就是下子，reward就是最终的输赢。</p><p><strong>Discovering hidden structures with unsupervised learning</strong><br>有监督学习中，建模前必须有正确的结果数据，增强学习也必须预定义reward函数。而无监督学习是试图探索数据中的潜在信息和结构模式。<br>Finding subgroups with clustering<br>聚类技术是将数据重组成有意义的簇，使得在某维度上簇内相似度最高、簇间相似度最低。<br><img src="/img/PythonMachineLearningI_03.png" alt=""></p><p>Dimensionality reduction for data compression<br>降维是另一种无监督学习，是一种常用的特征预处理方法，去除噪音数据，压缩数据维度空间，但仍保留有效的信息量。</p><h3 id="A-roadmap-for-building-machine-learning-systems"><a href="#A-roadmap-for-building-machine-learning-systems" class="headerlink" title="A roadmap for building machine learning systems"></a>A roadmap for building machine learning systems</h3><p>下图展示了一个典型的预测模型构建工作流程：<br><img src="/img/PythonMachineLearningI_04.gif" alt=""></p><p><strong>Preprocessing – getting data into shape</strong><br>数据预处理是最关键的步骤之一</p><p><strong>Training and selecting a predictive model</strong><br>每个分类算法都有其内在的偏向，在任务未知时没有哪个信号分类模型更加优秀。在比较不同模型效果是，首先需要定义和量指标，即分类的准确率。<br>由于我们无法知道最终预测数据是怎样的，所以引入了各种交叉检验技术将建模数据分为训练和检验部分来评估模型效果。最后我们还要使用超参数（hyperparameter）优化技术来对模型调优。</p><p><strong>Evaluating models and predicting unseen data instances</strong><br>一旦模型训练完成，我们能够用测试数据验证效果，如果模型效果满意，就能够用来预测未来的新数据。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Python-Machine-Learning&quot;&gt;&lt;a href=&quot;#Python-Machine-Learning&quot; class=&quot;headerlink&quot; title=&quot;Python Machine Learning&quot;&gt;&lt;/a&gt;Python Machine Le</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Machine Learning" scheme="http://gloomymoon.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Python for Data Analysis VII</title>
    <link href="http://gloomymoon.github.io/2017/01/07/Python-for-Data-Analysis-VII/"/>
    <id>http://gloomymoon.github.io/2017/01/07/Python-for-Data-Analysis-VII/</id>
    <published>2017-01-07T14:04:58.000Z</published>
    <updated>2017-01-26T08:48:28.946Z</updated>
    
    <content type="html"><![CDATA[<h2 id="8-绘图和可视化"><a href="#8-绘图和可视化" class="headerlink" title="8 绘图和可视化"></a>8 绘图和可视化</h2><p>绘图是数据分析工作中最重要的任务之一，通过可视化的方式能够让我们快速进行探索过程，找出异常值、进行数据转换、获取模型的idea。Python有许多可视化工具，这里主要介绍matplotlib。</p><h3 id="8-1-matplotlib-API入门"><a href="#8-1-matplotlib-API入门" class="headerlink" title="8.1 matplotlib API入门"></a>8.1 matplotlib API入门</h3><p>准备工作：</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib <span class="keyword">inline</span> # 在IPython中内嵌显示matplot图表，也可以在IPython启动时增加--pmatplotlib=<span class="keyword">inline</span>参数实现</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><p><strong>Figure和Subplot</strong></p><p>matplotlib的图像都位于Figure对象中，用<code>plt.figure</code>可以创建一个新的Figure对象，通过<code>plt.gcf()</code>获得当前Figure对象的引用，不能通过空Figure绘图，必须用<code>add_subplot</code>创建或多个subplot才行。</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">ax1 = fig.add_subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">ax2 = fig.add_subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">ax3 = fig.add_subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>上面的代码创建一个空2x2的Figure，并依次创建3个subplot。</p><p><img src="/img/PythonForDataAnalysisVII_01.png" alt=""></p><p>如果这是使用绘图指令，matplotlib会在最后一个用过的subplot上绘制，如果执行下列命令会在第二行第一个图中绘制图表。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">from</span> numpy.random <span class="keyword">import</span> randn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="title">plt</span>.plot(randn(<span class="number">50</span>).cumsum(), 'k<span class="comment">--')</span></span><br></pre></td></tr></table></figure><p><img src="/img/PythonForDataAnalysisVII_02.png" alt=""></p><p><code>k--</code>是一个线性选项，表示绘制黑色虚线图。<code>add_subplot</code>返回的是AxesSubplot对象，直接调用他们的实例方法就可以在其中直接画图。</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">_ = ax1.hist(randn(<span class="number">100</span>), bins=<span class="number">20</span>, color='k', alpha=<span class="number">0.3</span>)</span><br><span class="line">ax2.scatter(np.arange(<span class="number">30</span>), np.arange(<span class="number">30</span>) + <span class="number">3</span> * randn(<span class="number">30</span>))</span><br></pre></td></tr></table></figure><p><img src="/img/PythonForDataAnalysisVII_03.png" alt=""></p><p>由于根据特定布局创建Figure和Subplot非常常用，因此出现了跟方便的方法<code>plt.subplots</code>，可以创建一个新的Figure，并返回一个含有已创建subplot对象NumPy数组。</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">axes</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">array([[&lt;matplotlib<span class="selector-class">.axes</span><span class="selector-class">.AxesSubplot</span> <span class="selector-tag">object</span> at <span class="number">0</span>x109761290&gt;,</span><br><span class="line">        &lt;matplotlib<span class="selector-class">.axes</span><span class="selector-class">.AxesSubplot</span> <span class="selector-tag">object</span> at <span class="number">0</span>x109748bd0&gt;,</span><br><span class="line">        &lt;matplotlib<span class="selector-class">.axes</span><span class="selector-class">.AxesSubplot</span> <span class="selector-tag">object</span> at <span class="number">0</span>x10984f390&gt;],</span><br><span class="line">       [&lt;matplotlib<span class="selector-class">.axes</span><span class="selector-class">.AxesSubplot</span> <span class="selector-tag">object</span> at <span class="number">0</span>x109792f10&gt;,</span><br><span class="line">        &lt;matplotlib<span class="selector-class">.axes</span><span class="selector-class">.AxesSubplot</span> <span class="selector-tag">object</span> at <span class="number">0</span>x108fdb650&gt;,</span><br><span class="line">        &lt;matplotlib<span class="selector-class">.axes</span><span class="selector-class">.AxesSubplot</span> <span class="selector-tag">object</span> at <span class="number">0</span>x1093ced50&gt;]], dtype=object)</span><br></pre></td></tr></table></figure><p><strong>调整subplot周围的间距</strong></p><p>默认情况下，subplot外围预留一定的编剧，并在subplot之间留下一定的间距。间距跟图像的高度和宽度有关，因此会根据图像的大小自动调整，利用Figure的subplots_adjust方法修改间距，此外这是一个定基函数。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">subplots_adjuct(<span class="attribute">left</span>=None, <span class="attribute">buttom</span>=None, <span class="attribute">right</span>=None, <span class="attribute">top</span>=None, <span class="attribute">wspace</span>=None, <span class="attribute">hspace</span>=None)</span><br></pre></td></tr></table></figure><p>其中<code>wspace</code>和<code>hspace</code>用于控制宽度和高度的百分比，可以用作subplot之间的间距。如果将这两个参数设置为<code>0</code>，会发现两个subplot的轴标签产生了重叠。matplotlib不会检查标签是否重叠，所以这种情况需要自行设定刻度的位置和刻度的标签。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, axes = plt.subplots(2, 2, <span class="attribute">sharex</span>=<span class="literal">True</span>, <span class="attribute">sharey</span>=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(2):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(2):</span><br><span class="line">        axes[i, j].hist(randn(500), <span class="attribute">bins</span>=50, <span class="attribute">color</span>=<span class="string">'k'</span>, <span class="attribute">alpha</span>=0.5)</span><br><span class="line">plt.subplots_adjust(<span class="attribute">wspace</span>=0, <span class="attribute">hspace</span>=0)</span><br></pre></td></tr></table></figure><p><img src="/img/PythonForDataAnalysisVII_04.png" alt=""></p><p><strong>颜色、标记和线型</strong></p><p><code>plot</code>方法除了接收一组X和Y的坐标，还可以接受一个表示颜色和现行的字符串缩写，例如之间的<code>&quot;k--&quot;</code>表示黑色虚线，更为明确的方式如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ax.plot(x, y, <span class="attribute">linestyle</span>=<span class="string">'--'</span>, <span class="attribute">color</span>=<span class="string">'g'</span>, <span class="attribute">marker</span>=<span class="string">'o'</span>)</span><br></pre></td></tr></table></figure><p>分别表示线型、颜色和数据点的标记。常用颜色都有一个缩写，也可以通过RGB值的形式自定义任意颜色（’#CECECE’）。</p><p>在线型图中，非实际数据点默认是按线性方式插值的，但可以通过<code>drwastyle</code>选项修改。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = randn(<span class="number">30</span>).cumsum()</span><br><span class="line">plt.plot(data, <span class="string">'g--'</span>, <span class="keyword">label</span><span class="bash">=<span class="string">'Default'</span>)</span></span><br><span class="line"><span class="bash">plt.plot(data, <span class="string">'k-'</span>, drawstyle=<span class="string">'steps-post'</span>, label=<span class="string">'steps-post'</span>)</span></span><br><span class="line"><span class="bash">plt.legend(loc=<span class="string">'best'</span>)</span></span><br></pre></td></tr></table></figure><p><img src="/img/PythonForDataAnalysisVII_05.png" alt=""></p><p><strong>刻度、标签和图例</strong></p><p><strong>设置标题、轴标签、刻度以及刻度标签</strong></p><p>修改X轴的刻度可以使用<code>set_xticks</code>和<code>set_xticklabels</code>方法，前者表明讲刻度放在数据范围中的哪些位置，默认情况下，这些位置就是刻度标签。但是通过后一个方法可以将任何其他的值用作标签。</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">fig</span> = plt.figure(); <span class="attribute">a</span><span class="attribute">x</span> = fig.add_subplot(1, 1, 1)</span><br><span class="line">ax.plot(randn(1000).cumsum())</span><br><span class="line">ticks = ax.set_xticks([0, 250, 500, 750, 1000])</span><br><span class="line">labesl = ax.set_xticklabels([<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>, <span class="string">'four'</span>, <span class="string">'five'</span>], rotation=30, fontsize=<span class="string">'small'</span>)</span><br><span class="line">ax.set_title(<span class="string">'My first matplotlib plot'</span>) # 设置标题</span><br><span class="line">ax.set_xlabel(<span class="string">'Stages'</span>)# 设置X轴名称</span><br></pre></td></tr></table></figure><p><img src="/img/PythonForDataAnalysisVII_06.png" alt=""></p><p><strong>添加图例</strong></p><p>最简单的实在添加subplot时传入<code>label</code>参数，在此之后，可以调用<code>legeng()</code>方法来创建图例，<code>loc</code>参数告诉matplotlib将图里放在那里，一般来说<code>best</code>是一个不错的选择，它会选择最不碍事的位置。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ax.plot(randn(<span class="number">1000</span>).cumsum(), <span class="string">'k--'</span>, <span class="keyword">label</span><span class="bash">=<span class="string">'onw'</span>)</span></span><br><span class="line"><span class="bash">ax.lengend(loc=<span class="string">'best'</span>)</span></span><br></pre></td></tr></table></figure><p><strong>注解以及在Subplot上绘图</strong></p><p>除标准图标对象以外，matplotlib还支持绘制自定义的注解文本、标注箭头等图像，可以通过<code>text</code>、<code>arrow</code>和<code>annotate</code>等函数进行添加。</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ax.<span class="built_in">text</span>(x, y, <span class="string">'Hello word!'</span>, family=<span class="string">'monospace'</span>, fontsize=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>下面是一个示例，更多功能可以访问matplotlib在线示例库。<br><figure class="highlight qml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">from datetime <span class="keyword">import</span> datetime</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">data = pd.read_csv(<span class="string">'../../../pydata-book-master/ch08/spx.csv'</span>, index_col=<span class="number">0</span>, parse_dates=True)</span><br><span class="line">spx = data[<span class="string">'SPX'</span>]</span><br><span class="line"></span><br><span class="line">spx.plot(ax=ax, style=<span class="string">'k-'</span>)</span><br><span class="line">crisis_data = [</span><br><span class="line">    (datetime(<span class="number">2007</span>, <span class="number">10</span>, <span class="number">11</span>), <span class="string">'Peak of bull market'</span>),</span><br><span class="line">    (datetime(<span class="number">2008</span>, <span class="number">3</span>, <span class="number">12</span>), <span class="string">'Bear Stearns Fails'</span>),</span><br><span class="line">    (datetime(<span class="number">2008</span>, <span class="number">9</span>, <span class="number">15</span>), <span class="string">'Lehman Bankruptcy'</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">date</span>, label <span class="keyword">in</span> <span class="attribute">crisis_data</span>:</span><br><span class="line">    ax.annotate(label, xy=(<span class="built_in">date</span>, spx.asof(<span class="built_in">date</span>) + <span class="number">50</span>),</span><br><span class="line">                xytext=(<span class="built_in">date</span>, spx.asof(<span class="built_in">date</span>) + <span class="number">200</span>),</span><br><span class="line">                arrowprops=dict(facecolor=<span class="string">'black'</span>),</span><br><span class="line">                horizontalalignment=<span class="string">'left'</span>, verticalalignment=<span class="string">'top'</span>)</span><br><span class="line">ax.set_xlim([<span class="string">'1/1/2007'</span>, <span class="string">'1/1/2011'</span>])</span><br><span class="line">ax.set_ylim([<span class="number">600</span>, <span class="number">1800</span>])</span><br><span class="line"></span><br><span class="line">ax.set_title(<span class="string">'Important dates in 2008-2009 financial crisis'</span>)</span><br></pre></td></tr></table></figure></p><p><img src="/img/PythonForDataAnalysisVII_07.png" alt=""></p><p><strong>将图表保存到文件</strong></p><p>利用<code>plt.savefig</code>可以讲图表保存到文件，常用的选项<code>dpi</code>表示每英寸像素数和<code>bbox_inches</code>剪除当前图表周围空白部分。</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">plg</span><span class="selector-class">.savefig</span>(<span class="string">'figpath.svg'</span>, dpi=<span class="number">400</span>, bbox_inches=<span class="string">'tight'</span>)</span><br></pre></td></tr></table></figure><p><code>savefig</code>也可以写入任何文件类型对象，比如StringIO。这对于在Web上提供动态生成的图片很实用。</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">from</span> io <span class="meta">import</span> <span class="keyword">StringIO</span></span><br><span class="line"><span class="keyword">buffer </span>= <span class="keyword">StringIO()</span></span><br><span class="line"><span class="keyword">plot.savefig(buffer)</span></span><br><span class="line"><span class="keyword">plot_data </span>= <span class="keyword">buffer.getvalue()</span></span><br></pre></td></tr></table></figure><p><strong>matplotlib配置</strong></p><p>matplotlib自带一些配色方案，以及为生成出版质量图片的默认配置信息，一种才做配置信息的方式是利用<code>rc</code>方法。<code>rc</code>方法的第一个参数是希望定义的对象，如<code>&#39;figure&#39;</code>、<code>&#39;axes&#39;</code>、<code>&#39;xtick&#39;</code>、<code>&#39;ytick&#39;</code>、<code>&#39;grid&#39;</code>、<code>&#39;legend&#39;</code>等，其后可以跟上一系列关键字，简单的方法是将选项写成一个字典。</p><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">font_options = &#123;<span class="string">'family'</span>: <span class="string">'monospace'</span>,</span><br><span class="line">   <span class="string">'weight'</span>: <span class="string">'bold'</span>,</span><br><span class="line">   <span class="string">'size'</span>  : <span class="string">'small'</span>&#125;</span><br><span class="line">plt.rc(<span class="string">'font'</span>, **font_options)</span><br></pre></td></tr></table></figure><p>要了解全部的自定义，请查阅matplotlib的配置文件<code>matplotlibrc</code>（位于matplotlib/mpl-data目录中）。</p><h3 id="8-2-pandas中的绘图函数"><a href="#8-2-pandas中的绘图函数" class="headerlink" title="8.2 pandas中的绘图函数"></a>8.2 pandas中的绘图函数</h3><p>matplotlib实际上还是比较低级的，在pandas中提供了许多直接利用DataFrame对象数据组织特点来创建标准图表的高级绘图方法。</p><p><strong>线型图</strong></p><p>Series和DataFrame都有一个用于生成各类图表的<code>plot</code>方法，默认情况下生成的是线型图。</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s = Series(np.random.randn(<span class="number">10</span>).cumsum(), index=np.arange(<span class="number">0</span>, <span class="number">100</span>, <span class="number">10</span>))</span><br><span class="line">s.plot()</span><br></pre></td></tr></table></figure><p><img src="/img/PythonForDataAnalysisVII_08.png" alt=""></p><p>该Series对象的索引会被用以绘制X轴（可以通过<code>use_index=False</code>禁用），X轴的刻度和界限通过<code>xticks</code>和<code>xlim</code>选项调节，Y轴类似。pandas的大部分绘图方法都有一个可选的<code>ax</code>参数，用来在网格布局中灵活处理subplot的位置。</p><p>DataFrame的<code>plot</code>方法会在一个subplot中为各列绘制一条曲线，并自动创建图例。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df = DataFrame(np<span class="selector-class">.random</span><span class="selector-class">.randn</span>(<span class="number">10</span>, <span class="number">4</span>).cumsum(<span class="number">0</span>),</span><br><span class="line">               <span class="attribute">columns</span>=[<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'D'</span>],</span><br><span class="line">               index=np.arange(<span class="number">0</span>, <span class="number">100</span>, <span class="number">10</span>))</span><br><span class="line">df.plot()</span><br></pre></td></tr></table></figure><p><img src="/img/PythonForDataAnalysisVII_09.png" alt=""></p><p>Series.plot方法的参数：</p><ul><li>label: 用于图例的标签</li><li>ax：指定在其上进行绘制的subplot对象</li><li>style：床给matplotlib的风格字符串（例如<code>&#39;ko--&#39;</code>）</li><li>alpha：图表的不透明度（0~1之间）</li><li>kind：可以是’line’、’bar’、’barh’、’kde’</li><li>logy：在Y轴上使用对数标尺</li><li>use_index：是否将对象的索引用作刻度标签</li><li>rot：旋转刻度标签（0到360）</li><li>xticks：用作X轴刻度的值</li><li>yticks：用作Y轴刻度的值</li><li>xlim：X轴的界限（例如[0, 10]）</li><li>ylim：Y轴的界限</li><li>grid：显示轴网格线（默认关闭）</li></ul><p>DataFrame专用的plot参数：</p><ul><li>subplots：将各个DataFrame列绘制到单独的subplot中</li><li>sharex：如果subplots=True，则公用同一个X轴，包括刻度和界限</li><li>sharey：如果subplots=True，则公用同一个Y轴</li><li>figsize：表示图像大小的元组</li><li>title：表示图像标题的字符串</li><li>legend：添加一个subplot图例（默认为True）</li><li>sort_columns：以字母表顺序绘制各列，默认使用当前列顺序</li></ul><p><strong>柱状图</strong></p><p>在生成线型图的代码中加上<code>kind=&#39;bar&#39;</code>（垂直柱状图）或<code>kind=&#39;barh&#39;</code>（水平条形图）即可生成柱状图，设置<code>stacked=True</code>即可为DataFrame生成堆积柱状图，配合<code>value_counts</code>就可以生成百分比堆积柱图。</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tips = pd.read_csv(<span class="string">'../../../pydata-book-master/ch08/tips.csv'</span>)</span><br><span class="line">party_counts = pd.crosstab(tips.day, tips[<span class="string">'size'</span>])</span><br><span class="line">party_pcts = party_counts.<span class="keyword">div</span>(party_counts.sum(<span class="number">1</span>).astype(<span class="keyword">float</span>), axis=<span class="number">0</span>)</span><br><span class="line">party_pcts.plot(kind=<span class="string">'bar'</span>, stacked=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p><img src="/img/PythonForDataAnalysisVII_10.png" alt=""></p><p><strong>直方图和密度图</strong></p><p>直方图（histogram）是一种可以对值频率进行离散化显示的柱状图。前面的例子中，通过Series的<code>hist</code>方法，可以生成一张“消费占消费总额比例”的直方图。与此相关的是密度图，通过计算“可能会产生观测数据的连续概率分布估计”而产生，调用<code>plot</code>是加上<code>kind=&#39;kde&#39;</code>即可生成。</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tips[<span class="string">'tip_pct'</span>] = tips[<span class="string">'tip'</span>]/tips[<span class="string">'total_bill'</span>]</span><br><span class="line">tips[<span class="string">'tip_pct'</span>].hist(alpha=<span class="number">0.3</span>, bins=<span class="number">50</span>)</span><br><span class="line">tips[<span class="string">'tip_pct'</span>].plot(kind=<span class="string">'kde'</span>)</span><br></pre></td></tr></table></figure><p><img src="/img/PythonForDataAnalysisVII_11.png" alt=""></p><p><strong>散布图</strong></p><p>散布图（scatter plot）是观察两个一维数据序列之间关系的有效手段。matplotlib的<code>scatter</code>方法是绘制散布图的主要方法。在探索式数据分析工作中，同时观察一组变量的散布图是很有意义的，这也被称为散布图矩阵（scatter plot matrix），pandas提供了一个从DataFrame创建散布图矩阵的<code>scatter_matrix</code>函数，它还支持在对角线上放置各变量的直方图或密度图。</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">macro = pd.read_csv(<span class="string">'../../../pydata-book-master/ch08/macrodata.csv'</span>)</span><br><span class="line"><span class="keyword">data</span> = macro[[<span class="string">'cpi'</span>, <span class="string">'m1'</span>, <span class="string">'tbilrate'</span>, <span class="string">'unemp'</span>]]</span><br><span class="line">trans_data = np.<span class="built_in">log</span>(<span class="keyword">data</span>).diff().dropna()</span><br><span class="line">plt.scatter(trans_data[<span class="string">'m1'</span>], trans_data[<span class="string">'unemp'</span>])</span><br><span class="line">plt.<span class="built_in">title</span>(<span class="string">'Changes in log %s vs. log %s'</span> % (<span class="string">'m1'</span>, <span class="string">'unemp'</span>))</span><br></pre></td></tr></table></figure><p><img src="/img/PythonForDataAnalysisVII_12.png" alt=""></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.scatter_matrix(trans_data, <span class="attribute">diagonal</span>=<span class="string">'kde'</span>, <span class="attribute">c</span>=<span class="string">'k'</span>, <span class="attribute">alpha</span>=0.3)</span><br></pre></td></tr></table></figure><p><img src="/img/PythonForDataAnalysisVII_13.png" alt=""></p><h3 id="8-3-绘制地图：图形化显示海地地震危机数据"><a href="#8-3-绘制地图：图形化显示海地地震危机数据" class="headerlink" title="8.3 绘制地图：图形化显示海地地震危机数据"></a>8.3 绘制地图：图形化显示海地地震危机数据</h3><p><a href="http://community.ushahidi.com/research/datasets" target="_blank" rel="noopener">Ushahidi</a>是一家通过短信收集自然灾害和地缘政治事件信息的非盈利软件公司，这里我们利用pandas以及目前学过的工具处理2010年海地地震期间的数据，一边为分析和图形化工作做准备。<br>首先读入并看看数据的情况。<br><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv('ch08/Haiti.csv')</span><br><span class="line">data</span><br><span class="line">data[<span class="string">['INCIDIENT DATE', 'ATITUDE', 'LONGITUDE'</span>]][:10]</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">INCIDENT DATELATITUDELONGITUDE</span><br><span class="line"><span class="number">0</span><span class="number">05/07/2010</span> <span class="number">17</span>:<span class="number">2618.233333</span>-<span class="number">72.533333</span></span><br><span class="line"><span class="number">1</span><span class="number">28/06/2010</span> <span class="number">23</span>:<span class="number">0650.226029</span><span class="number">5.729886</span></span><br><span class="line"><span class="number">2</span><span class="number">24/06/2010</span> <span class="number">16</span>:<span class="number">21</span><span class="number">22.278381</span><span class="number">114.174287</span></span><br><span class="line"><span class="number">3</span><span class="number">20/06/2010</span> <span class="number">21</span>:<span class="number">59</span><span class="number">44.407062</span><span class="number">8.933989</span></span><br><span class="line"><span class="number">4</span><span class="number">18/05/2010</span> <span class="number">16</span>:<span class="number">26</span><span class="number">18.571084</span>-<span class="number">72.334671</span></span><br><span class="line"><span class="number">5</span><span class="number">26/04/2010</span> <span class="number">13</span>:<span class="number">14</span><span class="number">18.593707</span>-<span class="number">72.310079</span></span><br><span class="line"><span class="number">6</span><span class="number">26/04/2010</span> <span class="number">14</span>:<span class="number">19</span><span class="number">18.482800</span>-<span class="number">73.638800</span></span><br><span class="line"><span class="number">7</span><span class="number">26/04/2010</span> <span class="number">14</span>:<span class="number">27</span><span class="number">18.415000</span>-<span class="number">73.195000</span></span><br><span class="line"><span class="number">8</span><span class="number">15/03/2010</span> <span class="number">10</span>:<span class="number">58</span><span class="number">18.517443</span>-<span class="number">72.236841</span></span><br><span class="line"><span class="number">9</span><span class="number">15/03/2010</span> <span class="number">11</span>:<span class="number">00</span><span class="number">18.547790</span>-<span class="number">72.410010</span></span><br></pre></td></tr></table></figure></p><p>每条记录都有一个时间戳和经纬度。</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">'CATEGORY'</span>][<span class="symbol">:6</span>]</span><br></pre></td></tr></table></figure><p>Output:<br><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>          <span class="number">1</span>. Urgences <span class="string">| Emergency, 3. Public Health, </span></span><br><span class="line"><span class="number">1</span>    <span class="number">1</span>. Urgences <span class="string">| Emergency, 2. Urgences logistiqu...</span></span><br><span class="line"><span class="number">2</span>    <span class="number">2</span>. Urgences logistiques <span class="string">| Vital Lines, 8. Autr...</span></span><br><span class="line"><span class="number">3</span>                            <span class="number">1</span>. Urgences <span class="string">| Emergency, </span></span><br><span class="line"><span class="number">4</span>                            <span class="number">1</span>. Urgences <span class="string">| Emergency, </span></span><br><span class="line"><span class="number">5</span>                       <span class="number">5</span>e. Communication lines down, </span><br><span class="line">Name: CATEGORY, dtype: object</span><br></pre></td></tr></table></figure></p><p>CATEGORY字段存储消息的类型，类型是一组用逗号分隔的代码。仔细观察上面那个数据就会发现有些分类信息缺失。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">data</span>.describe()</span></span><br></pre></td></tr></table></figure><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SerialLATITUDELONGITUDE</span><br><span class="line">count<span class="number">3593.000000</span><span class="number">3593.000000</span><span class="number">3593.000000</span></span><br><span class="line">mean<span class="number">2080.277484</span><span class="number">18.611495</span><span class="number">-72.322680</span></span><br><span class="line">std<span class="number">1171.100360</span><span class="number">0.738572</span><span class="number">3.650776</span></span><br><span class="line">min<span class="number">4.000000</span><span class="number">18.041313</span><span class="number">-74.452757</span></span><br><span class="line"><span class="number">25</span>%<span class="number">1074.000000</span><span class="number">18.524070</span><span class="number">-72.417500</span></span><br><span class="line"><span class="number">50</span>%<span class="number">2163.000000</span><span class="number">18.539269</span><span class="number">-72.335000</span></span><br><span class="line"><span class="number">75</span>%<span class="number">3088.000000</span><span class="number">18.561820</span><span class="number">-72.293570</span></span><br><span class="line">max<span class="number">4052.000000</span><span class="number">50.226029</span><span class="number">114.174287</span></span><br></pre></td></tr></table></figure></p><p>地理位置信息明显存在一些异常，清除这些错误和确实信息是比较简单的。分类信息需要进行额外规整化处理，因此需要编写额外的函数来协助拆分和解析信息。<br><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">data</span> = <span class="keyword">data</span>[(<span class="keyword">data</span>.LATITUDE &gt; <span class="number">18</span>) &amp; (<span class="keyword">data</span>.LATITUDE &lt; <span class="number">20</span>) &amp;</span><br><span class="line">            (<span class="keyword">data</span>.LONGITUDE &gt; -<span class="number">75</span>) &amp; (<span class="keyword">data</span>.LONGITUDE &lt; -<span class="number">70</span>) &amp;</span><br><span class="line">            <span class="keyword">data</span>.CATEGORY.notnull()]</span><br><span class="line"></span><br><span class="line">def to_cat_list(catstr):</span><br><span class="line">    stripped = (x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> catstr.split(<span class="string">','</span>))</span><br><span class="line">    <span class="keyword">return</span> [x <span class="keyword">for</span> x <span class="keyword">in</span> stripped <span class="keyword">if</span> x]</span><br><span class="line"></span><br><span class="line">def get_all_categories(cat_series):</span><br><span class="line">    cat_sets = (<span class="keyword">set</span>(to_cat_list(x)) <span class="keyword">for</span> x <span class="keyword">in</span> cat_series)</span><br><span class="line">    <span class="keyword">return</span> sorted(<span class="keyword">set</span>.union(*cat_sets))</span><br><span class="line"></span><br><span class="line">def get_english(cat):</span><br><span class="line">    code, names = cat.split(<span class="string">'.'</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="string">'|'</span> <span class="keyword">in</span> names:</span><br><span class="line">        names = names.split(<span class="string">'|'</span>)[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> code, names.strip()</span><br><span class="line"></span><br><span class="line">all_cats = get_all_categories(<span class="keyword">data</span>.CATEGORY)</span><br><span class="line">english_mapping = dict(get_english(x) <span class="keyword">for</span> x <span class="keyword">in</span> all_cats)</span><br><span class="line">english_mapping[<span class="string">'2a'</span>]</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">'Food Shortage'</span><br></pre></td></tr></table></figure></p><p>为了使用方便，对于存在多个取值的分类变量可以通过添加哑变量的方式进行转换。这里无法使用pandas的<code>get_dummies</code>方法，因此需要手动编写遍历函数处理。<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def get_code(seq):</span><br><span class="line">    <span class="built_in">return</span> [x.<span class="built_in">split</span>('.')[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> seq <span class="keyword">if</span> x]</span><br><span class="line"></span><br><span class="line">all_codes = get_code(all_cats)</span><br><span class="line">code_index = pd.Index(<span class="built_in">np</span>.<span class="built_in">unique</span>(all_codes))</span><br><span class="line">dummy_frame = DataFrame(<span class="built_in">np</span>.zeros((len(data), len(code_index))), index=data.index, <span class="built_in">columns</span>=code_index)</span><br><span class="line">dummy_frame.ix[:, :<span class="number">6</span>]</span><br></pre></td></tr></table></figure></p><p>如果顺利的话这将构建一个包含所有哑变量（列）的全零DataFrame，行索引则和data的索引一样。Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span><span class="number">1</span>a<span class="number">1</span>b<span class="number">1</span>c<span class="number">1</span>d<span class="number">2</span></span><br><span class="line"><span class="number">0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">4</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">5</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">6</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">7</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">8</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">9</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">10</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line">.....................</span><br></pre></td></tr></table></figure></p><p>然后将各行中适当的项设置为1，再与data进行连接。<br><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">for</span> row, cat <span class="keyword">in</span> zip(<span class="class"><span class="keyword">data</span>.index, <span class="keyword">data</span>.<span class="type">CATEGORY</span>):</span></span><br><span class="line">    codes = get_code(to_cat_list(cat))</span><br><span class="line">    dummy_frame.ix[row, codes] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">data</span> = <span class="keyword">data</span>.join(<span class="title">dummy_frame</span>.<span class="title">add_prefix</span>('<span class="title">category_'</span>))</span></span><br><span class="line"><span class="class"><span class="keyword">data</span>.ix[:, 10:15]</span></span><br></pre></td></tr></table></figure></p><p>这样data基友了一些新的列来表示消息的分类。Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">category_1category_1acategory_1bcategory_1ccategory_1d</span><br><span class="line"><span class="number">0</span><span class="number">1.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">4</span><span class="number">1.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">5</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">6</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">7</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">8</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">9</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">10</span><span class="number">0.0</span><span class="number">1.0</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line">..................</span><br></pre></td></tr></table></figure></p><p>通过matplotlib的一个插件<a href="http://matplotlib.github.com/basemap" target="_blank" rel="noopener">basemap</a>，可以用Python在地图上会这2D地图数据。下面这个函数可以绘制一张简单的黑白海地地图。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpl_toolkits.basemap import Basemap</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">def basic_haiti_map(<span class="attribute">ax</span>=None, <span class="attribute">lllat</span>=17.25, <span class="attribute">urlat</span>=20.25, <span class="attribute">lllon</span>=-75, <span class="attribute">urlon</span>=-71):</span><br><span class="line">    m = Basemap(<span class="attribute">ax</span>=ax, <span class="attribute">projection</span>=<span class="string">'stere'</span>,</span><br><span class="line">                lon_0=(urlon + lllon) / 2,</span><br><span class="line">                lat_0=(urlat + lllat) / 2,</span><br><span class="line">                <span class="attribute">llcrnrlat</span>=lllat, <span class="attribute">urcrnrlat</span>=urlat,</span><br><span class="line">                <span class="attribute">llcrnrlon</span>=lllon, <span class="attribute">urcrnrlon</span>=urlon,</span><br><span class="line">                <span class="attribute">resolution</span>=<span class="string">'f'</span>)</span><br><span class="line">    m.drawcoastlines()</span><br><span class="line">    m.drawstates()</span><br><span class="line">    m.drawcountries()</span><br><span class="line">    return m</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;8-绘图和可视化&quot;&gt;&lt;a href=&quot;#8-绘图和可视化&quot; class=&quot;headerlink&quot; title=&quot;8 绘图和可视化&quot;&gt;&lt;/a&gt;8 绘图和可视化&lt;/h2&gt;&lt;p&gt;绘图是数据分析工作中最重要的任务之一，通过可视化的方式能够让我们快速进行探索过程，找出异常值</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Data Analysis" scheme="http://gloomymoon.github.io/tags/Data-Analysis/"/>
    
    <category term="pandas" scheme="http://gloomymoon.github.io/tags/pandas/"/>
    
    <category term="matplitlib" scheme="http://gloomymoon.github.io/tags/matplitlib/"/>
    
  </entry>
  
  <entry>
    <title>Python for Data Analysis VI</title>
    <link href="http://gloomymoon.github.io/2017/01/02/Python-for-Data-Analysis-VI/"/>
    <id>http://gloomymoon.github.io/2017/01/02/Python-for-Data-Analysis-VI/</id>
    <published>2017-01-02T05:55:06.000Z</published>
    <updated>2017-01-06T07:04:14.447Z</updated>
    
    <content type="html"><![CDATA[<h3 id="7-4-字符串操作"><a href="#7-4-字符串操作" class="headerlink" title="7.4 字符串操作"></a>7.4 字符串操作</h3><p><strong>字符串对象方法</strong></p><p>对于大部分字符串操作应用而言，python内置的字符串对象方法已经能够满足要求，例如<code>split</code>拆分、<code>strip</code>修剪空白符、<code>+</code>号连接字符串、<code>join</code>连接列表或元组、<code>in, index, find</code>方法定位子串、<code>count</code>方法返回子串出现次数、<code>replace</code>方法实现模式替换等等。</p><p><strong>正则表达式</strong></p><p>Python内置的<code>re</code>模块负责对字符串应用正则表达式，<code>re</code>模块的函数可以分为三类：模式匹配、替换以及拆分。一个<code>regex</code>描绘了需要在文本中定位的一个模式，例如标会一个或多个空白符的<code>regex</code>是<code>\s+</code>，为了便于重用，可以用<code>re.compile</code>编译一个<code>regex</code>对象。下面是<code>regex</code>的一些用法说明：</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">regex = re.compile(<span class="comment">'\s+\') # 编译一个可重用的regex对象</span></span><br><span class="line">regex.split(<span class="keyword">text</span>) <span class="meta"># 对text字符串按照regex进行拆分，获得一个拆分后的数组</span></span><br><span class="line">regex.findall(<span class="keyword">text</span>) <span class="meta"># 获取text中匹配regex的所有模式，也是一个数组</span></span><br><span class="line">regex.search(<span class="keyword">text</span>) <span class="meta"># 返回第一个匹配的模式，返回匹配的开始和结束位置</span></span><br><span class="line">regex.match(<span class="keyword">text</span>) <span class="meta"># 只匹配text字符串首部的模式</span></span><br><span class="line">regex.<span class="keyword">sub</span>(replacement, <span class="keyword">text</span>) <span class="meta"># 将text中匹配到的模式替换为replacement</span></span><br></pre></td></tr></table></figure><p>另外如果不仅要找到匹配的模式，还想将模式分段输出，可以将模式待分段的各部分用圆括号包起来。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pattern = <span class="string">r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\.([A-Z]&#123;2,4&#125;)'</span></span><br><span class="line"><span class="comment"># re.IGNORECASE makes the regex case-insensitive</span></span><br><span class="line">regex = re.compile(pattern, flags=re.IGNORECASE)</span><br><span class="line">m = regex.match(<span class="string">'wesm@bright.net'</span>)</span><br><span class="line">m.groups()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="symbol">'wesm</span>', <span class="symbol">'bright</span>', <span class="symbol">'net</span>')</span><br></pre></td></tr></table></figure><p>对于带有分组功能的模式，<code>findall</code>会返回一个元组列表。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">regex = re.compile(<span class="string">r"""</span></span><br><span class="line"><span class="string">    (?P&lt;username&gt;[A-Z0-9._%+-]+)</span></span><br><span class="line"><span class="string">    @</span></span><br><span class="line"><span class="string">    (?P&lt;domain&gt;[A-Z0-9.-]+)</span></span><br><span class="line"><span class="string">    \.</span></span><br><span class="line"><span class="string">    (?P&lt;suffix&gt;[A-Z]&#123;2,4&#125;)"""</span>, flags=re.IGNORECASE|re.VERBOSE)</span><br><span class="line">m = regex.match(<span class="string">'wesm@bright.net'</span>)</span><br><span class="line">m.groupdict()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">'domain'</span>: <span class="string">'bright'</span>, <span class="string">'suffix'</span>: <span class="string">'net'</span>, <span class="string">'username'</span>: <span class="string">'wesm'</span>&#125;</span><br></pre></td></tr></table></figure><p><strong>pandas中矢量化的字符串函数</strong></p><p>回到数据清理工作中，在分析前常常要做一些字符串规整化工作，包括处理缺失数据。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">data</span> = &#123;'<span class="type">Dave</span>': '<span class="title">dave</span>@<span class="title">google</span>.<span class="title">com'</span>, '<span class="type">Steve</span>': '<span class="title">steve</span>@<span class="title">gmail</span>.<span class="title">com'</span>,</span></span><br><span class="line"><span class="class">        '<span class="type">Rob</span>': '<span class="title">rob</span>@<span class="title">gmail</span>.<span class="title">com'</span>, '<span class="type">Wes</span>': <span class="title">np</span>.<span class="title">nan</span>&#125;</span></span><br><span class="line"><span class="class"><span class="keyword">data</span> = <span class="type">Series</span>(<span class="title">data</span>)</span></span><br></pre></td></tr></table></figure><p>虽然所有的字符串和正则表达式方法都能通过<code>data.map</code>方法应用于各个值，但是如果存在上述数据中的NA就会报错。为了解决这个问题，Series提供了一些能够跳过NA值的字符串操作方法。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data<span class="selector-class">.str</span><span class="selector-class">.contains</span>(<span class="string">'gmail'</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">Dave</span>     <span class="literal">False</span></span><br><span class="line"><span class="string">Rob</span>       <span class="literal">True</span></span><br><span class="line"><span class="string">Steve</span>     <span class="literal">True</span></span><br><span class="line"><span class="string">Wes</span>        <span class="string">NaN</span></span><br><span class="line"><span class="attr">dtype:</span> <span class="string">object</span></span><br></pre></td></tr></table></figure><p>同样支持增则表达式和相应的<code>re</code>选项。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">matches</span> = <span class="class"><span class="keyword">data</span>.str.match(<span class="title">pattern</span>, <span class="title">flags</span>=<span class="title">re</span>.<span class="type">IGNORECASE</span>)</span></span><br><span class="line"><span class="title">matches</span></span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Dave     (dave, google, <span class="keyword">com</span>)</span><br><span class="line">Rob        (rob, gmail, <span class="keyword">com</span>)</span><br><span class="line">Steve    (steve, gmail, <span class="keyword">com</span>)</span><br><span class="line">Wes                      NaN</span><br><span class="line"><span class="symbol">dtype:</span> object</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;7-4-字符串操作&quot;&gt;&lt;a href=&quot;#7-4-字符串操作&quot; class=&quot;headerlink&quot; title=&quot;7.4 字符串操作&quot;&gt;&lt;/a&gt;7.4 字符串操作&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;字符串对象方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于大部分字符串操作</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Data Analysis" scheme="http://gloomymoon.github.io/tags/Data-Analysis/"/>
    
    <category term="pandas" scheme="http://gloomymoon.github.io/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>Python for Data Analysis V</title>
    <link href="http://gloomymoon.github.io/2016/12/27/Python-for-Data-Analysis-V/"/>
    <id>http://gloomymoon.github.io/2016/12/27/Python-for-Data-Analysis-V/</id>
    <published>2016-12-27T12:00:55.000Z</published>
    <updated>2017-01-02T05:53:02.348Z</updated>
    
    <content type="html"><![CDATA[<h3 id="7-2-重塑和轴向旋转"><a href="#7-2-重塑和轴向旋转" class="headerlink" title="7.2 重塑和轴向旋转"></a>7.2 重塑和轴向旋转</h3><p><strong>重塑层次化索引</strong></p><ul><li><code>stack</code>：将数据的列旋转为行</li><li><code>unstack</code>：将数据的行旋转为列</li></ul><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = DataFrame(<span class="name">np</span>.arange(<span class="number">6</span>).reshape((<span class="number">2</span>, <span class="number">3</span>)),</span><br><span class="line">                 index=pd.Index(['Ohio', 'Colorado'], name='state'),</span><br><span class="line">                 columns=pd.Index(['one', 'two', 'three'], name='number'))</span><br><span class="line">data</span><br></pre></td></tr></table></figure><p>Data 1:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">numberonetwothree</span><br><span class="line"><span class="section">state</span></span><br><span class="line">Ohio<span class="number">0</span><span class="number">1</span><span class="number">2</span></span><br><span class="line">Colorado<span class="number">3</span><span class="number">4</span><span class="number">5</span></span><br></pre></td></tr></table></figure><p>使用<code>stack</code>方法可以将列转换为行，得到一个Series：</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">result</span> = <span class="class"><span class="keyword">data</span>.stack()</span></span><br><span class="line"><span class="title">result</span></span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">state     <span class="built_in">number</span></span><br><span class="line">Ohio      <span class="literal">one</span>       <span class="number">0</span></span><br><span class="line">          <span class="literal">two</span>       <span class="number">1</span></span><br><span class="line">          <span class="literal">three</span>     <span class="number">2</span></span><br><span class="line">Colorado  <span class="literal">one</span>       <span class="number">3</span></span><br><span class="line">          <span class="literal">two</span>       <span class="number">4</span></span><br><span class="line">          <span class="literal">three</span>     <span class="number">5</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>对于一个层次化索引的Series，看可以用<code>unstack</code>将其重排为一个DataFrame：</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">result</span>.unstack()</span><br></pre></td></tr></table></figure><p>Output like Data 1</p><p>默认情况下，<code>unstack</code>和<code>stack</code>操作的是最内层索引，但可以传入分层级别的编号或名称对其他级别进行重塑。</p><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result.unstack(<span class="number">0</span>)</span><br><span class="line">result.unstack('<span class="keyword">state</span>')</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">state</span>OhioColorado</span><br><span class="line">number</span><br><span class="line">one<span class="number">0</span><span class="number">3</span></span><br><span class="line">two<span class="number">1</span><span class="number">4</span></span><br><span class="line">three<span class="number">2</span><span class="number">5</span></span><br></pre></td></tr></table></figure><p>如果在重塑时，不是所有的分组都有值，则<code>unstack</code>操作会引入缺失值，而<code>stack</code>操作会滤除缺失值，因此这两个操作互相可逆。在DataFrame进行<code>unstack</code>操作时，作为旋转轴的级别会成为结果中最低级别。</p><p><strong>将“长格式”旋转为“宽格式”</strong></p><p>一般时间序列数据是以“长格式”或“堆叠格式”存储的，时间作为主键或主键之一，记录数据的关系型数据大多这样保存原始的时间序列数据。</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ldata<span class="string">[:10]</span></span><br></pre></td></tr></table></figure><p>Data:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dateitemvalue</span><br><span class="line"><span class="number">0</span><span class="number">1959</span><span class="number">-03</span><span class="number">-31</span>realgdp<span class="number">2710.349</span></span><br><span class="line"><span class="number">1</span><span class="number">1959</span><span class="number">-03</span><span class="number">-31</span>infl<span class="number">0.000</span></span><br><span class="line"><span class="number">2</span><span class="number">1959</span><span class="number">-03</span><span class="number">-31</span>unemp<span class="number">5.800</span></span><br><span class="line"><span class="number">3</span><span class="number">1959</span><span class="number">-06</span><span class="number">-30</span>realgdp<span class="number">2778.801</span></span><br><span class="line"><span class="number">4</span><span class="number">1959</span><span class="number">-06</span><span class="number">-30</span>infl<span class="number">2.340</span></span><br><span class="line"><span class="number">5</span><span class="number">1959</span><span class="number">-06</span><span class="number">-30</span>unemp<span class="number">5.100</span></span><br><span class="line"><span class="number">6</span><span class="number">1959</span><span class="number">-09</span><span class="number">-30</span>realgdp<span class="number">2775.488</span></span><br><span class="line"><span class="number">7</span><span class="number">1959</span><span class="number">-09</span><span class="number">-30</span>infl<span class="number">2.740</span></span><br><span class="line"><span class="number">8</span><span class="number">1959</span><span class="number">-09</span><span class="number">-30</span>unemp<span class="number">5.300</span></span><br><span class="line"><span class="number">9</span><span class="number">1959</span><span class="number">-12</span><span class="number">-31</span>realgdp<span class="number">2785.204</span></span><br></pre></td></tr></table></figure><p>在DataFrame中，你可能更喜欢这样操作数据：不同的item值分别形成一列，data列中的时间值则用做索引。DataFrame的<code>pivot</code>方法可以实现这个转换。</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">pivoted</span> = ldata.pivot(<span class="string">'date'</span>, <span class="string">'item'</span>, <span class="string">'value'</span>)</span><br><span class="line">pivoted.head()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">iteminflrealgdpunemp</span><br><span class="line">date</span><br><span class="line"><span class="number">1959</span><span class="number">-03</span><span class="number">-31</span><span class="number">0.00</span><span class="number">2710.349</span><span class="number">5.8</span></span><br><span class="line"><span class="number">1959</span><span class="number">-06</span><span class="number">-30</span><span class="number">2.34</span><span class="number">2778.801</span><span class="number">5.1</span></span><br><span class="line"><span class="number">1959</span><span class="number">-09</span><span class="number">-30</span><span class="number">2.74</span><span class="number">2775.488</span><span class="number">5.3</span></span><br><span class="line"><span class="number">1959</span><span class="number">-12</span><span class="number">-31</span><span class="number">0.27</span><span class="number">2785.204</span><span class="number">5.6</span></span><br><span class="line"><span class="number">1960</span><span class="number">-03</span><span class="number">-31</span><span class="number">2.31</span><span class="number">2847.699</span><span class="number">5.2</span></span><br></pre></td></tr></table></figure><p><code>pivot</code>的前两个参数值分别用作行和列索引的列名，最后一个参数值则是用于填充DataFrame的数据列的列名。如果有两个需要参与重塑的数据列，忽略最后一个参数得到的DataFrame就会带有层次化的列。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ldata[<span class="string">'value2'</span>] = np<span class="selector-class">.random</span><span class="selector-class">.randn</span>(len(ldata))</span><br><span class="line">ldata[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><p>Data:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dateitemvaluevalue2</span><br><span class="line"><span class="number">0</span><span class="number">1959</span><span class="number">-03</span><span class="number">-31</span>realgdp<span class="number">2710.349</span><span class="number">1.669025</span></span><br><span class="line"><span class="number">1</span><span class="number">1959</span><span class="number">-03</span><span class="number">-31</span>infl<span class="number">0.000</span><span class="number">-0.438570</span></span><br><span class="line"><span class="number">2</span><span class="number">1959</span><span class="number">-03</span><span class="number">-31</span>unemp<span class="number">5.800</span><span class="number">-0.539741</span></span><br><span class="line"><span class="number">3</span><span class="number">1959</span><span class="number">-06</span><span class="number">-30</span>realgdp<span class="number">2778.801</span><span class="number">0.476985</span></span><br><span class="line"><span class="number">4</span><span class="number">1959</span><span class="number">-06</span><span class="number">-30</span>infl<span class="number">2.340</span><span class="number">3.248944</span></span><br><span class="line"><span class="number">5</span><span class="number">1959</span><span class="number">-06</span><span class="number">-30</span>unemp<span class="number">5.100</span><span class="number">-1.021228</span></span><br><span class="line"><span class="number">6</span><span class="number">1959</span><span class="number">-09</span><span class="number">-30</span>realgdp<span class="number">2775.488</span><span class="number">-0.577087</span></span><br><span class="line"><span class="number">7</span><span class="number">1959</span><span class="number">-09</span><span class="number">-30</span>infl<span class="number">2.740</span><span class="number">0.124121</span></span><br><span class="line"><span class="number">8</span><span class="number">1959</span><span class="number">-09</span><span class="number">-30</span>unemp<span class="number">5.300</span><span class="number">0.302614</span></span><br><span class="line"><span class="number">9</span><span class="number">1959</span><span class="number">-12</span><span class="number">-31</span>realgdp<span class="number">2785.204</span><span class="number">0.523772</span></span><br></pre></td></tr></table></figure><p>本质上<code>pivot</code>等同于：用<code>set_index</code>创建层次化索引后再使用<code>unstack</code>重塑。下面两段代码的效果相同。</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pivoted = ldata.pivot(<span class="string">'date'</span>, <span class="string">'item'</span>)</span><br><span class="line">pivoted[:<span class="number">5</span>]</span><br><span class="line">unstacked = ldata.set_index([<span class="string">'date'</span>, <span class="string">'item'</span>]).unstack(<span class="string">'item'</span>)</span><br><span class="line">unstacked[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">valuevalue2</span><br><span class="line">iteminflrealgdpunempinflrealgdpunemp</span><br><span class="line">date</span><br><span class="line"><span class="number">1959</span><span class="number">-03</span><span class="number">-31</span><span class="number">0.00</span><span class="number">2710.349</span><span class="number">5.8</span><span class="number">-0.438570</span><span class="number">1.669025</span><span class="number">-0.539741</span></span><br><span class="line"><span class="number">1959</span><span class="number">-06</span><span class="number">-30</span><span class="number">2.34</span><span class="number">2778.801</span><span class="number">5.1</span><span class="number">3.248944</span><span class="number">0.476985</span><span class="number">-1.021228</span></span><br><span class="line"><span class="number">1959</span><span class="number">-09</span><span class="number">-30</span><span class="number">2.74</span><span class="number">2775.488</span><span class="number">5.3</span><span class="number">0.124121</span><span class="number">-0.577087</span><span class="number">0.302614</span></span><br><span class="line"><span class="number">1959</span><span class="number">-12</span><span class="number">-31</span><span class="number">0.27</span><span class="number">2785.204</span><span class="number">5.6</span><span class="number">0.000940</span><span class="number">0.523772</span><span class="number">1.343810</span></span><br><span class="line"><span class="number">1960</span><span class="number">-03</span><span class="number">-31</span><span class="number">2.31</span><span class="number">2847.699</span><span class="number">5.2</span><span class="number">-0.831154</span><span class="number">-0.713544</span><span class="number">-2.370232</span></span><br></pre></td></tr></table></figure><h3 id="7-3-数据转换"><a href="#7-3-数据转换" class="headerlink" title="7.3 数据转换"></a>7.3 数据转换</h3><p><strong>移除重复数据</strong></p><p>DataFrame中常常会出现重复行，DataFrame的<code>duplicated</code>返回一个布尔型Series，表示各行是否重复，DataFrame的<code>dorp_duplicates</code>返回一个移除重复行的DataFrame。默认情况下判断所有列，但是也可以传入希望过滤的列列表。默认情况下保留的是第一个出现的值组合，传入<code>take_last=True</code>参数则保留最后一个。</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data = <span class="symbol">DataFrame</span>(&#123;<span class="string">'k1'</span>: [<span class="string">'one'</span>] * <span class="number">3</span> + [<span class="string">'two'</span>] * <span class="number">4</span>,</span><br><span class="line">                  <span class="string">'k2'</span>: [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]&#125;)</span><br><span class="line">data[<span class="string">'v1'</span>] = range(<span class="number">7</span>)</span><br><span class="line">data.drop_duplicates([<span class="string">'k1'</span>])</span><br><span class="line"></span><br><span class="line">data.drop_duplicates([<span class="string">'k1'</span>, <span class="string">'k2'</span>], take_last=<span class="symbol">True</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">k1k2v1</span><br><span class="line"><span class="number">0</span><span class="literal">one</span><span class="number">1</span><span class="number">0</span></span><br><span class="line"><span class="number">3</span><span class="literal">two</span><span class="number">3</span><span class="number">3</span></span><br><span class="line"></span><br><span class="line">/Library/Python/<span class="number">2.7</span>/site-packages/ipykernel/__main__.py:<span class="number">1</span>: FutureWarning: <span class="keyword">the</span> take_last=True keyword is deprecated, use keep=<span class="string">'last'</span> instead</span><br><span class="line">k1k2v1</span><br><span class="line"><span class="number">1</span><span class="literal">one</span><span class="number">1</span><span class="number">1</span></span><br><span class="line"><span class="number">2</span><span class="literal">one</span><span class="number">2</span><span class="number">2</span></span><br><span class="line"><span class="number">4</span><span class="literal">two</span><span class="number">3</span><span class="number">4</span></span><br><span class="line"><span class="number">6</span><span class="literal">two</span><span class="number">4</span><span class="number">6</span></span><br></pre></td></tr></table></figure><p><strong>利用函数或映射进行数据转换</strong></p><p>更多的时候在处理数据时，我们希望根据某种逻辑关系对值进行转换。在说明前先看下如下关于肉类的演示数据：</p><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = <span class="type">DataFrame</span>(&#123;<span class="symbol">'food'</span>: [<span class="symbol">'bacon'</span>, <span class="symbol">'pulled</span> pork', <span class="symbol">'bacon'</span>, <span class="symbol">'Pastrami'</span>, <span class="symbol">'corned</span> beef', <span class="symbol">'Bacon'</span>, <span class="symbol">'pastrami'</span>, <span class="symbol">'honey</span> ham', <span class="symbol">'nova</span> lox'], <span class="symbol">'ounces'</span>: [<span class="number">4</span>, <span class="number">3</span>, <span class="number">12</span>, <span class="number">6</span>, <span class="number">7.5</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">6</span>]&#125;)</span><br><span class="line">data</span><br></pre></td></tr></table></figure><p>Data:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">foodounces</span><br><span class="line"><span class="number">0</span>bacon<span class="number">4.0</span></span><br><span class="line"><span class="number">1</span>pulled pork<span class="number">3.0</span></span><br><span class="line"><span class="number">2</span>bacon<span class="number">12.0</span></span><br><span class="line"><span class="number">3</span>Pastrami<span class="number">6.0</span></span><br><span class="line"><span class="number">4</span>corned beef<span class="number">7.5</span></span><br><span class="line"><span class="number">5</span>Bacon<span class="number">8.0</span></span><br><span class="line"><span class="number">6</span>pastrami<span class="number">3.0</span></span><br><span class="line"><span class="number">7</span>honey ham<span class="number">5.0</span></span><br><span class="line"><span class="number">8</span>nova lox<span class="number">6.0</span></span><br></pre></td></tr></table></figure><p>最常见的处理是创建新分类/分组，例如需要添加一列表示food来源的动物类型，肉类到动物的映射关系如下：</p><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">meat_to_animal = &#123;</span><br><span class="line">  <span class="symbol">'bacon'</span>: <span class="symbol">'pig'</span>,</span><br><span class="line">  <span class="symbol">'pulled</span> pork': <span class="symbol">'pig'</span>,</span><br><span class="line">  <span class="symbol">'pastrami'</span>: <span class="symbol">'cow'</span>,</span><br><span class="line">  <span class="symbol">'corned</span> beef': <span class="symbol">'cow'</span>,</span><br><span class="line">  <span class="symbol">'honey</span> ham': <span class="symbol">'pig'</span>,</span><br><span class="line">  <span class="symbol">'nova</span> lox': <span class="symbol">'salmon'</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Series的<code>map</code>方法可以根据一个函数或含有映射关系的字典对象，产生新的Series。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">data</span>['animal'] = <span class="keyword">data</span>['food'].map(<span class="title">str</span>.<span class="title">lower</span>).map(<span class="title">meat_to_animal</span>)</span></span><br><span class="line"><span class="class"><span class="keyword">data</span></span></span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">foodouncesanimal</span><br><span class="line"><span class="number">0</span>bacon<span class="number">4.0</span>pig</span><br><span class="line"><span class="number">1</span>pulled pork<span class="number">3.0</span>pig</span><br><span class="line"><span class="number">2</span>bacon<span class="number">12.0</span>pig</span><br><span class="line"><span class="number">3</span>Pastrami<span class="number">6.0</span>cow</span><br><span class="line"><span class="number">4</span>corned beef<span class="number">7.5</span>cow</span><br><span class="line"><span class="number">5</span>Bacon<span class="number">8.0</span>pig</span><br><span class="line"><span class="number">6</span>pastrami<span class="number">3.0</span>cow</span><br><span class="line"><span class="number">7</span>honey ham<span class="number">5.0</span>pig</span><br><span class="line"><span class="number">8</span>nova lox<span class="number">6.0</span>salmon</span><br></pre></td></tr></table></figure><p>注意因为原始数据里包含有大小写，因此首先做了一次小写转换。当然也可以直接传入一个完成全部工作的lambda函数，效果是一样的：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">data</span><span class="selector-attr">['food']</span><span class="selector-class">.map</span>(<span class="selector-tag">lambda</span> <span class="selector-tag">x</span>: <span class="selector-tag">meat_to_animal</span><span class="selector-attr">[x.lower()]</span>)</span><br></pre></td></tr></table></figure><p><strong>值替换</strong></p><p><code>fillna</code>方法是一种值替换的特殊情况，<code>replace</code>方法是更加通用、更加简单的方法。</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">data = Series([1., <span class="string">-999</span>., 2., <span class="string">-999</span>., <span class="string">-1000</span>., 3.])</span><br><span class="line">data</span><br><span class="line"></span><br><span class="line">0       1.0</span><br><span class="line">1    <span class="string">-999</span>.0</span><br><span class="line">2       2.0</span><br><span class="line">3    <span class="string">-999</span>.0</span><br><span class="line">4   <span class="string">-1000</span>.0</span><br><span class="line">5       3.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>-999可能是一个表示缺失的标记值，可以用<code>replace</code>方法替换为pandas的<code>nan</code>：</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">data</span>.replace(-999, <span class="title">np</span>.<span class="title">nan</span>)</span></span><br></pre></td></tr></table></figure><p>如果希望一次性替换多个值，可以传入一个由待替换值和替换值组成的列表或字典，下面两种方式等效：</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">data</span>.replace([-999, -1000], [<span class="title">np</span>.<span class="title">nan</span>, 0]))</span></span><br><span class="line"><span class="class"><span class="keyword">data</span>.replace(<span class="comment">&#123;-999: np.nan, -1000: 0&#125;)</span></span></span><br></pre></td></tr></table></figure><p><strong>重命名轴索引</strong></p><p><code>map</code>方法同样可以对数据的轴标签使用。DataFrame的<code>rename</code>方法可以直接返回修改index和columns的对象，如果希望就地修改不产生新对象，可以传入参数<code>inplace=True</code>。</p><p><strong>离散化和面元划分</strong></p><p>为了便于分析，连续数据常常被离散化或分bin，例如将年龄划分为不同的年龄组。</p><p>Data：</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ages = [<span class="number">20</span>, <span class="number">22</span>, <span class="number">25</span>, <span class="number">27</span>, <span class="number">21</span>, <span class="number">23</span>, <span class="number">37</span>, <span class="number">31</span>, <span class="number">61</span>, <span class="number">45</span>, <span class="number">41</span>, <span class="number">32</span>]</span><br></pre></td></tr></table></figure><p>如果要将这些数据分为“18到25”、“26到35”、“35到60”和“60以上”几个组，可以使用pandas的<code>cut</code>函数：</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bins = [<span class="number">18</span>, <span class="number">25</span>, <span class="number">35</span>, <span class="number">60</span>, <span class="number">100</span>]</span><br><span class="line">cats = pd.cut(ages, bins)</span><br><span class="line">cats</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="name">18</span>, <span class="number">25</span>], (<span class="name">18</span>, <span class="number">25</span>], (<span class="name">18</span>, <span class="number">25</span>], (<span class="name">25</span>, <span class="number">35</span>], (<span class="name">18</span>, <span class="number">25</span>], ..., (<span class="name">25</span>, <span class="number">35</span>], (<span class="name">60</span>, <span class="number">100</span>], (<span class="name">35</span>, <span class="number">60</span>], (<span class="name">35</span>, <span class="number">60</span>], (<span class="name">25</span>, <span class="number">35</span>]]</span><br><span class="line">Length: <span class="number">12</span></span><br><span class="line">Categories (<span class="name">4</span>, object): [(<span class="name">18</span>, <span class="number">25</span>] &lt; (<span class="name">25</span>, <span class="number">35</span>] &lt; (<span class="name">35</span>, <span class="number">60</span>] &lt; (<span class="name">60</span>, <span class="number">100</span>]]</span><br></pre></td></tr></table></figure><p><code>cut</code>函数返回的是一个特殊的Categorical对象。它含有一个表示不同分类名称的<code>categories</code>索引对象和一个为分组进行标号的<code>levels</code>数组。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cats.labels</span><br><span class="line"></span><br><span class="line">/Library/Python/<span class="number">2.7</span>/site-packages/ipykernel/__main__<span class="selector-class">.py</span>:<span class="number">1</span>: FutureWarning: <span class="string">'labels'</span> is deprecated. Use <span class="string">'codes'</span> instead</span><br><span class="line">  <span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"><span class="function"><span class="title">array</span><span class="params">([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], dtype=int8)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cats.categories</span><br><span class="line"></span><br><span class="line">Index([<span class="string">u'(18, 25]'</span>, <span class="string">u'(25, 35]'</span>, <span class="string">u'(35, 60]'</span>, <span class="string">u'(60, 100]'</span>], dtype=<span class="string">'object'</span>)</span><br></pre></td></tr></table></figure><p>categories是一个Index对象，实质是一个由python对象组成的 NumPy数组，其中存放的是每个分组的描述字符串。</p><p>如果想<code>cut</code>传入的是分组的数量而不是确切的分组边界，则会根据数据的最小值和最大值计算等长分组。<code>qcut</code>是个类似于<code>cut</code>的函数，它根据样本的分位数对数据进行分组划分。</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = np.random.randn(1000) <span class="comment"># 正态分布</span></span><br><span class="line">cats = pd.qcut(data, 4)<span class="comment"># 按四分位数进行切割</span></span><br><span class="line">cats</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[(-0.022, 0.634]</span>, <span class="selector-attr">[-3.745, -0.648]</span>, (0<span class="selector-class">.634</span>, 3<span class="selector-class">.26</span>], (<span class="selector-tag">-0</span><span class="selector-class">.022</span>, 0<span class="selector-class">.634</span>], (<span class="selector-tag">-0</span><span class="selector-class">.648</span>, <span class="selector-tag">-0</span><span class="selector-class">.022</span>], ..., (0<span class="selector-class">.634</span>, 3<span class="selector-class">.26</span>], (<span class="selector-tag">-0</span><span class="selector-class">.022</span>, 0<span class="selector-class">.634</span>], <span class="selector-attr">[-3.745, -0.648]</span>, (<span class="selector-tag">-0</span><span class="selector-class">.022</span>, 0<span class="selector-class">.634</span>], (<span class="selector-tag">-0</span><span class="selector-class">.022</span>, 0<span class="selector-class">.634</span>]]</span><br><span class="line"><span class="selector-tag">Length</span>: 1000</span><br><span class="line"><span class="selector-tag">Categories</span> (4, <span class="selector-tag">object</span>): <span class="selector-attr">[[-3.745, -0.648]</span> &lt; (<span class="selector-tag">-0</span><span class="selector-class">.648</span>, <span class="selector-tag">-0</span><span class="selector-class">.022</span>] &lt; (<span class="selector-tag">-0</span><span class="selector-class">.022</span>, 0<span class="selector-class">.634</span>] &lt; (0<span class="selector-class">.634</span>, 3<span class="selector-class">.26</span>]]</span><br></pre></td></tr></table></figure><p>跟<code>cut</code>一样，可以设置自定义的分位数（0到1之间的数值，包含端点）。</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.qcut(data, [<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">0.9</span>, <span class="number">1.</span>])</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[(-0.022, 1.298]</span>, <span class="selector-attr">[-3.745, -1.274]</span>, (<span class="selector-tag">-0</span><span class="selector-class">.022</span>, 1<span class="selector-class">.298</span>], (<span class="selector-tag">-0</span><span class="selector-class">.022</span>, 1<span class="selector-class">.298</span>], (<span class="selector-tag">-1</span><span class="selector-class">.274</span>, <span class="selector-tag">-0</span><span class="selector-class">.022</span>], ..., (<span class="selector-tag">-0</span><span class="selector-class">.022</span>, 1<span class="selector-class">.298</span>], (<span class="selector-tag">-0</span><span class="selector-class">.022</span>, 1<span class="selector-class">.298</span>], <span class="selector-attr">[-3.745, -1.274]</span>, (<span class="selector-tag">-0</span><span class="selector-class">.022</span>, 1<span class="selector-class">.298</span>], (<span class="selector-tag">-0</span><span class="selector-class">.022</span>, 1<span class="selector-class">.298</span>]]</span><br><span class="line"><span class="selector-tag">Length</span>: 1000</span><br><span class="line"><span class="selector-tag">Categories</span> (4, <span class="selector-tag">object</span>): <span class="selector-attr">[[-3.745, -1.274]</span> &lt; (<span class="selector-tag">-1</span><span class="selector-class">.274</span>, <span class="selector-tag">-0</span><span class="selector-class">.022</span>] &lt; (<span class="selector-tag">-0</span><span class="selector-class">.022</span>, 1<span class="selector-class">.298</span>] &lt; (1<span class="selector-class">.298</span>, 3<span class="selector-class">.26</span>]]</span><br></pre></td></tr></table></figure><p><strong> 检测和过滤异常值</strong></p><p>异常值（这里指异常点或离群值）的过滤或变换本质上就是数组的运算，利用布尔型DataFrame方法可以选出异常值，然后就可以轻松设置。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">np</span>.random.seed(<span class="number">12345</span>)</span><br><span class="line"><span class="class"><span class="keyword">data</span> = <span class="type">DataFrame</span>(<span class="title">np</span>.<span class="title">random</span>.<span class="title">randn</span>(1000, 4))</span></span><br><span class="line"><span class="class"><span class="keyword">data</span>[np.abs(<span class="title">data</span>) &gt; 3 ] = np.sign(<span class="title">data</span>) * 3 # 将绝对值超过3的值限制在-3到3之间</span></span><br><span class="line"><span class="class"><span class="keyword">data</span>[(<span class="title">np</span>.<span class="title">abs</span>(<span class="title">data</span>) &gt; 3).any(1)]</span></span><br></pre></td></tr></table></figure><p>No output.</p><p><strong>排列和随机采样</strong></p><p>利用numpy.random.permutation函数可以实现对Series或DataFrame的列重排，传入需要排列的轴长度值，可产生一个表示新顺序的整数数组。</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = DataFrame(np.arange(<span class="number">5</span> * <span class="number">4</span>).reshape(<span class="number">5</span>, <span class="number">4</span>))</span><br><span class="line">sampler = np.random.permutation(<span class="number">5</span>)</span><br><span class="line">sampler</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure><p>然后就可以在基于ix的索引操作或<code>take</code>函数中使用该数组实现对DataFrame的重排序。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">df</span><span class="selector-class">.take</span>(<span class="selector-tag">sampler</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span><span class="number">1</span><span class="number">2</span><span class="number">3</span></span><br><span class="line"><span class="number">1</span><span class="number">4</span><span class="number">5</span><span class="number">6</span><span class="number">7</span></span><br><span class="line"><span class="number">0</span><span class="number">0</span><span class="number">1</span><span class="number">2</span><span class="number">3</span></span><br><span class="line"><span class="number">2</span><span class="number">8</span><span class="number">9</span><span class="number">10</span><span class="number">11</span></span><br><span class="line"><span class="number">3</span><span class="number">12</span><span class="number">13</span><span class="number">14</span><span class="number">15</span></span><br><span class="line"><span class="number">4</span><span class="number">16</span><span class="number">17</span><span class="number">18</span><span class="number">19</span></span><br></pre></td></tr></table></figure><p>如果希望进行重复采样，可以通过<code>np.random.randint</code>得到一组随机整数。</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sampler = np.<span class="built_in">random</span>.randint(<span class="number">0</span>, <span class="built_in">len</span>(df), size=<span class="number">10</span>) <span class="comment"># 随机抽取10条</span></span><br><span class="line">df.take(sampler)</span><br></pre></td></tr></table></figure><p>Oupput:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span><span class="number">1</span><span class="number">2</span><span class="number">3</span></span><br><span class="line"><span class="number">2</span><span class="number">8</span><span class="number">9</span><span class="number">10</span><span class="number">11</span></span><br><span class="line"><span class="number">2</span><span class="number">8</span><span class="number">9</span><span class="number">10</span><span class="number">11</span></span><br><span class="line"><span class="number">4</span><span class="number">16</span><span class="number">17</span><span class="number">18</span><span class="number">19</span></span><br><span class="line"><span class="number">3</span><span class="number">12</span><span class="number">13</span><span class="number">14</span><span class="number">15</span></span><br><span class="line"><span class="number">3</span><span class="number">12</span><span class="number">13</span><span class="number">14</span><span class="number">15</span></span><br><span class="line"><span class="number">0</span><span class="number">0</span><span class="number">1</span><span class="number">2</span><span class="number">3</span></span><br><span class="line"><span class="number">1</span><span class="number">4</span><span class="number">5</span><span class="number">6</span><span class="number">7</span></span><br><span class="line"><span class="number">4</span><span class="number">16</span><span class="number">17</span><span class="number">18</span><span class="number">19</span></span><br><span class="line"><span class="number">1</span><span class="number">4</span><span class="number">5</span><span class="number">6</span><span class="number">7</span></span><br><span class="line"><span class="number">4</span><span class="number">16</span><span class="number">17</span><span class="number">18</span><span class="number">19</span></span><br></pre></td></tr></table></figure><p><strong>计算指标/哑变量</strong></p><p>另一种常用于统计建模或机器学习的转换方式是将分类变量转换为“哑变量矩阵”或“指标矩阵”。例如某一个列中含有k个不同的取值，则可以派生出一个k列矩阵，每列的值都是1或0。pandas有一个<code>get_dummies</code>函数可以直接实现该功能。</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = <span class="symbol">DataFrame</span>(&#123;<span class="string">'key'</span>: [<span class="string">'b'</span>, <span class="string">'b'</span>, <span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>], <span class="string">'data1'</span>: range(<span class="number">6</span>)&#125;)</span><br><span class="line">pd.get_dummies(df[<span class="string">'key'</span>])</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">abc</span><br><span class="line"><span class="number">0</span><span class="number">0</span><span class="number">1</span><span class="number">0</span></span><br><span class="line"><span class="number">1</span><span class="number">0</span><span class="number">1</span><span class="number">0</span></span><br><span class="line"><span class="number">2</span><span class="number">1</span><span class="number">0</span><span class="number">0</span></span><br><span class="line"><span class="number">3</span><span class="number">0</span><span class="number">0</span><span class="number">1</span></span><br><span class="line"><span class="number">4</span><span class="number">1</span><span class="number">0</span><span class="number">0</span></span><br><span class="line"><span class="number">5</span><span class="number">0</span><span class="number">1</span><span class="number">0</span></span><br></pre></td></tr></table></figure><p>如果DataFrame中某分类变量列的值属于多个分类，就需要做一些数据规整操作。</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mnames = [<span class="string">'movie_id'</span>, <span class="string">'title'</span>, <span class="string">'genres'</span>]</span><br><span class="line">movies = pd.read_table(<span class="string">'../../../pydata-book-master/ch02/movielens/movies.dat'</span>, sep=<span class="string">'::'</span>, header=<span class="symbol">None</span>,</span><br><span class="line">                        names=mnames)</span><br><span class="line">movies[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure><p>Data:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">movie_idtitlegenres</span><br><span class="line"><span class="number">0</span><span class="number">1</span>Toy Story (<span class="number">1995</span>)Animation|Children's|Comedy</span><br><span class="line"><span class="number">1</span><span class="number">2</span>Jumanji (<span class="number">1995</span>)Adventure|Children's|Fantasy</span><br><span class="line"><span class="number">2</span><span class="number">3</span>Grumpier Old Men (<span class="number">1995</span>)Comedy|Romance</span><br><span class="line"><span class="number">3</span><span class="number">4</span>Waiting to Exhale (<span class="number">1995</span>)Comedy|Drama</span><br><span class="line"><span class="number">4</span><span class="number">5</span>Father of the Bride Part II (<span class="number">1995</span>)Comedy</span><br><span class="line"><span class="number">5</span><span class="number">6</span>Heat (<span class="number">1995</span>)Action|Crime|Thriller</span><br><span class="line"><span class="number">6</span><span class="number">7</span>Sabrina (<span class="number">1995</span>)Comedy|Romance</span><br><span class="line"><span class="number">7</span><span class="number">8</span>Tom and Huck (<span class="number">1995</span>)Adventure|Children's</span><br><span class="line"><span class="number">8</span><span class="number">9</span>Sudden Death (<span class="number">1995</span>)Action</span><br><span class="line"><span class="number">9</span><span class="number">10</span>GoldenEye (<span class="number">1995</span>)Action|Adventure|Thriller</span><br></pre></td></tr></table></figure><p>以之前MovieLens 1M数据为例，首先需要从<code>genres</code>列中抽取出不同的genre值g。</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">genre_iter = (<span class="name">set</span>(<span class="name">x</span>.split('|')) for x in movies.genres)</span><br><span class="line">genres = sorted(<span class="name">set</span>.union(<span class="name">*genre_iter</span>))</span><br><span class="line">genres</span><br></pre></td></tr></table></figure><p>genre_iter是一个表达式生成器，<code>set.union</code>参数中，<code>*genre_iter</code>表示将生成器的每次迭代都作为一个set对象，最后传给<code>union</code>方法获得并集。Output:</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">'Action</span>',</span><br><span class="line"> <span class="symbol">'Adventure</span>',</span><br><span class="line"> <span class="symbol">'Animation</span>',</span><br><span class="line"> <span class="string">"Children's"</span>,</span><br><span class="line"> <span class="symbol">'Comedy</span>',</span><br><span class="line"> <span class="symbol">'Crime</span>',</span><br><span class="line"> <span class="symbol">'Documentary</span>',</span><br><span class="line"> <span class="symbol">'Drama</span>',</span><br><span class="line"> <span class="symbol">'Fantasy</span>',</span><br><span class="line"> <span class="symbol">'Film-Noir</span>',</span><br><span class="line"> <span class="symbol">'Horror</span>',</span><br><span class="line"> <span class="symbol">'Musical</span>',</span><br><span class="line"> <span class="symbol">'Mystery</span>',</span><br><span class="line"> <span class="symbol">'Romance</span>',</span><br><span class="line"> <span class="symbol">'Sci-Fi</span>',</span><br><span class="line"> <span class="symbol">'Thriller</span>',</span><br><span class="line"> <span class="symbol">'War</span>',</span><br><span class="line"> <span class="symbol">'Western</span>']</span><br></pre></td></tr></table></figure><p>为了构建指标，我们先从一个全零的DataFrame对象<code>dummies</code>开始，迭代每一部电影并将<code>dummies</code>各行的项设置为1或0，最后再将其与movies合并。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dummies = DataFrame(np.zeros((len(movies), len(genres))), <span class="attribute">columns</span>=genres)</span><br><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span>, gen <span class="keyword">in</span> enumerate(movies.genres):</span><br><span class="line">    dummies<span class="selector-class">.ix</span>[<span class="selector-tag">i</span>, gen.split(<span class="string">'|'</span>)] = <span class="number">1</span></span><br><span class="line">movies_windic = movies.join(dummies.add_prefix(<span class="string">'Gere_'</span>))</span><br><span class="line">movies_windic<span class="selector-class">.ix</span>[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">movie_id                                      <span class="number">1</span></span><br><span class="line">title                          <span class="type">Toy</span> <span class="type">Story</span> (<span class="number">1995</span>)</span><br><span class="line">genres              <span class="type">Animation</span>|<span class="type">Children</span><span class="symbol">'s</span>|<span class="type">Comedy</span></span><br><span class="line"><span class="type">Gere_Action</span>                                   <span class="number">0</span></span><br><span class="line"><span class="type">Gere_Adventure</span>                                <span class="number">0</span></span><br><span class="line"><span class="type">Gere_Animation</span>                                <span class="number">1</span></span><br><span class="line"><span class="type">Gere_Children</span><span class="symbol">'s</span>                               <span class="number">1</span></span><br><span class="line"><span class="type">Gere_Comedy</span>                                   <span class="number">1</span></span><br><span class="line"><span class="type">Gere_Crime</span>                                    <span class="number">0</span></span><br><span class="line"><span class="type">Gere_Documentary</span>                              <span class="number">0</span></span><br><span class="line"><span class="type">Gere_Drama</span>                                    <span class="number">0</span></span><br><span class="line"><span class="type">Gere_Fantasy</span>                                  <span class="number">0</span></span><br><span class="line"><span class="type">Gere_Film</span>-<span class="type">Noir</span>                                <span class="number">0</span></span><br><span class="line"><span class="type">Gere_Horror</span>                                   <span class="number">0</span></span><br><span class="line"><span class="type">Gere_Musical</span>                                  <span class="number">0</span></span><br><span class="line"><span class="type">Gere_Mystery</span>                                  <span class="number">0</span></span><br><span class="line"><span class="type">Gere_Romance</span>                                  <span class="number">0</span></span><br><span class="line"><span class="type">Gere_Sci</span>-<span class="type">Fi</span>                                   <span class="number">0</span></span><br><span class="line"><span class="type">Gere_Thriller</span>                                 <span class="number">0</span></span><br><span class="line"><span class="type">Gere_War</span>                                      <span class="number">0</span></span><br><span class="line"><span class="type">Gere_Western</span>                                  <span class="number">0</span></span><br><span class="line"><span class="type">Name</span>: <span class="number">0</span>, dtype: <span class="class"><span class="keyword">object</span></span></span><br></pre></td></tr></table></figure><p>一个实用的秘诀是将<code>get_dummies</code>和诸如<code>cut</code>的离散化函数生成你需要的哑变量指标。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;7-2-重塑和轴向旋转&quot;&gt;&lt;a href=&quot;#7-2-重塑和轴向旋转&quot; class=&quot;headerlink&quot; title=&quot;7.2 重塑和轴向旋转&quot;&gt;&lt;/a&gt;7.2 重塑和轴向旋转&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;重塑层次化索引&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Data Analysis" scheme="http://gloomymoon.github.io/tags/Data-Analysis/"/>
    
    <category term="pandas" scheme="http://gloomymoon.github.io/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>Start using Materialize in your website</title>
    <link href="http://gloomymoon.github.io/2016/11/29/Start-using-Materialize-in-your-website/"/>
    <id>http://gloomymoon.github.io/2016/11/29/Start-using-Materialize-in-your-website/</id>
    <published>2016-11-29T13:41:24.000Z</published>
    <updated>2016-12-01T14:18:27.659Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-About-Meterial-Design"><a href="#1-About-Meterial-Design" class="headerlink" title="1 About Meterial Design"></a>1 About Meterial Design</h2><p>Material Design是由Google发布的全平台设计规范，其原则如下：<br><strong>Material is the metaphor</strong><br>Google认为材质的触感可以通过纸片的隐喻来表达，通过在设计上运用符合运动规律的动画交互、通过光影打造层及设计的关系来创造全新的虚拟交互控件，将设计从2D拓展到了3D。</p><p><strong>Bold, graphic, intentional</strong><br>视觉设计上不仅要生动形象，还要表达 信息架构、意义、帮助用户聚焦，为用户使用提供指引，凸现当前页面的核心功能，确认设计的目的。</p><p><strong>Motion provides meaning</strong><br>交互动画的目本是吸引用户的注意，表达当下页面发生的变化，因此也与对视觉要求一样，反映设计的目的和意义</p><p>因为Google自带被墙属性，对于看厌了iOS、boostrap和Metro风格的高逼格同学，Materail Design确实看上去更高大上。</p><p>Material Design是一个设计规范，制订了一套遵循优秀设计的经典定则，让不同平台的应用都保持统一的外观。与iOS 7的走向极端的扁平化不同，Material Design仍然保留了阴影、光线、层次，以及现实世界中的物理法则，虽然不模拟现实，但是构建了真实的感觉。</p><p>Google自家的一系列应用已经来是陆续换上Material Design。对于Material Design规范可以参看<a href="http://google.com/design/spec" target="_blank" rel="noopener">官方文档</a>，不想翻墙的同学可以前往新的官方网站：<a href="www.material.io">www.material.io</a>，或非官方翻译版：<a href="http://www.uisdc.com/comprehensive-material-design-note" target="_blank" rel="noopener">帮你全面彻底搞定MATERIAL DESIGN的学习笔记</a>、<a href="http://www.uisdc.com/material-design-learning-experience" target="_blank" rel="noopener">MATERIAL DESIGN设计规范学习心得</a></p><p>Google官方发布了<a href="http://getmdl.io/" target="_blank" rel="noopener">Material Design Lite(MDL)</a>，一套基于CSS、JS和HTML的Material Design风格的组件实现方案，不依赖于任何第三方JS库，并针对各平台优化，向下支持到IE9。</p><p>此外还有第三方实现：</p><ul><li><a href="Materializecss.com">Materializecss.com</a></li></ul><h2 id="2-Flask-Materialize"><a href="#2-Flask-Materialize" class="headerlink" title="2 Flask Materialize"></a>2 Flask Materialize</h2><p><a href="https://github.com/HellerCommaA/flask-materialize" target="_blank" rel="noopener">flask-material</a>是一个基于flask-boostrap且封装了<a href="https://github.com/Dogfalo/materialize" target="_blank" rel="noopener">MaterializeCSS</a>的开源实现。因为<code>MDL</code>的发布，该项目作者计划迁移到基于官方的CSS框架下。</p><h3 id="2-1-Installation"><a href="#2-1-Installation" class="headerlink" title="2.1 Installation"></a>2.1 Installation</h3><p>直接通过<code>pip</code>安装即可：<br><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> flask-material</span><br></pre></td></tr></table></figure></p><h3 id="2-2-Init"><a href="#2-2-Init" class="headerlink" title="2.2 Init"></a>2.2 Init</h3><p>在flask项目中使用flask-material，首先需要在主程序的<code>__init__.py</code>中初始化插件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask_material <span class="keyword">import</span> Material</span><br><span class="line"></span><br><span class="line">material - Material()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_app</span><span class="params">(config_name)</span>:</span></span><br><span class="line">    app = Flask(__name__)</span><br><span class="line">    app.config.from_object(config[config_name])</span><br><span class="line">    config[config_name].init_app(app)</span><br><span class="line">    material.init_app(app)</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p><p>强制调用本地的<code>css</code>和<code>js</code>，还需要修改<code>config.py</code>配置文件：<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">class</span> <span class="attr">Config:</span></span><br><span class="line">    <span class="string">MATERIAL_SERVE_LOCAL</span> <span class="string">=</span> <span class="literal">True</span></span><br><span class="line">    <span class="string">MATERIAL_QUERYSTRING_REVVING</span> <span class="string">=</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure></p><p>注意一定要添加<code>MATERIAL_QUERYSTRING_REVVING = False</code>配置行，否则程序会报错。配置完之后只要在<code>html</code>模板文件开头添加<code>{ % extends &quot;material/base.html&quot; % }</code>，就能够调用MaterializeCSS的<code>css</code>和<code>js</code>：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;link <span class="attribute">href</span>=<span class="string">"/static/material/css/materialize.min.css"</span> <span class="attribute">rel</span>=<span class="string">"stylesheet"</span> <span class="attribute">media</span>=<span class="string">"screen"</span>&gt;</span><br><span class="line">&lt;script <span class="attribute">src</span>=<span class="string">"/static/material/js/jquery.min.js"</span>&gt;&lt;/script&gt;</span><br><span class="line">&lt;script <span class="attribute">src</span>=<span class="string">"/static/material/js/materialize.min.js"</span>&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure></p><h3 id="2-3-Using-Material-Icons"><a href="#2-3-Using-Material-Icons" class="headerlink" title="2.3 Using Material Icons"></a>2.3 Using Material Icons</h3><p>良心Google将900+ <a href="https://github.com/google/material-design-icons" target="_blank" rel="noopener">Material Icon</a>全部开源，包括共Web使用的Icon font、SVG和PNG文件。因为自带被墙属性，所以不推荐在应用里tongguoCDN的方式引用Icon font（<code>&lt;link href=&quot;https://fonts.googleapis.com/icon?family=Material+Icons&quot; rel=&quot;stylesheet&quot;&gt;</code>）。我们需要将Icon Font下载到本地。<br>下载<a href="https://github.com/google/material-design-icons/tree/master/iconfont" target="_blank" rel="noopener">icon font</a>下的所有文件，到项目的<code>static/font</code>目录中，然后再<code>base.html</code>中添加相应的css引用即可：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;link <span class="attribute">rel</span>=<span class="string">"stylesheet"</span> <span class="attribute">type</span>=<span class="string">"text/css"</span> <span class="attribute">href</span>=<span class="string">"&#123;&#123; url_for('static', filename='font/material-icons.css') &#125;&#125;"</span>&gt;</span><br></pre></td></tr></table></figure></p><p>在<code>html</code>中就可以渲染icon了：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"material-icons"</span>&gt;</span>face<span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>你也可以给icons添加更多辅助样式，比如大小和颜色等：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Rules for sizing the icon. */</span></span><br><span class="line"><span class="selector-class">.material-icons</span><span class="selector-class">.md-18</span> &#123; <span class="attribute">font-size</span>: <span class="number">18px</span>; &#125;</span><br><span class="line"><span class="selector-class">.material-icons</span><span class="selector-class">.md-24</span> &#123; <span class="attribute">font-size</span>: <span class="number">24px</span>; &#125;</span><br><span class="line"><span class="selector-class">.material-icons</span><span class="selector-class">.md-36</span> &#123; <span class="attribute">font-size</span>: <span class="number">36px</span>; &#125;</span><br><span class="line"><span class="selector-class">.material-icons</span><span class="selector-class">.md-48</span> &#123; <span class="attribute">font-size</span>: <span class="number">48px</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Rules for using icons as black on a light background. */</span></span><br><span class="line"><span class="selector-class">.material-icons</span><span class="selector-class">.md-dark</span> &#123; <span class="attribute">color</span>: <span class="built_in">rgba</span>(0, 0, 0, 0.54); &#125;</span><br><span class="line"><span class="selector-class">.material-icons</span><span class="selector-class">.md-dark</span><span class="selector-class">.md-inactive</span> &#123; <span class="attribute">color</span>: <span class="built_in">rgba</span>(0, 0, 0, 0.26); &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Rules for using icons as white on a dark background. */</span></span><br><span class="line"><span class="selector-class">.material-icons</span><span class="selector-class">.md-light</span> &#123; <span class="attribute">color</span>: <span class="built_in">rgba</span>(255, 255, 255, 1); &#125;</span><br><span class="line"><span class="selector-class">.material-icons</span><span class="selector-class">.md-light</span><span class="selector-class">.md-inactive</span> &#123; <span class="attribute">color</span>: <span class="built_in">rgba</span>(255, 255, 255, 0.3); &#125;</span><br></pre></td></tr></table></figure></p><p>具体可参见<a href="https://google.github.io/material-design-icons/" target="_blank" rel="noopener">material design icons/</a>。</p><h3 id="2-4-Basic-Layout"><a href="#2-4-Basic-Layout" class="headerlink" title="2.4 Basic Layout"></a>2.4 Basic Layout</h3><figure class="highlight django"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml">&#123; % extends "material/base.html" % &#125;</span></span><br><span class="line"><span class="xml"></span><span class="template-tag">&#123;% <span class="name">import</span> "material/utils.html" <span class="keyword">as</span> util %&#125;</span><span class="xml"></span></span><br><span class="line"><span class="xml"></span><span class="template-tag">&#123;% <span class="name">import</span> "material/wtf.html" <span class="keyword">as</span> wtf %&#125;</span><span class="xml"></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml"></span><span class="template-tag">&#123;% <span class="name"><span class="name">block</span></span> title %&#125;</span><span class="xml">Hello, world!</span><span class="template-tag">&#123;% <span class="name"><span class="name">endblock</span></span> %&#125;</span><span class="xml"></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml"></span><span class="template-tag">&#123;% <span class="name"><span class="name">block</span></span> content %&#125;</span><span class="xml"></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"container"</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"row"</span>&gt;</span></span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"col s12 m6"</span>&gt;</span></span></span><br><span class="line"><span class="xml">                    </span><span class="template-variable">&#123;&#123; util.card('Hello world!', wtf.quick_form(form) )&#125;&#125;</span><span class="xml"></span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"col s12 m6"</span>&gt;</span></span></span><br><span class="line"><span class="xml">                    </span><span class="template-variable">&#123;&#123; util.card('Isn\'t Flask great?', '&lt;p&gt;I really do enjoy it!&lt;/p&gt;', [['https://github.com/HellerCommaA', 'My Github']])&#125;&#125;</span><span class="xml"></span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span><span class="template-tag">&#123;% <span class="name"><span class="name">endblock</span></span> %&#125;</span><span class="xml"></span></span><br></pre></td></tr></table></figure><p>由于flask-material模板使用的说明文档不全，而且已经跟久没有更新，与MaterializeCSS相差已经非常大了，因此强烈建议迁移到最新的MaterializeCSS。</p><h2 id="3-MaterializeCSS"><a href="#3-MaterializeCSS" class="headerlink" title="3 MaterializeCSS"></a>3 MaterializeCSS</h2><h3 id="3-1-Update-CSS-and-JS"><a href="#3-1-Update-CSS-and-JS" class="headerlink" title="3.1 Update CSS and JS"></a>3.1 Update CSS and JS</h3><p>MaterializeCSS对于各种Components的使用都有详细的案例，因此可以在原先falsk-material的基础上，将CSS和JS文件替换掉。从<a href="http://materializecss.com/bin/materialize-v0.97.8.zip" target="_blank" rel="noopener">这里</a>下载获取最新的zip包，将包中的css、fonts、js文件夹尽数复制到<code>%project_dir%\venv\Lib\site-packages\flask_material\static</code>目录下，覆盖即可。</p><h3 id="3-2-Color"><a href="#3-2-Color" class="headerlink" title="3.2 Color"></a>3.2 Color</h3><p><a href="http://materializecss.com/color.html" target="_blank" rel="noopener">http://materializecss.com/color.html</a></p><h3 id="3-3-Grid"><a href="#3-3-Grid" class="headerlink" title="3.3 Grid"></a>3.3 Grid</h3><p><a href="http://materializecss.com/grid.html" target="_blank" rel="noopener">http://materializecss.com/grid.html</a></p><h3 id="3-4-Helpers"><a href="#3-4-Helpers" class="headerlink" title="3.4 Helpers"></a>3.4 Helpers</h3><p><a href="http://materializecss.com/helpers.html" target="_blank" rel="noopener">http://materializecss.com/helpers.html</a></p><h3 id="3-5-Media"><a href="#3-5-Media" class="headerlink" title="3.5 Media"></a>3.5 Media</h3><p><a href="http://materializecss.com/media-css.html" target="_blank" rel="noopener">http://materializecss.com/media-css.html</a></p><h3 id="3-6-Shadow"><a href="#3-6-Shadow" class="headerlink" title="3.6 Shadow"></a>3.6 Shadow</h3><p><a href="http://materializecss.com/shadow.html" target="_blank" rel="noopener">http://materializecss.com/shadow.html</a></p><h3 id="3-7-Table"><a href="#3-7-Table" class="headerlink" title="3.7 Table"></a>3.7 Table</h3><p><a href="http://materializecss.com/table.html" target="_blank" rel="noopener">http://materializecss.com/table.html</a></p><h3 id="3-8-Typography"><a href="#3-8-Typography" class="headerlink" title="3.8 Typography"></a>3.8 Typography</h3><p><a href="http://materializecss.com/typography.html" target="_blank" rel="noopener">http://materializecss.com/typography.html</a></p><h3 id="3-9-Badges"><a href="#3-9-Badges" class="headerlink" title="3.9 Badges"></a>3.9 Badges</h3><p><a href="http://materializecss.com/badges.html" target="_blank" rel="noopener">http://materializecss.com/badges.html</a></p><h3 id="3-10-Buttons"><a href="#3-10-Buttons" class="headerlink" title="3.10 Buttons"></a>3.10 Buttons</h3><p><a href="http://materializecss.com/buttons.html" target="_blank" rel="noopener">http://materializecss.com/buttons.html</a></p><h3 id="3-11-Cards"><a href="#3-11-Cards" class="headerlink" title="3.11 Cards"></a>3.11 Cards</h3><p><a href="http://materializecss.com/chips.html" target="_blank" rel="noopener">http://materializecss.com/chips.html</a></p><h3 id="3-12-Collections"><a href="#3-12-Collections" class="headerlink" title="3.12 Collections"></a>3.12 Collections</h3><p><a href="http://materializecss.com/collections.html" target="_blank" rel="noopener">http://materializecss.com/collections.html</a></p><h3 id="3-13-Footer"><a href="#3-13-Footer" class="headerlink" title="3.13 Footer"></a>3.13 Footer</h3><p><a href="http://materializecss.com/footer.html" target="_blank" rel="noopener">http://materializecss.com/footer.html</a></p><h3 id="3-14-Forms"><a href="#3-14-Forms" class="headerlink" title="3.14 Forms"></a>3.14 Forms</h3><p><a href="http://materializecss.com/forms.html" target="_blank" rel="noopener">http://materializecss.com/forms.html</a></p><h3 id="3-15-Navbar"><a href="#3-15-Navbar" class="headerlink" title="3.15 Navbar"></a>3.15 Navbar</h3><p><a href="http://materializecss.com/navbar.html" target="_blank" rel="noopener">http://materializecss.com/navbar.html</a></p><h3 id="3-16-Pagination"><a href="#3-16-Pagination" class="headerlink" title="3.16 Pagination"></a>3.16 Pagination</h3><p><a href="http://materializecss.com/pagination.html" target="_blank" rel="noopener">http://materializecss.com/pagination.html</a></p><h3 id="3-17-Preloader"><a href="#3-17-Preloader" class="headerlink" title="3.17 Preloader"></a>3.17 Preloader</h3><p><a href="http://materializecss.com/preloader.html" target="_blank" rel="noopener">http://materializecss.com/preloader.html</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-About-Meterial-Design&quot;&gt;&lt;a href=&quot;#1-About-Meterial-Design&quot; class=&quot;headerlink&quot; title=&quot;1 About Meterial Design&quot;&gt;&lt;/a&gt;1 About Meterial </summary>
      
    
    
    
    
    <category term="CSS" scheme="http://gloomymoon.github.io/tags/CSS/"/>
    
    <category term="Material Design" scheme="http://gloomymoon.github.io/tags/Material-Design/"/>
    
  </entry>
  
  <entry>
    <title>Using PostgreSQL for Flask</title>
    <link href="http://gloomymoon.github.io/2016/11/25/Using-PostgreSQL-for-Flask/"/>
    <id>http://gloomymoon.github.io/2016/11/25/Using-PostgreSQL-for-Flask/</id>
    <published>2016-11-25T12:28:26.000Z</published>
    <updated>2016-11-25T12:29:35.384Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-安装PostgreSQL"><a href="#1-安装PostgreSQL" class="headerlink" title="1 安装PostgreSQL"></a>1 安装PostgreSQL</h2><p>从官网下载windows install，直接安装，默认用户为postgres，密码一定需要设置。<br>在pgAdmin中新建数据库StudiousPrime</p><h2 id="2-安装Python驱动"><a href="#2-安装Python驱动" class="headerlink" title="2 安装Python驱动"></a>2 安装Python驱动</h2><p>从<a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#psycopg" target="_blank" rel="noopener">Unofficial Windows Binaries for Python Extension Packages</a>下载预编译好的<code>psycopg2-2.6.2-cp27-cp27m-win32.whl</code>包，通过<code>pip</code>安装。</p><p>正常情况下安装成功（windows server 2008 64bit、Python 2.7.10 32bi、非virtualenv、已预装PostgreSQL）<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">Processing</span> <span class="selector-tag">d</span>:\<span class="selector-tag">tools</span>\<span class="selector-tag">python</span>\<span class="selector-tag">psycopg2-2</span><span class="selector-class">.6</span><span class="selector-class">.2-cp27-cp27m-win32</span><span class="selector-class">.whl</span></span><br><span class="line"><span class="selector-tag">Installing</span> <span class="selector-tag">collected</span> <span class="selector-tag">packages</span>: <span class="selector-tag">psycopg2</span></span><br><span class="line"><span class="selector-tag">Successfully</span> <span class="selector-tag">installed</span> <span class="selector-tag">psycopg2-2</span><span class="selector-class">.6</span><span class="selector-class">.2</span></span><br></pre></td></tr></table></figure></p><p>但是在开发笔记本（windows 7 32bit、Python 2.7.9 32bit、virtualenv环境）上安装出现如下错误：<code>UnsupportedWheel: psycopg2-2.6.2-cp27-cp27m-win32.whl is not a supported wheel on this platform.</code></p><p>开始怀疑是没有安装PostgreSQL，但是安装完后依然出现上述错误。<br>通过搜索后，从<a href="http://www.stickpeople.com/projects/python/win-psycopg/" target="_blank" rel="noopener">http://www.stickpeople.com/projects/python/win-psycopg/</a>下载<code>psycopg2-2.6.2.win32-py2.7-pg9.5.3-release.exe</code>，然后使用easy_install安装成功。也可以使用<a href="https://github.com/nwcell/psycopg2-windows" target="_blank" rel="noopener">https://github.com/nwcell/psycopg2-windows</a>介绍的方式使用pip在virtualenv下安装。</p><h2 id="3-配置Flask"><a href="#3-配置Flask" class="headerlink" title="3 配置Flask"></a>3 配置Flask</h2><p>在<code>config.py</code>中，将<code>SQLALCHEMY_DATABASE_URI</code>修改为PostgreSQL的地址，替换其中的<code>username</code>（默认为postgres）和<code>password</code>，<code>host</code>为数据库IP或域名。：<br><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">postgresql:</span><span class="comment">//username:password@host/StudiousPrime</span></span><br></pre></td></tr></table></figure></p><p>Flask重启后，连接数据库出现如下错误：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">org<span class="selector-class">.postgresql</span><span class="selector-class">.util</span><span class="selector-class">.PSQLException</span>: FATAL: no pg_hba<span class="selector-class">.conf</span> entry <span class="keyword">for</span> host</span><br></pre></td></tr></table></figure></p><p>搜索问题后发现是因为PostgreSQL数据库为了安全，默认只会监听本地的连接请求，而我是访问服务器上的数据库。要解决这个问题，需要在服务器端PostgreSQL安装目录下找到<code>\data\pg_hba.conf</code>文件，打开找到其中<code># IPv4 local connections:</code>段，添加请求连接机器的IP。<br><figure class="highlight q"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># IPv4 local connections:</span><br><span class="line">host    <span class="built_in">all</span>             <span class="built_in">all</span>             <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>/<span class="number">32</span>            <span class="built_in">md5</span></span><br><span class="line">host    <span class="built_in">all</span>             <span class="built_in">all</span>             请求连接机器的IP/<span class="number">32</span>        <span class="built_in">md5</span></span><br></pre></td></tr></table></figure></p><p>在pgAdmin中<code>Reload Configuration</code>后，客户端就能顺利连接服务器上数据库了，剩下的工作就和SQLite一样交给SQLAlchemy就好。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-安装PostgreSQL&quot;&gt;&lt;a href=&quot;#1-安装PostgreSQL&quot; class=&quot;headerlink&quot; title=&quot;1 安装PostgreSQL&quot;&gt;&lt;/a&gt;1 安装PostgreSQL&lt;/h2&gt;&lt;p&gt;从官网下载windows install，直</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="PostgreSQL" scheme="http://gloomymoon.github.io/tags/PostgreSQL/"/>
    
  </entry>
  
  <entry>
    <title>Python for Data Analysis IV</title>
    <link href="http://gloomymoon.github.io/2016/11/23/Python-for-Data-Analysis-IV/"/>
    <id>http://gloomymoon.github.io/2016/11/23/Python-for-Data-Analysis-IV/</id>
    <published>2016-11-23T12:02:41.000Z</published>
    <updated>2016-12-27T11:48:21.293Z</updated>
    
    <content type="html"><![CDATA[<h2 id="7-数据规整化：清理、转换、合并、重塑"><a href="#7-数据规整化：清理、转换、合并、重塑" class="headerlink" title="7 数据规整化：清理、转换、合并、重塑"></a>7 数据规整化：清理、转换、合并、重塑</h2><p>数据分析和建模工作中大量的编程使用在数据准备上的：加载、清洗、转换以及重塑，大部分情况下存放在文本或数据库中的数据并不能满足应用的要求，幸运的是，pandas和Python标准库提供了一组高级、灵活、高效的核心函数和算法，使你能够轻松操作数据。</p><h3 id="7-1-合并数据集"><a href="#7-1-合并数据集" class="headerlink" title="7.1 合并数据集"></a>7.1 合并数据集</h3><ul><li><code>pandas.merge</code>可以根据一个或多个键将不同的DataFrame中的行连接起来，类似于SQL中的<code>join</code>操作。</li><li><code>pandas.concat</code>可以沿一条轴将多个对象堆叠到一起，，类似于SQL中的<code>union all</code>。</li><li>实例方法<code>combine_first</code>可以将重复数据编制在一起，用一个对象中的值填充另一个对象中的缺失值。</li></ul><p><strong>数据库风格的DataFrame合并</strong><br><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df1 = DataFrame(&#123;<span class="symbol">'key</span>': [<span class="string">'b'</span>,<span class="string">'b'</span>,<span class="string">'a'</span>,<span class="string">'c'</span>,<span class="string">'a'</span>,<span class="string">'a'</span>,<span class="string">'a'</span>], <span class="symbol">'data1</span>':<span class="keyword">range</span>(<span class="number">7</span>)&#125;)</span><br><span class="line">df2 = DataFrame(&#123;<span class="symbol">'key</span>': [<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'d'</span>], <span class="symbol">'data2</span>':<span class="keyword">range</span>(<span class="number">3</span>)&#125;)</span><br><span class="line">df1</span><br><span class="line">df2</span><br><span class="line">pd.merge(df1, df2)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> data1 <span class="type">key</span></span><br><span class="line"><span class="number">0</span> <span class="number">0</span> b</span><br><span class="line"><span class="number">1</span> <span class="number">1</span> b</span><br><span class="line"><span class="number">2</span> <span class="number">2</span> a</span><br><span class="line"><span class="number">3</span> <span class="number">3</span> c</span><br><span class="line"><span class="number">4</span> <span class="number">4</span> a</span><br><span class="line"><span class="number">5</span> <span class="number">5</span> a</span><br><span class="line"><span class="number">6</span> <span class="number">6</span> b</span><br><span class="line"></span><br><span class="line"> data2 <span class="type">key</span></span><br><span class="line"><span class="number">0</span> <span class="number">0</span> a</span><br><span class="line"><span class="number">1</span> <span class="number">1</span> b</span><br><span class="line"><span class="number">2</span> <span class="number">2</span> d</span><br><span class="line"></span><br><span class="line"> data1 <span class="type">key</span> data2</span><br><span class="line"><span class="number">0</span> <span class="number">0</span> b <span class="number">1</span></span><br><span class="line"><span class="number">1</span> <span class="number">1</span> b <span class="number">1</span></span><br><span class="line"><span class="number">2</span> <span class="number">6</span> b <span class="number">1</span></span><br><span class="line"><span class="number">3</span> <span class="number">2</span> a <span class="number">0</span></span><br><span class="line"><span class="number">4</span> <span class="number">4</span> a <span class="number">0</span></span><br><span class="line"><span class="number">5</span> <span class="number">5</span> a <span class="number">0</span></span><br></pre></td></tr></table></figure></p><p>由于没有指定用那个列进行连接，<code>merge</code>会将重叠的列名当作键，因此最好是显示指定连接的键。<br><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.<span class="built_in">merge</span>(df1, df2, <span class="keyword">on</span>=<span class="string">'key'</span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> data1 <span class="type">key</span> data2</span><br><span class="line"><span class="number">0</span> <span class="number">0</span> b <span class="number">1</span></span><br><span class="line"><span class="number">1</span> <span class="number">1</span> b <span class="number">1</span></span><br><span class="line"><span class="number">2</span> <span class="number">6</span> b <span class="number">1</span></span><br><span class="line"><span class="number">3</span> <span class="number">2</span> a <span class="number">0</span></span><br><span class="line"><span class="number">4</span> <span class="number">4</span> a <span class="number">0</span></span><br><span class="line"><span class="number">5</span> <span class="number">5</span> a <span class="number">0</span></span><br></pre></td></tr></table></figure></p><p>如果两个对象的列名不同，也可以分别进行指定<br><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df3 = DataFrame(&#123;<span class="symbol">'lkey</span>': [<span class="string">'b'</span>,<span class="string">'b'</span>,<span class="string">'a'</span>,<span class="string">'c'</span>,<span class="string">'a'</span>,<span class="string">'a'</span>,<span class="string">'b'</span>], <span class="symbol">'data1</span>':<span class="keyword">range</span>(<span class="number">7</span>)&#125;)</span><br><span class="line">df4 = DataFrame(&#123;<span class="symbol">'rkey</span>': [<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'d'</span>], <span class="symbol">'data2</span>':<span class="keyword">range</span>(<span class="number">3</span>)&#125;)</span><br><span class="line">pd.merge(df3, df4, left_on=<span class="symbol">'lkey</span>', right_on=<span class="symbol">'rkey</span>')</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> data1 lkey data2 rkey</span><br><span class="line"><span class="number">0</span> <span class="number">0</span> <span class="selector-tag">b</span> <span class="number">1</span> b</span><br><span class="line"><span class="number">1</span> <span class="number">1</span> <span class="selector-tag">b</span> <span class="number">1</span> b</span><br><span class="line"><span class="number">2</span> <span class="number">6</span> <span class="selector-tag">b</span> <span class="number">1</span> b</span><br><span class="line"><span class="number">3</span> <span class="number">2</span> <span class="selector-tag">a</span> <span class="number">0</span> a</span><br><span class="line"><span class="number">4</span> <span class="number">4</span> <span class="selector-tag">a</span> <span class="number">0</span> a</span><br><span class="line"><span class="number">5</span> <span class="number">5</span> <span class="selector-tag">a</span> <span class="number">0</span> a</span><br></pre></td></tr></table></figure></p><p><code>merge</code>方法默认情况下进行<code>inner</code>链接，结果中的键是交集。可以在参数中指定其他连接方式：<code>left</code>、<code>right</code>、<code>outer</code>。多对多的合并操作无需额外的参数和工作，产生的是行的笛卡儿积。。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(df1, df2, <span class="attribute">how</span>=<span class="string">'outer'</span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> data1 <span class="type">key</span> data2</span><br><span class="line"><span class="number">0</span> <span class="number">0</span> b <span class="number">1</span></span><br><span class="line"><span class="number">1</span> <span class="number">1</span> b <span class="number">1</span></span><br><span class="line"><span class="number">2</span> <span class="number">6</span> b <span class="number">1</span></span><br><span class="line"><span class="number">3</span> <span class="number">2</span> a <span class="number">0</span></span><br><span class="line"><span class="number">4</span> <span class="number">4</span> a <span class="number">0</span></span><br><span class="line"><span class="number">5</span> <span class="number">5</span> a <span class="number">0</span></span><br><span class="line"><span class="number">6</span> <span class="number">3</span> c NaN</span><br><span class="line"><span class="number">7</span> NaN d <span class="number">2</span></span><br></pre></td></tr></table></figure></p><p>要根据多个键进行合并，传入一个由列名组成的列表即可。<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">left = <span class="symbol">DataFrame</span>(&#123;<span class="string">'key1'</span>: [<span class="string">'foo'</span>, <span class="string">'foo'</span>, <span class="string">'bar'</span>],</span><br><span class="line">                  <span class="string">'key2'</span>: [<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'one'</span>],</span><br><span class="line">                  <span class="string">'lval'</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]&#125;)</span><br><span class="line">right = <span class="symbol">DataFrame</span>(&#123;<span class="string">'key1'</span>: [<span class="string">'foo'</span>, <span class="string">'foo'</span>, <span class="string">'bar'</span>, <span class="string">'bar'</span>],</span><br><span class="line">                   <span class="string">'key2'</span>: [<span class="string">'one'</span>, <span class="string">'one'</span>, <span class="string">'one'</span>, <span class="string">'two'</span>],</span><br><span class="line">                   <span class="string">'rval'</span>: [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]&#125;)</span><br><span class="line">pd.merge(left, right, on=[<span class="string">'key1'</span>, <span class="string">'key2'</span>], how=<span class="string">'outer'</span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">key1key2lvalrval</span><br><span class="line"><span class="number">0</span>fooone<span class="number">1.0</span><span class="number">4.0</span></span><br><span class="line"><span class="number">1</span>fooone<span class="number">1.0</span><span class="number">5.0</span></span><br><span class="line"><span class="number">2</span>footwo<span class="number">2.0</span>NaN</span><br><span class="line"><span class="number">3</span>barone<span class="number">3.0</span><span class="number">6.0</span></span><br><span class="line"><span class="number">4</span>bartwoNaN<span class="number">7.0</span></span><br></pre></td></tr></table></figure></p><p>注意进行merge时，DataFrame对象中的索引会被丢弃。<br>合并运算还需要考虑重复列名的处理，虽然可以手工处理列名重叠的问题（例如重命名轴标签），但是merge有一个更实用的suffixes选项，用于指定添加在左右两个DataFrame对象重叠列名上的字符串。<br><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.<span class="built_in">merge</span>(left, <span class="literal">right</span>, <span class="keyword">on</span>=<span class="string">'key1'</span>, <span class="title">suffixes</span>=(<span class="string">'_left'</span>, <span class="string">'_right'</span>))</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">key1key2_leftlvalkey2_rightrval</span><br><span class="line"><span class="number">0</span>fooone<span class="number">1</span>one<span class="number">4</span></span><br><span class="line"><span class="number">1</span>fooone<span class="number">1</span>one<span class="number">5</span></span><br><span class="line"><span class="number">2</span>footwo<span class="number">2</span>one<span class="number">4</span></span><br><span class="line"><span class="number">3</span>footwo<span class="number">2</span>one<span class="number">5</span></span><br><span class="line"><span class="number">4</span>barone<span class="number">3</span>one<span class="number">6</span></span><br><span class="line"><span class="number">5</span>barone<span class="number">3</span>two<span class="number">7</span></span><br></pre></td></tr></table></figure></p><p><strong>索引上的合并</strong><br>有时候，DataFrame中的连接键位于其索引中，可以传入left_index=True或right_index=True指明索引应该被用作连接键。<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">left1 = <span class="symbol">DataFrame</span>(&#123;<span class="string">'key'</span>: [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'a'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>],</span><br><span class="line">                  <span class="string">'value'</span>: range(<span class="number">6</span>)&#125;)</span><br><span class="line">right1 = <span class="symbol">DataFrame</span>(&#123;<span class="string">'group_val'</span>: [<span class="number">3.5</span>, <span class="number">7</span>]&#125;, index=[<span class="string">'a'</span>, <span class="string">'b'</span>])</span><br><span class="line">pd.merge(left1, right1, left_on=<span class="string">'key'</span>, right_index=<span class="symbol">True</span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">key</span>valuegroup_val</span><br><span class="line"><span class="number">0</span>a<span class="number">0</span><span class="number">3.5</span></span><br><span class="line"><span class="number">2</span>a<span class="number">2</span><span class="number">3.5</span></span><br><span class="line"><span class="number">3</span>a<span class="number">3</span><span class="number">3.5</span></span><br><span class="line"><span class="number">1</span>b<span class="number">1</span><span class="number">7.0</span></span><br><span class="line"><span class="number">4</span>b<span class="number">4</span><span class="number">7.0</span></span><br></pre></td></tr></table></figure></p><p>由于merge默认是求取连接键的交集，可以通过外连接的方式得到它们的并集。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(left1, right1, <span class="attribute">left_on</span>=<span class="string">'key'</span>, <span class="attribute">right_index</span>=<span class="literal">True</span>, <span class="attribute">how</span>=<span class="string">'outer'</span>)</span><br></pre></td></tr></table></figure></p><p>对于层次化索引的数据，处理起来需要以列表的形式指明用作合并键的多个列。<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lefth = <span class="symbol">DataFrame</span>(&#123;<span class="string">'key1'</span>: [<span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Nevada'</span>, <span class="string">'Nevada'</span>], <span class="string">'key2'</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>], <span class="string">'data'</span>: np.arange(<span class="number">5.</span>)&#125;)</span><br><span class="line">righth = <span class="symbol">DataFrame</span>(np.arange(<span class="number">12</span>).reshape((<span class="number">6</span>, <span class="number">2</span>)), index=[[<span class="string">'Nevada'</span>, <span class="string">'Nevada'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>], [<span class="number">2001</span>, <span class="number">2000</span>, <span class="number">2000</span>, <span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>]], columns=[<span class="string">'event1'</span>, <span class="string">'event2'</span>])</span><br><span class="line"></span><br><span class="line">pd.merge(lefth, righth, left_on=[<span class="string">'key1'</span>, <span class="string">'key2'</span>], right_index=<span class="symbol">True</span>)</span><br><span class="line"></span><br><span class="line">pd.merge(lefth, righth, left_on=[<span class="string">'key1'</span>, <span class="string">'key2'</span>],</span><br><span class="line">         right_index=<span class="symbol">True</span>, how=<span class="string">'outer'</span>)</span><br></pre></td></tr></table></figure></p><p>Output:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">datakey1key2event1event2</span><br><span class="line"><span class="number">0</span><span class="number">0.0</span>Ohio<span class="number">2000</span><span class="number">4</span><span class="number">5</span></span><br><span class="line"><span class="number">0</span><span class="number">0.0</span>Ohio<span class="number">2000</span><span class="number">6</span><span class="number">7</span></span><br><span class="line"><span class="number">1</span><span class="number">1.0</span>Ohio<span class="number">2001</span><span class="number">8</span><span class="number">9</span></span><br><span class="line"><span class="number">2</span><span class="number">2.0</span>Ohio<span class="number">2002</span><span class="number">10</span><span class="number">11</span></span><br><span class="line"><span class="number">3</span><span class="number">3.0</span>Nevada<span class="number">2001</span><span class="number">0</span><span class="number">1</span></span><br><span class="line"></span><br><span class="line">datakey1key2event1event2</span><br><span class="line"><span class="number">0</span><span class="number">0.0</span>Ohio<span class="number">2000</span><span class="number">4.0</span><span class="number">5.0</span></span><br><span class="line"><span class="number">0</span><span class="number">0.0</span>Ohio<span class="number">2000</span><span class="number">6.0</span><span class="number">7.0</span></span><br><span class="line"><span class="number">1</span><span class="number">1.0</span>Ohio<span class="number">2001</span><span class="number">8.0</span><span class="number">9.0</span></span><br><span class="line"><span class="number">2</span><span class="number">2.0</span>Ohio<span class="number">2002</span><span class="number">10.0</span><span class="number">11.0</span></span><br><span class="line"><span class="number">3</span><span class="number">3.0</span>Nevada<span class="number">2001</span><span class="number">0.0</span><span class="number">1.0</span></span><br><span class="line"><span class="number">4</span><span class="number">4.0</span>Nevada<span class="number">2002</span>NaNNaN</span><br><span class="line"><span class="number">4</span>NaNNevada<span class="number">2000</span><span class="number">2.0</span><span class="number">3.0</span></span><br></pre></td></tr></table></figure><p>DataFrame还有一个<code>join</code>实例方法，它能更方便地实现按索引合并，而且可用于合并多个带有相似索引的DataFrame对象，不管之间有没有重叠的列。</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">left2 = <span class="symbol">DataFrame</span>([[<span class="number">1.</span>, <span class="number">2.</span>], [<span class="number">3.</span>, <span class="number">4.</span>], [<span class="number">5.</span>, <span class="number">6.</span>]], index=[<span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'e'</span>], columns=[<span class="string">'Ohio'</span>, <span class="string">'Nevada'</span>])</span><br><span class="line">right2 = <span class="symbol">DataFrame</span>([[<span class="number">7.</span>, <span class="number">8.</span>], [<span class="number">9.</span>, <span class="number">10.</span>], [<span class="number">11.</span>, <span class="number">12.</span>], [<span class="number">13</span>, <span class="number">14</span>]], index=[<span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>], columns=[<span class="string">'Missouri'</span>, <span class="string">'Alabama'</span>])</span><br><span class="line"></span><br><span class="line">left2.join(right2, how=<span class="string">'outer'</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">Ohio</span><span class="selector-tag">Nevada</span><span class="selector-tag">Missouri</span><span class="selector-tag">Alabama</span></span><br><span class="line"><span class="selector-tag">a</span>1<span class="selector-class">.0</span>2<span class="selector-class">.0</span><span class="selector-tag">NaN</span><span class="selector-tag">NaN</span></span><br><span class="line"><span class="selector-tag">b</span><span class="selector-tag">NaN</span><span class="selector-tag">NaN</span>7<span class="selector-class">.0</span>8<span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">c</span>3<span class="selector-class">.0</span>4<span class="selector-class">.0</span>9<span class="selector-class">.0</span>10<span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">d</span><span class="selector-tag">NaN</span><span class="selector-tag">NaN</span>11<span class="selector-class">.0</span>12<span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">e</span>5<span class="selector-class">.0</span>6<span class="selector-class">.0</span>13<span class="selector-class">.0</span>14<span class="selector-class">.0</span></span><br></pre></td></tr></table></figure><p>与merge方法不同DataFrame的<code>join</code>方法默认实在连接键上做<strong>左连接</strong>。对于简单的索引合并，可以向<code>join</code>传入一组DataFrame（后面会介绍更为通用的<code>concat</code>函数）。</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">another = <span class="symbol">DataFrame</span>([[<span class="number">7.</span>, <span class="number">8.</span>], [<span class="number">9.</span>, <span class="number">10.</span>], [<span class="number">11.</span>, <span class="number">12.</span>], [<span class="number">16.</span>, <span class="number">17.</span>]],</span><br><span class="line">                    index=[<span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'e'</span>, <span class="string">'f'</span>], columns=[<span class="string">'New York'</span>, <span class="string">'Oregon'</span>])</span><br><span class="line">left2.join([right2, another], how=<span class="string">'outer'</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">Ohio</span><span class="selector-tag">Nevada</span><span class="selector-tag">Missouri</span><span class="selector-tag">Alabama</span><span class="selector-tag">New</span> <span class="selector-tag">York</span><span class="selector-tag">Oregon</span></span><br><span class="line"><span class="selector-tag">a</span>1<span class="selector-class">.0</span>2<span class="selector-class">.0</span><span class="selector-tag">NaN</span><span class="selector-tag">NaN</span>7<span class="selector-class">.0</span>8<span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">b</span><span class="selector-tag">NaN</span><span class="selector-tag">NaN</span>7<span class="selector-class">.0</span>8<span class="selector-class">.0</span><span class="selector-tag">NaN</span><span class="selector-tag">NaN</span></span><br><span class="line"><span class="selector-tag">c</span>3<span class="selector-class">.0</span>4<span class="selector-class">.0</span>9<span class="selector-class">.0</span>10<span class="selector-class">.0</span>9<span class="selector-class">.0</span>10<span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">d</span><span class="selector-tag">NaN</span><span class="selector-tag">NaN</span>11<span class="selector-class">.0</span>12<span class="selector-class">.0</span><span class="selector-tag">NaN</span><span class="selector-tag">NaN</span></span><br><span class="line"><span class="selector-tag">e</span>5<span class="selector-class">.0</span>6<span class="selector-class">.0</span>13<span class="selector-class">.0</span>14<span class="selector-class">.0</span>11<span class="selector-class">.0</span>12<span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">f</span><span class="selector-tag">NaN</span><span class="selector-tag">NaN</span><span class="selector-tag">NaN</span><span class="selector-tag">NaN</span>16<span class="selector-class">.0</span>17<span class="selector-class">.0</span></span><br></pre></td></tr></table></figure><p><strong>轴向连接</strong></p><p>轴向连接（concatenation）也称作绑定（binding）、堆叠（stacking），类似于SAS中的set方法。</p><p>对于pandas对象（Series和DataFrame），连接运算时还要考虑如下问题：</p><ul><li><p>如果各对象其他轴上的索引不同，那些轴应该是做并集还是交集？</p></li><li><p>结果对象中的分组需要各不相同吗？</p></li><li><p>用户连接的轴是否重要</p></li></ul><p>pandas的<code>concat</code>函数提供了一种解决这些问题的可靠连接方法。</p><p>假设有三个没有重叠索引的Series，对这些对象调用concat可以将值和索引拼接在一起：</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s1 = <span class="symbol">Series</span>([<span class="number">0</span>, <span class="number">1</span>], index=[<span class="string">'a'</span>, <span class="string">'b'</span>])</span><br><span class="line">s2 = <span class="symbol">Series</span>([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], index=[<span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>])</span><br><span class="line">s3 = <span class="symbol">Series</span>([<span class="number">5</span>, <span class="number">6</span>], index=[<span class="string">'f'</span>, <span class="string">'g'</span>])</span><br><span class="line">pd.concat([s1, s2, s3])</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">a</span>    <span class="number">0</span></span><br><span class="line"><span class="selector-tag">b</span>    <span class="number">1</span></span><br><span class="line">c    <span class="number">2</span></span><br><span class="line">d    <span class="number">3</span></span><br><span class="line">e    <span class="number">4</span></span><br><span class="line">f    <span class="number">5</span></span><br><span class="line">g    <span class="number">6</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>默认情况下，concat实在axis=0上拼接并产生一个新的Series，如果传入axis=1，则结果会变成一个DataFrame（axis=1是列），这种情况下另外一条轴上没有重叠。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pd.concat([s1, s2, s3], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">s4 = pd.concat([s1 * <span class="number">5</span>, s3])</span><br><span class="line">s4</span><br><span class="line"></span><br><span class="line">pd.concat([s1, s4], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span><span class="number">1</span><span class="number">2</span></span><br><span class="line">a<span class="number">0.0</span><span class="literal">NaN</span><span class="literal">NaN</span></span><br><span class="line">b<span class="number">1.0</span><span class="literal">NaN</span><span class="literal">NaN</span></span><br><span class="line">c<span class="literal">NaN</span><span class="number">2.0</span><span class="literal">NaN</span></span><br><span class="line">d<span class="literal">NaN</span><span class="number">3.0</span><span class="literal">NaN</span></span><br><span class="line">e<span class="literal">NaN</span><span class="number">4.0</span><span class="literal">NaN</span></span><br><span class="line">f<span class="literal">NaN</span><span class="literal">NaN</span><span class="number">5.0</span></span><br><span class="line">g<span class="literal">NaN</span><span class="literal">NaN</span><span class="number">6.0</span></span><br><span class="line"></span><br><span class="line">a    <span class="number">0</span></span><br><span class="line">b    <span class="number">5</span></span><br><span class="line">f    <span class="number">5</span></span><br><span class="line">g    <span class="number">6</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line"><span class="number">0</span><span class="number">1</span></span><br><span class="line">a<span class="number">0.0</span><span class="number">0</span></span><br><span class="line">b<span class="number">1.0</span><span class="number">5</span></span><br><span class="line">f<span class="literal">NaN</span><span class="number">5</span></span><br><span class="line">g<span class="literal">NaN</span><span class="number">6</span></span><br></pre></td></tr></table></figure><p>可以通过<code>join_axes</code>指定要在其他轴上使用的索引：</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.concat([s1, s4], axis=<span class="number">1</span>, join_axes=[[<span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'b'</span>, <span class="string">'e'</span>]])</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span><span class="number">1</span></span><br><span class="line">a<span class="number">0.0</span><span class="number">0.0</span></span><br><span class="line">cNaNNaN</span><br><span class="line">b<span class="number">1.0</span><span class="number">5.0</span></span><br><span class="line">eNaNNaN</span><br></pre></td></tr></table></figure><p>但是这样无法在结果数据中区分参与连接的片段来源，使用<code>keys</code>参数可以创建一个表明来源的索引，<code>unstack</code>方法稍后详细讲解。</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">result</span> = pd.concat([s1, s1, s3], <span class="built_in">keys</span>=[<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>])</span><br><span class="line"><span class="built_in">result</span></span><br><span class="line"><span class="built_in">result</span>.unstack()</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">one    <span class="selector-tag">a</span>    <span class="number">0</span></span><br><span class="line">       <span class="selector-tag">b</span>    <span class="number">1</span></span><br><span class="line">two    <span class="selector-tag">a</span>    <span class="number">0</span></span><br><span class="line">       <span class="selector-tag">b</span>    <span class="number">1</span></span><br><span class="line">three  f    <span class="number">5</span></span><br><span class="line">       g    <span class="number">6</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">a</span><span class="selector-tag">b</span>fg</span><br><span class="line">one<span class="number">0.0</span><span class="number">1.0</span>NaNNaN</span><br><span class="line">two<span class="number">0.0</span><span class="number">1.0</span>NaNNaN</span><br><span class="line">threeNaNNaN<span class="number">5.0</span><span class="number">6.0</span></span><br></pre></td></tr></table></figure><p>如果沿着axis=1对Series进行合并，则keys就会成为DataFrame的列头。</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.concat([s1, s2, s3], axis=<span class="number">1</span>, keys=[<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>])</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">onetwothree</span><br><span class="line">a<span class="number">0.0</span><span class="literal">NaN</span><span class="literal">NaN</span></span><br><span class="line">b<span class="number">1.0</span><span class="literal">NaN</span><span class="literal">NaN</span></span><br><span class="line">c<span class="literal">NaN</span><span class="number">2.0</span><span class="literal">NaN</span></span><br><span class="line">d<span class="literal">NaN</span><span class="number">3.0</span><span class="literal">NaN</span></span><br><span class="line">e<span class="literal">NaN</span><span class="number">4.0</span><span class="literal">NaN</span></span><br><span class="line">f<span class="literal">NaN</span><span class="literal">NaN</span><span class="number">5.0</span></span><br><span class="line">g<span class="literal">NaN</span><span class="literal">NaN</span><span class="number">6.0</span></span><br></pre></td></tr></table></figure><p>对DataFrame对象也是一样，如果传入的不是拼接的列表而是一个字典，则字典的键就会被当作keys选项的值。</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df1 = <span class="symbol">DataFrame</span>(np.arange(<span class="number">6</span>).reshape(<span class="number">3</span>, <span class="number">2</span>), index=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>],</span><br><span class="line">                columns=[<span class="string">'one'</span>, <span class="string">'two'</span>])</span><br><span class="line">df2 = <span class="symbol">DataFrame</span>(<span class="number">5</span> + np.arange(<span class="number">4</span>).reshape(<span class="number">2</span>, <span class="number">2</span>), index=[<span class="string">'a'</span>, <span class="string">'c'</span>],</span><br><span class="line">                columns=[<span class="string">'three'</span>, <span class="string">'four'</span>])</span><br><span class="line">pd.concat(&#123;<span class="string">'level1'</span>: df1, <span class="string">'level2'</span>: df2&#125;, axis=<span class="number">1</span>)</span><br><span class="line">pd.concat([df1, df2], axis=<span class="number">1</span>, keys=[<span class="string">'level1'</span>, <span class="string">'level2'</span>])</span><br></pre></td></tr></table></figure><p>Output都是:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">level1level2</span><br><span class="line">onetwothreefour</span><br><span class="line">a<span class="number">0</span><span class="number">1</span><span class="number">5.0</span><span class="number">6.0</span></span><br><span class="line">b<span class="number">2</span><span class="number">3</span>NaNNaN</span><br><span class="line">c<span class="number">4</span><span class="number">5</span><span class="number">7.0</span><span class="number">8.0</span></span><br></pre></td></tr></table></figure><p>最后一个是ignore_index=True选项，用于忽略原始数据上的行索引，产生一种range(total_length)的新索引。</p><p><strong>合并重叠数据</strong></p><p>Series和DataFrame有一个<code>combine_first</code>方法，可以用参数对象中的数据为调用者对象的缺失数据“打补丁”。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;7-数据规整化：清理、转换、合并、重塑&quot;&gt;&lt;a href=&quot;#7-数据规整化：清理、转换、合并、重塑&quot; class=&quot;headerlink&quot; title=&quot;7 数据规整化：清理、转换、合并、重塑&quot;&gt;&lt;/a&gt;7 数据规整化：清理、转换、合并、重塑&lt;/h2&gt;&lt;p&gt;数据</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Data Analysis" scheme="http://gloomymoon.github.io/tags/Data-Analysis/"/>
    
    <category term="pandas" scheme="http://gloomymoon.github.io/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>Python for Data Analysis III</title>
    <link href="http://gloomymoon.github.io/2016/11/16/Python-for-Data-Analysis-III/"/>
    <id>http://gloomymoon.github.io/2016/11/16/Python-for-Data-Analysis-III/</id>
    <published>2016-11-16T11:26:23.000Z</published>
    <updated>2016-11-23T11:19:53.684Z</updated>
    
    <content type="html"><![CDATA[<h2 id="6-数据加载、存储与文件格式"><a href="#6-数据加载、存储与文件格式" class="headerlink" title="6 数据加载、存储与文件格式"></a>6 数据加载、存储与文件格式</h2><h3 id="6-1-读写文本格式的数据"><a href="#6-1-读写文本格式的数据" class="headerlink" title="6.1 读写文本格式的数据"></a>6.1 读写文本格式的数据</h3><p>pandas提供了一些从文本都去为DataFrame对象的函数，常用的包括<code>read_csv</code>或<code>read_table</code>。<br><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv('..<span class="symbol">\\</span>..<span class="symbol">\\</span>public<span class="symbol">\\</span>pydata-book-master<span class="symbol">\\</span>ch06<span class="symbol">\\</span>ex1.csv')</span><br><span class="line">df</span><br><span class="line">pd.read_table('..<span class="symbol">\\</span>..<span class="symbol">\\</span>public<span class="symbol">\\</span>pydata-book-master<span class="symbol">\\</span>ch06<span class="symbol">\\</span>ex1.csv')</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a b c d message</span><br><span class="line"><span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> hello</span><br><span class="line"><span class="number">1</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span> world</span><br><span class="line"><span class="number">2</span> <span class="number">9</span> <span class="number">10</span> <span class="number">11</span> <span class="number">12</span> foo</span><br></pre></td></tr></table></figure></p><p>对于没有标题行的数据文件可以设置<code>header=None</code>参数分配默认列名，或通过<code>names</code>参数自定义列名。另外<code>index_col</code>参数可以将制定的数据列做成DataFrame的索引。<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">names</span> = [<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>,<span class="string">'message'</span>]</span><br><span class="line">pd.read_csv(<span class="string">'..\\..\\public\\pydata-book-master\\ch06\\ex2.csv'</span>, names=names, index_col=<span class="string">'message'</span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> a b c d</span><br><span class="line">message </span><br><span class="line">hello <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span></span><br><span class="line">world <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span></span><br><span class="line">foo <span class="number">9</span> <span class="number">10</span> <span class="number">11</span> <span class="number">12</span></span><br></pre></td></tr></table></figure></p><p>另外pandas在导入时还能够通过正则表达式处理异性结构文件和特定分隔符导入，针对缺失值的标记NA，这些在实际使用时不太会碰到，因此可以碰到时在研究解决方案。</p><p><strong>逐块读取文本文件</strong><br>如果只读取几行或逐行读取，可以设置<code>nrows</code>参数或<code>chunksize</code>（行数）参数。<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pd.read_csv(<span class="string">"..<span class="subst">\\</span>..<span class="subst">\\</span>public<span class="subst">\\</span>pydata-book-master<span class="subst">\\</span>ch06<span class="subst">\\</span>ex6.csv"</span>, nrows=<span class="number">5</span>)</span><br><span class="line">chunker = pd.read_csv(<span class="string">"..<span class="subst">\\</span>..<span class="subst">\\</span>public<span class="subst">\\</span>pydata-book-master<span class="subst">\\</span>ch06<span class="subst">\\</span>ex6.csv"</span>, chunksize=<span class="number">1000</span>)</span><br><span class="line">chunker</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> one two three four <span class="type">key</span></span><br><span class="line"><span class="number">0</span> <span class="number">0.467976</span> <span class="number">-0.038649</span> <span class="number">-0.295344</span> <span class="number">-1.824726</span> L</span><br><span class="line"><span class="number">1</span> <span class="number">-0.358893</span> <span class="number">1.404453</span> <span class="number">0.704965</span> <span class="number">-0.200638</span> B</span><br><span class="line"><span class="number">2</span> <span class="number">-0.501840</span> <span class="number">0.659254</span> <span class="number">-0.421691</span> <span class="number">-0.057688</span> G</span><br><span class="line"><span class="number">3</span> <span class="number">0.204886</span> <span class="number">1.074134</span> <span class="number">1.388361</span> <span class="number">-0.982404</span> R</span><br><span class="line"><span class="number">4</span> <span class="number">0.354628</span> <span class="number">-0.133116</span> <span class="number">0.283763</span> <span class="number">-0.837063</span> Q</span><br><span class="line"></span><br><span class="line">&lt;pandas.io.parsers.TextFileReader at <span class="number">0x6afca70</span>&gt;</span><br></pre></td></tr></table></figure></p><p><code>read_csv</code>返回的这个<code>TextFileReader</code>对象可以根据chunksize的大小对文件进行逐块迭代，例如说需要对<code>ex6.csv</code>数据聚合到<code>key</code>列，可以如下编码：<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tot</span> = Series([])</span><br><span class="line">for piece <span class="keyword">in</span> chunker:</span><br><span class="line">    <span class="attr">tot</span> = tot.add(piece['key'].value_counts(), <span class="attr">fill_value=0)</span></span><br><span class="line"><span class="attr">tot</span> = tot.order(<span class="attr">ascending=False)</span></span><br><span class="line">tot[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">E</span>    <span class="number">368</span></span><br><span class="line">X    <span class="number">364</span></span><br><span class="line">L    <span class="number">346</span></span><br><span class="line"><span class="keyword">O</span>    <span class="number">343</span></span><br><span class="line">Q    <span class="number">340</span></span><br><span class="line">M    <span class="number">338</span></span><br><span class="line">J    <span class="number">337</span></span><br><span class="line">F    <span class="number">335</span></span><br><span class="line"><span class="keyword">K</span>    <span class="number">334</span></span><br><span class="line">H    <span class="number">330</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p><p><strong>将数据写到文本格式</strong><br>DataFrame和Series都有<code>to_csv</code>方法，用于将数据写到一个以逗号分隔的文本文件，输出时可以指定分隔符、缺失值表示、是否输出行列标签，并可以指定列顺序。</p><p><strong>手工处理分隔符格式</strong><br>对于异性文件或含有畸形行的文件，可以使用Python内置的csv模块打开，并传递给<code>csv.reader</code>进行迭代处理。</p><p><strong>JSON数据</strong><br>有许多Python库可以读写JSON数据，例如<code>json</code>，通过<code>.loads</code>方法转换成Python对象，<code>.dumps</code>方法反之。<br>有一个简单的方法将一组JSON对象转换为DataFrame数据结构：想DataFrame构造器传入一组JSON对象，并选取数据字段的自己。<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">obj = <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">&#123;"</span><span class="built_in">name</span><span class="string">": "</span>Wes<span class="string">",</span></span><br><span class="line"><span class="string"> "</span>places_lived<span class="string">": ["</span>United States<span class="string">", "</span>Spain<span class="string">", "</span>Germany<span class="string">"],</span></span><br><span class="line"><span class="string"> "</span>pet<span class="string">": null,</span></span><br><span class="line"><span class="string"> "</span>siblings<span class="string">": [&#123;"</span><span class="built_in">name</span><span class="string">": "</span>Scott<span class="string">", "</span>age<span class="string">": 25, "</span>pet<span class="string">": "</span>Zuko<span class="string">"&#125;,</span></span><br><span class="line"><span class="string">              &#123;"</span><span class="built_in">name</span><span class="string">": "</span>Katie<span class="string">", "</span>age<span class="string">": 33, "</span>pet<span class="string">": "</span>Cisco<span class="string">"&#125;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">import json</span><br><span class="line"><span class="literal">result</span> = json.loads(obj)</span><br><span class="line">siblings = DataFrame(<span class="literal">result</span>['siblings'], columns=['<span class="built_in">name</span>','age'])</span><br><span class="line">siblings</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name age</span><br><span class="line"><span class="number">0</span> Scott <span class="number">25</span></span><br><span class="line"><span class="number">1</span> Katie <span class="number">33</span></span><br></pre></td></tr></table></figure></p><p><strong>XML和HTML：Web信息收集</strong><br>对于互联网上的HTML和XML数据，可以先使用<code>urllib2</code>抓取，然后用<code>lxml</code>库进行解析处理，这里更多的涉及到XML解析和XPATH技术，不做过多深入。</p><h3 id="6-2-二进制数据格式"><a href="#6-2-二进制数据格式" class="headerlink" title="6.2 二进制数据格式"></a>6.2 二进制数据格式</h3><p><strong>读取Microsoft Excel文件</strong><br>pandas的<code>ExcelFile</code>类支持读取Excel 2003或更高版本中的表格行数据，下述代码直接将工作表中的数据读取到到DataFrame对象中。<br><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">xls_file</span> = pd.ExcelFile(<span class="string">'data.xls'</span>)</span><br><span class="line"><span class="attr">table</span> = xls_file.parse(<span class="string">'Sheet1'</span>)</span><br></pre></td></tr></table></figure></p><h3 id="6-3-使用HTML和Web-API"><a href="#6-3-使用HTML和Web-API" class="headerlink" title="6.3 使用HTML和Web API"></a>6.3 使用HTML和Web API</h3><p>使用<code>requests</code>包模拟HTTP请求，可以获取网站上很多提供数据的公共API，返回的数据是JSON或其他格式，通过之前的几类方法加载到pandas对象中。</p><h3 id="6-4-使用数据库"><a href="#6-4-使用数据库" class="headerlink" title="6.4 使用数据库"></a>6.4 使用数据库</h3><p>大部分Python SQL驱动器都会返沪一个元祖列表，以SQLite为例。<br><figure class="highlight ceylon"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite<span class="number">3</span></span><br><span class="line"></span><br><span class="line">query = <span class="string">"""</span></span><br><span class="line"><span class="string">CREATE TABLE test</span></span><br><span class="line"><span class="string">(a VARCHAR(20), b VARCHAR(20),</span></span><br><span class="line"><span class="string"> c REAL,        d INTEGER</span></span><br><span class="line"><span class="string">);"""</span></span><br><span class="line"></span><br><span class="line">con = sqlite<span class="number">3</span>.connect(<span class="string">':memory:'</span>)</span><br><span class="line">con.execute(query)</span><br><span class="line">con.commit()</span><br><span class="line">data = [(<span class="string">'Atlanta'</span>, <span class="string">'Georgia'</span>, <span class="number">1.2</span><span class="number">5</span>, <span class="number">6</span>),</span><br><span class="line">        (<span class="string">'Tallahassee'</span>, <span class="string">'Florida'</span>, <span class="number">2.6</span>, <span class="number">3</span>),</span><br><span class="line">        (<span class="string">'Sacramento'</span>, <span class="string">'California'</span>, <span class="number">1.7</span>, <span class="number">5</span>)]</span><br><span class="line">stmt = <span class="string">"INSERT INTO test VALUES(?, ?, ?, ?)"</span></span><br><span class="line"></span><br><span class="line">con.executemany(stmt, data)</span><br><span class="line">con.commit()</span><br><span class="line">cursor = con.execute(<span class="string">'select * from test'</span>)</span><br><span class="line">rows = cursor.fetchall()</span><br><span class="line">rows</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="string">u'Atlanta'</span>, <span class="string">u'Georgia'</span>, <span class="number">1.25</span>, <span class="number">6</span>),</span><br><span class="line"> (<span class="string">u'Tallahassee'</span>, <span class="string">u'Florida'</span>, <span class="number">2.6</span>, <span class="number">3</span>),</span><br><span class="line"> (<span class="string">u'Sacramento'</span>, <span class="string">u'California'</span>, <span class="number">1.7</span>, <span class="number">5</span>)]</span><br></pre></td></tr></table></figure></p><p>pandas有一个简化导入的方法<code>read_frame</code>函数，传入select语句就能转化成相应的DataFrame对象。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import pandas<span class="selector-class">.io</span><span class="selector-class">.sql</span> as sql</span><br><span class="line">sql.read_frame(<span class="string">'select * from test'</span>, con)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a b c d</span><br><span class="line"><span class="number">0</span> Atlanta Georgia <span class="number">1.25</span> <span class="number">6</span></span><br><span class="line"><span class="number">1</span> Tallahassee Florida <span class="number">2.60</span> <span class="number">3</span></span><br><span class="line"><span class="number">2</span> Sacramento California <span class="number">1.70</span> <span class="number">5</span></span><br></pre></td></tr></table></figure></p><p><strong>存取MongoDB中的数据</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;6-数据加载、存储与文件格式&quot;&gt;&lt;a href=&quot;#6-数据加载、存储与文件格式&quot; class=&quot;headerlink&quot; title=&quot;6 数据加载、存储与文件格式&quot;&gt;&lt;/a&gt;6 数据加载、存储与文件格式&lt;/h2&gt;&lt;h3 id=&quot;6-1-读写文本格式的数据&quot;&gt;&lt;a</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Data Analysis" scheme="http://gloomymoon.github.io/tags/Data-Analysis/"/>
    
    <category term="pandas" scheme="http://gloomymoon.github.io/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>Python for Data Analysis Note II</title>
    <link href="http://gloomymoon.github.io/2016/11/14/Python-for-Data-Analysis-II/"/>
    <id>http://gloomymoon.github.io/2016/11/14/Python-for-Data-Analysis-II/</id>
    <published>2016-11-14T11:09:56.000Z</published>
    <updated>2016-11-16T11:01:31.263Z</updated>
    
    <content type="html"><![CDATA[<h2 id="5-pandas入门"><a href="#5-pandas入门" class="headerlink" title="5 pandas入门"></a>5 pandas入门</h2><p>约定：<br><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">from</span> pandas <span class="keyword">import</span> Series, DataFrame</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure></p><h3 id="5-1-pandas的数据机构介绍"><a href="#5-1-pandas的数据机构介绍" class="headerlink" title="5.1 pandas的数据机构介绍"></a>5.1 pandas的数据机构介绍</h3><p>pandas两个主要数据结构<code>Series</code>和<code>DataFrame</code></p><p><strong>Series</strong><br>Series有两个属性<code>values</code>和<code>index</code>，表示数据（各种NumPy数据类型）及与之相关的标签（索引），因此可以从一个Python字典中直接创建Series<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">sdata</span> = &#123;<span class="string">'Ohio'</span>: 35000, <span class="string">'Texas'</span>: 71000, <span class="string">'Oregon'</span>: 16000, <span class="string">'Utah'</span>: 5000&#125;</span><br><span class="line">obj3 = Series(sdata)</span><br><span class="line">obj3</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Ohio      <span class="number">35000</span></span><br><span class="line">Oregon    <span class="number">16000</span></span><br><span class="line">Texas     <span class="number">71000</span></span><br><span class="line">Utah       <span class="number">5000</span></span><br><span class="line"><span class="symbol">dtype:</span> int64</span><br></pre></td></tr></table></figure></p><p>可以指定index，注意只有index中的数据保留：<br><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">states = [<span class="string">'California'</span>, <span class="string">'Ohio'</span>, <span class="string">'Oregon'</span>, <span class="string">'Texas'</span>]</span><br><span class="line">obj4 = Series(sdata, <span class="keyword">index</span>=states)</span><br><span class="line">obj4</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">California      <span class="meta">NaN</span></span><br><span class="line">Ohio          <span class="number">35000</span></span><br><span class="line">Oregon        <span class="number">16000</span></span><br><span class="line">Texas         <span class="number">71000</span></span><br><span class="line"><span class="symbol">dtype:</span> <span class="meta">float64</span></span><br></pre></td></tr></table></figure></p><p>Series最重要的一个功能是：在算术运算中自动对齐不同索引的数据。<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">obj3</span> + obj4</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">California       <span class="meta">NaN</span></span><br><span class="line">Ohio           <span class="number">70000</span></span><br><span class="line">Oregon         <span class="number">32000</span></span><br><span class="line">Texas         <span class="number">142000</span></span><br><span class="line">Utah             <span class="meta">NaN</span></span><br><span class="line"><span class="symbol">dtype:</span> <span class="meta">float64</span></span><br></pre></td></tr></table></figure></p><p>Series对象本省及其索引都有一个<code>name</code>属性，这跟pandas其他关键功能关系密切。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">obj4<span class="selector-class">.name</span> = <span class="string">'population'</span></span><br><span class="line">obj4<span class="selector-class">.index</span><span class="selector-class">.name</span> = <span class="string">'state'</span></span><br><span class="line">obj4</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">state</span></span><br><span class="line">California      NaN</span><br><span class="line">Ohio          <span class="number">35000</span></span><br><span class="line">Oregon        <span class="number">16000</span></span><br><span class="line">Texas         <span class="number">71000</span></span><br><span class="line">Name: population, dtype: float64</span><br></pre></td></tr></table></figure></p><p><strong>DataFrame</strong><br>DataFrame是一个表格型数据结构，它含有一组有序的列，每列可以是不同的类型。DataFrame既有行索引也有列索引，可以看作是由Series组成的字典。<br>构建DataFrame最直接的方式是传入一个由等长列表或NumPy数组组成的字典：<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = &#123;<span class="string">'state'</span>: [<span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Nevada'</span>, <span class="string">'Nevada'</span>],</span><br><span class="line"><span class="string">'year'</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>],</span><br><span class="line"><span class="string">'pop'</span>: [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>]&#125;</span><br><span class="line">frame = <span class="symbol">DataFrame</span>(data)</span><br><span class="line">frame</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> pop <span class="section">state</span> year</span><br><span class="line"><span class="number">0</span> <span class="number">1.5</span> Ohio <span class="number">2000</span></span><br><span class="line"><span class="number">1</span> <span class="number">1.7</span> Ohio <span class="number">2001</span></span><br><span class="line"><span class="number">2</span> <span class="number">3.6</span> Ohio <span class="number">2002</span></span><br><span class="line"><span class="number">3</span> <span class="number">2.4</span> Nevada <span class="number">2001</span></span><br><span class="line"><span class="number">4</span> <span class="number">2.9</span> Nevada <span class="number">2002</span></span><br></pre></td></tr></table></figure></p><p>创建时可以指定列序列，DataFrame会按照指定顺序排列列。<br><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">frame2</span> = DataFrame(data, columns=[<span class="string">'year'</span>, <span class="string">'state'</span>, <span class="string">'pop'</span>], index=[<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>, <span class="string">'four'</span>, <span class="string">'five'</span>])</span><br></pre></td></tr></table></figure></p><p>如果传入的列在数据中找不到，就会产生<code>NaN</code>值。</p><p>通过字典标记的方式或属性的方式，可以已Series的方式获取DataFrame的列。<br><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">frame2['<span class="keyword">state</span>']</span><br><span class="line">frame2.year</span><br></pre></td></tr></table></figure></p><p>通过<code>ix</code>可以获取行。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frame2<span class="selector-class">.ix</span>[<span class="string">'three'</span>]</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">year     <span class="number">2002</span></span><br><span class="line"><span class="keyword">state</span>    Ohio</span><br><span class="line">pop       <span class="number">3.6</span></span><br><span class="line">Name: three, dtype: object</span><br></pre></td></tr></table></figure></p><p>用索引方式返回的都是源数据的视图，并非副本，因此所有的修改都会全部反映到源DataFrame中。</p><p><strong>索引对象</strong></p><h3 id="5-2-基本功能"><a href="#5-2-基本功能" class="headerlink" title="5.2 基本功能"></a>5.2 基本功能</h3><p><strong>重新索引</strong><br>pandas对象一个重要方法是<code>reindex</code>，创建一个适应新索引的新对象。</p><p><strong>丢弃指定轴上的项</strong><br><code>drop</code>防范可以删除任意轴上的索引项。</p><p><strong>索引、选取和过滤</strong><br><code>Series</code>索引用标签切片的运算与普通Python切片不同，是末端包含的。<br>对<code>DataFrame</code>进行索引就是获取一个或多个列，但是通过切片或布尔数组方式选取的是行，这是逻辑用法是来源于</p><p><strong>算术运算和数据对齐</strong><br>pandas对象相加时，如果存在不同的索引树，结果的索引就是该索引对的并集。<br>在算术方法中填充值时，如果希望对缺失值赋予一个特殊值，可以使用<code>fill_value</code>参数，该参数在重新索引时也可以使用。<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df1 = DataFrame(np.arange(<span class="number">12.</span>).reshape((<span class="number">3</span>,<span class="number">4</span>)), columns=<span class="type">list</span>('abcd'))</span><br><span class="line">df2 = DataFrame(np.arange(<span class="number">20.</span>).reshape((<span class="number">4</span>,<span class="number">5</span>)), columns=<span class="type">list</span>('abcde'))</span><br><span class="line">df1 + df2</span><br><span class="line">df1.add(df2, fill_value=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> a b c d e</span><br><span class="line"><span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">4</span> <span class="number">6</span> NaN</span><br><span class="line"><span class="number">1</span> <span class="number">9</span> <span class="number">11</span> <span class="number">13</span> <span class="number">15</span> NaN</span><br><span class="line"><span class="number">2</span> <span class="number">18</span> <span class="number">20</span> <span class="number">22</span> <span class="number">24</span> NaN</span><br><span class="line"><span class="number">3</span> NaN NaNNaNNaNNaN</span><br><span class="line"></span><br><span class="line"> a b c d e</span><br><span class="line"><span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">4</span> <span class="number">6</span> <span class="number">4</span></span><br><span class="line"><span class="number">1</span> <span class="number">9</span> <span class="number">11</span> <span class="number">13</span> <span class="number">15</span> <span class="number">9</span></span><br><span class="line"><span class="number">2</span> <span class="number">18</span> <span class="number">20</span> <span class="number">22</span> <span class="number">24</span> <span class="number">14</span></span><br><span class="line"><span class="number">3</span> <span class="number">15</span> <span class="number">16</span> <span class="number">17</span> <span class="number">18</span> <span class="number">19</span></span><br></pre></td></tr></table></figure></p><p><strong>DataFrame和Series之间的运算</strong><br>和NumPy中不同维度数组之间的广播机制类似，DataFrame和Series之间的算术运算会将Series的索引匹配到DataFrame的列，然后沿着行的防线一直向下广播。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">frame = DataFrame(np.arange(<span class="number">12</span>.).reshape((<span class="number">4</span>, <span class="number">3</span>)), <span class="attribute">columns</span>=list(<span class="string">'bde'</span>), index=[<span class="string">'Utah'</span>,<span class="string">'Ohio'</span>,<span class="string">'Texas'</span>,<span class="string">'Oregon'</span>])</span><br><span class="line">series = frame<span class="selector-class">.ix</span>[<span class="number">0</span>]</span><br><span class="line">frame - series</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> b d e</span><br><span class="line">Utah <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line">Ohio <span class="number">3</span> <span class="number">3</span> <span class="number">3</span></span><br><span class="line">Texas <span class="number">6</span> <span class="number">6</span> <span class="number">6</span></span><br><span class="line">Oregon <span class="number">9</span> <span class="number">9</span> <span class="number">9</span></span><br></pre></td></tr></table></figure></p><p>如果希望匹配行在列上广播，必须使用算术运算方法。<br><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">series<span class="number">3</span> = frame[<span class="string">'d'</span>]</span><br><span class="line">frame.sub<span class="comment">(series3, axis=0)</span></span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> b d e</span><br><span class="line">Utah <span class="number">-1</span> <span class="number">0</span> <span class="number">1</span></span><br><span class="line">Ohio <span class="number">-1</span> <span class="number">0</span> <span class="number">1</span></span><br><span class="line">Texas <span class="number">-1</span> <span class="number">0</span> <span class="number">1</span></span><br><span class="line">Oregon <span class="number">-1</span> <span class="number">0</span> <span class="number">1</span></span><br></pre></td></tr></table></figure></p><p><strong>函数应用和映射</strong><br>NumPy的ufuncs（元素级数组方法）也可用于操作pandas对象。另外一个常见的用法是将函数应用到各类或各行所在的一维数组上，DataFrame的<code>.apply()</code>方法可以实现此功能。<br><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">frame = DataFrame(np.<span class="built_in">random</span>.randn(<span class="number">4</span>,<span class="number">3</span>), columns=<span class="built_in">list</span>(<span class="string">'bde'</span>), index=[<span class="string">'Utah'</span>,<span class="string">'Ohio'</span>,<span class="string">'Texas'</span>,<span class="string">'Oregon'</span>])</span><br><span class="line">f = lambda x: x.<span class="built_in">max</span>() - x.<span class="built_in">min</span>()</span><br><span class="line">frame</span><br><span class="line">frame.<span class="built_in">apply</span>(f)</span><br><span class="line">frame.<span class="built_in">apply</span>(f, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> <span class="selector-tag">b</span> <span class="selector-tag">d</span> <span class="selector-tag">e</span></span><br><span class="line"><span class="selector-tag">Utah</span> 0<span class="selector-class">.062492</span> <span class="selector-tag">-1</span><span class="selector-class">.727616</span> <span class="selector-tag">-0</span><span class="selector-class">.079996</span></span><br><span class="line"><span class="selector-tag">Ohio</span> 1<span class="selector-class">.313402</span> 0<span class="selector-class">.658781</span> <span class="selector-tag">-0</span><span class="selector-class">.992717</span></span><br><span class="line"><span class="selector-tag">Texas</span> <span class="selector-tag">-1</span><span class="selector-class">.954599</span> 2<span class="selector-class">.428276</span> 1<span class="selector-class">.372190</span></span><br><span class="line"><span class="selector-tag">Oregon</span> <span class="selector-tag">-0</span><span class="selector-class">.821649</span> 0<span class="selector-class">.896800</span> 2<span class="selector-class">.221896</span></span><br><span class="line"></span><br><span class="line"><span class="selector-tag">b</span>    2<span class="selector-class">.389651</span></span><br><span class="line"><span class="selector-tag">d</span>    3<span class="selector-class">.365110</span></span><br><span class="line"><span class="selector-tag">e</span>    2<span class="selector-class">.934581</span></span><br><span class="line"><span class="selector-tag">dtype</span>: <span class="selector-tag">float64</span></span><br><span class="line"></span><br><span class="line"><span class="selector-tag">Utah</span>      0<span class="selector-class">.263963</span></span><br><span class="line"><span class="selector-tag">Ohio</span>      1<span class="selector-class">.964547</span></span><br><span class="line"><span class="selector-tag">Texas</span>     1<span class="selector-class">.133140</span></span><br><span class="line"><span class="selector-tag">Oregon</span>    1<span class="selector-class">.777723</span></span><br><span class="line"><span class="selector-tag">dtype</span>: <span class="selector-tag">float64</span></span><br></pre></td></tr></table></figure></p><p>除此之外，传递给<code>apply</code>的函数还可以是返回多个值的Series。<br><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def f(<span class="keyword">x</span>):</span><br><span class="line">return Series([<span class="keyword">x</span>.<span class="keyword">min</span>(), <span class="keyword">x</span>.<span class="keyword">max</span>()], index=['<span class="keyword">min</span>','<span class="keyword">max</span>'])</span><br><span class="line"></span><br><span class="line">frame.apply(f)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> <span class="selector-tag">b</span> <span class="selector-tag">d</span> <span class="selector-tag">e</span></span><br><span class="line"><span class="selector-tag">min</span> <span class="selector-tag">-0</span><span class="selector-class">.274731</span> <span class="selector-tag">-2</span><span class="selector-class">.239277</span> <span class="selector-tag">-2</span><span class="selector-class">.157811</span></span><br><span class="line"><span class="selector-tag">max</span> 0<span class="selector-class">.408729</span> 0<span class="selector-class">.724984</span> 0<span class="selector-class">.180029</span></span><br></pre></td></tr></table></figure></p><p>元素级的函数也可以使用<code>.applymap</code>方法实现。</p><p><strong>排序和排名</strong><br>使用<code>.sort_index</code>方法对行或列索引排序，将返回一个已排序的新对象。<br>如果希望对一个或多个列中的值进行排序，将列名传递给<code>by</code>选项即可。<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">frame = <span class="symbol">DataFrame</span>(&#123;<span class="string">'b'</span>:[<span class="number">4</span>,<span class="number">7</span><span class="number">-3</span>,<span class="number">2</span>], <span class="string">'a'</span>:[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>]&#125;)</span><br><span class="line">frame.sort_index(by=[<span class="string">'a'</span>,<span class="string">'b'</span>])</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> a b</span><br><span class="line"><span class="number">2</span> <span class="number">0</span> <span class="number">-3</span></span><br><span class="line"><span class="number">0</span> <span class="number">0</span> <span class="number">4</span></span><br><span class="line"><span class="number">3</span> <span class="number">1</span> <span class="number">2</span></span><br><span class="line"><span class="number">1</span> <span class="number">1</span> <span class="number">7</span></span><br></pre></td></tr></table></figure></p><p><strong>带有重复值的轴索引</strong><br>可以使用<code>index</code>的<code>.is_unique</code>属性来看轴索引是否有重复值。在数据选取时，如果索引对应多个值，则会返回Series，否则返回一个标量值。</p><h3 id="5-3-汇总和计算描述统计"><a href="#5-3-汇总和计算描述统计" class="headerlink" title="5.3 汇总和计算描述统计"></a>5.3 汇总和计算描述统计</h3><p>pandas的常用数学统计方法，都是基于没有缺失数据的假设而构建的。<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df = <span class="symbol">DataFrame</span>([[<span class="number">1.4</span>, np.nan], [<span class="number">7.1</span>, <span class="number">-4.5</span>],</span><br><span class="line">                [np.nan, np.nan], [<span class="number">0.75</span>, <span class="number">-1.3</span>]],</span><br><span class="line">               index=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>],</span><br><span class="line">               columns=[<span class="string">'one'</span>, <span class="string">'two'</span>])</span><br><span class="line">df</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  <span class="selector-tag">one</span>  <span class="selector-tag">two</span></span><br><span class="line"><span class="selector-tag">a</span>1<span class="selector-class">.40</span><span class="selector-tag">NaN</span></span><br><span class="line"><span class="selector-tag">b</span>7<span class="selector-class">.10</span><span class="selector-tag">-4</span><span class="selector-class">.5</span></span><br><span class="line"><span class="selector-tag">c</span><span class="selector-tag">NaN</span>  <span class="selector-tag">NaN</span></span><br><span class="line"><span class="selector-tag">d</span>0<span class="selector-class">.75</span><span class="selector-tag">-1</span><span class="selector-class">.3</span></span><br></pre></td></tr></table></figure></p><p><strong>相关系数与协方差</strong></p><p><strong>唯一值、值计数以及成员资格</strong><br>这类方法可以从一维<code>Series</code>的值中抽取信息，例如<code>unique</code>返回唯一值数组，<code>value_counts</code>计算各值出现的频率，<code>isin</code>用于判断矢量化集合的成员资格<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">obj = <span class="symbol">Series</span>([<span class="string">'c'</span>, <span class="string">'a'</span>, <span class="string">'d'</span>, <span class="string">'a'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'c'</span>])</span><br><span class="line">mask = obj.isin([<span class="string">'b'</span>, <span class="string">'c'</span>])</span><br><span class="line">mask</span><br><span class="line">obj[mask]</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">1</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">2</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">3</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">4</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">5</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">6</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">7</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">8</span>     <span class="literal">True</span></span><br><span class="line"><span class="attr">dtype:</span> <span class="string">bool</span></span><br><span class="line"></span><br><span class="line"><span class="number">0</span>    <span class="string">c</span></span><br><span class="line"><span class="number">5</span>    <span class="string">b</span></span><br><span class="line"><span class="number">6</span>    <span class="string">b</span></span><br><span class="line"><span class="number">7</span>    <span class="string">c</span></span><br><span class="line"><span class="number">8</span>    <span class="string">c</span></span><br><span class="line"><span class="attr">dtype:</span> <span class="string">object</span></span><br></pre></td></tr></table></figure></p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">data</span> = <span class="type">DataFrame</span>(&#123;'<span class="type">Qu1</span>': [1, 3, 4, 3, 4],</span></span><br><span class="line"><span class="class">                  '<span class="type">Qu2</span>': [2, 3, 1, 2, 3],</span></span><br><span class="line"><span class="class">                  '<span class="type">Qu3</span>': [1, 5, 2, 4, 4]&#125;)</span></span><br><span class="line"><span class="title">result</span> = <span class="class"><span class="keyword">data</span>.apply(<span class="title">pd</span>.<span class="title">value_counts</span>).fillna(0)</span></span><br><span class="line"><span class="title">result</span></span><br></pre></td></tr></table></figure><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">  Qu1Qu2Qu3</span><br><span class="line"><span class="number">1</span><span class="number">1.0</span><span class="number">1.0</span><span class="number">1.0</span></span><br><span class="line"><span class="number">2</span><span class="number">0.0</span><span class="number">2.0</span><span class="number">1.0</span></span><br><span class="line"><span class="number">3</span><span class="number">2.0</span><span class="number">2.0</span><span class="number">0.0</span></span><br><span class="line"><span class="number">4</span><span class="number">2.0</span><span class="number">0.0</span><span class="number">2.0</span></span><br><span class="line"><span class="number">5</span><span class="number">0.0</span><span class="number">0.0</span><span class="number">1.0</span></span><br></pre></td></tr></table></figure></p><h3 id="5-4-处理缺失数据"><a href="#5-4-处理缺失数据" class="headerlink" title="5.4 处理缺失数据"></a>5.4 处理缺失数据</h3><p>pandas使用浮点值<code>NaN</code>(Not a Number)表示浮点和非浮点数组中的缺失数字，Python内置的<code>None</code>也会被当作<code>NA</code>处理</p><p><strong>滤除缺失数据</strong><br><code>.dropna</code>方法或者使用<code>[data.notnull()]</code>布尔型索引都可以直接过滤掉缺失数据。对于<code>DataFrame</code>对象，<code>dtopna()</code>默认丢弃任何含有缺失的行。</p><p><strong>填充缺失数据</strong><br><code>fillna</code>方法是最主要的填充缺失数据的函数。通过传入一个字典，可以实现对不同列填充不同的值。传入<code>inplace=True</code>参数可以就地修改而不是默认返回新对象。<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">df.fillna(&#123;1: 0.5, 3: -1&#125;)</span></span><br><span class="line"><span class="comment"># always returns a reference to the filled object</span></span><br><span class="line">_ = df.fillna(0, inplace=True)</span><br></pre></td></tr></table></figure></p><h3 id="5-5-层次化索引"><a href="#5-5-层次化索引" class="headerlink" title="5.5 层次化索引"></a>5.5 层次化索引</h3><p>对于一个DataFrame，每条轴都可以有分层索引<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">frame = <span class="symbol">DataFrame</span>(np.arange(<span class="number">12</span>).reshape((<span class="number">4</span>,<span class="number">3</span>)), index=[[<span class="string">'a'</span>,<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'b'</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>]], columns=[[<span class="string">'Ohio'</span>,<span class="string">'Ohio'</span>,<span class="string">'Colorado'</span>],[<span class="string">'Green'</span>,<span class="string">'Red'</span>,<span class="string">'Green'</span>]])</span><br><span class="line">frame</span><br></pre></td></tr></table></figure></p><p>Output<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> Ohio Colorado</span><br><span class="line">Green Red Green</span><br><span class="line">a <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span></span><br><span class="line"><span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span></span><br><span class="line">b <span class="number">1</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span></span><br><span class="line"><span class="number">2</span> <span class="number">9</span> <span class="number">10</span> <span class="number">11</span></span><br></pre></td></tr></table></figure></p><p>各层都可以有名字，并且可以单独创建MultiIndex然后复用。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">frame<span class="selector-class">.index</span><span class="selector-class">.names</span> = [<span class="string">'key1'</span>,<span class="string">'key2'</span>]</span><br><span class="line">frame<span class="selector-class">.columns</span><span class="selector-class">.names</span> = [<span class="string">'state'</span>, <span class="string">'color'</span>]</span><br><span class="line">MultiIndex.from_array([[<span class="string">'Ohio'</span>,<span class="string">'Ohio'</span>,<span class="string">'Colorado'</span>],[<span class="string">'Green'</span>,<span class="string">'Red'</span>,<span class="string">'Green'</span>], names=[<span class="string">'statue'</span>,<span class="string">'color'</span>])</span><br></pre></td></tr></table></figure></p><p><strong>重排分级顺序</strong><br>如果需要调整某条轴上各级别的顺序时可以使用<code>swaplevel</code>方法，它接受两个级别编号或名称，斌返回互换级别的新对象（但数据不会变化）<br><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">frame</span><span class="selector-class">.swaplevel</span>(<span class="string">'key1'</span>, <span class="string">'key2'</span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">state</span> Ohio Colorado</span><br><span class="line">color Green Red Green</span><br><span class="line">key2 key1 </span><br><span class="line"><span class="number">1</span> a <span class="number">0</span> <span class="number">1</span> <span class="number">2</span></span><br><span class="line"><span class="number">2</span> a <span class="number">3</span> <span class="number">4</span> <span class="number">5</span></span><br><span class="line"><span class="number">1</span> b <span class="number">6</span> <span class="number">7</span> <span class="number">8</span></span><br><span class="line"><span class="number">2</span> b <span class="number">9</span> <span class="number">10</span> <span class="number">11</span></span><br></pre></td></tr></table></figure></p><p><code>sortlevel</code>方法则根据单个级别中的值对数据进行排序（稳定的）。注意这里的参数是索引的编号，索引编号是从外向内方向计数的。<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">frame</span><span class="selector-class">.sortlevel</span>(1)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">state</span> Ohio Colorado</span><br><span class="line">color Green Red Green</span><br><span class="line">key1 key2 </span><br><span class="line">a <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span></span><br><span class="line">b <span class="number">1</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span></span><br><span class="line">a <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span></span><br><span class="line">b <span class="number">2</span> <span class="number">9</span> <span class="number">10</span> <span class="number">11</span></span><br></pre></td></tr></table></figure></p><p>对层次化索引的分级重排是为了提升数据选取操作的效率，按照索引的顺序选取性能要好很多。</p><p><strong>根据级别汇总统计</strong><br>DataFrame和Series的描绘和汇总统计有一个<code>level</code>选项，用于指定在某条轴上求和的级别，这其实是利用了pandas的<code>groupby</code>功能<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frame.sum(<span class="attribute">level</span>=<span class="string">'color'</span>, <span class="attribute">axis</span>=1)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">color Green Red</span><br><span class="line">key1 key2 </span><br><span class="line">a <span class="number">1</span> <span class="number">2</span> <span class="number">1</span></span><br><span class="line"><span class="number">2</span> <span class="number">8</span> <span class="number">4</span></span><br><span class="line">b <span class="number">1</span> <span class="number">14</span> <span class="number">7</span></span><br><span class="line"><span class="number">2</span> <span class="number">20</span> <span class="number">10</span></span><br></pre></td></tr></table></figure></p><p><strong>使用DataFrame的列</strong><br>通常情况下，我们会将DataFrame的一个或多个列当作行索引，或者可以希望将行索引变成DataFrame的列。<br><code>set_index</code>会将一个或多个列专为行索引，并创建一个新的DataFrame。<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">frame = <span class="symbol">DataFrame</span>(&#123;<span class="string">'a'</span>: range(<span class="number">7</span>), <span class="string">'b'</span>: range(<span class="number">7</span>, <span class="number">0</span>, <span class="number">-1</span>), <span class="string">'c'</span>: [<span class="string">'one'</span>,<span class="string">'one'</span>,<span class="string">'one'</span>,<span class="string">'two'</span>,<span class="string">'two'</span>,<span class="string">'two'</span>,<span class="string">'tow'</span>], <span class="string">'d'</span>: [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]&#125;)</span><br><span class="line">frame2 = frame.set_index([<span class="string">'c'</span>,<span class="string">'d'</span>])</span><br><span class="line">frame2</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> a b</span><br><span class="line">c d </span><br><span class="line">one <span class="number">0</span> <span class="number">0</span> <span class="number">7</span></span><br><span class="line"><span class="number">1</span> <span class="number">1</span> <span class="number">6</span></span><br><span class="line"><span class="number">2</span> <span class="number">2</span> <span class="number">5</span></span><br><span class="line">two <span class="number">0</span> <span class="number">3</span> <span class="number">4</span></span><br><span class="line"><span class="number">1</span> <span class="number">4</span> <span class="number">3</span></span><br><span class="line"><span class="number">2</span> <span class="number">5</span> <span class="number">2</span></span><br><span class="line">tow <span class="number">3</span> <span class="number">6</span> <span class="number">1</span></span><br></pre></td></tr></table></figure></p><p>默认情况下这些列会从DataFrame中移除，但通过添加<code>dtop</code>参数可以将其保留。<br><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">frame2</span> = frame.set_index([<span class="string">'c'</span>,<span class="string">'d'</span>], drop=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> a b c d</span><br><span class="line">c d </span><br><span class="line">one <span class="number">0</span> <span class="number">0</span> <span class="number">7</span> one <span class="number">0</span></span><br><span class="line"><span class="number">1</span> <span class="number">1</span> <span class="number">6</span> one <span class="number">1</span></span><br><span class="line"><span class="number">2</span> <span class="number">2</span> <span class="number">5</span> one <span class="number">2</span></span><br><span class="line">two <span class="number">0</span> <span class="number">3</span> <span class="number">4</span> two <span class="number">0</span></span><br><span class="line"><span class="number">1</span> <span class="number">4</span> <span class="number">3</span> two <span class="number">1</span></span><br><span class="line"><span class="number">2</span> <span class="number">5</span> <span class="number">2</span> two <span class="number">2</span></span><br><span class="line">tow <span class="number">3</span> <span class="number">6</span> <span class="number">1</span> tow <span class="number">3</span></span><br></pre></td></tr></table></figure></p><p><code>reset_index</code>和<code>set_index</code>功能相反，将层次化的索引转移到列里面。</p><h3 id="5-6-其他有关pandas的话题"><a href="#5-6-其他有关pandas的话题" class="headerlink" title="5.6 其他有关pandas的话题"></a>5.6 其他有关pandas的话题</h3><p><strong>整数索引</strong><br>操作由整数索引的pandas对象要注意，因为跟内置Python数据结构在索引语义上的不同，经常会产生一个错误。<br><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ser</span> = Series(np.arange(<span class="number">3.</span>))</span><br><span class="line"><span class="keyword">ser</span>[<span class="number">-1</span>]</span><br></pre></td></tr></table></figure></p><p>上述代码会产生一个错误，但是如果设置了非整数索引，就不会产生问题。<br><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ser</span> = Series(np.arange(<span class="number">3.</span>), index[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>])</span><br><span class="line"><span class="keyword">ser</span>[<span class="number">-1</span>]</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2<span class="selector-class">.0</span></span><br></pre></td></tr></table></figure></p><p>如果你不考虑索引，而是完全基于位置的索引方法，可以使用Series的<code>iget_value</code>和DataFrame的<code>irow</code>和<code>icol</code>方法。</p><p><strong>面板数据</strong><br>pandas有一个<code>Panel</code>数据结果，可以视作是一个三维版的DataFrame，Panel中的每一项（类似于DataFrame的列）都是一个DataFrame。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;5-pandas入门&quot;&gt;&lt;a href=&quot;#5-pandas入门&quot; class=&quot;headerlink&quot; title=&quot;5 pandas入门&quot;&gt;&lt;/a&gt;5 pandas入门&lt;/h2&gt;&lt;p&gt;约定：&lt;br&gt;&lt;figure class=&quot;highlight elm&quot;&gt;&lt;</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Data Analysis" scheme="http://gloomymoon.github.io/tags/Data-Analysis/"/>
    
    <category term="pandas" scheme="http://gloomymoon.github.io/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>Python for Data Analysis Note I</title>
    <link href="http://gloomymoon.github.io/2016/11/11/Python-for-Data-Analysis-I/"/>
    <id>http://gloomymoon.github.io/2016/11/11/Python-for-Data-Analysis-I/</id>
    <published>2016-11-11T11:49:17.000Z</published>
    <updated>2016-11-14T11:10:17.618Z</updated>
    
    <content type="html"><![CDATA[<h3 id="0-Jupyter-Notebook"><a href="#0-Jupyter-Notebook" class="headerlink" title="0 Jupyter Notebook"></a>0 Jupyter Notebook</h3><p>建议直接安装<a href="https://www.continuum.io/downloads" target="_blank" rel="noopener">Anaconda</a>。</p><h3 id="1～3-准备工作"><a href="#1～3-准备工作" class="headerlink" title="1～3 准备工作"></a>1～3 准备工作</h3><p>直接使用Jupyter Notebook，这三个章节可以直接跳过。</p><h3 id="4-NumPy基础：数组和矢量计算"><a href="#4-NumPy基础：数组和矢量计算" class="headerlink" title="4 NumPy基础：数组和矢量计算"></a>4 NumPy基础：数组和矢量计算</h3><p>NumPy(Numerical Python)是高性能科学计算和数据分析的基础包，是python下几乎所有高级分析工具的构建基础。其主要功能如下：</p><ul><li>ndarray，一个具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组</li><li>对整组数据进行快速运算的标准数学函数</li><li>读写磁盘数据的工具以及用于操作内存映射文件的工具</li><li>线性代数、随机数生成以及傅里叶变换功能</li><li>用于集成由C、C++、Fortran等语言编写的代码的工具</li></ul><p>NumPy本身没有提供高级的分析功能，但是理解NumPy数组以及面向数据的计算对日后高效地使用诸如pandas之类的工具非常有益。对于大部分数据分析而言，我主要关注的功能集中在：</p><ul><li>数据导入、整理和清理，通过过滤和转换等矢量化数据组运算构建子集</li><li>数组算法如排序、唯一化、集合运算</li><li>描述统计、数据聚合/摘要运算</li><li>异构数据集合的合并、连接运算的数据对齐和关系型数据运算</li><li>将条件逻辑转化为数组表达式</li><li>分组运算（聚合、转换、函数应用等）<br>NumPy提供了这些基础计算功能，但是对于结构化数据，pandas提供更加简洁和丰富的接口，以及领域特定功能。</li></ul><h4 id="4-1-ndarray：一种多维数组对象"><a href="#4-1-ndarray：一种多维数组对象" class="headerlink" title="4.1 ndarray：一种多维数组对象"></a>4.1 ndarray：一种多维数组对象</h4><p><strong>创建数组</strong><br><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">data</span> = randn(2,3)</span></span><br><span class="line"><span class="class"><span class="keyword">data</span> = np.array([[1,2,3,4],[5,6,7,8]])</span></span><br><span class="line"><span class="class"><span class="keyword">data</span> + <span class="keyword">data</span></span></span><br><span class="line"><span class="class"><span class="keyword">data</span>.shape</span></span><br><span class="line"><span class="class"><span class="keyword">data</span>.dtype</span></span><br></pre></td></tr></table></figure></p><p>ndarray中所有元素必须是相同类型，每个数组有一个shape（表示各维度大小的元祖）和一个dtype（说明数组数据类型的对象）</p><p><code>np.zeros</code>、<code>np.ones</code>和<code>np.empty</code>分别创建指定长度和或形状的全0、全1或全空数组，注意<code>np.empty</code>中的元素是一些未初始化的垃圾值，而不是全0</p><p><code>arange</code>是Python内置<code>range</code>的数组版</p><p><strong>ndarray的数据类型</strong><br>使用<code>ndarray.astype</code>可以显示转换<code>dtype</code>，并（总是）生成一个新的数组。</p><p><strong>数组和标量之间的运算</strong><br>大小相等的数组之间的任何算术运算都会应用到元素级，而不同大小数组之间的运算叫做广播（broadcasting）</p><p><strong>基本的索引和切片</strong><br>对于数组切片上的修改都会直接反映到原数组上，因为NumPy设计目的是处理大数据，频繁的复制会产生性能和内存问题。如果需要切片副本，需要使用<code>.copy()</code>函数显示复制操作。</p><p>多维数组的索引可以是一个列表：<code>array[0][2]</code>效果等同<code>array[0,2]</code>。</p><p><strong>切片索引</strong></p><p><strong>布尔型索引</strong><br><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">names</span> = np.array([<span class="string">'Bob'</span>, <span class="string">'Joe'</span>,<span class="string">' Will'</span>, <span class="string">'Bob'</span>, <span class="string">'Will'</span>, <span class="string">'Joe'</span>, <span class="string">'Joe'</span>])</span><br><span class="line"><span class="attr">data</span> = randn(<span class="number">7</span>,<span class="number">4</span>)</span><br><span class="line"><span class="attr">names</span> == <span class="string">'Bob'</span></span><br><span class="line"><span class="attr">data[names</span> == <span class="string">'Bob'</span>]</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">array([</span> <span class="literal">True</span><span class="string">,</span> <span class="literal">False</span><span class="string">,</span> <span class="literal">False</span><span class="string">,</span>  <span class="literal">True</span><span class="string">,</span> <span class="literal">False</span><span class="string">,</span> <span class="literal">False</span><span class="string">,</span> <span class="literal">False</span><span class="string">],</span> <span class="string">dtype=bool)</span></span><br><span class="line"><span class="string">array([[</span> <span class="number">1.3653</span><span class="string">,</span> <span class="bullet">-0.9235</span><span class="string">,</span>  <span class="number">0.5542</span><span class="string">,</span>  <span class="number">1.0422</span><span class="string">],</span></span><br><span class="line">       <span class="string">[-0.5522,</span> <span class="bullet">-1.2451</span><span class="string">,</span> <span class="bullet">-0.7701</span><span class="string">,</span>  <span class="number">0.1165</span><span class="string">]])</span></span><br></pre></td></tr></table></figure></p><p>布尔索引选取可以通过<code>&amp;</code>（和）、<code>|</code>（或）组合多个表达式，注意这里不能用Python的<code>and</code>和<code>or</code>关键字<br><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">data</span>[(<span class="title">names</span> == '<span class="type">Bob</span>')|(<span class="title">names</span> == '<span class="type">Will</span>')]</span></span><br></pre></td></tr></table></figure></p><p>用布尔型数组设置值就非常方便，例如将所有负值置为<code>0</code><br><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">data</span>[<span class="keyword">data</span> &lt; 0] = 0</span></span><br></pre></td></tr></table></figure></p><p><strong>花式索引</strong><br>花式索引总是将数据复制到新数组中</p><p><strong>数组转置和轴对换</strong></p><h3 id="4-2-通用函数：快速的元素级数组函数"><a href="#4-2-通用函数：快速的元素级数组函数" class="headerlink" title="4.2 通用函数：快速的元素级数组函数"></a>4.2 通用函数：快速的元素级数组函数</h3><p>通用函数是一种对ndarray中的数据执行元素级运算的函数。可以看作是简单函数的矢量化包装器。<br>一元的函数如：<code>sqrt</code>和<code>exp</code><br>二元的函数如：<code>add</code>和<code>maximum</code></p><h3 id="4-3-利用数组进行数据处理"><a href="#4-3-利用数组进行数据处理" class="headerlink" title="4.3 利用数组进行数据处理"></a>4.3 利用数组进行数据处理</h3><p><strong>将条件逻辑表述为数组运维</strong><br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arr = randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">np.where(arr &gt; <span class="number">0</span>, <span class="number">2</span>, <span class="number">-2</span>)</span><br><span class="line">arr = randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">np.where(arr &gt; <span class="number">0</span>, <span class="number">2</span>, arr) #只将正值设置为<span class="number">2</span></span><br></pre></td></tr></table></figure></p><p><strong>数学和统计方法</strong></p><p><strong>用于布尔型数组的方法</strong></p><p><strong>排序</strong><br><code>np.sort</code>返回已排序数组的副本，就地排序会修改数组本身</p><p><strong>唯一化以及其他的集合逻辑</strong><br><code>np.unique</code>方法找出数组中的不重复值并返回已排序结果<br><code>np.in1d</code>测试一个数组中每个值在另一个数组中的成员资格，返回布尔型数组</p><h3 id="4-4-用于数组的文件输入输出"><a href="#4-4-用于数组的文件输入输出" class="headerlink" title="4.4 用于数组的文件输入输出"></a>4.4 用于数组的文件输入输出</h3><p><strong>将数组以二进制格式保存到磁盘</strong><br><code>np.save</code>和<code>np.load</code>可以读写磁盘上的二进制数组文件，扩展名为<code>.npy</code><br><code>np.savez</code>可以以压缩形式将多个数组保存到一个<code>.npz</code>文件中</p><p><strong>存取文本文件</strong><br><code>np.loadtxt</code>支持指定分隔符将txt文件导入数组<br><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">arr</span> = np.loadtxt(<span class="string">'filename.txt'</span>, delimiter=<span class="string">','</span>)</span><br></pre></td></tr></table></figure></p><h3 id="4-5-线性代数"><a href="#4-5-线性代数" class="headerlink" title="4.5 线性代数"></a>4.5 线性代数</h3><h3 id="4-6-随机数生成"><a href="#4-6-随机数生成" class="headerlink" title="4.6 随机数生成"></a>4.6 随机数生成</h3><p><code>numpy.random</code>模块内置了高效生成多种概率分布的随机函数，如正态分布<code>normal</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;0-Jupyter-Notebook&quot;&gt;&lt;a href=&quot;#0-Jupyter-Notebook&quot; class=&quot;headerlink&quot; title=&quot;0 Jupyter Notebook&quot;&gt;&lt;/a&gt;0 Jupyter Notebook&lt;/h3&gt;&lt;p&gt;建议直接安装</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Data Analysis" scheme="http://gloomymoon.github.io/tags/Data-Analysis/"/>
    
    <category term="NumPy" scheme="http://gloomymoon.github.io/tags/NumPy/"/>
    
  </entry>
  
  <entry>
    <title>StudiousPrime</title>
    <link href="http://gloomymoon.github.io/2016/11/06/StudiousPrime/"/>
    <id>http://gloomymoon.github.io/2016/11/06/StudiousPrime/</id>
    <published>2016-11-05T23:25:17.000Z</published>
    <updated>2016-11-06T00:31:09.900Z</updated>
    
    <content type="html"><![CDATA[<p>应领导要求给儿子做了一个英语单词联系网页<a href="https://github.com/Gloomymoon/StudiousPrime.git" target="_blank" rel="noopener">StudiousPrime</a>，目前为版本号为0.2，主要功能如下：</p><ol><li><p>根据单词掌握程度新建测试Exercise，每个测试25道题Question，题目形式为根据中文单词（及词组）填充。题目中的单词会根据长度随机显示:有限个字母总长5个及以下的单词随机展示1个字母，6个及以上随机展示2个，10个以上随机展示3个，答对得1分且该单词得分+1，答错不得分。<br><img src="/img/StudiousPrime_02.png" alt=""></p></li><li><p>测试完成后能够显示得分和所有错误题目。<br><img src="/img/StudiousPrime_03.png" alt=""></p></li><li><p>单词的记忆熟练等级根据得分提升：0～2分为1级，3～4分为2级，5～6分为3级，7～9分为4级，10～分为5级，目前选题逻辑为从高到低，除5级以外每个等级随机选取5题，1级选取10题，如果高级别可选题目不足则由低级别题目中选取。</p></li><li><p>可以展示所有测试的统计情况、掌握的单词数和分布情况。<br><img src="/img/StudiousPrime_04.png" alt=""></p></li><li><p>首页随机显示等级1的新单词，以及出错最多的5个单词，便于复习和巩固。<br><img src="/img/StudiousPrime_01.png" alt=""></p></li><li><p>录入生词，浏览和修改词库。<br><img src="/img/StudiousPrime_05.png" alt=""></p></li><li><p>技术架构：采用Flask框架，数据库采用sqlite，前端通过jquery.inputmask实现单词输入掩码。业务类模型如下图所示：<br><img src="http://yuml.me/diagram/class/[EnglishBook|+name]&lt;&gt;1-&gt;*[EnglishWord|+english;+chinese;+example], [EnglishWordScore|+score;+level|+random_word（）]-&gt;[EnglishWord], [EnglishWordScore]-&gt;[User], [EnglishExercise|+total;+corrent;+correct;+start;+finish]++1-&gt;*[EnglishQuestion|+english;+word_mask;+answer;+result],[EnglishQuestion]-&gt;[EnglishWord], [EnglishExercise]-&gt;[User], [User]-&gt;[Role], [EnglishStatistic||+wrong_words]（）,+achievements（）" alt=""></p></li><li><p>Todo:</p><ul><li>分角色权限已预装，但并未实际使用</li><li>增加单词发音</li><li>录入生词时从web自动抓取中文和例句</li><li>增加累计统计图表</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;应领导要求给儿子做了一个英语单词联系网页&lt;a href=&quot;https://github.com/Gloomymoon/StudiousPrime.git&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;StudiousPrime&lt;/a&gt;，目前为版本号为0.2</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Flask" scheme="http://gloomymoon.github.io/tags/Flask/"/>
    
  </entry>
  
  <entry>
    <title>Improving your submission</title>
    <link href="http://gloomymoon.github.io/2016/10/30/Improving-your-submission/"/>
    <id>http://gloomymoon.github.io/2016/10/30/Improving-your-submission/</id>
    <published>2016-10-30T06:37:50.000Z</published>
    <updated>2016-10-31T14:48:01.380Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-Improving-Our-Features"><a href="#1-Improving-Our-Features" class="headerlink" title="1 Improving Our Features"></a>1 Improving Our Features</h3><p>书接上回，我们刚刚完成了第一个Kaggle竞赛模型的提交，预测准确率是75%左右，排名将近5000。</p><p>本回将从以下三个方面来提高：</p><ul><li>使用更好的机器学习算法</li><li>优化特征变量</li><li>结合多种机器学习算法</li></ul><p>Let’s do it.</p><h3 id="2-Random-Forest-Introduction"><a href="#2-Random-Forest-Introduction" class="headerlink" title="2 Random Forest Introduction"></a>2 Random Forest Introduction</h3><p>首先我们引入一个新的算法决策树，决策树能够有效应对非线性关系。</p><p>举个栗子：<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Age    Sex    Survived</span><br><span class="line"><span class="number">5</span>      <span class="number">0</span>      <span class="number">1</span></span><br><span class="line"><span class="number">30</span>     <span class="number">1</span>      <span class="number">0</span></span><br><span class="line"><span class="number">70</span>     <span class="number">0</span>      <span class="number">1</span></span><br><span class="line"><span class="number">20</span>     <span class="number">0</span>      <span class="number">1</span></span><br></pre></td></tr></table></figure></p><p><code>Age</code>和<code>Survived</code>没有线性关系，这里可以使用决策树建立<code>Age</code>、<code>Sex</code>和<code>Survived</code>之间的关系：<br><img src="/img/Improving-your-submission_01.png" alt=""></p><ul><li>首先按照<code>Age</code>分组，小于等于<code>29</code>岁的进入左侧分枝，大于<code>29</code>岁的进入右侧分支</li><li>左侧分枝全部存活</li><li>右侧分枝再根据<code>Sex</code>进行分组，女性存活，男性未存活</li></ul><p>由于决策条件过分依赖于训练数据集的分布情况，其主要缺点是对于训练数据集的过拟合。</p><p>由此基础上我们产生了随机森林(Random Forest)算法。在整体样本上随机产生多个训练子集，然后通过对决策点条件随机化，建立上百颗决策树，然后通过对预测结果的平均化，就可以得出一个最小化过拟合的整体预测结果。</p><h3 id="3-Implementing-A-Random-Forest"><a href="#3-Implementing-A-Random-Forest" class="headerlink" title="3 Implementing A Random Forest"></a>3 Implementing A Random Forest</h3><p><code>sklearn</code>已经为我们提供了随机森林算法，我们可以直接在训练集上使用并进行交叉检验。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble import RandomForestClassifier</span><br><span class="line"></span><br><span class="line">predictors = [<span class="string">"Pclass"</span>, <span class="string">"Sex"</span>, <span class="string">"Age"</span>, <span class="string">"SibSp"</span>, <span class="string">"Parch"</span>, <span class="string">"Fare"</span>, <span class="string">"Embarked"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize our algorithm with the default paramters</span></span><br><span class="line"><span class="comment"># n_estimators is the number of trees we want to make</span></span><br><span class="line"><span class="comment"># min_samples_split is the minimum number of rows we need to make a split</span></span><br><span class="line"><span class="comment"># min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)</span></span><br><span class="line">alg = RandomForestClassifier(<span class="attribute">random_state</span>=1, <span class="attribute">n_estimators</span>=10, <span class="attribute">min_samples_split</span>=2, <span class="attribute">min_samples_leaf</span>=1)</span><br><span class="line"></span><br><span class="line">kf = KFold(<span class="attribute">n_splits</span>=3, <span class="attribute">random_state</span>=1).split(titanic)</span><br><span class="line">scores = model_selection.cross_val_score(alg, titanic[predictors], titanic[<span class="string">"Survived"</span>], <span class="attribute">cv</span>=kf)</span><br><span class="line"><span class="builtin-name">print</span>(scores.mean())</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0<span class="selector-class">.785634118967</span></span><br></pre></td></tr></table></figure></p><h3 id="4-Parameter-Tuning"><a href="#4-Parameter-Tuning" class="headerlink" title="4 Parameter Tuning"></a>4 Parameter Tuning</h3><p>首先也是最简单的提升随机森林算法精准度的方法是增加决策树的数量。训练更多的决策树需要花费更多的时间，但是因为我们最终是使用所有预测的平均值，这也意味着能够大大提升精准度。</p><p>我们也可以调整（增加）<code>min_samples_split</code>和<code>min_sambles_leaf</code>变量来降低过拟合，提升模型得分。一个更通用（也就是没有过拟合）的模型，在未知的数据上表现更好，但是在已知的数据上则相反。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">alg2 = RandomForestClassifier(<span class="attribute">random_state</span>=1, <span class="attribute">n_estimators</span>=50, <span class="attribute">min_samples_split</span>=4, <span class="attribute">min_samples_leaf</span>=2)</span><br><span class="line"></span><br><span class="line">scores2 = model_selection.cross_val_score(alg2, titanic[predictors], titanic[<span class="string">"Survived"</span>], <span class="attribute">cv</span>=3)</span><br><span class="line"><span class="builtin-name">print</span>(scores2, scores2.mean())</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name">array</span>([ <span class="number">0.8013468</span> ,  <span class="number">0.82154882</span>,  <span class="number">0.83838384</span>]), <span class="number">0.82042648709315369</span>)</span><br></pre></td></tr></table></figure></p><h3 id="5-Generating-New-Features"><a href="#5-Generating-New-Features" class="headerlink" title="5 Generating New Features"></a>5 Generating New Features</h3><p>我们还可以衍生新的变量，例如：</p><ul><li>姓名的长度，可能和乘客的富有程度有关，而富有程度与舱位有关</li><li>家庭的总人数<code>SibSp</code> + <code>Parch</code></li></ul><p>pandas的<code>.apply</code>方法可以轻易的生成衍生变量，通过传入一个<code>lambda</code>函数来定义变量上的操作。<br><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Generating a familysize column</span></span><br><span class="line">titanic[<span class="string">"FamilySize"</span>] = titanic[<span class="string">"SibSp"</span>] + titanic[<span class="string">"Parch"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># The .apply method generates a new series</span></span><br><span class="line">titanic[<span class="string">"NameLength"</span>] = titanic[<span class="string">"Name"</span>]<span class="string">.apply</span><span class="params">(lambda x: len(x)</span>)</span><br></pre></td></tr></table></figure></p><h3 id="6-Using-The-title"><a href="#6-Using-The-title" class="headerlink" title="6 Using The title"></a>6 Using The title</h3><p>通过分析发现姓名中包含有乘客头衔，型如<code>Master.</code>、<code>Mr.</code>、<code>Mrs.</code>等，其中不乏常用的，也有仅1、2个人用的特殊头衔。</p><p>我们将利用正则表达式提取出所有的头衔，然后转换成整型，最后生成一个数值型变量<code>Title</code>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># A function to get the title from a name.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_title</span><span class="params">(name)</span>:</span></span><br><span class="line">    <span class="comment"># Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.</span></span><br><span class="line">    title_search = re.search(<span class="string">' ([A-Za-z]+)\.'</span>, name)</span><br><span class="line">    <span class="comment"># If the title exists, extract and return it.</span></span><br><span class="line">    <span class="keyword">if</span> title_search:</span><br><span class="line">        <span class="keyword">return</span> title_search.group(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get all the titles and print how often each one occurs.</span></span><br><span class="line">titles = titanic[<span class="string">"Name"</span>].apply(get_title)</span><br><span class="line">print(pandas.value_counts(titles))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.</span></span><br><span class="line">title_mapping = &#123;<span class="string">"Mr"</span>: <span class="number">1</span>, <span class="string">"Miss"</span>: <span class="number">2</span>, <span class="string">"Mrs"</span>: <span class="number">3</span>, <span class="string">"Master"</span>: <span class="number">4</span>, <span class="string">"Dr"</span>: <span class="number">5</span>, <span class="string">"Rev"</span>: <span class="number">6</span>, <span class="string">"Major"</span>: <span class="number">7</span>, <span class="string">"Col"</span>: <span class="number">7</span>, <span class="string">"Mlle"</span>: <span class="number">8</span>, <span class="string">"Mme"</span>: <span class="number">8</span>, <span class="string">"Don"</span>: <span class="number">9</span>, <span class="string">"Lady"</span>: <span class="number">10</span>, <span class="string">"Countess"</span>: <span class="number">10</span>, <span class="string">"Jonkheer"</span>: <span class="number">10</span>, <span class="string">"Sir"</span>: <span class="number">9</span>, <span class="string">"Capt"</span>: <span class="number">7</span>, <span class="string">"Ms"</span>: <span class="number">2</span>&#125;</span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> title_mapping.items():</span><br><span class="line">    titles[titles == k] = v</span><br><span class="line"></span><br><span class="line"><span class="comment"># Verify that we converted everything.</span></span><br><span class="line">print(pandas.value_counts(titles))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add in the title column.</span></span><br><span class="line">titanic[<span class="string">"Title"</span>] = titles</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Mr          517</span><br><span class="line">Miss        182</span><br><span class="line">Mrs         125</span><br><span class="line">Master       40</span><br><span class="line">Dr            7</span><br><span class="line">Rev           6</span><br><span class="line">Col           2</span><br><span class="line">Major         2</span><br><span class="line">Mlle          2</span><br><span class="line">Countess      1</span><br><span class="line">Ms            1</span><br><span class="line">Lady          1</span><br><span class="line">Jonkheer      1</span><br><span class="line">Don           1</span><br><span class="line">Mme           1</span><br><span class="line">Capt          1</span><br><span class="line">Sir           1</span><br><span class="line">Name: Name, dtype: int64</span><br><span class="line">1     517</span><br><span class="line">2     183</span><br><span class="line">3     125</span><br><span class="line">4      40</span><br><span class="line">5       7</span><br><span class="line">6       6</span><br><span class="line">7       5</span><br><span class="line">10      3</span><br><span class="line">8       3</span><br><span class="line">9       2</span><br><span class="line">Name: Name, dtype: int64</span><br></pre></td></tr></table></figure></p><h3 id="7-Family-Groups"><a href="#7-Family-Groups" class="headerlink" title="7 Family Groups"></a>7 Family Groups</h3><p>幸存者很可能是依靠家人或者周围的朋友的帮助，因此乘客所属的家庭有可能是一个好变量。这里我们通过乘客的姓氏，加上<code>FamilySize</code>来标识出不同的家庭，然后根据每个乘客所属的家庭赋一个代码。<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="comment"># A dictionary mapping family name to id</span></span><br><span class="line"><span class="attr">family_id_mapping</span> = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># A function to get the id given a row</span></span><br><span class="line">def get_family_id(row):</span><br><span class="line">    <span class="comment"># Find the last name by splitting on a comma</span></span><br><span class="line">    <span class="attr">last_name</span> = row[<span class="string">"Name"</span>].split(<span class="string">","</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># Create the family id</span></span><br><span class="line">    <span class="attr">family_id</span> = <span class="string">"&#123;0&#125;&#123;1&#125;"</span>.format(last_name, row[<span class="string">"FamilySize"</span>])</span><br><span class="line">    <span class="comment"># Look up the id in the mapping</span></span><br><span class="line">    <span class="keyword">if</span> family_id not <span class="keyword">in</span> family_id_mapping:</span><br><span class="line">        <span class="keyword">if</span> len(family_id_mapping) == <span class="number">0</span>:</span><br><span class="line">            <span class="attr">current_id</span> = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># Get the maximum id from the mapping and add one to it if we don't have an id</span></span><br><span class="line">            <span class="attr">current_id</span> = (max(family_id_mapping.items(), <span class="attr">key=operator.itemgetter(1))[1]</span> + <span class="number">1</span>)</span><br><span class="line">        family_id_mapping[family_id] = current_id</span><br><span class="line">    return family_id_mapping[family_id]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the family ids with the apply method</span></span><br><span class="line"><span class="attr">family_ids</span> = titanic.apply(get_family_id, <span class="attr">axis=1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># There are a lot of family ids, so we'll compress all of the families under 3 members into one code.</span></span><br><span class="line">family_ids[titanic[<span class="string">"FamilySize"</span>] &lt; <span class="number">3</span>] = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the count of each unique id.</span></span><br><span class="line">print(pandas.value_counts(family_ids))</span><br><span class="line"></span><br><span class="line">titanic[<span class="string">"FamilyId"</span>] = family_ids</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">-1      800</span><br><span class="line"><span class="number"> 14 </span>      8</span><br><span class="line"><span class="number"> 149 </span>     7</span><br><span class="line"><span class="number"> 63 </span>      6</span><br><span class="line"><span class="number"> 50 </span>      6</span><br><span class="line"><span class="number"> 59 </span>      6</span><br><span class="line"><span class="number"> 17 </span>      5</span><br><span class="line"><span class="number"> 384 </span>     4</span><br><span class="line"><span class="number"> 27 </span>      4</span><br><span class="line"><span class="number"> 25 </span>      4</span><br><span class="line"><span class="number"> 162 </span>     4</span><br><span class="line"><span class="number"> 8 </span>       4</span><br><span class="line"><span class="number"> 84 </span>      4</span><br><span class="line"><span class="number"> 340 </span>     4</span><br><span class="line"><span class="number"> 43 </span>      3</span><br><span class="line"><span class="number"> 269 </span>     3</span><br><span class="line"><span class="number"> 58 </span>      3</span><br><span class="line"><span class="number"> 633 </span>     2</span><br><span class="line"><span class="number"> 167 </span>     2</span><br><span class="line"><span class="number"> 280 </span>     2</span><br><span class="line"><span class="number"> 510 </span>     2</span><br><span class="line"><span class="number"> 90 </span>      2</span><br><span class="line"><span class="number"> 83 </span>      1</span><br><span class="line"><span class="number"> 625 </span>     1</span><br><span class="line"><span class="number"> 376 </span>     1</span><br><span class="line"><span class="number"> 449 </span>     1</span><br><span class="line"><span class="number"> 498 </span>     1</span><br><span class="line"><span class="number"> 588 </span>     1</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p><h3 id="8-Finding-The-Best-Features"><a href="#8-Finding-The-Best-Features" class="headerlink" title="8 Finding The Best Features"></a>8 Finding The Best Features</h3><p>机器学习最重要的工作是变量设计，我们希望能够选用最好的变量。一个方法是单变量特征选择（<em>univariate feature selection</em>），它通过逐个分析那个字段与目标之间的关系强烈。</p><p>同样，<code>sklearn</code>内置的函数<code>SelectKBest</code>能够帮我们筛选出最强的特征。<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">%pylab inline</span><br><span class="line">import numpy as <span class="built_in">np</span></span><br><span class="line">from sklearn.feature_selection import SelectKBest, f_classif</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">predictors = [<span class="string">"Pclass"</span>, <span class="string">"Sex"</span>, <span class="string">"Age"</span>, <span class="string">"SibSp"</span>, <span class="string">"Parch"</span>, <span class="string">"Fare"</span>, <span class="string">"Embarked"</span>, <span class="string">"FamilySize"</span>, <span class="string">"Title"</span>, <span class="string">"FamilyId"</span>]</span><br><span class="line"></span><br><span class="line"># Perform <span class="built_in">feature</span> selection</span><br><span class="line">selector = SelectKBest(f_classif, k=<span class="number">5</span>)</span><br><span class="line">selector.fit(titanic[predictors], titanic[<span class="string">"Survived"</span>])</span><br><span class="line"></span><br><span class="line"># Get the raw p-<span class="built_in">values</span> <span class="keyword">for</span> each <span class="built_in">feature</span>, <span class="keyword">and</span> <span class="built_in">transform</span> from p-<span class="built_in">values</span> into scores</span><br><span class="line">scores = -<span class="built_in">np</span>.log10(selector.pvalues_)</span><br><span class="line"></span><br><span class="line"># Plot the scores.  See how <span class="string">"Pclass"</span>, <span class="string">"Sex"</span>, <span class="string">"Title"</span>, <span class="keyword">and</span> <span class="string">"Fare"</span> are the best?</span><br><span class="line">plt.bar(<span class="built_in">range</span>(len(predictors)), scores)</span><br><span class="line">plt.xticks(<span class="built_in">range</span>(len(predictors)), predictors, rotation='vertical')</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br></pre></td></tr></table></figure></p><p>Output:<br><img src="/img/Improving-your-submission_02.png" alt=""></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Pick only the four best features.</span></span><br><span class="line">predictors = [<span class="string">"Pclass"</span>, <span class="string">"Sex"</span>, <span class="string">"Fare"</span>, <span class="string">"Title"</span>]</span><br><span class="line"></span><br><span class="line">alg3 = RandomForestClassifier(<span class="attribute">random_state</span>=1, <span class="attribute">n_estimators</span>=50, <span class="attribute">min_samples_split</span>=8, <span class="attribute">min_samples_leaf</span>=4)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)</span></span><br><span class="line">scores3 = model_selection.cross_val_score(alg3, titanic[predictors], titanic[<span class="string">"Survived"</span>], <span class="attribute">cv</span>=3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Take the mean of the scores (because we have one for each fold)</span></span><br><span class="line"><span class="builtin-name">print</span>(scores3, scores3.mean())</span><br></pre></td></tr></table></figure><p>Output:<br><figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name">array</span>([ <span class="number">0.78114478</span>,  <span class="number">0.83838384</span>,  <span class="number">0.83164983</span>]), <span class="number">0.81705948372615034</span>)</span><br></pre></td></tr></table></figure></p><h3 id="9-Gradient-Boosting"><a href="#9-Gradient-Boosting" class="headerlink" title="9 Gradient Boosting"></a>9 Gradient Boosting</h3><p>梯度上升决策树是另一种常用的算法（基于<a href="https://en.wikipedia.org/wiki/Gradient_boosting" target="_blank" rel="noopener">gradient boosting classifier</a>）。决策树一棵接一棵训练并不断修正之前的错误。当我们训练过多棵树时会产生过拟合，由于训练集数据量很小，这里限制树的棵树为<code>25</code>。</p><p>另一种防止过拟合的方式是限制决策树的深度，这里我们讲述的深度限为<code>3</code>。然后我们用GBDT算法来训练，看下是效果是不是比随机森林要好。</p><h3 id="10-Ensembling"><a href="#10-Ensembling" class="headerlink" title="10 Ensembling"></a>10 Ensembling</h3><p>另一个提升预测精度的方法是混合使用不同的分类器，而不仅仅是一种。通常情况下，模型种类越多，预测得越准确。模型多样化意味着利用更多不同的特征字段、或显著的算法差异性。混合决策树和随机森林提升效果不明显，因为两者本质类似，但是用线性回归和随机森林混合就可能很有效。</p><p>混合的前提是所使用的分类器模型在精准度上没有显著差异，否则会使混合后的效果更差。</p><p>在本章节中，我们会混合基于某些存在线性关系字段的逻辑回归和基于所有预测因素的梯度上升算法。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble import GradientBoostingClassifier</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment"># The algorithms we want to ensemble.</span></span><br><span class="line"><span class="comment"># We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.</span></span><br><span class="line">algorithms = [</span><br><span class="line">    [GradientBoostingClassifier(<span class="attribute">random_state</span>=1, <span class="attribute">n_estimators</span>=25, <span class="attribute">max_depth</span>=3), [<span class="string">"Pclass"</span>, <span class="string">"Sex"</span>, <span class="string">"Age"</span>, <span class="string">"Fare"</span>, <span class="string">"Embarked"</span>, <span class="string">"FamilySize"</span>, <span class="string">"Title"</span>, <span class="string">"FamilyId"</span>]],</span><br><span class="line">    [LogisticRegression(<span class="attribute">random_state</span>=1), [<span class="string">"Pclass"</span>, <span class="string">"Sex"</span>, <span class="string">"Fare"</span>, <span class="string">"FamilySize"</span>, <span class="string">"Title"</span>, <span class="string">"Age"</span>, <span class="string">"Embarked"</span>]]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize the cross validation folds</span></span><br><span class="line">kf = KFold(<span class="attribute">n_splits</span>=3, <span class="attribute">random_state</span>=1).split(titanic)</span><br><span class="line"></span><br><span class="line">predictions = []</span><br><span class="line"><span class="keyword">for</span> train, test <span class="keyword">in</span> kf:</span><br><span class="line">    train_target = titanic[<span class="string">"Survived"</span>].iloc[train]</span><br><span class="line">    full_test_predictions = []</span><br><span class="line">    # Make predictions <span class="keyword">for</span> each algorithm on each fold</span><br><span class="line">    <span class="keyword">for</span> alg, predictors <span class="keyword">in</span> algorithms:</span><br><span class="line">        # Fit the algorithm on the training data.</span><br><span class="line">        alg.fit(titanic[predictors].iloc[train,:], train_target)</span><br><span class="line">        # Select <span class="keyword">and</span> predict on the test fold.  </span><br><span class="line">        # The .astype(float) is necessary <span class="keyword">to</span> convert the dataframe <span class="keyword">to</span> all floats <span class="keyword">and</span> avoid an sklearn error.</span><br><span class="line">        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]</span><br><span class="line">        full_test_predictions.append(test_predictions)</span><br><span class="line">    # Use a<span class="built_in"> simple </span>ensembling scheme -- just average the predictions <span class="keyword">to</span> <span class="builtin-name">get</span> the final classification.</span><br><span class="line">    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2</span><br><span class="line">    # Any value over .5 is assumed <span class="keyword">to</span> be a 1 prediction, <span class="keyword">and</span> below .5 is a 0 prediction.</span><br><span class="line">    test_predictions[test_predictions &lt;= .5] = 0</span><br><span class="line">    test_predictions[test_predictions &gt; .5] = 1</span><br><span class="line">    predictions.append(test_predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Put all the predictions together into one array.</span></span><br><span class="line">predictions = np.concatenate(predictions, <span class="attribute">axis</span>=0)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute accuracy by comparing to the training data.</span></span><br><span class="line">accuracy = sum(predictions == titanic[<span class="string">"Survived"</span>]) / len(predictions)</span><br><span class="line"><span class="builtin-name">print</span>(accuracy)</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0<span class="selector-class">.819304152637</span></span><br></pre></td></tr></table></figure></p><h3 id="11-Matching-Our-Changes-On-The-Test-Set"><a href="#11-Matching-Our-Changes-On-The-Test-Set" class="headerlink" title="11 Matching Our Changes On The Test Set"></a>11 Matching Our Changes On The Test Set</h3><p>现在让我们限提交截止为止学到的内容。首先需要对测试数据集进行同样的加工，生成四个新变量<code>NameLength</code>、<code>FamilySize</code>、<code>Title</code>、<code>FamilyId</code>。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># First, we'll add titles to the test set.</span></span><br><span class="line">titles = titanic_test[<span class="string">"Name"</span>].apply(get_title)</span><br><span class="line"><span class="comment"># We're adding the Dona title to the mapping, because it's in the test set, but not the training set</span></span><br><span class="line">title_mapping = &#123;<span class="string">"Mr"</span>: 1, <span class="string">"Miss"</span>: 2, <span class="string">"Mrs"</span>: 3, <span class="string">"Master"</span>: 4, <span class="string">"Dr"</span>: 5, <span class="string">"Rev"</span>: 6, <span class="string">"Major"</span>: 7, <span class="string">"Col"</span>: 7, <span class="string">"Mlle"</span>: 8, <span class="string">"Mme"</span>: 8, <span class="string">"Don"</span>: 9, <span class="string">"Lady"</span>: 10, <span class="string">"Countess"</span>: 10, <span class="string">"Jonkheer"</span>: 10, <span class="string">"Sir"</span>: 9, <span class="string">"Capt"</span>: 7, <span class="string">"Ms"</span>: 2, <span class="string">"Dona"</span>: 10&#125;</span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> title_mapping.items():</span><br><span class="line">    titles[titles == k] = v</span><br><span class="line">titanic_test[<span class="string">"Title"</span>] = titles</span><br><span class="line"><span class="comment"># Check the counts of each unique title.</span></span><br><span class="line"><span class="builtin-name">print</span>(pandas.value_counts(titanic_test[<span class="string">"Title"</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we add the family size column.</span></span><br><span class="line">titanic_test[<span class="string">"FamilySize"</span>] = titanic_test[<span class="string">"SibSp"</span>] + titanic_test[<span class="string">"Parch"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now we can add family ids.</span></span><br><span class="line"><span class="comment"># We'll use the same ids that we did earlier.</span></span><br><span class="line"><span class="builtin-name">print</span>(family_id_mapping)</span><br><span class="line"></span><br><span class="line">family_ids = titanic_test.apply(get_family_id, <span class="attribute">axis</span>=1)</span><br><span class="line">family_ids[titanic_test[<span class="string">"FamilySize"</span>] &lt; 3] = -1</span><br><span class="line">titanic_test[<span class="string">"FamilyId"</span>] = family_ids</span><br><span class="line">titanic_test[<span class="string">"NameLength"</span>] = titanic_test[<span class="string">"Name"</span>].apply(lambda x: len(x))</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>     <span class="number">240</span></span><br><span class="line"><span class="number">2</span>      <span class="number">79</span></span><br><span class="line"><span class="number">3</span>      <span class="number">72</span></span><br><span class="line"><span class="number">4</span>      <span class="number">21</span></span><br><span class="line"><span class="number">7</span>       <span class="number">2</span></span><br><span class="line"><span class="number">6</span>       <span class="number">2</span></span><br><span class="line"><span class="number">10</span>      <span class="number">1</span></span><br><span class="line"><span class="number">5</span>       <span class="number">1</span></span><br><span class="line"><span class="string">Name:</span> Title, <span class="string">dtype:</span> int64</span><br><span class="line">&#123;<span class="string">"O'Sullivan0"</span>: <span class="number">426</span>, <span class="string">'Mangan0'</span>: <span class="number">620</span>, <span class="string">'Lindqvist1'</span>: <span class="number">543</span>, <span class="string">'Denkoff0'</span>: <span class="number">297</span>, <span class="string">'Rouse0'</span>: <span class="number">413</span>, <span class="string">'Berglund0'</span>: <span class="number">207</span>, <span class="string">'Meo0'</span>: <span class="number">142</span>, <span class="string">'Arnold-Franchi1'</span>: <span class="number">49</span>, <span class="string">'Chronopoulos1'</span>: <span class="number">71</span>, <span class="string">'Skoog5'</span>: <span class="number">63</span>, <span class="string">'Widener2'</span>: <span class="number">329</span>, <span class="string">'Pengelly0'</span>: <span class="number">217</span>, <span class="string">'Goncalves0'</span>: <span class="number">400</span>, <span class="string">'Myhrman0'</span>: <span class="number">626</span>, <span class="string">'Beane1'</span>: <span class="number">456</span>, <span class="string">'Moss0'</span>: <span class="number">104</span>, <span class="string">'Carlsson0'</span>: <span class="number">610</span>, <span class="string">'Nicholls2'</span>: <span class="number">136</span>, <span class="string">'Jussila1'</span>: <span class="number">110</span>, <span class="string">'Jussila0'</span>: <span class="number">483</span>, <span class="string">'Long0'</span>: <span class="number">632</span>, <span class="string">'Wheadon0'</span>: <span class="number">33</span>, <span class="string">'Connolly0'</span>: <span class="number">261</span>, <span class="string">'Hansen2'</span>: <span class="number">680</span>, <span class="string">'Stephenson1'</span>: <span class="number">493</span>, <span class="string">'Davies0'</span>: <span class="number">336</span>, <span class="string">'Silven2'</span>: <span class="number">359</span>, ...</span><br></pre></td></tr></table></figure></p><h3 id="12-Predicting-On-The-Test-Set"><a href="#12-Predicting-On-The-Test-Set" class="headerlink" title="12 Predicting On The Test Set"></a>12 Predicting On The Test Set</h3><p>创建第二个submission文件。<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">predictors = [<span class="string">"Pclass"</span>, <span class="string">"Sex"</span>, <span class="string">"Age"</span>, <span class="string">"Fare"</span>, <span class="string">"Embarked"</span>, <span class="string">"FamilySize"</span>, <span class="string">"Title"</span>, <span class="string">"FamilyId"</span>]</span><br><span class="line"></span><br><span class="line">algorithms = [</span><br><span class="line">    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],</span><br><span class="line">    [LogisticRegression(random_state=1), [<span class="string">"Pclass"</span>, <span class="string">"Sex"</span>, <span class="string">"Fare"</span>, <span class="string">"FamilySize"</span>, <span class="string">"Title"</span>, <span class="string">"Age"</span>, <span class="string">"Embarked"</span>]]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">full_predictions = []</span><br><span class="line">for alg, predictors in algorithms:</span><br><span class="line">    <span class="comment"># Fit the algorithm using the full training data.</span></span><br><span class="line">    alg.fit(titanic[predictors], titanic[<span class="string">"Survived"</span>])</span><br><span class="line">    <span class="comment"># Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.</span></span><br><span class="line">    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]</span><br><span class="line">    full_predictions.append(predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The gradient boosting classifier generates better predictions, so we weight it higher.</span></span><br><span class="line">predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4</span><br><span class="line"></span><br><span class="line">predictions[predictions &lt;= .5] = 0</span><br><span class="line">predictions[predictions &gt; .5] = 1</span><br><span class="line">predictions = predictions.astype(int)</span><br><span class="line">submission = pandas.DataFrame(&#123;</span><br><span class="line">        <span class="string">"PassengerId"</span>: titanic_test[<span class="string">"PassengerId"</span>],</span><br><span class="line">        <span class="string">"Survived"</span>: predictions</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure></p><p>这里注意要将<code>predictions</code>用<code>.astype(int)</code>方法转换为整型，负责Kaggle会给你0分。</p><h3 id="13-Final-Thoughts"><a href="#13-Final-Thoughts" class="headerlink" title="13 Final Thoughts"></a>13 Final Thoughts</h3><p>完成，现在你有了个大约能得到<code>799</code>分的模型。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">submission.to_csv(<span class="string">"kaggle2.csv"</span>, <span class="attribute">index</span>=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p><p><img src="/img/Improving-your-submission_03.png" alt=""></p><p>下一步，变量优化：</p><ul><li>尝试衍生于<code>Cabin</code>相关的变量</li><li>进一步挖掘关于家庭人数的变量——家庭中妇女的数量（比例）是否对整个家庭的存活有关系？</li><li>乘客的国籍是否会对预测有帮助？</li></ul><p>算法优化：</p><ul><li>尝试混合使用随机森林</li><li>支持向量机可能在该问题上很有效果</li><li>也可以试下神经网络</li><li>使用其他基础分类器来提升可能有效</li></ul><p>模型混合：</p><ul><li>majority voting是否比平均概率要好？</li></ul><p><code>titanic</code>这个案例因为数据量较小，很容易产生过拟合，接下来你可以尝试Kaggle上的其他竞赛，它们有更大的数据量和更多的变量可供挖掘分析。</p><p>Hope you enjoyed this tutorial, and good luck with the machine learning competitions!</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;1-Improving-Our-Features&quot;&gt;&lt;a href=&quot;#1-Improving-Our-Features&quot; class=&quot;headerlink&quot; title=&quot;1 Improving Our Features&quot;&gt;&lt;/a&gt;1 Improving Ou</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Kaggle" scheme="http://gloomymoon.github.io/tags/Kaggle/"/>
    
    <category term="Machine Learning" scheme="http://gloomymoon.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Getting started with Kaggle</title>
    <link href="http://gloomymoon.github.io/2016/10/29/Getting-started-with-Kaggle/"/>
    <id>http://gloomymoon.github.io/2016/10/29/Getting-started-with-Kaggle/</id>
    <published>2016-10-29T13:31:31.000Z</published>
    <updated>2016-10-30T06:47:35.500Z</updated>
    
    <content type="html"><![CDATA[<h3 id="0-Preface"><a href="#0-Preface" class="headerlink" title="0 Preface"></a>0 Preface</h3><p><a href="https://www.dataquest.io/dashboard" target="_blank" rel="noopener">dataquest.io</a>是一个在线学习数据科学的网站，内容涵盖Python、数据分析、数据可视化、统计学、机器学习、大数据工具、R等内容，并提供在线交互式编程环境，今天我们先来学习Kaggle的一个入门教程：<a href="https://www.dataquest.io/mission/74/getting-started-with-kaggle" target="_blank" rel="noopener">Getting started with Kaggle</a></p><h3 id="1-The-Competition"><a href="#1-The-Competition" class="headerlink" title="1 The Competition"></a>1 The Competition</h3><p>首先我们从Kaggle上最简单的题目入手：<a href="https://www.kaggle.com/c/titanic" target="_blank" rel="noopener">Titanic: Machine Learning from Disaster</a>，预测Titanic号上乘客的幸存情况，在这个教程中，我们首先浏览数据，然后训练第一个模型。</p><p>数据是<code>.csv</code>格式的，环境使用本地的Jupyter Notebook。首先需要下载训练和验证数据集：<a href="https://www.kaggle.com/c/titanic/download/train.csv" target="_blank" rel="noopener">train.csv</a>和<a href="https://www.kaggle.com/c/titanic/download/test.csv" target="_blank" rel="noopener">test.csv</a>，这两个文件格式相同，每一行数据代表Titanic号上的一名乘客，包含的字段如下：</p><ul><li><code>PassengerId</code> 唯一的乘客号</li><li><code>Survived</code> 表示乘客是（1）否(0)幸存，也是我们需要预测的目标值</li><li><code>Pclass</code> 乘客所住舱位等级，分为1、2、3，1最高</li><li><code>Name</code> 乘客的姓名</li><li><code>Sex</code> 乘客的性别，male或female</li><li><code>Age</code> 乘客的年龄，有缺失</li><li><code>SibSp</code> 乘客在船上的兄弟或配偶数</li><li><code>Parch</code> 乘客在船上的父母或子女数</li><li><code>Ticket</code> 乘客的船票号码</li><li><code>Fare</code> 乘客船票的票价</li><li><code>Cabin</code> 乘客所住的船舱号</li><li><code>Embarked</code> 乘客登船地点</li></ul><p>建模前首先需要学习领域知识，思考下那些变量可能与我们需要预测的目标存在关联。了解Titanic号事件的背景知识肯定会对此有所助益。</p><p>通常来说妇女和儿童更容易幸存，因此<code>Age</code>和<code>Sex</code>是较显著的预测变量。舱位等级也可能对目标产生影响，因为头等舱更加靠近甲板，票价和舱位等级相关，因此也很有用。同伴数（包括兄弟、配偶、父母、子女）可能也会有关，因为同伴越多意味着帮助你的人越多。</p><p>其他诸如<code>Name</code>、<code>Ticket</code>、<code>Embarked</code>可能就与目标没有什么关联。</p><h3 id="2-Looking-At-The-Data"><a href="#2-Looking-At-The-Data" class="headerlink" title="2 Looking At The Data"></a>2 Looking At The Data</h3><p>了解训练数据的概貌是一个不错的开始，这里我们使用pandas的<code>.discribe()</code>方法来查看下不同变量的特征和分布。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import pandas</span><br><span class="line"><span class="comment"># We can use the pandas library in python to read in the csv file.</span></span><br><span class="line"><span class="comment"># This creates a pandas dataframe and assigns it to the titanic variable.</span></span><br><span class="line">titanic = pandas.read_csv(<span class="string">"train.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the first 5 rows of the dataframe.</span></span><br><span class="line"><span class="builtin-name">print</span>(titanic.head(5))</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(titanic.describe())</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">   PassengerId  Survived  Pclass  \</span><br><span class="line"><span class="number">0</span>            <span class="number">1</span>         <span class="number">0</span>       <span class="number">3</span>   </span><br><span class="line"><span class="number">1</span>            <span class="number">2</span>         <span class="number">1</span>       <span class="number">1</span>   </span><br><span class="line"><span class="number">2</span>            <span class="number">3</span>         <span class="number">1</span>       <span class="number">3</span>   </span><br><span class="line"><span class="number">3</span>            <span class="number">4</span>         <span class="number">1</span>       <span class="number">1</span>   </span><br><span class="line"><span class="number">4</span>            <span class="number">5</span>         <span class="number">0</span>       <span class="number">3</span>   </span><br><span class="line"></span><br><span class="line">                                                Name     Sex   Age  SibSp  \</span><br><span class="line"><span class="number">0</span>                            Braund, Mr. Owen Harris    male  <span class="number">22.0</span>      <span class="number">1</span>   </span><br><span class="line"><span class="number">1</span>  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  <span class="number">38.0</span>      <span class="number">1</span>   </span><br><span class="line"><span class="number">2</span>                             Heikkinen, Miss. Laina  female  <span class="number">26.0</span>      <span class="number">0</span>   </span><br><span class="line"><span class="number">3</span>       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  <span class="number">35.0</span>      <span class="number">1</span>   </span><br><span class="line"><span class="number">4</span>                           Allen, Mr. William Henry    male  <span class="number">35.0</span>      <span class="number">0</span>   </span><br><span class="line"></span><br><span class="line">   Parch            Ticket     Fare Cabin Embarked  </span><br><span class="line"><span class="number">0</span>      <span class="number">0</span>         A/<span class="number">5</span> <span class="number">21171</span>   <span class="number">7.2500</span>   NaN        S  </span><br><span class="line"><span class="number">1</span>      <span class="number">0</span>          PC <span class="number">17599</span>  <span class="number">71.2833</span>   C85        C  </span><br><span class="line"><span class="number">2</span>      <span class="number">0</span>  STON/O2. <span class="number">3101282</span>   <span class="number">7.9250</span>   NaN        S  </span><br><span class="line"><span class="number">3</span>      <span class="number">0</span>            <span class="number">113803</span>  <span class="number">53.1000</span>  C123        S  </span><br><span class="line"><span class="number">4</span>      <span class="number">0</span>            <span class="number">373450</span>   <span class="number">8.0500</span>   NaN        S  </span><br><span class="line">       PassengerId    Survived      Pclass         Age       SibSp  \</span><br><span class="line">count   <span class="number">891.000000</span>  <span class="number">891.000000</span>  <span class="number">891.000000</span>  <span class="number">714.000000</span>  <span class="number">891.000000</span>   </span><br><span class="line">mean    <span class="number">446.000000</span>    <span class="number">0.383838</span>    <span class="number">2.308642</span>   <span class="number">29.699118</span>    <span class="number">0.523008</span>   </span><br><span class="line">std     <span class="number">257.353842</span>    <span class="number">0.486592</span>    <span class="number">0.836071</span>   <span class="number">14.526497</span>    <span class="number">1.102743</span>   </span><br><span class="line">min       <span class="number">1.000000</span>    <span class="number">0.000000</span>    <span class="number">1.000000</span>    <span class="number">0.420000</span>    <span class="number">0.000000</span>   </span><br><span class="line"><span class="number">25</span>%     <span class="number">223.500000</span>    <span class="number">0.000000</span>    <span class="number">2.000000</span>         NaN    <span class="number">0.000000</span>   </span><br><span class="line"><span class="number">50</span>%     <span class="number">446.000000</span>    <span class="number">0.000000</span>    <span class="number">3.000000</span>         NaN    <span class="number">0.000000</span>   </span><br><span class="line"><span class="number">75</span>%     <span class="number">668.500000</span>    <span class="number">1.000000</span>    <span class="number">3.000000</span>         NaN    <span class="number">1.000000</span>   </span><br><span class="line">max     <span class="number">891.000000</span>    <span class="number">1.000000</span>    <span class="number">3.000000</span>   <span class="number">80.000000</span>    <span class="number">8.000000</span>   </span><br><span class="line"></span><br><span class="line">            Parch        Fare  </span><br><span class="line">count  <span class="number">891.000000</span>  <span class="number">891.000000</span>  </span><br><span class="line">mean     <span class="number">0.381594</span>   <span class="number">32.204208</span>  </span><br><span class="line">std      <span class="number">0.806057</span>   <span class="number">49.693429</span>  </span><br><span class="line">min      <span class="number">0.000000</span>    <span class="number">0.000000</span>  </span><br><span class="line"><span class="number">25</span>%      <span class="number">0.000000</span>    <span class="number">7.910400</span>  </span><br><span class="line"><span class="number">50</span>%      <span class="number">0.000000</span>   <span class="number">14.454200</span>  </span><br><span class="line"><span class="number">75</span>%      <span class="number">0.000000</span>   <span class="number">31.000000</span>  </span><br><span class="line">max      <span class="number">6.000000</span>  <span class="number">512.329200</span></span><br></pre></td></tr></table></figure></p><h3 id="3-Missing-Data"><a href="#3-Missing-Data" class="headerlink" title="3 Missing Data"></a>3 Missing Data</h3><p>从上一步中可以看到<code>Age</code>字段计数只有<code>714</code>，而其他字段都有<code>891</code>个，意味着该字段存在缺失。<code>Age</code>字段仍然有用，我们不能因为有部分记录缺失就完全抛弃它，一个比较简单的数据清洗方式是为所有缺失值赋一个固定值，比如说所有非缺失值的中位数。<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">titanic[<span class="string">"Age"</span>] =titanic[<span class="string">"Age"</span>].fillna(titanic[<span class="string">"Age"</span>].median())</span><br></pre></td></tr></table></figure></p><h3 id="4-Non-numeric-Columns"><a href="#4-Non-numeric-Columns" class="headerlink" title="4 Non-numeric Columns"></a>4 Non-numeric Columns</h3><p>除了<code>Age</code>字段存在缺失以外，我们还发现通过<code>.describe()</code>方法显示的数据概貌信息中并没有显示所有的字段，仅显示了数值型字段。非数值型字段无法在预测模型生效，因为机器学习算法只接受数值型变量，因此要找一个将我们需要的字段转换成数值型的方法。<code>Ticket</code>、<code>Cabin</code>、<code>Name</code>暂时在我们抛弃的列表中。</p><h3 id="5-Converting-The-Sex-Column"><a href="#5-Converting-The-Sex-Column" class="headerlink" title="5 Converting The Sex Column"></a>5 Converting The Sex Column</h3><p><code>Sex</code>是一个我们希望保留的非数值型变量，我们可以将每一个性别类型用一个数值表示。<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Find <span class="keyword">all</span> the unique genders -- the column appears <span class="keyword">to</span> contain <span class="keyword">only</span> male <span class="built_in">and</span> female.</span><br><span class="line"><span class="keyword">print</span>(titanic[<span class="string">"Sex"</span>].unique())</span><br><span class="line"></span><br><span class="line"># Replace <span class="keyword">all</span> the occurences of male with the <span class="keyword">number</span> <span class="number">0</span>.</span><br><span class="line">titanic.<span class="keyword">loc</span>[titanic[<span class="string">"Sex"</span>] == <span class="string">"male"</span>, <span class="string">"Sex"</span>] = <span class="number">0</span></span><br><span class="line">titanic.<span class="keyword">loc</span>[titanic[<span class="string">"Sex"</span>] == <span class="string">"female"</span>, <span class="string">"Sex"</span>] = <span class="number">1</span></span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">'male</span>' <span class="symbol">'female</span>']</span><br></pre></td></tr></table></figure></p><h3 id="6-Converting-The-Embarked-Column"><a href="#6-Converting-The-Embarked-Column" class="headerlink" title="6 Converting The Embarked Column"></a>6 Converting The Embarked Column</h3><p>我们可以使用与之前类似的方式来处理<code>Embarked</code>字段，出现最多的取值为<code>S</code>，我们可以将缺失值全赋为<code>S</code>。然后将<code>S</code>转化为<code>0</code>，<code>C</code>转化为<code>1</code>、<code>Q</code>转化为<code>2</code>。<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># <span class="symbol">Find</span> all the unique values for <span class="string">"Embarked"</span>.</span><br><span class="line">print(titanic[<span class="string">"Embarked"</span>].unique())</span><br><span class="line"></span><br><span class="line">titanic[<span class="string">"Embarked"</span>] = titanic[<span class="string">"Embarked"</span>].fillna(<span class="string">'S'</span>)</span><br><span class="line">titanic.loc[titanic[<span class="string">"Embarked"</span>] == <span class="string">"S"</span>, <span class="string">"Embarked"</span>] = <span class="number">0</span></span><br><span class="line">titanic.loc[titanic[<span class="string">"Embarked"</span>] == <span class="string">"C"</span>, <span class="string">"Embarked"</span>] = <span class="number">1</span></span><br><span class="line">titanic.loc[titanic[<span class="string">"Embarked"</span>] == <span class="string">"Q"</span>, <span class="string">"Embarked"</span>] = <span class="number">2</span></span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">'S</span>' <span class="symbol">'C</span>' <span class="symbol">'Q</span>' nan]</span><br></pre></td></tr></table></figure></p><h3 id="7-On-To-Machine-Learning"><a href="#7-On-To-Machine-Learning" class="headerlink" title="7 On To Machine Learning!"></a>7 On To Machine Learning!</h3><p>原文这里介绍线性回归，比较简单不再展开，线性回归有两个问题：</p><ul><li>如果变量和目标非线性相关，那么线性回归方法效果不好</li><li>线性回归无法给出每个人的幸存率，只能给出是否幸存（即01标识）</li></ul><h3 id="8-Cross-Validation"><a href="#8-Cross-Validation" class="headerlink" title="8 Cross Validation"></a>8 Cross Validation</h3><p>为了避免模型的过度拟合，我们需要尽可能在不同的数据上进行训练，然后再独立的测试集上进行验证。交叉检验就是一个简单的避免过度拟合的方法，我们可以将训练集分成几个部分。</p><p>例如将数据分成3份，然后：</p><ul><li>在第1、2份上训练，用第3份验证</li><li>在第1、3份上训练，用第2份验证</li><li>在第2、3份上寻良，用第1份验证</li></ul><h3 id="9-Making-Predictions"><a href="#9-Making-Predictions" class="headerlink" title="9 Making Predictions"></a>9 Making Predictions</h3><p>我们使用优秀的<code>scikit-learn</code>包来建立预测模型，使用<code>KFold</code>将数据切分用于交叉检验，然后按照#8中的步骤进行建模。<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import the linear regression class</span></span><br><span class="line">from sklearn.linear_model <span class="built_in">import</span> LinearRegression</span><br><span class="line"><span class="comment"># Sklearn also has a helper that makes it easy to do cross validation</span></span><br><span class="line">from sklearn.cross_validation <span class="built_in">import</span> KFold</span><br><span class="line"></span><br><span class="line"><span class="comment"># The columns we'll use to predict the target</span></span><br><span class="line"><span class="attr">predictors</span> = [<span class="string">"Pclass"</span>, <span class="string">"Sex"</span>, <span class="string">"Age"</span>, <span class="string">"SibSp"</span>, <span class="string">"Parch"</span>, <span class="string">"Fare"</span>, <span class="string">"Embarked"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize our algorithm class</span></span><br><span class="line"><span class="attr">alg</span> = LinearRegression()</span><br><span class="line"><span class="comment"># Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.</span></span><br><span class="line"><span class="comment"># We set random_state to ensure we get the same splits every time we run this.</span></span><br><span class="line"><span class="attr">kf</span> = KFold(<span class="attr">n_splits=3,</span> <span class="attr">random_state=1).split(titanic)</span></span><br><span class="line"></span><br><span class="line"><span class="attr">predictions</span> = []</span><br><span class="line">for train, test <span class="keyword">in</span> kf:</span><br><span class="line">    <span class="comment"># The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.</span></span><br><span class="line">    <span class="attr">train_predictors</span> = (titanic[predictors].iloc[train,:])</span><br><span class="line">    <span class="comment"># The target we're using to train the algorithm.</span></span><br><span class="line">    <span class="attr">train_target</span> = titanic[<span class="string">"Survived"</span>].iloc[train]</span><br><span class="line">    <span class="comment"># Training the algorithm using the predictors and target.</span></span><br><span class="line">    alg.fit(train_predictors, train_target)</span><br><span class="line">    <span class="comment"># We can now make predictions on the test fold</span></span><br><span class="line">    <span class="attr">test_predictions</span> = alg.predict(titanic[predictors].iloc[test,:])</span><br><span class="line">    predictions.append(test_predictions)</span><br></pre></td></tr></table></figure></p><p>注意这里<code>KFold</code>使用方法和原文中的不同，是因为在<code>sklearn 0.18</code>版本中<code>sklearn.cross_validation</code>已经更新为<code>sklearn.model_selection</code>，<code>KFold</code>的<a href="http://scikit-learn.org/stable/whats_new.html" target="_blank" rel="noopener">使用方法</a>有所改变。</p><h3 id="10-Evaludating-Error"><a href="#10-Evaludating-Error" class="headerlink" title="10 Evaludating Error"></a>10 Evaludating Error</h3><p>接下来就能够检验一下我们模型的预测结果，根据Kaggle竞赛的规则，衡量模型结果的指标是正确预测结果的比率，我们也使用这个指标来评估我们的模型。</p><p>预测结果字段为<code>predictions</code>，只要简单比较一下和<code>titanic[&quot;Survived&quot;]</code>相同的量，然后再除以总人数即可。<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from __future__ import division</span><br><span class="line">accuracy = sum(<span class="name">predictions</span> == titanic[<span class="string">"Survived"</span>]) / len(<span class="name">predictions</span>)</span><br><span class="line">print accuracy</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0<span class="selector-class">.783389450056</span></span><br></pre></td></tr></table></figure></p><h3 id="11-Logistic-regression"><a href="#11-Logistic-regression" class="headerlink" title="11 Logistic regression"></a>11 Logistic regression</h3><p>第一个预测模型完成了，看上去效果不是很好，准确率只有<code>78.3%</code>。我们可以使用逻辑回归将输出转换为<code>0</code>到<code>1</code>之间（也就是概率）。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn import model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model import LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize our algorithm</span></span><br><span class="line">alg = LogisticRegression(<span class="attribute">random_state</span>=1)</span><br><span class="line"><span class="comment"># Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)</span></span><br><span class="line">scores = model_selection.cross_val_score(alg, titanic[predictors], titanic[<span class="string">"Survived"</span>], <span class="attribute">cv</span>=3)</span><br><span class="line"><span class="comment"># Take the mean of the scores (because we have one for each fold)</span></span><br><span class="line"><span class="builtin-name">print</span>(scores.mean())</span><br></pre></td></tr></table></figure></p><p>Output:<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0<span class="selector-class">.787878787879</span></span><br></pre></td></tr></table></figure></p><h3 id="12-Processing-The-Test-Set"><a href="#12-Processing-The-Test-Set" class="headerlink" title="12 Processing The Test Set"></a>12 Processing The Test Set</h3><p>现在预测的准确度有所提升，但是还不够好，在我们进一步优化前先要掌握提交我们的模型给Kaggle。</p><p>测试数据集一样需要预先清洗，注意给<code>Age</code>赋缺失值时需要使用训练集的中位数，另外测试集中<code>Fare</code>也存在缺失值，因此也要赋给一个新的值。<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">titanic_test = pandas.read_csv(<span class="string">"test.csv"</span>)</span><br><span class="line">titanic_test[<span class="string">"Age"</span>] =titanic_test[<span class="string">"Age"</span>].fillna(titanic[<span class="string">"Age"</span>].median())</span><br><span class="line">titanic_test.loc[titanic_test[<span class="string">"Sex"</span>] == <span class="string">"male"</span>, <span class="string">"Sex"</span>] = <span class="number">0</span></span><br><span class="line">titanic_test.loc[titanic_test[<span class="string">"Sex"</span>] == <span class="string">"female"</span>, <span class="string">"Sex"</span>] = <span class="number">1</span></span><br><span class="line">titanic_test[<span class="string">"Embarked"</span>] = titanic_test[<span class="string">"Embarked"</span>].fillna(<span class="string">'S'</span>)</span><br><span class="line">titanic_test.loc[titanic_test[<span class="string">"Embarked"</span>] == <span class="string">"S"</span>, <span class="string">"Embarked"</span>] = <span class="number">0</span></span><br><span class="line">titanic_test.loc[titanic_test[<span class="string">"Embarked"</span>] == <span class="string">"C"</span>, <span class="string">"Embarked"</span>] = <span class="number">1</span></span><br><span class="line">titanic_test.loc[titanic_test[<span class="string">"Embarked"</span>] == <span class="string">"Q"</span>, <span class="string">"Embarked"</span>] = <span class="number">2</span></span><br><span class="line">titanic_test[<span class="string">"Fare"</span>] =titanic_test[<span class="string">"Fare"</span>].fillna(titanic[<span class="string">"Fare"</span>].median())</span><br></pre></td></tr></table></figure></p><h3 id="13-Generating-A-Submission-File"><a href="#13-Generating-A-Submission-File" class="headerlink" title="13 Generating A Submission File"></a>13 Generating A Submission File</h3><p>现在我们已经在训练集上建立了一个模型，并且可以在测试集上进行预测。最终我们将预测结果生成一个<code>csv</code>文件，使用<code>submission.to_csv(&quot;Kaggle.csv&quot;, index=False)</code>方法即可产生一个最终提交的<code>csv</code>文件。</p><h3 id="14-Next-Steps"><a href="#14-Next-Steps" class="headerlink" title="14 Next Steps"></a>14 Next Steps</h3><p>进入<a href="https://www.kaggle.com/c/titanic/submissions/attach" target="_blank" rel="noopener">Make a submission</a>页面，将我们生成的<code>csv</code>文件上传：<br><img src="/img/Getting-started-with-Kaggle_01.png" alt=""><br>点击<code>Submit</code>按钮就能够看到成绩：<br><img src="/img/Getting-started-with-Kaggle_02.png" alt=""></p><p>恭喜你已经成功提交了第一个Kaggle模型，后面我们会进一步学习如何来优化模型提升得分。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;0-Preface&quot;&gt;&lt;a href=&quot;#0-Preface&quot; class=&quot;headerlink&quot; title=&quot;0 Preface&quot;&gt;&lt;/a&gt;0 Preface&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://www.dataquest.io/dashboar</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
    <category term="Kaggle" scheme="http://gloomymoon.github.io/tags/Kaggle/"/>
    
    <category term="Machine Learning" scheme="http://gloomymoon.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Convert PDF to Images using Python</title>
    <link href="http://gloomymoon.github.io/2016/10/27/Convert-PDF-to-Images-using-Python/"/>
    <id>http://gloomymoon.github.io/2016/10/27/Convert-PDF-to-Images-using-Python/</id>
    <published>2016-10-27T13:09:19.000Z</published>
    <updated>2016-10-27T15:09:41.266Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Install-GhostScript"><a href="#1-Install-GhostScript" class="headerlink" title="1 Install GhostScript"></a>1 Install GhostScript</h2><p>从<a href="http://ghostscript.com/" target="_blank" rel="noopener">GhostScript</a>官网下载<a href="https://github.com/ArtifexSoftware/ghostpdl-downloads/releases/download/gs920/gs920w32.exe" target="_blank" rel="noopener">Ghostscript 9.20 for Windows(32bit)安装包</a>，注意即便是64位的系统也请安装32位。安装完成后将<strong>%安装目录\bin</strong>加入到系统Path环境变量，如果使用默认安装的话，则添加：<br><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:<span class="symbol">\P</span>rogram Files (x86)<span class="symbol">\g</span>s<span class="symbol">\g</span>s9.20<span class="symbol">\b</span>in</span><br></pre></td></tr></table></figure></p><h2 id="2-Install-ImageMagick"><a href="#2-Install-ImageMagick" class="headerlink" title="2 Install ImageMagick"></a>2 Install ImageMagick</h2><p>从<a href="http://www.imagemagick.org/" target="_blank" rel="noopener">ImageMagick</a>官网下载<a href="http://www.imagemagick.org/download/binaries/ImageMagick-6.9.6-2-Q16-x86-dll.exe" target="_blank" rel="noopener">ImageMagick 6.9.6-2-Q16-x86 windows 32-bit安装包</a>，安装时请选中 <strong>Install development headers and libraries for C and C++</strong> 选项：<br><img src="http://docs.wand-py.org/en/latest/_images/windows-setup.png" alt=""><br>安装完之后需要在系统变量里新增<strong>MAGICK_HOME</strong>环境变量，设为ImageMagic安装的路径，如使用默认安装的话，则添加：<br><code>C:\Program Files (x86)\ImageMagick-6.9.6-Q16</code><br>同时也需要将该目录加入系统Path环境变量。</p><h2 id="3-Install-PythonMagic"><a href="#3-Install-PythonMagic" class="headerlink" title="3 Install PythonMagic"></a>3 Install PythonMagic</h2><p>从<a href="http://www.lfd.uci.edu/~gohlke/pythonlibs" target="_blank" rel="noopener">Unofficial WIndows Binaries for Python Extension Packages</a>页面下载与编译好的<a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/dp2ng7en/PythonMagick-0.9.10-cp27-none-win32.whl" target="_blank" rel="noopener">PythonMagic whl包</a>，然后使用pip install安装，不要直接使用easy_install或pip通过在线下载安装。</p><h2 id="4-Check-if-your-setup-works"><a href="#4-Check-if-your-setup-works" class="headerlink" title="4 Check if your setup works"></a>4 Check if your setup works</h2><p>进入命令行，在含有pdf（例如some.pdf文件的目录下输入：<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">convert</span> <span class="built_in">some</span>.pdf <span class="built_in">some</span>.jpg</span><br></pre></td></tr></table></figure></p><p>如果能够成功看到some.jpg文件生成（若pdf有多页，则会看到some-0.jpg, some-1.jpg…），若报错或者没有图片文件生成，则说前面1～3步安装有问题。</p><h2 id="5-Convert-PDF-to-Images-using-Python"><a href="#5-Convert-PDF-to-Images-using-Python" class="headerlink" title="5 Convert PDF to Images using Python"></a>5 Convert PDF to Images using Python</h2><p>在Python中可以直接使用如下代码进行转化：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PythonMagick <span class="keyword">import</span> Image</span><br><span class="line">image = Image()</span><br><span class="line">image.read(<span class="string">r"C:\Path\To\Some.pdf"</span>)</span><br><span class="line">image.write(<span class="string">"some.jpg"</span>)</span><br></pre></td></tr></table></figure></p><p>若PDF文件有多页，可以使用如下代码（需在安装pyPdf）：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line"><span class="keyword">from</span> pyPdf import PdfFileReader, PdfFileWriter</span><br><span class="line"><span class="keyword">from</span> tempfile import NamedTemporaryFile</span><br><span class="line"><span class="keyword">from</span> PythonMagick import Image</span><br><span class="line"></span><br><span class="line">reader = PdfFileReader(open(<span class="string">"C:\Path\To\Some.pdf"</span>, <span class="string">"rb"</span>))</span><br><span class="line"><span class="keyword">for</span> page_num <span class="keyword">in</span> xrange(reader.getNumPages()):</span><br><span class="line">    writer = PdfFileWriter()</span><br><span class="line">    writer.addPage(reader.getPage(page_num))</span><br><span class="line">    temp = NamedTemporaryFile(<span class="attribute">prefix</span>=str(page_num), <span class="attribute">suffix</span>=<span class="string">".pdf"</span>, <span class="attribute">delete</span>=<span class="literal">False</span>)</span><br><span class="line">    writer.write(temp)</span><br><span class="line">    temp.close()</span><br><span class="line"></span><br><span class="line">    im = Image()</span><br><span class="line">    im.density(<span class="string">"300"</span>) # DPI, <span class="keyword">for</span> better quality</span><br><span class="line">    im.read(temp.name)</span><br><span class="line">    im.write(<span class="string">"some_%d.png"</span> % (page_num))</span><br><span class="line"></span><br><span class="line">    os.<span class="builtin-name">remove</span>(temp.name)</span><br></pre></td></tr></table></figure></p><p>然后便可以快乐地将爬到的70+G乐高图纸转成图片进行分析了:p</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-Install-GhostScript&quot;&gt;&lt;a href=&quot;#1-Install-GhostScript&quot; class=&quot;headerlink&quot; title=&quot;1 Install GhostScript&quot;&gt;&lt;/a&gt;1 Install GhostScript&lt;/</summary>
      
    
    
    
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Building LegoSpyder Part III</title>
    <link href="http://gloomymoon.github.io/2016/10/23/Building-LegoSpyder-Part-III/"/>
    <id>http://gloomymoon.github.io/2016/10/23/Building-LegoSpyder-Part-III/</id>
    <published>2016-10-23T11:53:24.000Z</published>
    <updated>2016-10-25T12:56:47.280Z</updated>
    
    <content type="html"><![CDATA[<h2 id="4-Finish-The-LegoSpyder"><a href="#4-Finish-The-LegoSpyder" class="headerlink" title="4 Finish The LegoSpyder"></a>4 Finish The LegoSpyder</h2><h3 id="4-1-Define-Items"><a href="#4-1-Define-Items" class="headerlink" title="4.1 Define Items"></a>4.1 Define Items</h3><p>通过分析Search API返回的json数据格式，得出的结果数据格式如下：<br><img src="http://yuml.me/diagram/nofunky/class/[Search Result|+count;+moreData;+products;+totalCount;+themeName;+launchYear;]++1->*[Product|+productId;+productName;+productImage], [Product]++1->*[BuildingInstruction|+description;+pdfLocation;+downloadSize;+frontpageInfo;+isAlternative;]"></p><p>考虑到所需要保存的数据和便于下载文件，最终设计的items类如下图：<br><img src="http://yuml.me/diagram/nofunky/class/[LegoBaseItem|+productId;+file_urls;+files;+file_paths]^-[LegoProductItem|+productName;+productImage;+theme;+year;], [LegoBaseItem]^-[LegoBuildingInstructionsItem|+description;]"></p><p>最终items.py的代码如下：<br><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">from</span> scrapy <span class="keyword">import</span> Field, Item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">LegoBaseItem</span>(<span class="type">Item</span>):</span></span><br><span class="line"><span class="class">    productId = <span class="type">Field</span>()</span></span><br><span class="line"><span class="class">    file_urls = <span class="type">Field</span>()</span></span><br><span class="line"><span class="class">    files = <span class="type">Field</span>()</span></span><br><span class="line"><span class="class">    file_paths = <span class="type">Field</span>()</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">LegoProductItem</span>(<span class="type">LegoBaseItem</span>):</span></span><br><span class="line"><span class="class">    # define the fields for your item here like:</span></span><br><span class="line"><span class="class">    # name = <span class="type">Field</span>()</span></span><br><span class="line"><span class="class">    productName = <span class="type">Field</span>()</span></span><br><span class="line"><span class="class">    productImage = <span class="type">Field</span>()</span></span><br><span class="line"><span class="class">    theme = <span class="type">Field</span>()</span></span><br><span class="line"><span class="class">    year = <span class="type">Field</span>()</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">LegoBuildingInstructionsItem</span>(<span class="type">LegoBaseItem</span>):</span></span><br><span class="line"><span class="class">    description = <span class="type">Field</span>()</span></span><br></pre></td></tr></table></figure></p><h3 id="4-2-Modify-Pipelines"><a href="#4-2-Modify-Pipelines" class="headerlink" title="4.2 Modify Pipelines"></a>4.2 Modify Pipelines</h3><p>因为我们只需要下载图片和PDF，因此可以用一个FilesPipeline搞定，并且为了文档管理需将不同类型的文件存放在不同的目录下，pipelines.py的最终代码修改如下：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LegoFilePipeline</span>(<span class="title">FilesPipeline</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_path</span><span class="params">(<span class="keyword">self</span>, request, response=None, info=None)</span></span><span class="symbol">:</span></span><br><span class="line">        file_guid = request.url.split(<span class="string">'/'</span>)[-<span class="number">1</span>]</span><br><span class="line">        group = request.url.split(<span class="string">'.'</span>)[-<span class="number">1</span>]</span><br><span class="line">        <span class="comment">#group is the subdirectory of the downloaded files or images</span></span><br><span class="line">        <span class="keyword">if</span> group <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'jpg'</span>,<span class="string">'jpeg'</span>,<span class="string">'png'</span>,<span class="string">'gif'</span>,<span class="string">'pdf'</span>]<span class="symbol">:</span></span><br><span class="line">            group = <span class="string">'unknown'</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'%s/%s'</span> % (group, file_guid)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(<span class="keyword">self</span>, item, info)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'file_urls'</span> <span class="keyword">in</span> <span class="symbol">item:</span></span><br><span class="line">            <span class="keyword">for</span> file_url <span class="keyword">in</span> item[<span class="string">'file_urls'</span>]<span class="symbol">:</span></span><br><span class="line">                <span class="keyword">yield</span> Request(file_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span><span class="params">(<span class="keyword">self</span>, results, item, info)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'file_urls'</span> <span class="keyword">in</span> <span class="symbol">item:</span></span><br><span class="line">            file_paths = [x[<span class="string">'path'</span>] <span class="keyword">for</span> ok, x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="symbol">file_paths:</span></span><br><span class="line">                raise DropItem(<span class="string">'File download failed: %s'</span> % file_paths)</span><br><span class="line">            item[<span class="string">'file_paths'</span>] = file_paths</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></p><h3 id="4-3-Refine-the-Spider"><a href="#4-3-Refine-the-Spider" class="headerlink" title="4.3 Refine the Spider"></a>4.3 Refine the Spider</h3><p>最后需要修正spider程序BuildingInstructionSpider.py，使其能够递归循环爬取所有结果中的图片和PDF。由于部分分类下的Product超过10个（一次Search返回的结果数），所以需要根据moreData来判断是否还要继续同条件下的搜索：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BuildingInstructionsSpider</span>(<span class="title">scrapy</span>.<span class="title">Spider</span>):</span></span><br><span class="line">    name = <span class="string">'lego'</span></span><br><span class="line">    search_base_url = <span class="string">"https://wwwsecure.us.lego.com//service/biservice/searchbythemeandyear?fromIndex=%s&amp;onlyAlternatives=false&amp;theme=%s&amp;year=%s"</span></span><br><span class="line">    allowed_domains = [<span class="string">'lego.com'</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'https://wwwsecure.us.lego.com/en-us/service/buildinginstructions'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        year_str = response.css(<span class="string">'div.product-search::attr(data-search-years)'</span>).extract_first()</span><br><span class="line">        theme_str = response.css(<span class="string">'div.product-search::attr(data-search-themes)'</span>).extract_first()</span><br><span class="line">        <span class="keyword">for</span> theme <span class="keyword">in</span> json.loads(theme_str)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">for</span> year <span class="keyword">in</span> json.loads(year_str)<span class="symbol">:</span></span><br><span class="line">                search_url = <span class="keyword">self</span>.search_base_url % (<span class="number">0</span>, theme[<span class="string">'Key'</span>], year)</span><br><span class="line">                <span class="keyword">yield</span> scrapy.Request(search_url, callback=<span class="keyword">self</span>.parse_search)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_search</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        result = json.loads(response.body)</span><br><span class="line">        param = parse_qs(urlparse(response.url).query)</span><br><span class="line">        <span class="keyword">if</span> result[<span class="string">'count'</span>]<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> result[<span class="string">'products'</span>]<span class="symbol">:</span></span><br><span class="line">                product = LegoProductItem()</span><br><span class="line">                product[<span class="string">'theme'</span>] = param[<span class="string">"theme"</span>][<span class="number">0</span>]</span><br><span class="line">                product[<span class="string">'year'</span>] = param[<span class="string">"year"</span>][<span class="number">0</span>]</span><br><span class="line">                product[<span class="string">'productId'</span>] = p[<span class="string">'productId'</span>]</span><br><span class="line">                product[<span class="string">'productName'</span>] = p[<span class="string">'productName'</span>]</span><br><span class="line">                product[<span class="string">'productImage'</span>] = p[<span class="string">'productImage'</span>]</span><br><span class="line">                product[<span class="string">'file_urls'</span>] = [p[<span class="string">'productImage'</span>]]</span><br><span class="line">                <span class="keyword">yield</span> product</span><br><span class="line">                <span class="keyword">for</span> bi <span class="keyword">in</span> p[<span class="string">'buildingInstructions'</span>]<span class="symbol">:</span></span><br><span class="line">                    instruction = LegoBuildingInstructionsItem()</span><br><span class="line">                    instruction[<span class="string">'productId'</span>] = p[<span class="string">'productId'</span>]</span><br><span class="line">                    instruction[<span class="string">'description'</span>] = bi[<span class="string">'description'</span>]</span><br><span class="line">                    instruction[<span class="string">'file_urls'</span>] = [bi[<span class="string">'pdfLocation'</span>], bi[<span class="string">'frontpageInfo'</span>]]</span><br><span class="line">                    <span class="keyword">yield</span> instruction</span><br><span class="line">        <span class="keyword">if</span> result[<span class="string">'moreData'</span>]<span class="symbol">:</span></span><br><span class="line">            search_next = <span class="keyword">self</span>.search_base_url % (int(param[<span class="string">'fromIndex'</span>][<span class="number">0</span>]) + int(result[<span class="string">'count'</span>]), param[<span class="string">"theme"</span>][<span class="number">0</span>], param[<span class="string">"year"</span>][<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(search_next, callback=<span class="keyword">self</span>.parse_search</span><br></pre></td></tr></table></figure></p><h3 id="5-Run！"><a href="#5-Run！" class="headerlink" title="5 Run！"></a>5 Run！</h3><p>将main.py修改为：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">cmdline</span><span class="selector-class">.execute</span>("<span class="selector-tag">scrapy</span> <span class="selector-tag">crawl</span> <span class="selector-tag">lego</span> <span class="selector-tag">-o</span> <span class="selector-tag">lego</span><span class="selector-class">.jl</span>"<span class="selector-class">.split</span>())</span><br></pre></td></tr></table></figure></p><p>运行就可以看到Download目录下源源不断生成的jpg、png和pdf文件，而且最后所有item的数据都会存放在lego.jl文件中：</p><blockquote><p>{“file_paths”: [“jpg/4655-0000-XX-12-1.jpg”], “productName”: “Quick Fix Station”, “productImage”: “<a href="http://cache.lego.com/images/shop/prod/4655-0000-XX-12-1.jpg&quot;" target="_blank" rel="noopener">http://cache.lego.com/images/shop/prod/4655-0000-XX-12-1.jpg&quot;</a>, “theme”: “10000-20070”, “file_urls”: [“<a href="http://cache.lego.com/images/shop/prod/4655-0000-XX-12-1.jpg&quot;]" target="_blank" rel="noopener">http://cache.lego.com/images/shop/prod/4655-0000-XX-12-1.jpg&quot;]</a>, “year”: “2003”, “productId”: “4655”}<br>{“productId”: “4655”, “file_paths”: [“pdf/4234989.pdf”, “png/4234989.png”], “file_urls”: [“<a href="http://cache.lego.com/bigdownloads/buildinginstructions/4234989.pdf&quot;" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/4234989.pdf&quot;</a>, “<a href="http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/4234989.png&quot;]" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/4234989.png&quot;]</a>, “description”: “BI, 4655 IN”}<br>{“productId”: “4655”, “file_paths”: [“pdf/4235788.pdf”, “png/4235788.png”], “file_urls”: [“<a href="http://cache.lego.com/bigdownloads/buildinginstructions/4235788.pdf&quot;" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/4235788.pdf&quot;</a>, “<a href="http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/4235788.png&quot;]" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/4235788.png&quot;]</a>, “description”: “BI, 4655 NA”}<br>{“file_paths”: [“jpg/4657-0000-XX-12-1.jpg”], “productName”: “Fire Squad HQ”, “productImage”: “<a href="http://cache.lego.com/images/shop/prod/4657-0000-XX-12-1.jpg&quot;" target="_blank" rel="noopener">http://cache.lego.com/images/shop/prod/4657-0000-XX-12-1.jpg&quot;</a>, “theme”: “10000-20070”, “file_urls”: [“<a href="http://cache.lego.com/images/shop/prod/4657-0000-XX-12-1.jpg&quot;]" target="_blank" rel="noopener">http://cache.lego.com/images/shop/prod/4657-0000-XX-12-1.jpg&quot;]</a>, “year”: “2003”, “productId”: “4657”}<br>{“productId”: “4657”, “file_paths”: [“pdf/4234999.pdf”, “png/4234999.png”], “file_urls”: [“<a href="http://cache.lego.com/bigdownloads/buildinginstructions/4234999.pdf&quot;" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/4234999.pdf&quot;</a>, “<a href="http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/4234999.png&quot;]" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/4234999.png&quot;]</a>, “description”: “BI, 4657 IN”}<br>…</p></blockquote><h2 id="6-Some-Bugs"><a href="#6-Some-Bugs" class="headerlink" title="6 Some Bugs"></a>6 Some Bugs</h2><h3 id="6-1-Error-processing-file-from"><a href="#6-1-Error-processing-file-from" class="headerlink" title="6.1 Error processing file from"></a>6.1 Error processing file from</h3><p><code>2016-10-23 21:14:35 [scrapy] ERROR: File (unknown-error): Error processing file from &lt;GET https://mi-od-live-s.legocdn.com/r/www/r/service/-/media/franchises/customer%20service/technic/8052_b_part2.pdf?l.r2=704137121&gt; referred in &lt;None&gt;</code><br>由于部分下载链接带有url参数，因此需要将LegoFiePipline.py文件如下内容：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file_guid = request<span class="selector-class">.url</span><span class="selector-class">.split</span>(<span class="string">'/'</span>)[-<span class="number">1</span>]</span><br><span class="line">group = request<span class="selector-class">.url</span><span class="selector-class">.split</span>(<span class="string">'.'</span>)[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure></p><p>修改为：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file_guid = request<span class="selector-class">.url</span><span class="selector-class">.split</span>(<span class="string">'?'</span>)[<span class="number">0</span>].split(<span class="string">'/'</span>)[-<span class="number">1</span>]</span><br><span class="line">group = request<span class="selector-class">.url</span><span class="selector-class">.split</span>(<span class="string">'?'</span>)[<span class="number">0</span>].split(<span class="string">'.'</span>)[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure></p><h3 id="6-2-WARNING-Received-more-bytes-than-download-warn-size-33554432-in-request"><a href="#6-2-WARNING-Received-more-bytes-than-download-warn-size-33554432-in-request" class="headerlink" title="6.2 WARNING: Received more bytes than download warn size (33554432) in request"></a>6.2 WARNING: Received more bytes than download warn size (33554432) in request</h3><p>因为部分PDF文件较大，下载时间较长，超过了预设的timeout=180，造成部分文件下载失败，需要修改settings.py：<br><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">DOWNLOAD_MAXSIZE</span> = <span class="number">0</span></span><br><span class="line"><span class="attr">DOWNLOAD_TIMEOUT</span> = <span class="number">18000</span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;4-Finish-The-LegoSpyder&quot;&gt;&lt;a href=&quot;#4-Finish-The-LegoSpyder&quot; class=&quot;headerlink&quot; title=&quot;4 Finish The LegoSpyder&quot;&gt;&lt;/a&gt;4 Finish The Lego</summary>
      
    
    
    
    
    <category term="Lego" scheme="http://gloomymoon.github.io/tags/Lego/"/>
    
    <category term="Scrapy" scheme="http://gloomymoon.github.io/tags/Scrapy/"/>
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Building LegoSpyder Part II</title>
    <link href="http://gloomymoon.github.io/2016/10/22/Building-LegoSpyder-Part-II/"/>
    <id>http://gloomymoon.github.io/2016/10/22/Building-LegoSpyder-Part-II/</id>
    <published>2016-10-22T02:21:36.000Z</published>
    <updated>2016-10-23T12:12:55.500Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2-Installing-Scrapy"><a href="#2-Installing-Scrapy" class="headerlink" title="2. Installing Scrapy"></a>2. Installing Scrapy</h2><p>直接用pip安装即可：<br><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip <span class="keyword">install</span> Scrapy</span><br></pre></td></tr></table></figure></p><p>如果出现如下错误：<br><code>exceptions.ImportError: No module named win32api</code></p><p>需要手动安装pypiwin32:<br><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip <span class="keyword">install</span> pypiwin32</span><br></pre></td></tr></table></figure></p><p>如果需要生成下载预览图片的缩略图，请手动安装image：<br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install <span class="built_in">image</span></span><br></pre></td></tr></table></figure></p><h2 id="3-Building-Spider"><a href="#3-Building-Spider" class="headerlink" title="3 Building Spider"></a>3 Building Spider</h2><h3 id="3-0-Create-Scrapy-Project"><a href="#3-0-Create-Scrapy-Project" class="headerlink" title="3.0 Create Scrapy Project"></a>3.0 Create Scrapy Project</h3><p>进入项目目录，在命令行输入如下命令就可以创建一个空白的Scrapy项目<strong>LegoSpyder</strong>：<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>scrapy startproject LegoSpyder</span><br></pre></td></tr></table></figure></p><p>生成的项目框架如下所示：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">LegoSpyder/</span><br><span class="line">    scrapy.cfg</span><br><span class="line">    LegoSpyder/</span><br><span class="line">        __init__.py</span><br><span class="line">        items.py</span><br><span class="line">        pipelines.py</span><br><span class="line">        settings.py</span><br><span class="line">        spiders/</span><br><span class="line">            __init__.py</span><br><span class="line">            ...</span><br></pre></td></tr></table></figure></p><h3 id="3-1-Create-Spider"><a href="#3-1-Create-Spider" class="headerlink" title="3.1 Create Spider"></a>3.1 Create Spider</h3><p>然后在spiders目录下新建BuildingInstructionsSpider.py文件，这就是我们爬虫程序。<br>根据之前对Lego网站的分析，就能够获取所有Set的相关json数据：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BuildingInstructionsSpider</span>(<span class="title">scrapy</span>.<span class="title">Spider</span>):</span></span><br><span class="line">    name = <span class="string">'lego'</span></span><br><span class="line">    search_base_url = <span class="string">"https://wwwsecure.us.lego.com//service/biservice/searchbythemeandyear?fromIndex=0&amp;onlyAlternatives=false&amp;theme=%s&amp;year=%s"</span></span><br><span class="line">    allowed_domains = [<span class="string">'lego.com'</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'https://wwwsecure.us.lego.com/en-us/service/buildinginstructions'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        year_str = response.css(<span class="string">'div.product-search::attr(data-search-years)'</span>).extract_first()</span><br><span class="line">        theme_str = response.css(<span class="string">'div.product-search::attr(data-search-themes)'</span>).extract_first()</span><br><span class="line">        <span class="keyword">for</span> theme <span class="keyword">in</span> json.loads(theme_str)<span class="symbol">:</span></span><br><span class="line">            <span class="comment">#print theme</span></span><br><span class="line">            <span class="keyword">for</span> year <span class="keyword">in</span> json.loads(year_str)<span class="symbol">:</span></span><br><span class="line">                <span class="comment">#print year</span></span><br><span class="line">                search_url = <span class="keyword">self</span>.search_base_url % (theme[<span class="string">'Key'</span>], year)</span><br><span class="line">                <span class="keyword">yield</span> scrapy.Request(search_url, callback=<span class="keyword">self</span>.parse_search)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_search</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        print response.body</span><br></pre></td></tr></table></figure></p><p>为了方便在PyCharm中进行调试，在项目的根目录创建main.py：<br><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from scrapy <span class="keyword">import</span> cmdline</span><br><span class="line">cmdline.execute(<span class="string">"scrapy crawl lego"</span>.<span class="built_in">split</span>())</span><br></pre></td></tr></table></figure></p><p>这样从main.py运行就能够调试spider的脚本了，而不用从命令行用scrapy crawl的方式运行爬虫。<br>Run之后就能看到所有的Set信息：<br><code>2016-10-22 11:19:15 [scrapy] INFO: Spider opened2016-10-22 11:19:15 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)2016-10-22 11:19:15 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:60242016-10-22 11:19:17 [scrapy] DEBUG: Crawled (200) &lt;GET https://wwwsecure.us.lego.com/en-us/service/buildinginstructions&gt; (referer: None)2016-10-22 11:19:17 [scrapy] DEBUG: Crawled (200) &lt;GET https://wwwsecure.us.lego.com//service/biservice/searchbythemeandyear?fromIndex=0&amp;onlyAlternatives=false&amp;theme=10000-20070&amp;year=1995&gt; (referer: https://wwwsecure.us.lego.com/en-us/service/buildinginstructions){&quot;count&quot;:0,&quot;moreData&quot;:false,&quot;products&quot;:[],&quot;totalCount&quot;:0,&quot;years&quot;:[&quot;2004&quot;,&quot;2003&quot;],&quot;themes&quot;:[&quot;10000-20032&quot;,&quot;500-346&quot;]}2016-10-22 11:19:17 [scrapy] DEBUG: Crawled (200) &lt;GET https://wwwsecure.us.lego.com//service/biservice/searchbythemeandyear?fromIndex=0&amp;onlyAlternatives=false&amp;theme=10000-20070&amp;year=2003&gt; (referer: https://wwwsecure.us.lego.com/en-us/service/buildinginstructions){&quot;count&quot;:2,&quot;moreData&quot;:false,&quot;products&quot;:[{&quot;productId&quot;:&quot;4655&quot;,&quot;productName&quot;:&quot;Quick Fix Station&quot;,&quot;productImage&quot;:&quot;http://cache.lego.com/images/shop/prod/4655-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;:[{&quot;description&quot;:&quot;BI, 4655 IN&quot;,&quot;pdfLocation&quot;:&quot;http://cache.lego.com/bigdownloads/buildinginstructions/4234989.pdf&quot;,&quot;downloadSize&quot;:&quot;1.23 Mb&quot;,&quot;frontpageInfo&quot;:&quot;http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/4234989.png&quot;,&quot;isAlternative&quot;:false},{&quot;description&quot;:&quot;BI, 4655 NA&quot;,&quot;pdfLocation&quot;:&quot;http://cache.lego.com/bigdownloads/buildinginstructions/4235788.pdf&quot;,&quot;downloadSize&quot;:&quot;1.26 Mb&quot;,&quot;frontpageInfo&quot;:&quot;http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/4235788.png&quot;,&quot;isAlternative&quot;:false}],&quot;themeName&quot;:&quot;4juniors&quot;,&quot;launchYear&quot;:2003},{&quot;productId&quot;: ... } ],&quot;totalCount&quot;:2,&quot;years&quot;:[&quot;2004&quot;,&quot;2003&quot;],&quot;themes&quot;:[&quot;10000-20070&quot;,&quot;10000-20031&quot;,&quot;10000-20051&quot;,&quot;10000-20057&quot;,&quot;10000-20009&quot;,&quot;10000-20017&quot;,&quot;10000-20016&quot;,&quot;10000-20008&quot;,&quot;10000-20216&quot;,&quot;10000-20106&quot;,&quot;10000-20105&quot;,&quot;10000-20084&quot;,&quot;10000-20129&quot;,&quot;10000-20238&quot;,&quot;10000-20003&quot;,&quot;10000-20189&quot;,&quot;10000-20039&quot;,&quot;10000-20081&quot;,&quot;10000-20040&quot;,&quot;10000-20080&quot;,&quot;10000-20037&quot;,&quot;10000-20035&quot;,&quot;10000-20056&quot;,&quot;10000-20002&quot;,&quot;10000-20124&quot;,&quot;10000-20071&quot;]}...</code></p><h3 id="3-2-Download-Images"><a href="#3-2-Download-Images" class="headerlink" title="3.2 Download Images"></a>3.2 Download Images</h3><p>Scrapy自带File和image下载的模块，我们先创建一个TestSpider来实现封面图片的下载功能。<br>修改items.py，新增LegoImageItem类：<br><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">LegoImageItem</span>(<span class="title">scrapy</span>.<span class="type">Item</span>):</span></span><br><span class="line"><span class="class">    image_urls = scrapy.<span class="type">Field</span>()</span></span><br><span class="line"><span class="class">    images = scrapy.<span class="type">Field</span>()</span></span><br><span class="line"><span class="class">    image_paths = scrapy.<span class="type">Field</span>()</span></span><br></pre></td></tr></table></figure></p><p>修改pipelines.py，新增LegoImagePipeline类：<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LegoImagePipeline</span>(<span class="title">ImagesPipeline</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(<span class="keyword">self</span>, item, info)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">for</span> image_url <span class="keyword">in</span> item[<span class="string">'image_urls'</span>]<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">yield</span> Request(image_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span><span class="params">(<span class="keyword">self</span>, results, item, info)</span></span><span class="symbol">:</span></span><br><span class="line">        image_paths = [x[<span class="string">'path'</span>] <span class="keyword">for</span> ok, x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="symbol">image_paths:</span></span><br><span class="line">            raise DropItem(<span class="string">'Image download failed: %s'</span> % image_paths)</span><br><span class="line">        item[<span class="string">'image_paths'</span>] = image_paths</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></p><p>修改spiders.BuildingInstructionsSpider.py，增加一个新的TestSpider：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'test'</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'https://wwwsecure.us.lego.com//service/biservice/searchbythemeandyear?fromIndex=0&amp;onlyAlternatives=false&amp;theme=10000-20127&amp;year=2015'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        result = json.loads(response.body)</span><br><span class="line">        <span class="keyword">print</span> result[<span class="string">'count'</span>], result[<span class="string">'moreData'</span>]</span><br><span class="line">        item = LegoImageItem()</span><br><span class="line">        url_list = []</span><br><span class="line">        <span class="keyword">for</span> product <span class="keyword">in</span> result[<span class="string">'products'</span>]:</span><br><span class="line">            <span class="comment">#print product</span></span><br><span class="line">            url_list.append(product[<span class="string">'productImage'</span>])</span><br><span class="line">        <span class="keyword">print</span> url_list</span><br><span class="line">        item[<span class="string">'image_urls'</span>] = url_list</span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure></p><p>最后修改settings.py，增加相关的配置信息：<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    'LegoSpyder.pipelines.LegoImagePipeline': 1,</span><br><span class="line">&#125;</span><br><span class="line">IMAGES_STORE = '\\Download\\Test' <span class="comment">#图片下载目录</span></span><br><span class="line">IMAGES_EXPIRES = 90</span><br></pre></td></tr></table></figure></p><p>运行后就可以在相应的目录下看到抓取的图片文件了<br><img src="TestSpider.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;2-Installing-Scrapy&quot;&gt;&lt;a href=&quot;#2-Installing-Scrapy&quot; class=&quot;headerlink&quot; title=&quot;2. Installing Scrapy&quot;&gt;&lt;/a&gt;2. Installing Scrapy&lt;/h2&gt;&lt;p&gt;</summary>
      
    
    
    
    
    <category term="Lego" scheme="http://gloomymoon.github.io/tags/Lego/"/>
    
    <category term="Scrapy" scheme="http://gloomymoon.github.io/tags/Scrapy/"/>
    
    <category term="Python" scheme="http://gloomymoon.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Building LegoSpyder Part I</title>
    <link href="http://gloomymoon.github.io/2016/10/20/Building-LegoSpyder-Part-I/"/>
    <id>http://gloomymoon.github.io/2016/10/20/Building-LegoSpyder-Part-I/</id>
    <published>2016-10-20T14:12:15.000Z</published>
    <updated>2017-03-21T05:43:55.405Z</updated>
    
    <content type="html"><![CDATA[<h2 id="0-Preface"><a href="#0-Preface" class="headerlink" title="0. Preface"></a>0. Preface</h2><p><img src="/img/studio_home_tout_720_2.jpg" alt="Architecture Studio"><br>10月8日收到了新买的Architecture Studo，前两天无意中发现了<a href="lego.com">Lego.com</a>竟然提供了所有Set的<a href="https://wwwsecure.us.lego.com/en-us/service/buildinginstructions" target="_blank" rel="noopener">Building Instructions</a>。<br>这是一个搜索页面，可以根据主题和年份搜索到所有Set的图纸，于是产生了一个邪恶的想法：把所有的图纸用爬虫Download下来。</p><h2 id="1-分析页面"><a href="#1-分析页面" class="headerlink" title="1. 分析页面"></a>1. 分析页面</h2><p>在开始爬之前首先需要分析页面的结构，根据firebug监控Net流量发现，实际查询请求的URL为：</p><blockquote><p><a href="https://wwwsecure.us.lego.com//service/biservice/searchbythemeandyear?fromIndex=0&amp;onlyAlternatives=false&amp;theme=10000-20127&amp;year=2015" target="_blank" rel="noopener">https://wwwsecure.us.lego.com//service/biservice/searchbythemeandyear?fromIndex=0&amp;onlyAlternatives=false&amp;theme=10000-20127&amp;year=2015</a></p></blockquote><p>其返回结果是一个简单的json文件：</p><blockquote><p>{“count”:8,”moreData”:false,”products”:[{“productId”:”70166”,”productName”:”Spyclops Infiltration”,”productImage”<br>:”<a href="http://cache.lego.com/images/shop/prod/70166-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;:[{&quot;description&quot;" target="_blank" rel="noopener">http://cache.lego.com/images/shop/prod/70166-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;:[{&quot;description&quot;</a><br>:”BI 3003/32- 70166 V29”,”pdfLocation”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/6112710" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/6112710</a><br>.pdf”,”downloadSize”:”4.77 Mb”,”frontpageInfo”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions</a><br>/fpimg/6112710.png”,”isAlternative”:false},{“description”:”BI 3003/32- 70166 V39”,”pdfLocation”:”http<br>://cache.lego.com/bigdownloads/buildinginstructions/6112711.pdf”,”downloadSize”:”4.71 Mb”,”frontpageInfo”<br>:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6112711.png&quot;,&quot;isAlternative&quot;:false}]" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6112711.png&quot;,&quot;isAlternative&quot;:false}]</a><br>,”themeName”:”Agents”,”launchYear”:2015},{“productId”:”70167”,”productName”:”Invizable Gold Getaway”<br>,”productImage”:”<a href="http://cache.lego.com/images/shop/prod/70167-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;" target="_blank" rel="noopener">http://cache.lego.com/images/shop/prod/70167-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;</a><br>:[{“description”:”BI 3004/60+4/65+115g 70167 V29”,”pdfLocation”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions</a><br>/6112723.pdf”,”downloadSize”:”5.85 Mb”,”frontpageInfo”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions</a><br>/fpimg/6112723.png”,”isAlternative”:false},{“description”:”BI 3004/60+4/65+115g 70167 V39”,”pdfLocation”<br>:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/6112724.pdf&quot;,&quot;downloadSize&quot;:&quot;5.79" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/6112724.pdf&quot;,&quot;downloadSize&quot;:&quot;5.79</a> Mb”,”frontpageInfo”<br>:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6112724.png&quot;,&quot;isAlternative&quot;:false}]" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6112724.png&quot;,&quot;isAlternative&quot;:false}]</a><br>,”themeName”:”Agents”,”launchYear”:2015},{“productId”:”70168”,”productName”:”Drillex Diamond Job”,”productImage”<br>:”<a href="http://cache.lego.com/images/shop/prod/70168-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;:[{&quot;description&quot;" target="_blank" rel="noopener">http://cache.lego.com/images/shop/prod/70168-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;:[{&quot;description&quot;</a><br>:”BI 3004/72+4<em>- 70168 V29”,”pdfLocation”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/6119298" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/6119298</a><br>.pdf”,”downloadSize”:”7.06 Mb”,”frontpageInfo”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions</a><br>/fpimg/6119298.png”,”isAlternative”:false},{“description”:”BI 3004/72+4</em>- 70168 V39”,”pdfLocation”:”http<br>://cache.lego.com/bigdownloads/buildinginstructions/6119299.pdf”,”downloadSize”:”7 Mb”,”frontpageInfo”<br>:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6119299.png&quot;,&quot;isAlternative&quot;:false}]" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6119299.png&quot;,&quot;isAlternative&quot;:false}]</a><br>,”themeName”:”Agents”,”launchYear”:2015},{“productId”:”70169”,”productName”:”Agent Stealth Patrol”,”productImage”<br>:”<a href="http://cache.lego.com/images/shop/prod/70169-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;:[{&quot;description&quot;" target="_blank" rel="noopener">http://cache.lego.com/images/shop/prod/70169-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;:[{&quot;description&quot;</a><br>:”BI 3017/100+4/65+200g- 70169 V39”,”pdfLocation”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions</a><br>/6115430.pdf”,”downloadSize”:”11.22 Mb”,”frontpageInfo”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions</a><br>/fpimg/6115430.png”,”isAlternative”:false},{“description”:”BI 3017/100+4/65+200g-70169 V29”,”pdfLocation”<br>:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/6115427.pdf&quot;,&quot;downloadSize&quot;:&quot;12.11" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/6115427.pdf&quot;,&quot;downloadSize&quot;:&quot;12.11</a> Mb”,”frontpageInfo”<br>:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6115427.png&quot;,&quot;isAlternative&quot;:false}]" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6115427.png&quot;,&quot;isAlternative&quot;:false}]</a><br>,”themeName”:”Agents”,”launchYear”:2015},{“productId”:”70170”,”productName”:”UltraCopter vs. AntiMatter”<br>,”productImage”:”<a href="http://cache.lego.com/images/shop/prod/70170-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;" target="_blank" rel="noopener">http://cache.lego.com/images/shop/prod/70170-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;</a><br>:[{“description”:”BI 3019/100+4/65+200g- 70170 V29”,”pdfLocation”:”<a href="http://cache.lego.com/bigdownloads" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads</a><br>/buildinginstructions/6115458.pdf”,”downloadSize”:”17.36 Mb”,”frontpageInfo”:”<a href="http://cache.lego.com/bigdownloads" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads</a><br>/buildinginstructions/fpimg/6115458.png”,”isAlternative”:false},{“description”:”BI 3019/100+4/65+200g-<br> 70170 V39”,”pdfLocation”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/6115472.pdf&quot;,&quot;downloadSize&quot;" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/6115472.pdf&quot;,&quot;downloadSize&quot;</a><br>:”14.74 Mb”,”frontpageInfo”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6115472.png&quot;" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6115472.png&quot;</a><br>,”isAlternative”:false}],”themeName”:”Agents”,”launchYear”:2015},{“productId”:”70171”,”productName”:”Ultrasonic<br> Showdown”,”productImage”:”<a href="http://cache.lego.com/images/shop/prod/70171-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;" target="_blank" rel="noopener">http://cache.lego.com/images/shop/prod/70171-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;</a><br>:[{“description”:”BI 3004/60+4/65+115g - 70171 V29”,”pdfLocation”:”<a href="http://cache.lego.com/bigdownloads" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads</a><br>/buildinginstructions/6127741.pdf”,”downloadSize”:”5.83 Mb”,”frontpageInfo”:”<a href="http://cache.lego.com/bigdownloads" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads</a><br>/buildinginstructions/fpimg/6127741.png”,”isAlternative”:false},{“description”:”BI 3004/60+4/65+115g<br> - 70171 V39”,”pdfLocation”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/6127743.pdf&quot;,&quot;downloadSize&quot;" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/6127743.pdf&quot;,&quot;downloadSize&quot;</a><br>:”5.79 Mb”,”frontpageInfo”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6127743.png&quot;" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6127743.png&quot;</a><br>,”isAlternative”:false}],”themeName”:”Agents”,”launchYear”:2015},{“productId”:”70172”,”productName”:”AntiMatter’s<br> Portal Hideout”,”productImage”:”<a href="http://cache.lego.com/images/shop/prod/70172-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;" target="_blank" rel="noopener">http://cache.lego.com/images/shop/prod/70172-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;</a><br>:[{“description”:”BI 3016/96+4/65+200g - 70172 V29”,”pdfLocation”:”<a href="http://cache.lego.com/bigdownloads" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads</a><br>/buildinginstructions/6129665.pdf”,”downloadSize”:”12.45 Mb”,”frontpageInfo”:”<a href="http://cache.lego.com/bigdownloads" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads</a><br>/buildinginstructions/fpimg/6129665.png”,”isAlternative”:false},{“description”:”BI 3016/96+4/65+200g<br> - 70172 V39”,”pdfLocation”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/6129666.pdf&quot;,&quot;downloadSize&quot;" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/6129666.pdf&quot;,&quot;downloadSize&quot;</a><br>:”10.57 Mb”,”frontpageInfo”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6129666.png&quot;" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6129666.png&quot;</a><br>,”isAlternative”:false}],”themeName”:”Agents”,”launchYear”:2015},{“productId”:”70173”,”productName”:”Ultra<br> Agents Ocean HQ”,”productImage”:”<a href="http://cache.lego.com/images/shop/prod/70173-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;" target="_blank" rel="noopener">http://cache.lego.com/images/shop/prod/70173-0000-XX-12-1.jpg&quot;,&quot;buildingInstructions&quot;</a><br>:[{“description”:”BI 3019/176+4/65+200 - 70173 V29”,”pdfLocation”:”<a href="http://cache.lego.com/bigdownloads" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads</a><br>/buildinginstructions/6129674.pdf”,”downloadSize”:”24 Mb”,”frontpageInfo”:”<a href="http://cache.lego.com/bigdownloads" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads</a><br>/buildinginstructions/fpimg/6129674.png”,”isAlternative”:false},{“description”:”BI 3019/176+4/65+200<br> - 70173 V39”,”pdfLocation”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/6129675.pdf&quot;,&quot;downloadSize&quot;" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/6129675.pdf&quot;,&quot;downloadSize&quot;</a><br>:”22.14 Mb”,”frontpageInfo”:”<a href="http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6129675.png&quot;" target="_blank" rel="noopener">http://cache.lego.com/bigdownloads/buildinginstructions/fpimg/6129675.png&quot;</a><br>,”isAlternative”:false}],”themeName”:”Agents”,”launchYear”:2015}],”totalCount”:8,”years”:[“2015”,”2014”<br>,”2009”,”2008”],”themes”:[“10000-20127”,”10000-20057”,”10000-20009”,”10000-20263”,”10000-20264”,”10000-20248”<br>,”10000-20147”,”10000-20246”,”10000-20243”,”10000-20020”,”10000-20226”,”10000-20018”,”10000-20062”,”10000-20016”<br>,”10000-20008”,”10000-20174”,”10000-20216”,”10000-20229”,”10000-20218”,”10000-20090”,”10000-20194”,”10000-20245”<br>,”10000-20155”,”10000-20019”,”10000-20094”,”10000-20230”,”10000-20223”,”10000-20005”,”10000-20239”,”10000-20219”<br>,”10000-20244”,”10000-20139”,”10000-20238”,”10000-20003”,”10000-20055”,”10000-20000”,”10000-20140”,”10000-20128”<br>,”10000-20221”,”10000-20041”,”10000-20231”,”10000-20225”,”10000-20049”,”10000-20039”,”10000-20242”,”10000-20222”<br>,”10000-20241”,”10000-20056”,”10000-20101”,”10000-20002”]}</p></blockquote><p>非常简单的方式就能够获取所有Set的主题、发售年份、名称、编号、包装图片和最重要的pdf版搭建图纸，唯一的问题是URL参数中theme的取值范围是多少。</p><p>再次分析搜索的HTML页面，发现搜索框的DIV中已经完全告诉我们theme及对应的参数：</p><blockquote><p>&lt;div class=”product-search ng-scope” …  data-search-themes=”[{“Label”:”4juniors”,”Key”:”10000-20070”},{“Label”:”Adventurers”,”Key”:”10000-20031”},{“Label”:”Agents”,”Key”:”10000-20127”},{“Label”:”Alpha Team”,”Key”:”10000-20085”},{“Label”:”Angry Birds”,”Key”:”10000-20251”},{“Label”:”Aqua Raiders”,”Key”:”10000-20113”},{“Label”:”Aquazone”,”Key”:”10000-20032”},{“Label”:”Artic”,”Key”:”10000-20097”},{“Label”:”Atlantis”,”Key”:”10000-20115”},{“Label”:”Avatar TM”,”Key”:”10000-20068”},{“Label”:”Batman TM”,”Key”:”10000-20114”},{“Label”:”Belville”,”Key”:”10000-20051”},{“Label”:…,”Key”:”10000-20002”},{“Label”:”Time Cruisers”,”Key”:”10000-20096”},{“Label”:”Town”,”Key”:”500-714”},{“Label”:”Toy Story TM”,”Key”:”10000-20109”},{“Label”:”Trains”,”Key”:”500-717”},{“Label”:”Transport”,”Key”:”500-720”},{“Label”:”Vikings”,”Key”:”10000-20102”},{“Label”:”Wild West”,”Key”:”10000-20015”},{“Label”:”Williams TM”,”Key”:”10000-20124”},{“Label”:”World City”,”Key”:”10000-20071”},{“Label”:”World Racers”,”Key”:”10000-20130”},{“Label”:”X-Treme”,”Key”:”10000-20098”},{“Label”:”ZNAP”,”Key”:”10000-20064”}]</p></blockquote><p>一切就绪，下一步就是要规划爬取数据的步骤了：</p><ol><li>首先获取所有theme的label和对应的key</li><li>将key和year代入遍历所有的URL，发送request</li><li>根据response获取所有set的信息</li><li>若本地没有，则下载set的图片和pdf资源</li><li>每隔一段时间从1开始重新爬取，就可以保证和官网资源同步</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;0-Preface&quot;&gt;&lt;a href=&quot;#0-Preface&quot; class=&quot;headerlink&quot; title=&quot;0. Preface&quot;&gt;&lt;/a&gt;0. Preface&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/img/studio_home_tout_720_2.jp</summary>
      
    
    
    
    
    <category term="Lego" scheme="http://gloomymoon.github.io/tags/Lego/"/>
    
  </entry>
  
  <entry>
    <title>Build A Blog With GitHub And Hexo</title>
    <link href="http://gloomymoon.github.io/2016/10/18/Build-A-Blog-With-GitHub-And-Hexo/"/>
    <id>http://gloomymoon.github.io/2016/10/18/Build-A-Blog-With-GitHub-And-Hexo/</id>
    <published>2016-10-18T12:18:47.000Z</published>
    <updated>2016-10-22T02:29:49.530Z</updated>
    
    <content type="html"><![CDATA[<p>第一篇肯定是关于如何搭建一个基于<a href="https://github.com" target="_blank" rel="noopener">GitHub</a>的Blog。<br>主要的过程都是通过网络搜索获得，使用的主题也是简单挑选的一个Hexo主题<a href="https://github.com/Huxpro/huxpro.github.io" target="_blank" rel="noopener">HuxBlog</a>。</p><h2 id="1-开发环境"><a href="#1-开发环境" class="headerlink" title="1. 开发环境"></a>1. 开发环境</h2><h3 id="1-1-安装Git"><a href="#1-1-安装Git" class="headerlink" title="1.1 安装Git"></a>1.1 安装Git</h3><p>从<a href="https://git-scm.com" target="_blank" rel="noopener">Git</a>的官网下载最新的版本，我下载的是<a href="https://github.com/git-for-windows/git/releases/download/v2.10.1.windows.1/Git-2.10.1-64-bit.exe" target="_blank" rel="noopener">Git for Windows 64-bit</a>版本，你可以从<a href="https://git-scm.com/downloads" target="_blank" rel="noopener">下载页面</a>获取其他系统和版本。</p><p>安装时的注意事项：</p><ul><li>使用默认选项：<em>Use git from Windows Command Prompt</em>，如果你担心污染PATH变量，也可以选择：<em>Use Git from Git Bash only</em></li><li>使用默认选项：<em>Use OpenSSH</em></li><li>使用默认选项：<em>Checkout Windows-style, commit Unix-style line endings</em></li><li>如果不需要使用IPython，使用默认选项：<em>Use MinTTY</em></li></ul><h3 id="1-2-安装node-js"><a href="#1-2-安装node-js" class="headerlink" title="1.2 安装node.js"></a>1.2 安装node.js</h3><p>从<a href="https://nodejs.org" target="_blank" rel="noopener">nodejs</a>官网下载最新的版本，我下载的是<a href="https://nodejs.org/dist/v4.6.0/node-v4.6.0-x64.msi" target="_blank" rel="noopener">nodejs for Windows(x64) v4.6.0 LTS</a>，你可以从<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">下载页面</a>获取其他系统和版本。<br>nodejs安装相对简单，保持默认选项即可。</p><h3 id="1-3-代码编辑软件"><a href="#1-3-代码编辑软件" class="headerlink" title="1.3 代码编辑软件"></a>1.3 代码编辑软件</h3><p>如果你从来没有写过代码，并且希望享受代码编写的了却，那需要一个比记事本更强大友好的代码编辑软件，下面是一些推荐：</p><ul><li><a href="https://atom.io/" target="_blank" rel="noopener">Atom</a></li><li><a href="http://www.sublimetext.com/" target="_blank" rel="noopener">Sublime Text</a></li><li><a href="https://code.visualstudio.com/" target="_blank" rel="noopener">Visual Studio Code</a></li><li>Notepad++或UltraEdit</li></ul><h2 id="2-GitHub"><a href="#2-GitHub" class="headerlink" title="2 GitHub"></a>2 GitHub</h2><h3 id="2-1-注册GitHub"><a href="#2-1-注册GitHub" class="headerlink" title="2.1 注册GitHub"></a>2.1 注册GitHub</h3><p>因为最终Blog的内容是要发布在GitHub上的，所以肯定需要注册一个GitHub账号，直接访问官网申请注册即可，GitHub的普通账号是免费的，使用上稍有限制，但是不影响搭建一个完整的Blog。</p><h3 id="2-2-建立仓库Repository"><a href="#2-2-建立仓库Repository" class="headerlink" title="2.2 建立仓库Repository"></a>2.2 建立仓库Repository</h3><p>仓库Repository可以理解为存放一个项目所有相关资源的文件夹，我们需要给Blog建议一个单独的仓库，且仓库的名称必须严格限制为：<strong>your_user_name</strong>.github.io，这里需要将your_user_name替换成你在GitHub上注册的用户名。</p><h3 id="2-3-配置SSH-key"><a href="#2-3-配置SSH-key" class="headerlink" title="2.3 配置SSH key"></a>2.3 配置SSH key</h3><p>SSH key是用来为你提供一个远程发布/更新代码的密钥，一旦在GitHub上添加了SSH key，就可以在本地通过SSH直接访问GitHub中的内容，并进行各种操作。</p><p>配置SSH-Key的过程有些繁琐：</p><h4 id="Step-1-生成一个新的SSH-key"><a href="#Step-1-生成一个新的SSH-key" class="headerlink" title="Step 1 生成一个新的SSH key"></a>Step 1 生成一个新的SSH key</h4><ol><li>进入Git Bash，如果你不知道如何进入Git Bash，可以右键点击资源管理器中的任意目录，选择Git Bash Here</li><li><p>输入如下命令，注意将<a href="mailto:your_email@example.com" target="_blank" rel="noopener">your_email@example.com</a>替换成你注册GitHub的邮件地址：</p><figure class="highlight smalltalk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">$ </span>ssh-keygen -t rsa -b <span class="number">4096</span> -<span class="type">C</span> <span class="comment">"your-email@example.com"</span></span><br></pre></td></tr></table></figure></li><li><p>你会看到如下提示：</p><blockquote><p>Generating public/private rsa key pair.</p></blockquote></li><li><p>输入生成密钥的文件名，直接按回车将使用默认文件名id_rsa，请注意密钥文件存放的目录位置</p><blockquote><p>Enter a file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]</p></blockquote></li><li><p>输入口令，可以直接按回车不使用口令</p><blockquote><p>Enter passphrase (empty for no passphrase): [Type a passphrase]<br>Enter same passphrase again: [Type passphrase again]</p></blockquote></li><li><p>然后会在提示的本地目录下声场id_rsa和id_rsa.pub两个文件</p></li></ol><h4 id="Step-2-将SSH-key添加到ssh-agent"><a href="#Step-2-将SSH-key添加到ssh-agent" class="headerlink" title="Step 2 将SSH key添加到ssh-agent"></a>Step 2 将SSH key添加到ssh-agent</h4><ol><li><p>首先确保ssh-agent启用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">eval</span> <span class="string">"<span class="variable">$(ssh-agent -s)</span>"</span></span></span><br></pre></td></tr></table></figure><p>如果返回如下则表示ssh-agent已经启用</p><blockquote><p>Agent pid 59566</p></blockquote><p>如果使用的不是Git Bash请尝试如下命令：</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>eval <span class="variable">$(</span>ssh-agent -s)</span><br></pre></td></tr></table></figure></li><li><p>添加新的SSH key<br>将之前的生成的id_rsa文件添加到ssh-agent中：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-<span class="keyword">add</span><span class="bash"> ~/.ssh/id_rsa</span></span><br></pre></td></tr></table></figure></li><li><p>输入下述命令检查添加是否成功：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="keyword">ls</span> -al ~<span class="string">/.ssh</span></span><br></pre></td></tr></table></figure><p>通常情况下将会列出之前添加的key：</p><blockquote><p>id_rsa.pub</p></blockquote></li></ol><h4 id="Step-3-将SSH-key添加到GitHub账户中"><a href="#Step-3-将SSH-key添加到GitHub账户中" class="headerlink" title="Step 3 将SSH key添加到GitHub账户中"></a>Step 3 将SSH key添加到GitHub账户中</h4><ol><li><p>将SSH key复制到剪贴板中：</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>clip &lt; ~<span class="regexp">/.ssh/id</span>_rsa.pub</span><br></pre></td></tr></table></figure></li><li><p>登录GitHub，在点击左上角头像，并选择Settings菜单选项：<br><img src="https://help.github.com/assets/images/help/settings/userbar-account-settings.png" alt=""></p></li><li>在左侧项目菜单中选择<strong>SSH and GPG keys</strong>：<br><img src="https://help.github.com/assets/images/help/settings/settings-sidebar-ssh-keys.png" alt=""></li><li>点击<strong>New SSH key</strong>或<strong>Add SSH key</strong>：<br><img src="https://help.github.com/assets/images/help/settings/ssh-add-ssh-key.png" alt=""></li><li>在Title栏输入描述信息，例如你开发环境的机器名“Personal MacBook Air”，在Key栏粘帖SSH key的内容（在1中复制的内容）：<br><img src="https://help.github.com/assets/images/help/settings/ssh-key-paste.png" alt=""></li><li>最后点击<strong>Add SSH key</strong>完成添加</li><li>如果必要的话，在弹出对话框中输入GitHub密码确认：<br><img src="https://help.github.com/assets/images/help/settings/sudo_mode_popup.png" alt=""></li></ol><h2 id="3-安装Hexo"><a href="#3-安装Hexo" class="headerlink" title="3 安装Hexo"></a>3 安装Hexo</h2><h3 id="3-1-安装Hexo"><a href="#3-1-安装Hexo" class="headerlink" title="3.1 安装Hexo"></a>3.1 安装Hexo</h3><ol><li>打开Git命令行，执行如下命令：<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm <span class="keyword">install</span> -g hexo</span><br></pre></td></tr></table></figure></li></ol><h3 id="3-2-Quick-Start"><a href="#3-2-Quick-Start" class="headerlink" title="3.2 Quick Start"></a>3.2 Quick Start</h3><ol><li><p>Setup your Blog<br>在电脑中新建一个文件夹并命名为Hexo，例如我建在F:\Workspace\nodejs\Hexo下，然后爱此文件夹点击右键进入Git Bash<br>执行如下命令以获取Hexo所需要的源文件：</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>hexo init</span><br></pre></td></tr></table></figure><p>系统会提示：</p><blockquote><p>[info] Copying data<br>[info] You are almost done! Don’t forget to run <code>npm install</code> before you start blogging with Hexo!</p></blockquote><p>根据提示运行会在Hexo目录下安装所需要的node_mdules：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm <span class="keyword">install</span></span><br></pre></td></tr></table></figure></li><li><p>Start Server<br>直接运行：</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>hexo s</span><br></pre></td></tr></table></figure><p>系统提示如下则表明Hexo Server已经启动，直接在浏览器访问<a href="http://localhost:4000就可以访问并查看效果" target="_blank" rel="noopener">http://localhost:4000就可以访问并查看效果</a></p><blockquote><p>[info] Hexo is running at <a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a>. Press Ctrl+C to stop.</p></blockquote><p>但是这个时候blog还是运行在本地服务器上，我们还需要部署到GitHub上</p></li><li><p>发布到GitHub<br>首先需要修改Hexo目录下的_config.yml文件，找到如下内容：</p><blockquote><p># Deployment<br>## Docs: <a href="http://hexo.io/docs/deployment.html" target="_blank" rel="noopener">http://hexo.io/docs/deployment.html</a><br>deploy:<br>  type:</p></blockquote><p>替换成如下内容，注意将your_user_name替换成你的GitHub用户名：</p><blockquote><p># Deployment<br>## Docs: <a href="http://hexo.io/docs/deployment.html" target="_blank" rel="noopener">http://hexo.io/docs/deployment.html</a><br>deploy:<br>  type: github<br>  repo: <a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>:<strong>your_user_name</strong>/<strong>your_user_name</strong>.github.io.git<br>  branch: master</p></blockquote><p>然后在Git Bash中运行：</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>hexo d -g</span><br></pre></td></tr></table></figure><p>系统将生成静态页面，并部署到GitHub服务器上</p></li><li><p>验证结果<br>访问<a href="**your_user_name**.github.io"><strong>your_user_name</strong>.github.io</a>，正常显示网页则表明部署成功。<br>至此，一个新的Blog搭建完成。后续再逐步介绍如何编写文章、更换主题、进行个性化配置和添加插件等。</p></li></ol><p>谢谢收看。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;第一篇肯定是关于如何搭建一个基于&lt;a href=&quot;https://github.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub&lt;/a&gt;的Blog。&lt;br&gt;主要的过程都是通过网络搜索获得，使用的主题也是简单挑选的一个Hexo主题&lt;a hr</summary>
      
    
    
    
    
    <category term="GitHub" scheme="http://gloomymoon.github.io/tags/GitHub/"/>
    
    <category term="nodejs" scheme="http://gloomymoon.github.io/tags/nodejs/"/>
    
    <category term="Hexo" scheme="http://gloomymoon.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://gloomymoon.github.io/2016/10/16/hello-world/"/>
    <id>http://gloomymoon.github.io/2016/10/16/hello-world/</id>
    <published>2016-10-16T14:51:00.000Z</published>
    <updated>2021-12-17T13:39:47.207Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.</summary>
      
    
    
    
    
  </entry>
  
</feed>
