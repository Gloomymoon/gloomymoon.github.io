<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
          Python Machine Learning IV - Master Gloomymoon&#39;s R2D2
        
    </title>

    <link rel="canonical" href="http://gloomymoon.github.io/2017/01/25/Python-Machine-Learning-IV/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/hux-blog.css">

    <!-- Pygments Highlight CSS -->
    <link rel="stylesheet" href="/css/highlight.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link rel="stylesheet" href="/css/font-awesome.min.css">
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Gloomymoon</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/archives/">Archives</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">Tags</a>
                        </li>
                        
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    
<!-- Image to hack wechat -->
<!-- <img src="http://gloomymoon.github.io/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="{{ site.baseurl }}/{% if page.header-img %}{{ page.header-img }}{% else %}{{ site.header-img }}{% endif %}" width="0" height="0"> -->

<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        background-image: url('/img/lego-star-wars-war-all-about-pokeman101.png')
    }
</style>
<header class="intro-header" >
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                          <a class="tag" href="/tags/#Python" title="Python">Python</a>
                        
                          <a class="tag" href="/tags/#Machine Learning" title="Machine Learning">Machine Learning</a>
                        
                          <a class="tag" href="/tags/#scikit-learn" title="scikit-learn">scikit-learn</a>
                        
                    </div>
                    <h1>Python Machine Learning IV</h1>
                    <h2 class="subheading"></h2>
                    <span class="meta">
                        Posted by Gloomymoon on
                        2017-01-25
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <h2 id="4-Building-Good-Training-Sets-–-Data-Preprocessing"><a href="#4-Building-Good-Training-Sets-–-Data-Preprocessing" class="headerlink" title="4 Building Good Training Sets – Data Preprocessing"></a>4 Building Good Training Sets – Data Preprocessing</h2><p>数据的质量和有效信息含量直接决定了机器学习算法能够学得多好。因此在建模前绝对应当对数据进行细查和预处理。本章节将介绍构建模型前必须要具备的数据预处理技术。</p>
<ul>
<li>清除或插补缺失值</li>
<li>将分类数据塑形成模型可用的形式</li>
<li>为模型构建选择相关的特征变量</li>
</ul>
<h3 id="Dealing-with-missing-data"><a href="#Dealing-with-missing-data" class="headerlink" title="Dealing with missing data"></a>Dealing with missing data</h3><p>我们通常将缺失值视为空格或者<code>NaN</code>。不幸的是，很多计算工具无法处理这类缺失值或者会产生无法预测的结果，因此在进一步分析前需要预先处理这类缺失值。讨论这些方法前我们先来创建一个简单的样例数据，这是一个CSV（comma-separated values）文件。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">from</span> io <span class="keyword">import</span> StringIO</div><div class="line">csv_data = <span class="string">'''A,B,C,D</span></div><div class="line">    1.0,2.0,3.,4.0</div><div class="line">    5.0,6.0,,8.0</div><div class="line">    0.0,11.0,12.0,'''</div><div class="line">csv_data = unicode(csv_data)</div><div class="line">df = pd.read_csv(StringIO(csv_data))</div><div class="line">df</div></pre></td></tr></table></figure></p>
<p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">A	B	C	D</div><div class="line"><span class="number">0</span>	<span class="number">1</span>	<span class="number">2</span>	<span class="number">3</span>	<span class="number">4</span></div><div class="line"><span class="number">1</span>	<span class="number">5</span>	<span class="number">6</span>	NaN	<span class="number">8</span></div><div class="line"><span class="number">2</span>	<span class="number">0</span>	<span class="number">11</span>	<span class="number">12</span>	NaN</div></pre></td></tr></table></figure></p>
<p>从输出结果看到我们从CSV格式的数据读入到DataFrame对象后，缺失值被替换为<code>NaN</code>。如果使用Python3，则无需使用unicode函数。对于更大的DataFrame，可以使用<code>insnull</code>方法查看每个单元是否含有数值类型的值，然后用<code>sum</code>方法统计缺失的数量。<br><figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">df</span><span class="selector-class">.isnull</span>()<span class="selector-class">.sum</span>()</div></pre></td></tr></table></figure></p>
<p>Output:<br><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">A    <span class="number">0</span></div><div class="line">B    <span class="number">0</span></div><div class="line"><span class="keyword">C</span>    <span class="number">1</span></div><div class="line"><span class="keyword">D</span>    <span class="number">1</span></div><div class="line">dtype: int64</div></pre></td></tr></table></figure></p>
<blockquote>
<p>scikit-learn是基于NumPy开发的，有时候用DataFrame处理数据更加便利，因此我们可以通过DataFrame的<code>values</code>方法获取NumPy数组类型的的数据，并将它喂给scikit-learn的算法。</p>
</blockquote>
<p><strong>Eliminating samples or features with missing values</strong><br>最简单的缺失处理方法是扔掉对应的特征（列）或样本（行）。列和行可以方便地通过<code>dropna</code>方法剔除掉。<br><figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">df</span><span class="selector-class">.dropna</span>()</div><div class="line"><span class="selector-tag">df</span><span class="selector-class">.dropna</span>(axis=<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">	A	B	C	D</div><div class="line"><span class="number">0</span>	<span class="number">1</span>	<span class="number">2</span>	<span class="number">3</span>	<span class="number">4</span></div><div class="line"></div><div class="line">	A	B</div><div class="line"><span class="number">0</span>	<span class="number">1</span>	<span class="number">2</span></div><div class="line"><span class="number">1</span>	<span class="number">5</span>	<span class="number">6</span></div><div class="line"><span class="number">2</span>	<span class="number">0</span>	<span class="number">11</span></div></pre></td></tr></table></figure></p>
<p><code>dropna</code>方法还有一些额外的参数可以实现更加灵活的剔除逻辑。<br><figure class="highlight vala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="meta"># 仅剔除所有特征都为NaN的记录</span></div><div class="line">df.dropna(how=<span class="string">'all'</span>)</div><div class="line"></div><div class="line"><span class="meta"># 仅剔除至少有4个特征为NaN的记录</span></div><div class="line">df.dropna(thresh=<span class="number">4</span>)</div><div class="line"></div><div class="line"><span class="meta"># 仅剔除特定列（这里是C）是NaN的记录</span></div><div class="line">df.dropna(subset=[<span class="string">'C'</span>])</div></pre></td></tr></table></figure></p>
<p>剔除缺失数据简单，但是可能会丢失过多的样本或者太多特征变量，损失对分类算法来说有用的信息。</p>
<p><strong>Imputing missing values</strong><br>通过其他样本的数据来对缺失值应用各种插补技术，是另外一种处理方式。一个最常用的方式是使用均值插补，scikit-learn的<code>Imputer</code>类可以方便地实现这类工作。<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">from sklearn.preprocessing <span class="built_in">import</span> Imputer</div><div class="line"><span class="attr">imr</span> = Imputer(<span class="attr">missing_values='NaN',</span> <span class="attr">strategy='mean',</span> <span class="attr">axis=0)</span></div><div class="line"><span class="attr">imr</span> = imr.fit(df)</div><div class="line"><span class="attr">imputed_data</span> = imr.transform(df.values)</div><div class="line">imputed_data</div></pre></td></tr></table></figure></p>
<p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">array([[  <span class="number">1.</span> ,   <span class="number">2.</span> ,   <span class="number">3.</span> ,   <span class="number">4.</span> ],</div><div class="line">       [  <span class="number">5.</span> ,   <span class="number">6.</span> ,   <span class="number">7.5</span>,   <span class="number">8.</span> ],</div><div class="line">       [  <span class="number">0.</span> ,  <span class="number">11.</span> ,  <span class="number">12.</span> ,   <span class="number">6.</span> ]])</div></pre></td></tr></table></figure></p>
<p>该例子中将缺失值<code>NaN</code>替换为每列的平均值，如果将参数<code>axis=0</code>改为<code>axis=1</code>，将替换为行的平均值。<code>strategy</code>参数其他选项还有<code>median</code>和<code>most_frequent</code>，表示中值和最常出现的值。</p>
<p><strong>Understanding the scikit-learn estimator API</strong><br><code>Imputer</code>类在scikit-learn中属于transformer类，主要用来对数据进行各种变形，通常包含两个重要的方法<code>fit</code>和<code>transform</code>。<code>fit</code>方法用来在训练集上学习参数，然后通过<code>transform</code>方法和参数对训练数据集进行转换。被转换的数据集必须与学习的数据集具有相同的特征变量数，下图展现了学习参数并应用于新数据集的转化过程。<br><img src="/img/PythonMachineLearningIV_01.png" alt=""></p>
<h3 id="Handling-categorical-data"><a href="#Handling-categorical-data" class="headerlink" title="Handling categorical data"></a>Handling categorical data</h3><p>至此，我们处理的都是数值类型特征，但在真实数据世界中存在各种分类（categorical）特征数据。分类数据可以分为有序的（ordinal）和无序的（nominal），有序的特征例如T恤衫的尺寸，因为根据定义XL大于L大于M。无序的特征比如T恤衫的颜色，颜色之间的大小排序没有现实意义。<br>同样我们先来创建一个样例数据集。<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">import pandas as pd</div><div class="line">df = pd.<span class="symbol">DataFrame</span>([</div><div class="line">        [<span class="string">'green'</span>, <span class="string">'M'</span>, <span class="number">10.1</span>, <span class="string">'class1'</span>],</div><div class="line">        [<span class="string">'red'</span>, <span class="string">'L'</span>, <span class="number">13.5</span>, <span class="string">'class2'</span>],</div><div class="line">        [<span class="string">'blue'</span>, <span class="string">'XL'</span>, <span class="number">15.3</span>, <span class="string">'class1'</span>]</div><div class="line">    ])</div><div class="line">df.columns=[<span class="string">'color'</span>, <span class="string">'size'</span>, <span class="string">'price'</span>, <span class="string">'classlabel'</span>]</div><div class="line">df</div></pre></td></tr></table></figure></p>
<p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">	color	size	price	classlabel</div><div class="line"><span class="number">0</span>	green	M	<span class="number">10.1</span>	class1</div><div class="line"><span class="number">1</span>	red	L	<span class="number">13.5</span>	class2</div><div class="line"><span class="number">2</span>	blue	XL	<span class="number">15.3</span>	class1</div></pre></td></tr></table></figure></p>
<p>该数据中包含一个无序分类特征（颜色），一个有序分类特征（尺寸），一个数值特征（价格），和一个分类标识。本书中讨论的分类算法都无视分类标识中的大小和优先关系。</p>
<p><strong>Mapping ordinal features</strong><br>我们必须手工定义有序分类特征到整形的映射逻辑关系，假设我们知道特征之间的区别关系，如：XL=L+1=M+2<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">size_mapping = &#123;<span class="string">'XL'</span>: <span class="number">3</span>,</div><div class="line">                <span class="string">'L'</span>: <span class="number">2</span>,</div><div class="line">                <span class="string">'M'</span>: <span class="number">1</span>&#125;</div><div class="line">df[<span class="string">'size'</span>] = df[<span class="string">'size'</span>].map(size_mapping)</div><div class="line">df</div></pre></td></tr></table></figure></p>
<p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">	color	size	price	classlabel</div><div class="line"><span class="number">0</span>	green	<span class="number">1</span>	<span class="number">10.1</span>	class1</div><div class="line"><span class="number">1</span>	red	<span class="number">2</span>	<span class="number">13.5</span>	class2</div><div class="line"><span class="number">2</span>	blue	<span class="number">3</span>	<span class="number">15.3</span>	class1</div></pre></td></tr></table></figure></p>
<p>如果需要将整型转会原始的字符串，可以定义逆映射<code>inv_size_mapping = {v:k for k, v in size_mapping.items()}</code>，然后同样适用<code>map</code>方法做一次转换。</p>
<p><strong>Encoding class labels</strong><br>许多机器学习库都要求分类标识必须使用整型数值，我们可以使用类似于对有序分类特征映射的方法对分类标签进行转换，由于分类标识之间没有优先关系，所以具体数值大小无关紧要，我们可以简单从0开始枚举。<br><figure class="highlight ceylon"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy as np</div><div class="line"><span class="keyword">class</span><span class="number">_m</span>apping = &#123;label:idx <span class="keyword">for</span> idx, label <span class="keyword">in</span> enumerate(np.unique(df[<span class="string">'classlabel'</span>]))&#125;</div><div class="line"><span class="keyword">class</span><span class="number">_m</span>apping</div><div class="line">df[<span class="string">'classlabel'</span>] = df[<span class="string">'classlabel'</span>].map(<span class="keyword">class</span><span class="number">_m</span>apping)</div><div class="line">df</div></pre></td></tr></table></figure></p>
<p>Output:<br><figure class="highlight processing"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&#123;<span class="string">'class1'</span>: <span class="number">0</span>, <span class="string">'class2'</span>: <span class="number">1</span>&#125;</div><div class="line"></div><div class="line">	<span class="built_in">color</span>	<span class="built_in">size</span>	price	classlabel</div><div class="line"><span class="number">0</span>	<span class="built_in">green</span>	<span class="number">1</span>	<span class="number">10.1</span>	<span class="number">0</span></div><div class="line"><span class="number">1</span>	<span class="built_in">red</span>	<span class="number">2</span>	<span class="number">13.5</span>	<span class="number">1</span></div><div class="line"><span class="number">2</span>	<span class="built_in">blue</span>	<span class="number">3</span>	<span class="number">15.3</span>	<span class="number">0</span></div></pre></td></tr></table></figure></p>
<p>scikit-learn直接实现了一个更方便的LabelEncoder类可以直接实现上述功能。<br><figure class="highlight ceylon"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">inv<span class="number">_</span><span class="keyword">class</span><span class="number">_m</span>apping = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="keyword">class</span><span class="number">_m</span>apping.items()&#125;</div><div class="line">df[<span class="string">'classlabel'</span>] = df[<span class="string">'classlabel'</span>].map(inv<span class="number">_</span><span class="keyword">class</span><span class="number">_m</span>apping)</div><div class="line">from sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</div><div class="line"><span class="keyword">class</span><span class="number">_</span>le = LabelEncoder()</div><div class="line">y = <span class="keyword">class</span><span class="number">_</span>le.fit<span class="number">_</span>transform(df[<span class="string">'classlabel'</span>].values)</div><div class="line">y</div></pre></td></tr></table></figure></p>
<p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</div></pre></td></tr></table></figure></p>
<p><code>fit_transform</code>是调用<code>fit</code>和<code>transform</code>的快捷方式，另外还可以直接使用<code>inverse_transform</code>进行逆向转换。<br><figure class="highlight ceylon"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span><span class="number">_</span>le.inverse<span class="number">_</span>transform(y)</div></pre></td></tr></table></figure></p>
<p><strong>Performing ont-hot encoding on nominal features</strong><br>可以使用同样的技术对无序分类特征转换成整型，例如：blue -&gt; 0, green -&gt; 1, red -&gt; 2，机器学习算法会假设绿色大于蓝色，红色大于绿色，尽管这个假设并不正确，但是仍然可以得出一些有用的结果（当然不是最优的）。<br>一个常用的解决是独热编码（one-hot encoding），通过给变量的每一个可能取值都创建一个独立的哑变量（dummy feature）。本例中，可以将颜色特征转换成三个新的变量：blue, green, red，每个变量都通过二元标识来表示对应的颜色取值情况，比如蓝色样本的变量取值为：blue=1, green=0, red=0。scikit-learn.preprocessing模块中的OneHotEncoder实现了该类转换功能.<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="symbol">X</span> = df[[<span class="string">'color'</span>, <span class="string">'size'</span>, <span class="string">'price'</span>]].values</div><div class="line">color_le = <span class="symbol">LabelEncoder</span>()</div><div class="line"><span class="symbol">X</span>[:, <span class="number">0</span>] = color_le.fit_transform(<span class="symbol">X</span>[:, <span class="number">0</span>])</div><div class="line">from sklearn.preprocessing import <span class="symbol">OneHotEncoder</span></div><div class="line">ohe = <span class="symbol">OneHotEncoder</span>(categorical_features=[<span class="number">0</span>])</div><div class="line">ohe.fit_transform(<span class="symbol">X</span>).toarray()</div></pre></td></tr></table></figure></p>
<p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">array([[  <span class="number">0.</span> ,   <span class="number">1.</span> ,   <span class="number">0.</span> ,   <span class="number">1.</span> ,  <span class="number">10.1</span>],</div><div class="line">       [  <span class="number">0.</span> ,   <span class="number">0.</span> ,   <span class="number">1.</span> ,   <span class="number">2.</span> ,  <span class="number">13.5</span>],</div><div class="line">       [  <span class="number">1.</span> ,   <span class="number">0.</span> ,   <span class="number">0.</span> ,   <span class="number">3.</span> ,  <span class="number">15.3</span>]])</div></pre></td></tr></table></figure></p>
<p>DataFrame甚至有一个更加简单的<code>get_dummies</code>方法可以直接将字符类型变量转换成哑变量。<br><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pd.get_dummies(df<span class="string">[['price', 'color', 'size']]</span>)</div></pre></td></tr></table></figure></p>
<p>Output:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">	price	size	color_blue	color_green	color_red</div><div class="line"><span class="number">0</span>	<span class="number">10.1</span>	<span class="number">1</span>	<span class="number">0.0</span>	<span class="number">1.0</span>	<span class="number">0.0</span></div><div class="line"><span class="number">1</span>	<span class="number">13.5</span>	<span class="number">2</span>	<span class="number">0.0</span>	<span class="number">0.0</span>	<span class="number">1.0</span></div><div class="line"><span class="number">2</span>	<span class="number">15.3</span>	<span class="number">3</span>	<span class="number">1.0</span>	<span class="number">0.0</span>	<span class="number">0.0</span></div></pre></td></tr></table></figure></p>
<h3 id="Partioning-a-dataset-in-training-and-test-sets"><a href="#Partioning-a-dataset-in-training-and-test-sets" class="headerlink" title="Partioning a dataset in training and test sets"></a>Partioning a dataset in training and test sets</h3><p>第一章和第三章都介绍过将建模数据切分为训练集和测试集的概念，本节我们将引入一个新的数据集，通过数据预处理学习几种特征选择的降维技术。</p>
<p>新数据是由<a href="https://archive.ics.uci.edu/ml/datasets/Wine" target="_blank" rel="external">UCI</a>提供的葡萄酒数据，其包含了178个酒品样本和13个描述化学属性的特征变量，通过pandas我们可以直接从互联网都如该数据。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">df_wine = pd.read_csv(<span class="string">'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'</span>, header=None)</div><div class="line">df_wine<span class="selector-class">.columns</span> = [<span class="string">'Class label'</span>, <span class="string">'Alcohol'</span>, <span class="string">'Malic acid'</span>, <span class="string">'Ash'</span>,</div><div class="line">                   <span class="string">'Alcalinity of ash'</span>, <span class="string">'Magnesium'</span>, <span class="string">'Total phenols'</span>, <span class="string">'Flavanoids'</span>,</div><div class="line">                   <span class="string">'Nonflavanoid phenols'</span>, <span class="string">'Proanthocyanins'</span>, <span class="string">'Color intensity'</span>, <span class="string">'Hue'</span>,</div><div class="line">                   <span class="string">'OD280/OD315 of diluted wines'</span>, <span class="string">'Proline'</span>]</div><div class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Class labels'</span>, np.unique(df_wine[<span class="string">'Class label'</span>])</span></span>)</div><div class="line">df_wine.head()</div></pre></td></tr></table></figure></p>
<p>Output:</p>
<figure class="highlight clojure"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(<span class="name">'Class</span> labels', array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=int64))</div></pre></td></tr></table></figure>
<p>样本包含3个分类，1、2和3，对应意大利不同区域种植的三种不同的葡萄。<br>通过cross_validation模块的<code>train_test_split</code>方法可以将数据随机分到测试集和训练集。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">from sklearn<span class="selector-class">.cross_validation</span> import train_test_split</div><div class="line">X, y = df_wine<span class="selector-class">.iloc</span>[:, <span class="number">1</span>:]<span class="selector-class">.values</span>, df_wine<span class="selector-class">.iloc</span>[:, <span class="number">0</span>]<span class="selector-class">.values</span></div><div class="line">X_train, X_test, y_train, y_test = \</div><div class="line">    train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)</div></pre></td></tr></table></figure>
<h3 id="Bringing-features-onto-the-same-scale"><a href="#Bringing-features-onto-the-same-scale" class="headerlink" title="Bringing features onto the same scale"></a>Bringing features onto the same scale</h3><p>特征归一化（feature scaling）是预处理前容易被忽略的重要步骤，除了决策树和随机森林等少数几类算法，将特征变量映射到统一尺度下有助于大多数机器学习算法和调优，通常来说主要有两种方法：归一化（normalization）和标准化（standardization）。归一化指将特征重新映射到[0, 1]的范围，这是一种最大最小归一化的特殊情况（min-max scaling）。每个样本的特征值xi可以按照下述公式得到新值：x’ = (x - min(x))/(max(x)-min(x))。scikit-learn中可以直接使用MinMaxScaler实现。</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">from sklearn.preprocessing <span class="built_in">import</span> MinMaxScaler</div><div class="line"><span class="attr">mms</span> = MinMaxScaler()</div><div class="line"><span class="attr">X_train_norm</span> = mms.fit_transform(X_train)</div><div class="line"><span class="attr">X_test_norm</span> = mms.transform(X_test)</div></pre></td></tr></table></figure>
<p>实际中标准化比归一化更加常用，因为许多线性模型（如逻辑回归和SBM）的权重初始值会设置为0或者接近0的小随机数，变量经过标准化后形成正态分布，均值为0，标准差为1，标准化还能够保留离群值（outliers）信息，但又不会影响算法。标准化常用的方法如下：<br><img src="/img/PythonMachineLearningIV_02.png" alt=""></p>
<p>其中µ 是样本均值，σ 是标准差。</p>
<p>下表展示了同一个变量经过归一化和标准化之后的结果：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">input</span> <span class="selector-tag">standardized</span> <span class="selector-tag">normalized</span></div><div class="line">0<span class="selector-class">.0</span> <span class="selector-tag">-1</span><span class="selector-class">.336306</span> 0<span class="selector-class">.0</span></div><div class="line">1<span class="selector-class">.0</span> <span class="selector-tag">-0</span><span class="selector-class">.801784</span> 0<span class="selector-class">.2</span></div><div class="line">2<span class="selector-class">.0</span> <span class="selector-tag">-0</span><span class="selector-class">.267261</span> 0<span class="selector-class">.4</span></div><div class="line">3<span class="selector-class">.0</span> 0<span class="selector-class">.267261</span> 0<span class="selector-class">.6</span></div><div class="line">4<span class="selector-class">.0</span> 0<span class="selector-class">.801784</span> 0<span class="selector-class">.8</span></div><div class="line">5<span class="selector-class">.0</span> 1<span class="selector-class">.336306</span> 1<span class="selector-class">.0</span></div></pre></td></tr></table></figure>
<p>scikit-learn同样实现了标准化的类：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">from sklearn.preprocessing <span class="built_in">import</span> StandardScaler</div><div class="line"><span class="attr">stdsc</span> = StandardScaler()</div><div class="line"><span class="attr">X_train_std</span> = stdsc.fit_transform(X_train)</div><div class="line"><span class="attr">X_test_std</span> = stdsc.transform(X_test)</div><div class="line">X_test_std</div></pre></td></tr></table></figure>
<p>注意StandardScaler只训练一次，然后用来后续的所有测试和验证数据集。</p>
<blockquote>
<p>更加细节内容可以参照：<a href="http://www.zhaokv.com/2016/01/normalization-and-standardization.html" target="_blank" rel="external">http://www.zhaokv.com/2016/01/normalization-and-standardization.html</a></p>
</blockquote>
<h3 id="Selecting-meaningful-features"><a href="#Selecting-meaningful-features" class="headerlink" title="Selecting meaningful features"></a>Selecting meaningful features</h3><p>如果一个模型在训练集上的表现明显优于测试集，则意味着过拟合，也称为高方差（variance），通常是模型过于复杂造成。解决方案如下：</p>
<ul>
<li><p>收集更多训练数据</p>
</li>
<li><p>进入针对复杂程度的惩罚系数，例如之前介绍的正则化方法</p>
</li>
<li><p>选择一个参数更少的简单模型</p>
</li>
<li><p>对建模数据进行降维</p>
<p>收集更多数据通常受到实际限制，本节将介绍正则化和变量选择降维技术来降低过拟合。</p>
<p><strong>Sparse solutions with L1 regularization</strong></p>
<p>第三章中介绍L2 regularization是一种降低模型复杂程度的方法，L1 regularization则是另一种。对于scikit-learn中支持L1 regularization的模型，可以简单的添加<code>penalty</code>参数并设置为`’l1’。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">from sklearn<span class="selector-class">.linear_model</span> import LogisticRegression</div><div class="line">lr = LogisticRegression(penalty=<span class="string">'l1'</span>, C=<span class="number">0.1</span>)</div><div class="line">lr.fit(X_train_std, y_train)</div><div class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Training accuracy:'</span>, lr.score(X_train_std, y_train)</span></span>)</div><div class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Test accuracy:'</span>, lr.score(X_test_std, y_test)</span></span>)</div></pre></td></tr></table></figure>
<p>Output:</p>
<figure class="highlight subunit"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Training accuracy: 0.983870967742</div><div class="line"><span class="keyword">Test </span>accuracy: 0.981481481481</div></pre></td></tr></table></figure>
<p>​</p>
</li>
</ul>


                <hr>

                

                <ul class="pager">
                    
                        <li class="previous">
                            <a href="/2017/03/15/Bit-City/" data-toggle="tooltip" data-placement="top" title="Bit City">&larr; Previous Post</a>
                        </li>
                    
                    
                        <li class="next">
                            <a href="/2017/01/21/Python-Machine-Learning-III/" data-toggle="tooltip" data-placement="top" title="Python Machine Learning III">Next Post &rarr;</a>
                        </li>
                    
                </ul>

                

                

            </div>
    <!-- Side Catalog Container -->
        

    <!-- Sidebar Container -->

            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                          <a class="tag" href="/tags/#Python" title="Python">Python</a>
                        
                          <a class="tag" href="/tags/#Machine Learning" title="Machine Learning">Machine Learning</a>
                        
                          <a class="tag" href="/tags/#scikit-learn" title="scikit-learn">scikit-learn</a>
                        
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
            </div>

        </div>
    </div>
</article>







<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'always',
          placement: 'right',
          icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                
                
                

                

                

                
                    <li>
                        <a target="_blank"  href="https://github.com/Gloomymoon">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; Gloomymoon 2017
                    <br>
                    Theme by <a href="http://huangxuan.me">Hux</a>
                    <span style="display: inline-block; margin: 0 5px;">
                        <i class="fa fa-heart"></i>
                    </span>
                    Ported by <a href="http://blog.kaijun.rocks">Kaijun</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=kaijun&repo=hexo-theme-huxblog&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!--
     Because of the native support for backtick-style fenced code blocks
     right within the Markdown is landed in Github Pages,
     From V1.6, There is no need for Highlight.js,
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("http://gloomymoon.github.io/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->




<!-- Baidu Tongji -->


<!-- Side Catalog -->




<!-- Image to hack wechat -->
<img src="http://gloomymoon.github.io/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
